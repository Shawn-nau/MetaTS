{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import os, sys, gc, time, warnings, pickle, random\n",
    "\n",
    "from tsfmeta.data import MetaDataset,RawData, Md_utils,temporal_signal_split\n",
    "from tsfmeta import utils\n",
    "from tsfmeta import nn as MetaNN\n",
    "from tsfmeta.experiments import meta_learning_run\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TurbID</th>\n",
       "      <th>Day</th>\n",
       "      <th>Tmstamp</th>\n",
       "      <th>Wspd</th>\n",
       "      <th>Wdir</th>\n",
       "      <th>Etmp</th>\n",
       "      <th>Itmp</th>\n",
       "      <th>Ndir</th>\n",
       "      <th>Pab1</th>\n",
       "      <th>Pab2</th>\n",
       "      <th>Pab3</th>\n",
       "      <th>Prtv</th>\n",
       "      <th>Patv</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>00:00</td>\n",
       "      <td>12.23</td>\n",
       "      <td>-0.83</td>\n",
       "      <td>29.08</td>\n",
       "      <td>41.90</td>\n",
       "      <td>-23.73</td>\n",
       "      <td>1.07</td>\n",
       "      <td>1.07</td>\n",
       "      <td>1.07</td>\n",
       "      <td>-0.21</td>\n",
       "      <td>1549.53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>00:10</td>\n",
       "      <td>11.58</td>\n",
       "      <td>-3.32</td>\n",
       "      <td>29.01</td>\n",
       "      <td>42.01</td>\n",
       "      <td>-23.70</td>\n",
       "      <td>1.06</td>\n",
       "      <td>1.06</td>\n",
       "      <td>1.06</td>\n",
       "      <td>-0.25</td>\n",
       "      <td>1549.71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>00:20</td>\n",
       "      <td>11.21</td>\n",
       "      <td>-1.38</td>\n",
       "      <td>29.17</td>\n",
       "      <td>42.24</td>\n",
       "      <td>-28.84</td>\n",
       "      <td>1.04</td>\n",
       "      <td>1.04</td>\n",
       "      <td>1.04</td>\n",
       "      <td>-0.25</td>\n",
       "      <td>1534.77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>00:30</td>\n",
       "      <td>10.84</td>\n",
       "      <td>0.06</td>\n",
       "      <td>29.46</td>\n",
       "      <td>42.43</td>\n",
       "      <td>-31.39</td>\n",
       "      <td>1.03</td>\n",
       "      <td>1.03</td>\n",
       "      <td>1.03</td>\n",
       "      <td>-0.25</td>\n",
       "      <td>1508.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>00:40</td>\n",
       "      <td>11.03</td>\n",
       "      <td>2.03</td>\n",
       "      <td>29.82</td>\n",
       "      <td>42.77</td>\n",
       "      <td>-31.39</td>\n",
       "      <td>1.03</td>\n",
       "      <td>1.03</td>\n",
       "      <td>1.03</td>\n",
       "      <td>-66.01</td>\n",
       "      <td>1517.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3550459</th>\n",
       "      <td>134</td>\n",
       "      <td>184</td>\n",
       "      <td>23:10</td>\n",
       "      <td>2.36</td>\n",
       "      <td>-74.19</td>\n",
       "      <td>7.30</td>\n",
       "      <td>11.70</td>\n",
       "      <td>238.59</td>\n",
       "      <td>90.39</td>\n",
       "      <td>90.37</td>\n",
       "      <td>90.36</td>\n",
       "      <td>-0.30</td>\n",
       "      <td>-0.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3550460</th>\n",
       "      <td>134</td>\n",
       "      <td>184</td>\n",
       "      <td>23:20</td>\n",
       "      <td>1.72</td>\n",
       "      <td>-67.92</td>\n",
       "      <td>7.21</td>\n",
       "      <td>11.70</td>\n",
       "      <td>238.59</td>\n",
       "      <td>90.39</td>\n",
       "      <td>90.37</td>\n",
       "      <td>90.36</td>\n",
       "      <td>-0.30</td>\n",
       "      <td>-0.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3550461</th>\n",
       "      <td>134</td>\n",
       "      <td>184</td>\n",
       "      <td>23:30</td>\n",
       "      <td>1.46</td>\n",
       "      <td>-59.15</td>\n",
       "      <td>7.10</td>\n",
       "      <td>11.70</td>\n",
       "      <td>238.59</td>\n",
       "      <td>90.39</td>\n",
       "      <td>90.37</td>\n",
       "      <td>90.36</td>\n",
       "      <td>-0.30</td>\n",
       "      <td>-0.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3550462</th>\n",
       "      <td>134</td>\n",
       "      <td>184</td>\n",
       "      <td>23:40</td>\n",
       "      <td>1.31</td>\n",
       "      <td>-64.11</td>\n",
       "      <td>7.10</td>\n",
       "      <td>11.70</td>\n",
       "      <td>238.59</td>\n",
       "      <td>90.39</td>\n",
       "      <td>90.37</td>\n",
       "      <td>90.36</td>\n",
       "      <td>-0.30</td>\n",
       "      <td>-0.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3550463</th>\n",
       "      <td>134</td>\n",
       "      <td>184</td>\n",
       "      <td>23:50</td>\n",
       "      <td>1.23</td>\n",
       "      <td>-72.49</td>\n",
       "      <td>7.10</td>\n",
       "      <td>11.80</td>\n",
       "      <td>238.59</td>\n",
       "      <td>90.39</td>\n",
       "      <td>90.37</td>\n",
       "      <td>90.36</td>\n",
       "      <td>-0.30</td>\n",
       "      <td>-0.30</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3550464 rows Ã— 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         TurbID  Day Tmstamp   Wspd   Wdir   Etmp   Itmp    Ndir   Pab1  \\\n",
       "0             1    1   00:00  12.23  -0.83  29.08  41.90  -23.73   1.07   \n",
       "1             1    1   00:10  11.58  -3.32  29.01  42.01  -23.70   1.06   \n",
       "2             1    1   00:20  11.21  -1.38  29.17  42.24  -28.84   1.04   \n",
       "3             1    1   00:30  10.84   0.06  29.46  42.43  -31.39   1.03   \n",
       "4             1    1   00:40  11.03   2.03  29.82  42.77  -31.39   1.03   \n",
       "...         ...  ...     ...    ...    ...    ...    ...     ...    ...   \n",
       "3550459     134  184   23:10   2.36 -74.19   7.30  11.70  238.59  90.39   \n",
       "3550460     134  184   23:20   1.72 -67.92   7.21  11.70  238.59  90.39   \n",
       "3550461     134  184   23:30   1.46 -59.15   7.10  11.70  238.59  90.39   \n",
       "3550462     134  184   23:40   1.31 -64.11   7.10  11.70  238.59  90.39   \n",
       "3550463     134  184   23:50   1.23 -72.49   7.10  11.80  238.59  90.39   \n",
       "\n",
       "          Pab2   Pab3   Prtv     Patv  \n",
       "0         1.07   1.07  -0.21  1549.53  \n",
       "1         1.06   1.06  -0.25  1549.71  \n",
       "2         1.04   1.04  -0.25  1534.77  \n",
       "3         1.03   1.03  -0.25  1508.20  \n",
       "4         1.03   1.03 -66.01  1517.76  \n",
       "...        ...    ...    ...      ...  \n",
       "3550459  90.37  90.36  -0.30    -0.30  \n",
       "3550460  90.37  90.36  -0.30    -0.30  \n",
       "3550461  90.37  90.36  -0.30    -0.30  \n",
       "3550462  90.37  90.36  -0.30    -0.30  \n",
       "3550463  90.37  90.36  -0.30    -0.30  \n",
       "\n",
       "[3550464 rows x 13 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "dir_ = 'E:/Datasets/KDD2022/' # input only here\n",
    "sdwpf = pd.read_csv(dir_+'sdwpf_baidukddcup2022_full.CSV')\n",
    "sdwpf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "location = pd.read_csv(dir_+'sdwpf_baidukddcup2022_turb_location.CSV')\n",
    "location_max = location[['x','y']].max()\n",
    "location[['x','y']] = location[['x','y']]/location_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sdwpf.loc[sdwpf['Patv'] < 0, 'Patv'] = 0\n",
    "sdwpf = sdwpf.groupby(['TurbID','Day']).mean().reset_index()\n",
    "sdwpf = sdwpf.merge(location,on = 'TurbID')\n",
    "#sdwpf['TurbID_feature'] =  sdwpf['TurbID']  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "target =['Patv']\n",
    "features_num = ['Wspd','Wdir','Etmp','Itmp','Pab1','Pab2','Pab3','Prtv','x','y'] ## target should be the first\n",
    "features_cat = [] \n",
    "idx = ['TurbID']  \n",
    "tdx = ['Day']\n",
    "dynamic_known_features_num = ['Pab1','Pab2','Pab3']  ## should be part of features_num\n",
    "dynamic_known_features_cat = []   ## should be part of features_cat\n",
    "static_known_features = ['x','y'] ## should be part of known_features_cat\n",
    "\n",
    "df = Md_utils.Df_to_rawdata(df = sdwpf,\n",
    "                   idx = idx,\n",
    "                   tdx = tdx,\n",
    "                   target = target,\n",
    "                   features_num = features_num,\n",
    "                   features_cat= features_cat,\n",
    "                   static_known_features = static_known_features,\n",
    "                   dynamic_known_features_num = dynamic_known_features_num,\n",
    "                   dynamic_known_features_cat = dynamic_known_features_cat,\n",
    "                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Int64Index([ 78,  79,  80,  81,  82,  83,  84,  85,  86,  87,\n",
       "            ...\n",
       "            175, 176, 177, 178, 179, 180, 181, 182, 183, 184],\n",
       "           dtype='int64', name='Day', length=107)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_slots = df.data_segment(W=100, H=7,step=2,nseg = 40)\n",
    "df_slots[3].npdata.shape\n",
    "df_slots[0].time_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(df_slots)):\n",
    "    df_slots[i] = df_slots[i].Raw2Meta(H=7)\n",
    "    #df_slots[i].reduce_mem_usage()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\MSH\\.conda\\envs\\pytorch\\lib\\site-packages\\statsmodels\\tsa\\holtwinters\\model.py:917: ConvergenceWarning: Optimization failed to converge. Check mle_retvals.\n",
      "  ConvergenceWarning,\n",
      "c:\\Users\\MSH\\.conda\\envs\\pytorch\\lib\\site-packages\\statsmodels\\tsa\\holtwinters\\model.py:917: ConvergenceWarning: Optimization failed to converge. Check mle_retvals.\n",
      "  ConvergenceWarning,\n",
      "c:\\Users\\MSH\\.conda\\envs\\pytorch\\lib\\site-packages\\statsmodels\\tsa\\holtwinters\\model.py:917: ConvergenceWarning: Optimization failed to converge. Check mle_retvals.\n",
      "  ConvergenceWarning,\n",
      "c:\\Users\\MSH\\.conda\\envs\\pytorch\\lib\\site-packages\\statsmodels\\tsa\\holtwinters\\model.py:917: ConvergenceWarning: Optimization failed to converge. Check mle_retvals.\n",
      "  ConvergenceWarning,\n",
      "c:\\Users\\MSH\\.conda\\envs\\pytorch\\lib\\site-packages\\statsmodels\\tsa\\holtwinters\\model.py:917: ConvergenceWarning: Optimization failed to converge. Check mle_retvals.\n",
      "  ConvergenceWarning,\n",
      "c:\\Users\\MSH\\.conda\\envs\\pytorch\\lib\\site-packages\\statsmodels\\tsa\\holtwinters\\model.py:917: ConvergenceWarning: Optimization failed to converge. Check mle_retvals.\n",
      "  ConvergenceWarning,\n",
      "c:\\Users\\MSH\\.conda\\envs\\pytorch\\lib\\site-packages\\statsmodels\\tsa\\holtwinters\\model.py:917: ConvergenceWarning: Optimization failed to converge. Check mle_retvals.\n",
      "  ConvergenceWarning,\n",
      "c:\\Users\\MSH\\.conda\\envs\\pytorch\\lib\\site-packages\\statsmodels\\tsa\\holtwinters\\model.py:917: ConvergenceWarning: Optimization failed to converge. Check mle_retvals.\n",
      "  ConvergenceWarning,\n",
      "c:\\Users\\MSH\\.conda\\envs\\pytorch\\lib\\site-packages\\statsmodels\\tsa\\holtwinters\\model.py:917: ConvergenceWarning: Optimization failed to converge. Check mle_retvals.\n",
      "  ConvergenceWarning,\n",
      "c:\\Users\\MSH\\.conda\\envs\\pytorch\\lib\\site-packages\\statsmodels\\tsa\\holtwinters\\model.py:917: ConvergenceWarning: Optimization failed to converge. Check mle_retvals.\n",
      "  ConvergenceWarning,\n",
      "c:\\Users\\MSH\\.conda\\envs\\pytorch\\lib\\site-packages\\statsmodels\\tsa\\holtwinters\\model.py:917: ConvergenceWarning: Optimization failed to converge. Check mle_retvals.\n",
      "  ConvergenceWarning,\n",
      "c:\\Users\\MSH\\.conda\\envs\\pytorch\\lib\\site-packages\\statsmodels\\tsa\\holtwinters\\model.py:917: ConvergenceWarning: Optimization failed to converge. Check mle_retvals.\n",
      "  ConvergenceWarning,\n",
      "c:\\Users\\MSH\\.conda\\envs\\pytorch\\lib\\site-packages\\statsmodels\\tsa\\holtwinters\\model.py:917: ConvergenceWarning: Optimization failed to converge. Check mle_retvals.\n",
      "  ConvergenceWarning,\n"
     ]
    }
   ],
   "source": [
    "# SES example\n",
    "from statsmodels.tsa.holtwinters import SimpleExpSmoothing\n",
    "from random import random\n",
    "\n",
    "for slot in range(len(df_slots)):\n",
    "\n",
    "    Nts,_, T = df_slots[slot].X.shape \n",
    "    _, H = df_slots[slot].Y.shape\n",
    "    model = [SimpleExpSmoothing(df_slots[slot].X[i,0]).fit() for i in range(Nts)]\n",
    "    model_pred = [model[i].predict(T,T + H -1) for i in range(Nts)]\n",
    "    model_pred = np.stack(model_pred,0)\n",
    "    df_slots[slot].add_Base_forecasts(model_pred,'SimpleExpSmoothing')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\MSH\\.conda\\envs\\pytorch\\lib\\site-packages\\statsmodels\\tsa\\holtwinters\\model.py:917: ConvergenceWarning: Optimization failed to converge. Check mle_retvals.\n",
      "  ConvergenceWarning,\n",
      "c:\\Users\\MSH\\.conda\\envs\\pytorch\\lib\\site-packages\\statsmodels\\tsa\\holtwinters\\model.py:917: ConvergenceWarning: Optimization failed to converge. Check mle_retvals.\n",
      "  ConvergenceWarning,\n",
      "c:\\Users\\MSH\\.conda\\envs\\pytorch\\lib\\site-packages\\statsmodels\\tsa\\holtwinters\\model.py:917: ConvergenceWarning: Optimization failed to converge. Check mle_retvals.\n",
      "  ConvergenceWarning,\n",
      "c:\\Users\\MSH\\.conda\\envs\\pytorch\\lib\\site-packages\\statsmodels\\tsa\\holtwinters\\model.py:917: ConvergenceWarning: Optimization failed to converge. Check mle_retvals.\n",
      "  ConvergenceWarning,\n",
      "c:\\Users\\MSH\\.conda\\envs\\pytorch\\lib\\site-packages\\statsmodels\\tsa\\holtwinters\\model.py:917: ConvergenceWarning: Optimization failed to converge. Check mle_retvals.\n",
      "  ConvergenceWarning,\n",
      "c:\\Users\\MSH\\.conda\\envs\\pytorch\\lib\\site-packages\\statsmodels\\tsa\\holtwinters\\model.py:917: ConvergenceWarning: Optimization failed to converge. Check mle_retvals.\n",
      "  ConvergenceWarning,\n"
     ]
    }
   ],
   "source": [
    "# HEWS example\n",
    "from statsmodels.tsa.holtwinters import ExponentialSmoothing\n",
    "from random import random\n",
    "\n",
    "for slot in range(len(df_slots)):\n",
    "\n",
    "    Nts,_, T = df_slots[slot].X.shape \n",
    "    _, H = df_slots[slot].Y.shape\n",
    "    model = [ExponentialSmoothing(df_slots[slot].X[i,0], trend = 'add',damped_trend=True).fit() for i in range(Nts)]\n",
    "    model_pred = [model[i].predict(T,T + H -1) for i in range(Nts)]\n",
    "    model_pred = np.stack(model_pred,0)\n",
    "    df_slots[slot].add_Base_forecasts(model_pred,'ExponentialSmoothing')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003407 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 20021\n",
      "[LightGBM] [Info] Number of data points in the train set: 9219, number of used features: 79\n",
      "[LightGBM] [Info] Start training from score 368.883862\n",
      "Training until validation scores don't improve for 125 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\MSH\\.conda\\envs\\pytorch\\lib\\site-packages\\lightgbm\\engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "c:\\Users\\MSH\\.conda\\envs\\pytorch\\lib\\site-packages\\lightgbm\\engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[30]\ttraining's rmse: 174.179\tvalid_1's rmse: 180.539\n",
      "[60]\ttraining's rmse: 104.966\tvalid_1's rmse: 115.274\n",
      "[90]\ttraining's rmse: 67.5316\tvalid_1's rmse: 82.2701\n",
      "[120]\ttraining's rmse: 47.4168\tvalid_1's rmse: 66.4001\n",
      "[150]\ttraining's rmse: 36.6831\tvalid_1's rmse: 59.2611\n",
      "[180]\ttraining's rmse: 30.4944\tvalid_1's rmse: 55.8302\n",
      "[210]\ttraining's rmse: 26.4782\tvalid_1's rmse: 53.8617\n",
      "[240]\ttraining's rmse: 23.5426\tvalid_1's rmse: 52.6896\n",
      "[270]\ttraining's rmse: 21.2478\tvalid_1's rmse: 51.8422\n",
      "[300]\ttraining's rmse: 19.357\tvalid_1's rmse: 51.2918\n",
      "[330]\ttraining's rmse: 17.744\tvalid_1's rmse: 50.8816\n",
      "[360]\ttraining's rmse: 16.3551\tvalid_1's rmse: 50.5994\n",
      "[390]\ttraining's rmse: 15.1212\tvalid_1's rmse: 50.3869\n",
      "[420]\ttraining's rmse: 14.0062\tvalid_1's rmse: 50.218\n",
      "[450]\ttraining's rmse: 13.0135\tvalid_1's rmse: 50.064\n",
      "[480]\ttraining's rmse: 12.1273\tvalid_1's rmse: 49.9593\n",
      "[510]\ttraining's rmse: 11.3093\tvalid_1's rmse: 49.8426\n",
      "[540]\ttraining's rmse: 10.5645\tvalid_1's rmse: 49.7703\n",
      "[570]\ttraining's rmse: 9.88598\tvalid_1's rmse: 49.7026\n",
      "[600]\ttraining's rmse: 9.27197\tvalid_1's rmse: 49.6743\n",
      "[630]\ttraining's rmse: 8.70353\tvalid_1's rmse: 49.599\n",
      "[660]\ttraining's rmse: 8.1746\tvalid_1's rmse: 49.5649\n",
      "[690]\ttraining's rmse: 7.68021\tvalid_1's rmse: 49.5181\n",
      "[720]\ttraining's rmse: 7.22177\tvalid_1's rmse: 49.4965\n",
      "[750]\ttraining's rmse: 6.79658\tvalid_1's rmse: 49.4667\n",
      "[780]\ttraining's rmse: 6.40357\tvalid_1's rmse: 49.4499\n",
      "[810]\ttraining's rmse: 6.04139\tvalid_1's rmse: 49.4206\n",
      "[840]\ttraining's rmse: 5.70445\tvalid_1's rmse: 49.3899\n",
      "[870]\ttraining's rmse: 5.39133\tvalid_1's rmse: 49.3745\n",
      "[900]\ttraining's rmse: 5.09236\tvalid_1's rmse: 49.3452\n",
      "[930]\ttraining's rmse: 4.81567\tvalid_1's rmse: 49.3235\n",
      "[960]\ttraining's rmse: 4.55921\tvalid_1's rmse: 49.3111\n",
      "[990]\ttraining's rmse: 4.31707\tvalid_1's rmse: 49.3066\n",
      "[1020]\ttraining's rmse: 4.08871\tvalid_1's rmse: 49.2965\n",
      "[1050]\ttraining's rmse: 3.87625\tvalid_1's rmse: 49.2839\n",
      "[1080]\ttraining's rmse: 3.6703\tvalid_1's rmse: 49.2695\n",
      "[1110]\ttraining's rmse: 3.4752\tvalid_1's rmse: 49.26\n",
      "[1140]\ttraining's rmse: 3.29831\tvalid_1's rmse: 49.2583\n",
      "[1170]\ttraining's rmse: 3.13018\tvalid_1's rmse: 49.2494\n",
      "[1200]\ttraining's rmse: 2.97159\tvalid_1's rmse: 49.2552\n",
      "[1230]\ttraining's rmse: 2.82253\tvalid_1's rmse: 49.2544\n",
      "[1260]\ttraining's rmse: 2.68121\tvalid_1's rmse: 49.2467\n",
      "[1290]\ttraining's rmse: 2.54584\tvalid_1's rmse: 49.2463\n",
      "[1320]\ttraining's rmse: 2.4208\tvalid_1's rmse: 49.2461\n",
      "[1350]\ttraining's rmse: 2.30067\tvalid_1's rmse: 49.24\n",
      "[1380]\ttraining's rmse: 2.186\tvalid_1's rmse: 49.237\n",
      "[1410]\ttraining's rmse: 2.07924\tvalid_1's rmse: 49.2331\n",
      "[1440]\ttraining's rmse: 1.97761\tvalid_1's rmse: 49.2293\n",
      "[1470]\ttraining's rmse: 1.88237\tvalid_1's rmse: 49.2238\n",
      "[1500]\ttraining's rmse: 1.79113\tvalid_1's rmse: 49.2253\n",
      "[1530]\ttraining's rmse: 1.70623\tvalid_1's rmse: 49.2247\n",
      "[1560]\ttraining's rmse: 1.62288\tvalid_1's rmse: 49.2234\n",
      "[1590]\ttraining's rmse: 1.54665\tvalid_1's rmse: 49.2175\n",
      "[1620]\ttraining's rmse: 1.47484\tvalid_1's rmse: 49.2157\n",
      "[1650]\ttraining's rmse: 1.40381\tvalid_1's rmse: 49.216\n",
      "[1680]\ttraining's rmse: 1.33669\tvalid_1's rmse: 49.2142\n",
      "[1710]\ttraining's rmse: 1.2749\tvalid_1's rmse: 49.2137\n",
      "[1740]\ttraining's rmse: 1.21649\tvalid_1's rmse: 49.2127\n",
      "[1770]\ttraining's rmse: 1.15933\tvalid_1's rmse: 49.212\n",
      "[1800]\ttraining's rmse: 1.10597\tvalid_1's rmse: 49.2108\n",
      "[1830]\ttraining's rmse: 1.05388\tvalid_1's rmse: 49.2091\n",
      "[1860]\ttraining's rmse: 1.00329\tvalid_1's rmse: 49.2076\n",
      "[1890]\ttraining's rmse: 0.957376\tvalid_1's rmse: 49.2085\n",
      "[1920]\ttraining's rmse: 0.913449\tvalid_1's rmse: 49.2077\n",
      "[1950]\ttraining's rmse: 0.872286\tvalid_1's rmse: 49.2082\n",
      "[1980]\ttraining's rmse: 0.833078\tvalid_1's rmse: 49.2078\n",
      "Early stopping, best iteration is:\n",
      "[1864]\ttraining's rmse: 0.996996\tvalid_1's rmse: 49.2069\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002162 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 20021\n",
      "[LightGBM] [Info] Number of data points in the train set: 9219, number of used features: 79\n",
      "[LightGBM] [Info] Start training from score 370.840749\n",
      "Training until validation scores don't improve for 125 rounds\n",
      "[30]\ttraining's rmse: 176.457\tvalid_1's rmse: 180.714\n",
      "[60]\ttraining's rmse: 108.088\tvalid_1's rmse: 117.949\n",
      "[90]\ttraining's rmse: 71.021\tvalid_1's rmse: 86.4543\n",
      "[120]\ttraining's rmse: 50.8841\tvalid_1's rmse: 71.1673\n",
      "[150]\ttraining's rmse: 39.8446\tvalid_1's rmse: 63.5804\n",
      "[180]\ttraining's rmse: 33.4694\tvalid_1's rmse: 59.5209\n",
      "[210]\ttraining's rmse: 29.1351\tvalid_1's rmse: 57.1941\n",
      "[240]\ttraining's rmse: 25.9564\tvalid_1's rmse: 55.8191\n",
      "[270]\ttraining's rmse: 23.3428\tvalid_1's rmse: 54.7603\n",
      "[300]\ttraining's rmse: 21.2316\tvalid_1's rmse: 54.0441\n",
      "[330]\ttraining's rmse: 19.5123\tvalid_1's rmse: 53.4863\n",
      "[360]\ttraining's rmse: 17.9287\tvalid_1's rmse: 53.0728\n",
      "[390]\ttraining's rmse: 16.5335\tvalid_1's rmse: 52.7421\n",
      "[420]\ttraining's rmse: 15.3003\tvalid_1's rmse: 52.4881\n",
      "[450]\ttraining's rmse: 14.204\tvalid_1's rmse: 52.2831\n",
      "[480]\ttraining's rmse: 13.2075\tvalid_1's rmse: 52.123\n",
      "[510]\ttraining's rmse: 12.2954\tvalid_1's rmse: 51.9296\n",
      "[540]\ttraining's rmse: 11.4837\tvalid_1's rmse: 51.8039\n",
      "[570]\ttraining's rmse: 10.7451\tvalid_1's rmse: 51.7196\n",
      "[600]\ttraining's rmse: 10.0736\tvalid_1's rmse: 51.6206\n",
      "[630]\ttraining's rmse: 9.45136\tvalid_1's rmse: 51.5516\n",
      "[660]\ttraining's rmse: 8.87591\tvalid_1's rmse: 51.5063\n",
      "[690]\ttraining's rmse: 8.34226\tvalid_1's rmse: 51.4391\n",
      "[720]\ttraining's rmse: 7.84567\tvalid_1's rmse: 51.3999\n",
      "[750]\ttraining's rmse: 7.38142\tvalid_1's rmse: 51.3505\n",
      "[780]\ttraining's rmse: 6.94691\tvalid_1's rmse: 51.3277\n",
      "[810]\ttraining's rmse: 6.55212\tvalid_1's rmse: 51.2874\n",
      "[840]\ttraining's rmse: 6.17692\tvalid_1's rmse: 51.2672\n",
      "[870]\ttraining's rmse: 5.83847\tvalid_1's rmse: 51.2409\n",
      "[900]\ttraining's rmse: 5.51829\tvalid_1's rmse: 51.2139\n",
      "[930]\ttraining's rmse: 5.21845\tvalid_1's rmse: 51.1949\n",
      "[960]\ttraining's rmse: 4.92963\tvalid_1's rmse: 51.1729\n",
      "[990]\ttraining's rmse: 4.66389\tvalid_1's rmse: 51.1504\n",
      "[1020]\ttraining's rmse: 4.41517\tvalid_1's rmse: 51.1438\n",
      "[1050]\ttraining's rmse: 4.18184\tvalid_1's rmse: 51.1318\n",
      "[1080]\ttraining's rmse: 3.96003\tvalid_1's rmse: 51.1219\n",
      "[1110]\ttraining's rmse: 3.75396\tvalid_1's rmse: 51.1157\n",
      "[1140]\ttraining's rmse: 3.56143\tvalid_1's rmse: 51.1166\n",
      "[1170]\ttraining's rmse: 3.3769\tvalid_1's rmse: 51.1081\n",
      "[1200]\ttraining's rmse: 3.20464\tvalid_1's rmse: 51.1045\n",
      "[1230]\ttraining's rmse: 3.04281\tvalid_1's rmse: 51.0956\n",
      "[1260]\ttraining's rmse: 2.89158\tvalid_1's rmse: 51.0899\n",
      "[1290]\ttraining's rmse: 2.74639\tvalid_1's rmse: 51.0853\n",
      "[1320]\ttraining's rmse: 2.6058\tvalid_1's rmse: 51.0823\n",
      "[1350]\ttraining's rmse: 2.47572\tvalid_1's rmse: 51.0758\n",
      "[1380]\ttraining's rmse: 2.35402\tvalid_1's rmse: 51.0685\n",
      "[1410]\ttraining's rmse: 2.23762\tvalid_1's rmse: 51.0699\n",
      "[1440]\ttraining's rmse: 2.12884\tvalid_1's rmse: 51.0619\n",
      "[1470]\ttraining's rmse: 2.02671\tvalid_1's rmse: 51.058\n",
      "[1500]\ttraining's rmse: 1.93006\tvalid_1's rmse: 51.0595\n",
      "[1530]\ttraining's rmse: 1.83735\tvalid_1's rmse: 51.0593\n",
      "[1560]\ttraining's rmse: 1.74854\tvalid_1's rmse: 51.0557\n",
      "[1590]\ttraining's rmse: 1.6651\tvalid_1's rmse: 51.0523\n",
      "[1620]\ttraining's rmse: 1.58694\tvalid_1's rmse: 51.0464\n",
      "[1650]\ttraining's rmse: 1.51294\tvalid_1's rmse: 51.0467\n",
      "[1680]\ttraining's rmse: 1.4417\tvalid_1's rmse: 51.0442\n",
      "[1710]\ttraining's rmse: 1.37183\tvalid_1's rmse: 51.0405\n",
      "[1740]\ttraining's rmse: 1.30826\tvalid_1's rmse: 51.0364\n",
      "[1770]\ttraining's rmse: 1.24758\tvalid_1's rmse: 51.0345\n",
      "[1800]\ttraining's rmse: 1.18917\tvalid_1's rmse: 51.0307\n",
      "[1830]\ttraining's rmse: 1.1336\tvalid_1's rmse: 51.0297\n",
      "[1860]\ttraining's rmse: 1.08182\tvalid_1's rmse: 51.0275\n",
      "[1890]\ttraining's rmse: 1.03291\tvalid_1's rmse: 51.0252\n",
      "[1920]\ttraining's rmse: 0.985565\tvalid_1's rmse: 51.0243\n",
      "[1950]\ttraining's rmse: 0.941368\tvalid_1's rmse: 51.0245\n",
      "[1980]\ttraining's rmse: 0.897508\tvalid_1's rmse: 51.0243\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's rmse: 0.871496\tvalid_1's rmse: 51.023\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002575 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 20021\n",
      "[LightGBM] [Info] Number of data points in the train set: 9219, number of used features: 79\n",
      "[LightGBM] [Info] Start training from score 373.489213\n",
      "Training until validation scores don't improve for 125 rounds\n",
      "[30]\ttraining's rmse: 175.864\tvalid_1's rmse: 179.107\n",
      "[60]\ttraining's rmse: 107.004\tvalid_1's rmse: 115.654\n",
      "[90]\ttraining's rmse: 69.6603\tvalid_1's rmse: 83.3932\n",
      "[120]\ttraining's rmse: 49.4844\tvalid_1's rmse: 68.1783\n",
      "[150]\ttraining's rmse: 38.433\tvalid_1's rmse: 61.1306\n",
      "[180]\ttraining's rmse: 31.9546\tvalid_1's rmse: 57.729\n",
      "[210]\ttraining's rmse: 27.7966\tvalid_1's rmse: 55.8613\n",
      "[240]\ttraining's rmse: 24.6921\tvalid_1's rmse: 54.8379\n",
      "[270]\ttraining's rmse: 22.2344\tvalid_1's rmse: 54.1115\n",
      "[300]\ttraining's rmse: 20.2058\tvalid_1's rmse: 53.7056\n",
      "[330]\ttraining's rmse: 18.5296\tvalid_1's rmse: 53.3883\n",
      "[360]\ttraining's rmse: 17.0848\tvalid_1's rmse: 53.1609\n",
      "[390]\ttraining's rmse: 15.804\tvalid_1's rmse: 53.0249\n",
      "[420]\ttraining's rmse: 14.6538\tvalid_1's rmse: 52.8582\n",
      "[450]\ttraining's rmse: 13.6553\tvalid_1's rmse: 52.8085\n",
      "[480]\ttraining's rmse: 12.7424\tvalid_1's rmse: 52.7525\n",
      "[510]\ttraining's rmse: 11.9031\tvalid_1's rmse: 52.6726\n",
      "[540]\ttraining's rmse: 11.137\tvalid_1's rmse: 52.6004\n",
      "[570]\ttraining's rmse: 10.4287\tvalid_1's rmse: 52.541\n",
      "[600]\ttraining's rmse: 9.80385\tvalid_1's rmse: 52.5071\n",
      "[630]\ttraining's rmse: 9.19755\tvalid_1's rmse: 52.4654\n",
      "[660]\ttraining's rmse: 8.65429\tvalid_1's rmse: 52.4305\n",
      "[690]\ttraining's rmse: 8.14372\tvalid_1's rmse: 52.3911\n",
      "[720]\ttraining's rmse: 7.66295\tvalid_1's rmse: 52.3645\n",
      "[750]\ttraining's rmse: 7.21923\tvalid_1's rmse: 52.3345\n",
      "[780]\ttraining's rmse: 6.80855\tvalid_1's rmse: 52.2943\n",
      "[810]\ttraining's rmse: 6.42518\tvalid_1's rmse: 52.2803\n",
      "[840]\ttraining's rmse: 6.0592\tvalid_1's rmse: 52.2548\n",
      "[870]\ttraining's rmse: 5.73125\tvalid_1's rmse: 52.2255\n",
      "[900]\ttraining's rmse: 5.42028\tvalid_1's rmse: 52.2072\n",
      "[930]\ttraining's rmse: 5.12812\tvalid_1's rmse: 52.197\n",
      "[960]\ttraining's rmse: 4.8402\tvalid_1's rmse: 52.187\n",
      "[990]\ttraining's rmse: 4.58411\tvalid_1's rmse: 52.1756\n",
      "[1020]\ttraining's rmse: 4.3467\tvalid_1's rmse: 52.1553\n",
      "[1050]\ttraining's rmse: 4.11763\tvalid_1's rmse: 52.146\n",
      "[1080]\ttraining's rmse: 3.9071\tvalid_1's rmse: 52.139\n",
      "[1110]\ttraining's rmse: 3.71182\tvalid_1's rmse: 52.1338\n",
      "[1140]\ttraining's rmse: 3.52474\tvalid_1's rmse: 52.1296\n",
      "[1170]\ttraining's rmse: 3.3497\tvalid_1's rmse: 52.1194\n",
      "[1200]\ttraining's rmse: 3.18632\tvalid_1's rmse: 52.1168\n",
      "[1230]\ttraining's rmse: 3.02446\tvalid_1's rmse: 52.1128\n",
      "[1260]\ttraining's rmse: 2.87372\tvalid_1's rmse: 52.1099\n",
      "[1290]\ttraining's rmse: 2.73314\tvalid_1's rmse: 52.1052\n",
      "[1320]\ttraining's rmse: 2.59852\tvalid_1's rmse: 52.1033\n",
      "[1350]\ttraining's rmse: 2.47414\tvalid_1's rmse: 52.0971\n",
      "[1380]\ttraining's rmse: 2.35369\tvalid_1's rmse: 52.093\n",
      "[1410]\ttraining's rmse: 2.2385\tvalid_1's rmse: 52.0906\n",
      "[1440]\ttraining's rmse: 2.12696\tvalid_1's rmse: 52.0871\n",
      "[1470]\ttraining's rmse: 2.02411\tvalid_1's rmse: 52.0835\n",
      "[1500]\ttraining's rmse: 1.92699\tvalid_1's rmse: 52.0829\n",
      "[1530]\ttraining's rmse: 1.83557\tvalid_1's rmse: 52.0774\n",
      "[1560]\ttraining's rmse: 1.74834\tvalid_1's rmse: 52.0725\n",
      "[1590]\ttraining's rmse: 1.66561\tvalid_1's rmse: 52.0742\n",
      "[1620]\ttraining's rmse: 1.58777\tvalid_1's rmse: 52.0738\n",
      "[1650]\ttraining's rmse: 1.51344\tvalid_1's rmse: 52.0727\n",
      "[1680]\ttraining's rmse: 1.44475\tvalid_1's rmse: 52.0718\n",
      "[1710]\ttraining's rmse: 1.37724\tvalid_1's rmse: 52.0688\n",
      "[1740]\ttraining's rmse: 1.31522\tvalid_1's rmse: 52.067\n",
      "[1770]\ttraining's rmse: 1.2558\tvalid_1's rmse: 52.0643\n",
      "[1800]\ttraining's rmse: 1.19863\tvalid_1's rmse: 52.0616\n",
      "[1830]\ttraining's rmse: 1.14381\tvalid_1's rmse: 52.0589\n",
      "[1860]\ttraining's rmse: 1.09296\tvalid_1's rmse: 52.0582\n",
      "[1890]\ttraining's rmse: 1.04327\tvalid_1's rmse: 52.0567\n",
      "[1920]\ttraining's rmse: 0.995663\tvalid_1's rmse: 52.0565\n",
      "[1950]\ttraining's rmse: 0.950642\tvalid_1's rmse: 52.0536\n",
      "[1980]\ttraining's rmse: 0.908799\tvalid_1's rmse: 52.0514\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's rmse: 0.881819\tvalid_1's rmse: 52.0518\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003270 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 20021\n",
      "[LightGBM] [Info] Number of data points in the train set: 9219, number of used features: 79\n",
      "[LightGBM] [Info] Start training from score 372.203804\n",
      "Training until validation scores don't improve for 125 rounds\n",
      "[30]\ttraining's rmse: 175.177\tvalid_1's rmse: 180.46\n",
      "[60]\ttraining's rmse: 106.472\tvalid_1's rmse: 116.868\n",
      "[90]\ttraining's rmse: 69.2811\tvalid_1's rmse: 85.1433\n",
      "[120]\ttraining's rmse: 49.1863\tvalid_1's rmse: 69.9986\n",
      "[150]\ttraining's rmse: 38.2667\tvalid_1's rmse: 62.9706\n",
      "[180]\ttraining's rmse: 31.8853\tvalid_1's rmse: 59.471\n",
      "[210]\ttraining's rmse: 27.6126\tvalid_1's rmse: 57.5797\n",
      "[240]\ttraining's rmse: 24.4798\tvalid_1's rmse: 56.294\n",
      "[270]\ttraining's rmse: 22.0225\tvalid_1's rmse: 55.4239\n",
      "[300]\ttraining's rmse: 19.9706\tvalid_1's rmse: 54.7836\n",
      "[330]\ttraining's rmse: 18.2398\tvalid_1's rmse: 54.3313\n",
      "[360]\ttraining's rmse: 16.7891\tvalid_1's rmse: 54.1252\n",
      "[390]\ttraining's rmse: 15.5133\tvalid_1's rmse: 53.9159\n",
      "[420]\ttraining's rmse: 14.3916\tvalid_1's rmse: 53.704\n",
      "[450]\ttraining's rmse: 13.3805\tvalid_1's rmse: 53.5679\n",
      "[480]\ttraining's rmse: 12.4596\tvalid_1's rmse: 53.4622\n",
      "[510]\ttraining's rmse: 11.6213\tvalid_1's rmse: 53.3731\n",
      "[540]\ttraining's rmse: 10.8617\tvalid_1's rmse: 53.2916\n",
      "[570]\ttraining's rmse: 10.1697\tvalid_1's rmse: 53.2278\n",
      "[600]\ttraining's rmse: 9.54589\tvalid_1's rmse: 53.1945\n",
      "[630]\ttraining's rmse: 8.95334\tvalid_1's rmse: 53.155\n",
      "[660]\ttraining's rmse: 8.40722\tvalid_1's rmse: 53.1296\n",
      "[690]\ttraining's rmse: 7.90377\tvalid_1's rmse: 53.0936\n",
      "[720]\ttraining's rmse: 7.44562\tvalid_1's rmse: 53.0663\n",
      "[750]\ttraining's rmse: 7.0173\tvalid_1's rmse: 53.0397\n",
      "[780]\ttraining's rmse: 6.61327\tvalid_1's rmse: 53.0051\n",
      "[810]\ttraining's rmse: 6.24338\tvalid_1's rmse: 52.977\n",
      "[840]\ttraining's rmse: 5.8975\tvalid_1's rmse: 52.9435\n",
      "[870]\ttraining's rmse: 5.57379\tvalid_1's rmse: 52.931\n",
      "[900]\ttraining's rmse: 5.2712\tvalid_1's rmse: 52.9132\n",
      "[930]\ttraining's rmse: 4.98339\tvalid_1's rmse: 52.8966\n",
      "[960]\ttraining's rmse: 4.71721\tvalid_1's rmse: 52.878\n",
      "[990]\ttraining's rmse: 4.4683\tvalid_1's rmse: 52.8745\n",
      "[1020]\ttraining's rmse: 4.23754\tvalid_1's rmse: 52.8684\n",
      "[1050]\ttraining's rmse: 4.01908\tvalid_1's rmse: 52.8589\n",
      "[1080]\ttraining's rmse: 3.8077\tvalid_1's rmse: 52.8519\n",
      "[1110]\ttraining's rmse: 3.60753\tvalid_1's rmse: 52.8392\n",
      "[1140]\ttraining's rmse: 3.4246\tvalid_1's rmse: 52.831\n",
      "[1170]\ttraining's rmse: 3.25235\tvalid_1's rmse: 52.8229\n",
      "[1200]\ttraining's rmse: 3.08606\tvalid_1's rmse: 52.8129\n",
      "[1230]\ttraining's rmse: 2.92951\tvalid_1's rmse: 52.8043\n",
      "[1260]\ttraining's rmse: 2.78046\tvalid_1's rmse: 52.7995\n",
      "[1290]\ttraining's rmse: 2.64214\tvalid_1's rmse: 52.7892\n",
      "[1320]\ttraining's rmse: 2.51501\tvalid_1's rmse: 52.7817\n",
      "[1350]\ttraining's rmse: 2.38991\tvalid_1's rmse: 52.7726\n",
      "[1380]\ttraining's rmse: 2.26978\tvalid_1's rmse: 52.7709\n",
      "[1410]\ttraining's rmse: 2.15686\tvalid_1's rmse: 52.7651\n",
      "[1440]\ttraining's rmse: 2.05208\tvalid_1's rmse: 52.7618\n",
      "[1470]\ttraining's rmse: 1.95166\tvalid_1's rmse: 52.7569\n",
      "[1500]\ttraining's rmse: 1.85867\tvalid_1's rmse: 52.7535\n",
      "[1530]\ttraining's rmse: 1.76781\tvalid_1's rmse: 52.7508\n",
      "[1560]\ttraining's rmse: 1.68459\tvalid_1's rmse: 52.746\n",
      "[1590]\ttraining's rmse: 1.60444\tvalid_1's rmse: 52.7431\n",
      "[1620]\ttraining's rmse: 1.52674\tvalid_1's rmse: 52.7374\n",
      "[1650]\ttraining's rmse: 1.45314\tvalid_1's rmse: 52.7358\n",
      "[1680]\ttraining's rmse: 1.38466\tvalid_1's rmse: 52.7315\n",
      "[1710]\ttraining's rmse: 1.31744\tvalid_1's rmse: 52.7273\n",
      "[1740]\ttraining's rmse: 1.25613\tvalid_1's rmse: 52.7235\n",
      "[1770]\ttraining's rmse: 1.19825\tvalid_1's rmse: 52.7211\n",
      "[1800]\ttraining's rmse: 1.14229\tvalid_1's rmse: 52.7196\n",
      "[1830]\ttraining's rmse: 1.0889\tvalid_1's rmse: 52.7179\n",
      "[1860]\ttraining's rmse: 1.03725\tvalid_1's rmse: 52.7165\n",
      "[1890]\ttraining's rmse: 0.989453\tvalid_1's rmse: 52.7153\n",
      "[1920]\ttraining's rmse: 0.943124\tvalid_1's rmse: 52.7138\n",
      "[1950]\ttraining's rmse: 0.900422\tvalid_1's rmse: 52.7125\n",
      "[1980]\ttraining's rmse: 0.860218\tvalid_1's rmse: 52.7114\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's rmse: 0.835314\tvalid_1's rmse: 52.7112\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002618 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 20021\n",
      "[LightGBM] [Info] Number of data points in the train set: 9219, number of used features: 79\n",
      "[LightGBM] [Info] Start training from score 374.774056\n",
      "Training until validation scores don't improve for 125 rounds\n",
      "[30]\ttraining's rmse: 178.203\tvalid_1's rmse: 179.359\n",
      "[60]\ttraining's rmse: 109.43\tvalid_1's rmse: 116.336\n",
      "[90]\ttraining's rmse: 71.7766\tvalid_1's rmse: 84.8127\n",
      "[120]\ttraining's rmse: 51.5531\tvalid_1's rmse: 70.0189\n",
      "[150]\ttraining's rmse: 40.2546\tvalid_1's rmse: 62.7401\n",
      "[180]\ttraining's rmse: 33.6383\tvalid_1's rmse: 58.9546\n",
      "[210]\ttraining's rmse: 29.2455\tvalid_1's rmse: 56.8195\n",
      "[240]\ttraining's rmse: 25.9898\tvalid_1's rmse: 55.4056\n",
      "[270]\ttraining's rmse: 23.3728\tvalid_1's rmse: 54.5838\n",
      "[300]\ttraining's rmse: 21.2778\tvalid_1's rmse: 53.9939\n",
      "[330]\ttraining's rmse: 19.545\tvalid_1's rmse: 53.5903\n",
      "[360]\ttraining's rmse: 18.0508\tvalid_1's rmse: 53.3367\n",
      "[390]\ttraining's rmse: 16.7017\tvalid_1's rmse: 53.046\n",
      "[420]\ttraining's rmse: 15.4754\tvalid_1's rmse: 52.8483\n",
      "[450]\ttraining's rmse: 14.4009\tvalid_1's rmse: 52.7305\n",
      "[480]\ttraining's rmse: 13.4325\tvalid_1's rmse: 52.6213\n",
      "[510]\ttraining's rmse: 12.5701\tvalid_1's rmse: 52.4417\n",
      "[540]\ttraining's rmse: 11.7777\tvalid_1's rmse: 52.3471\n",
      "[570]\ttraining's rmse: 11.0405\tvalid_1's rmse: 52.2393\n",
      "[600]\ttraining's rmse: 10.3752\tvalid_1's rmse: 52.1843\n",
      "[630]\ttraining's rmse: 9.75672\tvalid_1's rmse: 52.0881\n",
      "[660]\ttraining's rmse: 9.17407\tvalid_1's rmse: 52.0144\n",
      "[690]\ttraining's rmse: 8.6432\tvalid_1's rmse: 51.9839\n",
      "[720]\ttraining's rmse: 8.14772\tvalid_1's rmse: 51.9281\n",
      "[750]\ttraining's rmse: 7.6914\tvalid_1's rmse: 51.8937\n",
      "[780]\ttraining's rmse: 7.26167\tvalid_1's rmse: 51.8572\n",
      "[810]\ttraining's rmse: 6.86532\tvalid_1's rmse: 51.8377\n",
      "[840]\ttraining's rmse: 6.50208\tvalid_1's rmse: 51.8296\n",
      "[870]\ttraining's rmse: 6.1507\tvalid_1's rmse: 51.7829\n",
      "[900]\ttraining's rmse: 5.82531\tvalid_1's rmse: 51.7632\n",
      "[930]\ttraining's rmse: 5.52757\tvalid_1's rmse: 51.7222\n",
      "[960]\ttraining's rmse: 5.24415\tvalid_1's rmse: 51.703\n",
      "[990]\ttraining's rmse: 4.979\tvalid_1's rmse: 51.69\n",
      "[1020]\ttraining's rmse: 4.72953\tvalid_1's rmse: 51.6682\n",
      "[1050]\ttraining's rmse: 4.49221\tvalid_1's rmse: 51.6398\n",
      "[1080]\ttraining's rmse: 4.27309\tvalid_1's rmse: 51.621\n",
      "[1110]\ttraining's rmse: 4.07162\tvalid_1's rmse: 51.602\n",
      "[1140]\ttraining's rmse: 3.88159\tvalid_1's rmse: 51.5921\n",
      "[1170]\ttraining's rmse: 3.69835\tvalid_1's rmse: 51.572\n",
      "[1200]\ttraining's rmse: 3.52214\tvalid_1's rmse: 51.5624\n",
      "[1230]\ttraining's rmse: 3.36018\tvalid_1's rmse: 51.5538\n",
      "[1260]\ttraining's rmse: 3.19919\tvalid_1's rmse: 51.5478\n",
      "[1290]\ttraining's rmse: 3.0481\tvalid_1's rmse: 51.5367\n",
      "[1320]\ttraining's rmse: 2.90706\tvalid_1's rmse: 51.5221\n",
      "[1350]\ttraining's rmse: 2.77622\tvalid_1's rmse: 51.5124\n",
      "[1380]\ttraining's rmse: 2.64837\tvalid_1's rmse: 51.5089\n",
      "[1410]\ttraining's rmse: 2.53051\tvalid_1's rmse: 51.4986\n",
      "[1440]\ttraining's rmse: 2.42432\tvalid_1's rmse: 51.4901\n",
      "[1470]\ttraining's rmse: 2.31791\tvalid_1's rmse: 51.4794\n",
      "[1500]\ttraining's rmse: 2.21849\tvalid_1's rmse: 51.4797\n",
      "[1530]\ttraining's rmse: 2.12348\tvalid_1's rmse: 51.4726\n",
      "[1560]\ttraining's rmse: 2.03557\tvalid_1's rmse: 51.4625\n",
      "[1590]\ttraining's rmse: 1.94857\tvalid_1's rmse: 51.4603\n",
      "[1620]\ttraining's rmse: 1.86682\tvalid_1's rmse: 51.4532\n",
      "[1650]\ttraining's rmse: 1.79324\tvalid_1's rmse: 51.4465\n",
      "[1680]\ttraining's rmse: 1.71793\tvalid_1's rmse: 51.4461\n",
      "[1710]\ttraining's rmse: 1.64653\tvalid_1's rmse: 51.439\n",
      "[1740]\ttraining's rmse: 1.58311\tvalid_1's rmse: 51.4339\n",
      "[1770]\ttraining's rmse: 1.51858\tvalid_1's rmse: 51.4313\n",
      "[1800]\ttraining's rmse: 1.45681\tvalid_1's rmse: 51.4288\n",
      "[1830]\ttraining's rmse: 1.39458\tvalid_1's rmse: 51.4221\n",
      "[1860]\ttraining's rmse: 1.3373\tvalid_1's rmse: 51.4192\n",
      "[1890]\ttraining's rmse: 1.27939\tvalid_1's rmse: 51.4172\n",
      "[1920]\ttraining's rmse: 1.23028\tvalid_1's rmse: 51.4121\n",
      "[1950]\ttraining's rmse: 1.18202\tvalid_1's rmse: 51.4084\n",
      "[1980]\ttraining's rmse: 1.13479\tvalid_1's rmse: 51.4064\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's rmse: 1.10647\tvalid_1's rmse: 51.4054\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004080 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 20021\n",
      "[LightGBM] [Info] Number of data points in the train set: 9219, number of used features: 79\n",
      "[LightGBM] [Info] Start training from score 375.739763\n",
      "Training until validation scores don't improve for 125 rounds\n",
      "[30]\ttraining's rmse: 177.945\tvalid_1's rmse: 178.887\n",
      "[60]\ttraining's rmse: 108.597\tvalid_1's rmse: 115.749\n",
      "[90]\ttraining's rmse: 70.8855\tvalid_1's rmse: 84.1648\n",
      "[120]\ttraining's rmse: 50.6318\tvalid_1's rmse: 69.1205\n",
      "[150]\ttraining's rmse: 39.5747\tvalid_1's rmse: 62.203\n",
      "[180]\ttraining's rmse: 32.9769\tvalid_1's rmse: 58.7025\n",
      "[210]\ttraining's rmse: 28.6289\tvalid_1's rmse: 56.6311\n",
      "[240]\ttraining's rmse: 25.3637\tvalid_1's rmse: 55.2945\n",
      "[270]\ttraining's rmse: 22.869\tvalid_1's rmse: 54.4621\n",
      "[300]\ttraining's rmse: 20.8052\tvalid_1's rmse: 53.8819\n",
      "[330]\ttraining's rmse: 19.0657\tvalid_1's rmse: 53.4959\n",
      "[360]\ttraining's rmse: 17.5796\tvalid_1's rmse: 53.1806\n",
      "[390]\ttraining's rmse: 16.2628\tvalid_1's rmse: 52.9646\n",
      "[420]\ttraining's rmse: 15.0872\tvalid_1's rmse: 52.7572\n",
      "[450]\ttraining's rmse: 14.061\tvalid_1's rmse: 52.6252\n",
      "[480]\ttraining's rmse: 13.1296\tvalid_1's rmse: 52.545\n",
      "[510]\ttraining's rmse: 12.2584\tvalid_1's rmse: 52.4824\n",
      "[540]\ttraining's rmse: 11.4925\tvalid_1's rmse: 52.3773\n",
      "[570]\ttraining's rmse: 10.7724\tvalid_1's rmse: 52.3421\n",
      "[600]\ttraining's rmse: 10.1259\tvalid_1's rmse: 52.2708\n",
      "[630]\ttraining's rmse: 9.52138\tvalid_1's rmse: 52.1991\n",
      "[660]\ttraining's rmse: 8.96226\tvalid_1's rmse: 52.1467\n",
      "[690]\ttraining's rmse: 8.4551\tvalid_1's rmse: 52.1028\n",
      "[720]\ttraining's rmse: 7.98327\tvalid_1's rmse: 52.0646\n",
      "[750]\ttraining's rmse: 7.53218\tvalid_1's rmse: 52.0191\n",
      "[780]\ttraining's rmse: 7.1151\tvalid_1's rmse: 51.9798\n",
      "[810]\ttraining's rmse: 6.73083\tvalid_1's rmse: 51.9382\n",
      "[840]\ttraining's rmse: 6.37487\tvalid_1's rmse: 51.9123\n",
      "[870]\ttraining's rmse: 6.03879\tvalid_1's rmse: 51.8939\n",
      "[900]\ttraining's rmse: 5.72073\tvalid_1's rmse: 51.8686\n",
      "[930]\ttraining's rmse: 5.42291\tvalid_1's rmse: 51.838\n",
      "[960]\ttraining's rmse: 5.13611\tvalid_1's rmse: 51.8231\n",
      "[990]\ttraining's rmse: 4.87597\tvalid_1's rmse: 51.8093\n",
      "[1020]\ttraining's rmse: 4.63554\tvalid_1's rmse: 51.7868\n",
      "[1050]\ttraining's rmse: 4.40362\tvalid_1's rmse: 51.7755\n",
      "[1080]\ttraining's rmse: 4.18353\tvalid_1's rmse: 51.7615\n",
      "[1110]\ttraining's rmse: 3.98006\tvalid_1's rmse: 51.7647\n",
      "[1140]\ttraining's rmse: 3.78476\tvalid_1's rmse: 51.7525\n",
      "[1170]\ttraining's rmse: 3.60116\tvalid_1's rmse: 51.7397\n",
      "[1200]\ttraining's rmse: 3.42436\tvalid_1's rmse: 51.7285\n",
      "[1230]\ttraining's rmse: 3.2631\tvalid_1's rmse: 51.7241\n",
      "[1260]\ttraining's rmse: 3.1093\tvalid_1's rmse: 51.7125\n",
      "[1290]\ttraining's rmse: 2.95989\tvalid_1's rmse: 51.7084\n",
      "[1320]\ttraining's rmse: 2.81762\tvalid_1's rmse: 51.7055\n",
      "[1350]\ttraining's rmse: 2.68306\tvalid_1's rmse: 51.6977\n",
      "[1380]\ttraining's rmse: 2.56053\tvalid_1's rmse: 51.69\n",
      "[1410]\ttraining's rmse: 2.44016\tvalid_1's rmse: 51.686\n",
      "[1440]\ttraining's rmse: 2.32991\tvalid_1's rmse: 51.6793\n",
      "[1470]\ttraining's rmse: 2.22555\tvalid_1's rmse: 51.6808\n",
      "[1500]\ttraining's rmse: 2.12305\tvalid_1's rmse: 51.6821\n",
      "[1530]\ttraining's rmse: 2.02872\tvalid_1's rmse: 51.682\n",
      "[1560]\ttraining's rmse: 1.93849\tvalid_1's rmse: 51.6786\n",
      "[1590]\ttraining's rmse: 1.85284\tvalid_1's rmse: 51.6748\n",
      "[1620]\ttraining's rmse: 1.77072\tvalid_1's rmse: 51.6732\n",
      "[1650]\ttraining's rmse: 1.69316\tvalid_1's rmse: 51.6713\n",
      "[1680]\ttraining's rmse: 1.61875\tvalid_1's rmse: 51.6699\n",
      "[1710]\ttraining's rmse: 1.54691\tvalid_1's rmse: 51.6674\n",
      "[1740]\ttraining's rmse: 1.4822\tvalid_1's rmse: 51.6669\n",
      "[1770]\ttraining's rmse: 1.4175\tvalid_1's rmse: 51.6665\n",
      "[1800]\ttraining's rmse: 1.35492\tvalid_1's rmse: 51.6658\n",
      "[1830]\ttraining's rmse: 1.2979\tvalid_1's rmse: 51.6647\n",
      "[1860]\ttraining's rmse: 1.23986\tvalid_1's rmse: 51.6635\n",
      "[1890]\ttraining's rmse: 1.18717\tvalid_1's rmse: 51.6614\n",
      "[1920]\ttraining's rmse: 1.13687\tvalid_1's rmse: 51.6624\n",
      "[1950]\ttraining's rmse: 1.08852\tvalid_1's rmse: 51.6599\n",
      "[1980]\ttraining's rmse: 1.04512\tvalid_1's rmse: 51.6566\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's rmse: 1.01683\tvalid_1's rmse: 51.6563\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002425 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 20021\n",
      "[LightGBM] [Info] Number of data points in the train set: 9219, number of used features: 79\n",
      "[LightGBM] [Info] Start training from score 374.860380\n",
      "Training until validation scores don't improve for 125 rounds\n",
      "[30]\ttraining's rmse: 178.098\tvalid_1's rmse: 184.588\n",
      "[60]\ttraining's rmse: 109.039\tvalid_1's rmse: 120.2\n",
      "[90]\ttraining's rmse: 71.4847\tvalid_1's rmse: 87.2467\n",
      "[120]\ttraining's rmse: 51.3205\tvalid_1's rmse: 71.2312\n",
      "[150]\ttraining's rmse: 40.2627\tvalid_1's rmse: 63.8313\n",
      "[180]\ttraining's rmse: 33.746\tvalid_1's rmse: 59.9873\n",
      "[210]\ttraining's rmse: 29.333\tvalid_1's rmse: 57.7868\n",
      "[240]\ttraining's rmse: 26.0798\tvalid_1's rmse: 56.6032\n",
      "[270]\ttraining's rmse: 23.5429\tvalid_1's rmse: 55.8033\n",
      "[300]\ttraining's rmse: 21.408\tvalid_1's rmse: 55.1993\n",
      "[330]\ttraining's rmse: 19.607\tvalid_1's rmse: 54.8073\n",
      "[360]\ttraining's rmse: 18.0535\tvalid_1's rmse: 54.5595\n",
      "[390]\ttraining's rmse: 16.728\tvalid_1's rmse: 54.3572\n",
      "[420]\ttraining's rmse: 15.523\tvalid_1's rmse: 54.2087\n",
      "[450]\ttraining's rmse: 14.4415\tvalid_1's rmse: 54.0411\n",
      "[480]\ttraining's rmse: 13.4591\tvalid_1's rmse: 53.8816\n",
      "[510]\ttraining's rmse: 12.5516\tvalid_1's rmse: 53.7672\n",
      "[540]\ttraining's rmse: 11.7395\tvalid_1's rmse: 53.6906\n",
      "[570]\ttraining's rmse: 11.0032\tvalid_1's rmse: 53.6353\n",
      "[600]\ttraining's rmse: 10.3223\tvalid_1's rmse: 53.5647\n",
      "[630]\ttraining's rmse: 9.69416\tvalid_1's rmse: 53.5372\n",
      "[660]\ttraining's rmse: 9.10855\tvalid_1's rmse: 53.4835\n",
      "[690]\ttraining's rmse: 8.58773\tvalid_1's rmse: 53.4529\n",
      "[720]\ttraining's rmse: 8.09094\tvalid_1's rmse: 53.4081\n",
      "[750]\ttraining's rmse: 7.62653\tvalid_1's rmse: 53.3718\n",
      "[780]\ttraining's rmse: 7.20214\tvalid_1's rmse: 53.3677\n",
      "[810]\ttraining's rmse: 6.79581\tvalid_1's rmse: 53.3443\n",
      "[840]\ttraining's rmse: 6.42651\tvalid_1's rmse: 53.3382\n",
      "[870]\ttraining's rmse: 6.07854\tvalid_1's rmse: 53.318\n",
      "[900]\ttraining's rmse: 5.75678\tvalid_1's rmse: 53.2944\n",
      "[930]\ttraining's rmse: 5.44991\tvalid_1's rmse: 53.2866\n",
      "[960]\ttraining's rmse: 5.16393\tvalid_1's rmse: 53.2692\n",
      "[990]\ttraining's rmse: 4.89705\tvalid_1's rmse: 53.2551\n",
      "[1020]\ttraining's rmse: 4.64542\tvalid_1's rmse: 53.2401\n",
      "[1050]\ttraining's rmse: 4.41338\tvalid_1's rmse: 53.2275\n",
      "[1080]\ttraining's rmse: 4.19476\tvalid_1's rmse: 53.2215\n",
      "[1110]\ttraining's rmse: 3.98493\tvalid_1's rmse: 53.2016\n",
      "[1140]\ttraining's rmse: 3.77697\tvalid_1's rmse: 53.1878\n",
      "[1170]\ttraining's rmse: 3.59109\tvalid_1's rmse: 53.1785\n",
      "[1200]\ttraining's rmse: 3.40947\tvalid_1's rmse: 53.1591\n",
      "[1230]\ttraining's rmse: 3.24423\tvalid_1's rmse: 53.1552\n",
      "[1260]\ttraining's rmse: 3.08819\tvalid_1's rmse: 53.15\n",
      "[1290]\ttraining's rmse: 2.93549\tvalid_1's rmse: 53.1445\n",
      "[1320]\ttraining's rmse: 2.79299\tvalid_1's rmse: 53.1413\n",
      "[1350]\ttraining's rmse: 2.65886\tvalid_1's rmse: 53.1299\n",
      "[1380]\ttraining's rmse: 2.53037\tvalid_1's rmse: 53.1243\n",
      "[1410]\ttraining's rmse: 2.40849\tvalid_1's rmse: 53.1167\n",
      "[1440]\ttraining's rmse: 2.29607\tvalid_1's rmse: 53.1072\n",
      "[1470]\ttraining's rmse: 2.18859\tvalid_1's rmse: 53.1026\n",
      "[1500]\ttraining's rmse: 2.08644\tvalid_1's rmse: 53.095\n",
      "[1530]\ttraining's rmse: 1.98804\tvalid_1's rmse: 53.0902\n",
      "[1560]\ttraining's rmse: 1.89806\tvalid_1's rmse: 53.0859\n",
      "[1590]\ttraining's rmse: 1.80995\tvalid_1's rmse: 53.0826\n",
      "[1620]\ttraining's rmse: 1.72639\tvalid_1's rmse: 53.0744\n",
      "[1650]\ttraining's rmse: 1.64786\tvalid_1's rmse: 53.0714\n",
      "[1680]\ttraining's rmse: 1.57566\tvalid_1's rmse: 53.0669\n",
      "[1710]\ttraining's rmse: 1.50744\tvalid_1's rmse: 53.0596\n",
      "[1740]\ttraining's rmse: 1.44135\tvalid_1's rmse: 53.0555\n",
      "[1770]\ttraining's rmse: 1.37688\tvalid_1's rmse: 53.0491\n",
      "[1800]\ttraining's rmse: 1.31512\tvalid_1's rmse: 53.0445\n",
      "[1830]\ttraining's rmse: 1.25786\tvalid_1's rmse: 53.042\n",
      "[1860]\ttraining's rmse: 1.20498\tvalid_1's rmse: 53.0399\n",
      "[1890]\ttraining's rmse: 1.15271\tvalid_1's rmse: 53.0359\n",
      "[1920]\ttraining's rmse: 1.10166\tvalid_1's rmse: 53.0317\n",
      "[1950]\ttraining's rmse: 1.05508\tvalid_1's rmse: 53.028\n",
      "[1980]\ttraining's rmse: 1.00889\tvalid_1's rmse: 53.0223\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's rmse: 0.980009\tvalid_1's rmse: 53.0217\n",
      "1\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002440 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 20021\n",
      "[LightGBM] [Info] Number of data points in the train set: 9219, number of used features: 79\n",
      "[LightGBM] [Info] Start training from score 371.342398\n",
      "Training until validation scores don't improve for 125 rounds\n",
      "[30]\ttraining's rmse: 174.361\tvalid_1's rmse: 183.37\n",
      "[60]\ttraining's rmse: 105.026\tvalid_1's rmse: 118.015\n",
      "[90]\ttraining's rmse: 67.2705\tvalid_1's rmse: 84.9661\n",
      "[120]\ttraining's rmse: 47.1789\tvalid_1's rmse: 69.642\n",
      "[150]\ttraining's rmse: 36.3642\tvalid_1's rmse: 62.4254\n",
      "[180]\ttraining's rmse: 30.1688\tvalid_1's rmse: 58.9227\n",
      "[210]\ttraining's rmse: 26.1523\tvalid_1's rmse: 57.1988\n",
      "[240]\ttraining's rmse: 23.2225\tvalid_1's rmse: 55.9532\n",
      "[270]\ttraining's rmse: 20.9497\tvalid_1's rmse: 55.2469\n",
      "[300]\ttraining's rmse: 19.0984\tvalid_1's rmse: 54.5567\n",
      "[330]\ttraining's rmse: 17.4793\tvalid_1's rmse: 54.1203\n",
      "[360]\ttraining's rmse: 16.1179\tvalid_1's rmse: 53.7977\n",
      "[390]\ttraining's rmse: 14.8949\tvalid_1's rmse: 53.5536\n",
      "[420]\ttraining's rmse: 13.8164\tvalid_1's rmse: 53.3656\n",
      "[450]\ttraining's rmse: 12.8353\tvalid_1's rmse: 53.217\n",
      "[480]\ttraining's rmse: 11.9482\tvalid_1's rmse: 53.0253\n",
      "[510]\ttraining's rmse: 11.1646\tvalid_1's rmse: 52.8744\n",
      "[540]\ttraining's rmse: 10.4559\tvalid_1's rmse: 52.7674\n",
      "[570]\ttraining's rmse: 9.79891\tvalid_1's rmse: 52.6806\n",
      "[600]\ttraining's rmse: 9.18182\tvalid_1's rmse: 52.6033\n",
      "[630]\ttraining's rmse: 8.62422\tvalid_1's rmse: 52.5199\n",
      "[660]\ttraining's rmse: 8.09852\tvalid_1's rmse: 52.4188\n",
      "[690]\ttraining's rmse: 7.63094\tvalid_1's rmse: 52.3688\n",
      "[720]\ttraining's rmse: 7.19649\tvalid_1's rmse: 52.3208\n",
      "[750]\ttraining's rmse: 6.78788\tvalid_1's rmse: 52.2786\n",
      "[780]\ttraining's rmse: 6.39841\tvalid_1's rmse: 52.2269\n",
      "[810]\ttraining's rmse: 6.04702\tvalid_1's rmse: 52.189\n",
      "[840]\ttraining's rmse: 5.71167\tvalid_1's rmse: 52.132\n",
      "[870]\ttraining's rmse: 5.39744\tvalid_1's rmse: 52.1008\n",
      "[900]\ttraining's rmse: 5.10578\tvalid_1's rmse: 52.069\n",
      "[930]\ttraining's rmse: 4.82774\tvalid_1's rmse: 52.0469\n",
      "[960]\ttraining's rmse: 4.56853\tvalid_1's rmse: 52.0227\n",
      "[990]\ttraining's rmse: 4.32371\tvalid_1's rmse: 51.9989\n",
      "[1020]\ttraining's rmse: 4.0954\tvalid_1's rmse: 51.987\n",
      "[1050]\ttraining's rmse: 3.88023\tvalid_1's rmse: 51.9727\n",
      "[1080]\ttraining's rmse: 3.67517\tvalid_1's rmse: 51.9444\n",
      "[1110]\ttraining's rmse: 3.49339\tvalid_1's rmse: 51.9396\n",
      "[1140]\ttraining's rmse: 3.31697\tvalid_1's rmse: 51.9317\n",
      "[1170]\ttraining's rmse: 3.14845\tvalid_1's rmse: 51.9155\n",
      "[1200]\ttraining's rmse: 2.99201\tvalid_1's rmse: 51.8998\n",
      "[1230]\ttraining's rmse: 2.84405\tvalid_1's rmse: 51.8774\n",
      "[1260]\ttraining's rmse: 2.70332\tvalid_1's rmse: 51.8654\n",
      "[1290]\ttraining's rmse: 2.5668\tvalid_1's rmse: 51.8526\n",
      "[1320]\ttraining's rmse: 2.44119\tvalid_1's rmse: 51.8454\n",
      "[1350]\ttraining's rmse: 2.31938\tvalid_1's rmse: 51.839\n",
      "[1380]\ttraining's rmse: 2.20476\tvalid_1's rmse: 51.8371\n",
      "[1410]\ttraining's rmse: 2.09464\tvalid_1's rmse: 51.8244\n",
      "[1440]\ttraining's rmse: 1.99364\tvalid_1's rmse: 51.8122\n",
      "[1470]\ttraining's rmse: 1.89782\tvalid_1's rmse: 51.8059\n",
      "[1500]\ttraining's rmse: 1.80652\tvalid_1's rmse: 51.8017\n",
      "[1530]\ttraining's rmse: 1.72257\tvalid_1's rmse: 51.7972\n",
      "[1560]\ttraining's rmse: 1.63766\tvalid_1's rmse: 51.7935\n",
      "[1590]\ttraining's rmse: 1.55923\tvalid_1's rmse: 51.7844\n",
      "[1620]\ttraining's rmse: 1.4853\tvalid_1's rmse: 51.7829\n",
      "[1650]\ttraining's rmse: 1.41493\tvalid_1's rmse: 51.7794\n",
      "[1680]\ttraining's rmse: 1.34819\tvalid_1's rmse: 51.7758\n",
      "[1710]\ttraining's rmse: 1.28363\tvalid_1's rmse: 51.7715\n",
      "[1740]\ttraining's rmse: 1.22497\tvalid_1's rmse: 51.7667\n",
      "[1770]\ttraining's rmse: 1.16918\tvalid_1's rmse: 51.7655\n",
      "[1800]\ttraining's rmse: 1.11523\tvalid_1's rmse: 51.7643\n",
      "[1830]\ttraining's rmse: 1.06409\tvalid_1's rmse: 51.7622\n",
      "[1860]\ttraining's rmse: 1.01579\tvalid_1's rmse: 51.7583\n",
      "[1890]\ttraining's rmse: 0.968527\tvalid_1's rmse: 51.7576\n",
      "[1920]\ttraining's rmse: 0.92479\tvalid_1's rmse: 51.7558\n",
      "[1950]\ttraining's rmse: 0.88363\tvalid_1's rmse: 51.7536\n",
      "[1980]\ttraining's rmse: 0.844022\tvalid_1's rmse: 51.7521\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's rmse: 0.818905\tvalid_1's rmse: 51.7514\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004052 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 20021\n",
      "[LightGBM] [Info] Number of data points in the train set: 9219, number of used features: 79\n",
      "[LightGBM] [Info] Start training from score 372.672896\n",
      "Training until validation scores don't improve for 125 rounds\n",
      "[30]\ttraining's rmse: 175.384\tvalid_1's rmse: 185.394\n",
      "[60]\ttraining's rmse: 107.745\tvalid_1's rmse: 121.476\n",
      "[90]\ttraining's rmse: 71.1458\tvalid_1's rmse: 90.0058\n",
      "[120]\ttraining's rmse: 51.3337\tvalid_1's rmse: 75.3274\n",
      "[150]\ttraining's rmse: 40.5135\tvalid_1's rmse: 68.0686\n",
      "[180]\ttraining's rmse: 34.0583\tvalid_1's rmse: 64.5024\n",
      "[210]\ttraining's rmse: 29.6851\tvalid_1's rmse: 62.5406\n",
      "[240]\ttraining's rmse: 26.4901\tvalid_1's rmse: 61.169\n",
      "[270]\ttraining's rmse: 23.875\tvalid_1's rmse: 60.292\n",
      "[300]\ttraining's rmse: 21.7348\tvalid_1's rmse: 59.6244\n",
      "[330]\ttraining's rmse: 19.9037\tvalid_1's rmse: 59.0931\n",
      "[360]\ttraining's rmse: 18.3512\tvalid_1's rmse: 58.7362\n",
      "[390]\ttraining's rmse: 16.9663\tvalid_1's rmse: 58.4539\n",
      "[420]\ttraining's rmse: 15.7311\tvalid_1's rmse: 58.2\n",
      "[450]\ttraining's rmse: 14.5951\tvalid_1's rmse: 57.9721\n",
      "[480]\ttraining's rmse: 13.5748\tvalid_1's rmse: 57.8601\n",
      "[510]\ttraining's rmse: 12.6801\tvalid_1's rmse: 57.7696\n",
      "[540]\ttraining's rmse: 11.8408\tvalid_1's rmse: 57.6735\n",
      "[570]\ttraining's rmse: 11.0858\tvalid_1's rmse: 57.5319\n",
      "[600]\ttraining's rmse: 10.3934\tvalid_1's rmse: 57.4329\n",
      "[630]\ttraining's rmse: 9.75181\tvalid_1's rmse: 57.3599\n",
      "[660]\ttraining's rmse: 9.16837\tvalid_1's rmse: 57.2779\n",
      "[690]\ttraining's rmse: 8.6193\tvalid_1's rmse: 57.1947\n",
      "[720]\ttraining's rmse: 8.11014\tvalid_1's rmse: 57.1544\n",
      "[750]\ttraining's rmse: 7.64301\tvalid_1's rmse: 57.1022\n",
      "[780]\ttraining's rmse: 7.20147\tvalid_1's rmse: 57.0583\n",
      "[810]\ttraining's rmse: 6.79018\tvalid_1's rmse: 56.9863\n",
      "[840]\ttraining's rmse: 6.41098\tvalid_1's rmse: 56.9475\n",
      "[870]\ttraining's rmse: 6.05269\tvalid_1's rmse: 56.9274\n",
      "[900]\ttraining's rmse: 5.72137\tvalid_1's rmse: 56.9126\n",
      "[930]\ttraining's rmse: 5.4063\tvalid_1's rmse: 56.8878\n",
      "[960]\ttraining's rmse: 5.11407\tvalid_1's rmse: 56.852\n",
      "[990]\ttraining's rmse: 4.84608\tvalid_1's rmse: 56.8501\n",
      "[1020]\ttraining's rmse: 4.59865\tvalid_1's rmse: 56.8266\n",
      "[1050]\ttraining's rmse: 4.34907\tvalid_1's rmse: 56.8098\n",
      "[1080]\ttraining's rmse: 4.11593\tvalid_1's rmse: 56.77\n",
      "[1110]\ttraining's rmse: 3.90616\tvalid_1's rmse: 56.7407\n",
      "[1140]\ttraining's rmse: 3.70113\tvalid_1's rmse: 56.7183\n",
      "[1170]\ttraining's rmse: 3.51378\tvalid_1's rmse: 56.703\n",
      "[1200]\ttraining's rmse: 3.32997\tvalid_1's rmse: 56.6901\n",
      "[1230]\ttraining's rmse: 3.16037\tvalid_1's rmse: 56.6754\n",
      "[1260]\ttraining's rmse: 2.99564\tvalid_1's rmse: 56.6708\n",
      "[1290]\ttraining's rmse: 2.8447\tvalid_1's rmse: 56.6623\n",
      "[1320]\ttraining's rmse: 2.69785\tvalid_1's rmse: 56.6568\n",
      "[1350]\ttraining's rmse: 2.5607\tvalid_1's rmse: 56.6542\n",
      "[1380]\ttraining's rmse: 2.43018\tvalid_1's rmse: 56.6452\n",
      "[1410]\ttraining's rmse: 2.30977\tvalid_1's rmse: 56.6418\n",
      "[1440]\ttraining's rmse: 2.19626\tvalid_1's rmse: 56.634\n",
      "[1470]\ttraining's rmse: 2.08405\tvalid_1's rmse: 56.6232\n",
      "[1500]\ttraining's rmse: 1.97633\tvalid_1's rmse: 56.6145\n",
      "[1530]\ttraining's rmse: 1.8794\tvalid_1's rmse: 56.6082\n",
      "[1560]\ttraining's rmse: 1.78832\tvalid_1's rmse: 56.6035\n",
      "[1590]\ttraining's rmse: 1.70328\tvalid_1's rmse: 56.597\n",
      "[1620]\ttraining's rmse: 1.62079\tvalid_1's rmse: 56.5903\n",
      "[1650]\ttraining's rmse: 1.54224\tvalid_1's rmse: 56.5906\n",
      "[1680]\ttraining's rmse: 1.46784\tvalid_1's rmse: 56.5873\n",
      "[1710]\ttraining's rmse: 1.39845\tvalid_1's rmse: 56.5802\n",
      "[1740]\ttraining's rmse: 1.3323\tvalid_1's rmse: 56.5768\n",
      "[1770]\ttraining's rmse: 1.26878\tvalid_1's rmse: 56.5739\n",
      "[1800]\ttraining's rmse: 1.20926\tvalid_1's rmse: 56.5673\n",
      "[1830]\ttraining's rmse: 1.15137\tvalid_1's rmse: 56.5645\n",
      "[1860]\ttraining's rmse: 1.09797\tvalid_1's rmse: 56.5627\n",
      "[1890]\ttraining's rmse: 1.04711\tvalid_1's rmse: 56.5612\n",
      "[1920]\ttraining's rmse: 0.998348\tvalid_1's rmse: 56.5606\n",
      "[1950]\ttraining's rmse: 0.951698\tvalid_1's rmse: 56.5581\n",
      "[1980]\ttraining's rmse: 0.90787\tvalid_1's rmse: 56.5565\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's rmse: 0.879394\tvalid_1's rmse: 56.555\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003090 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 20021\n",
      "[LightGBM] [Info] Number of data points in the train set: 9219, number of used features: 79\n",
      "[LightGBM] [Info] Start training from score 368.883862\n",
      "Training until validation scores don't improve for 125 rounds\n",
      "[30]\ttraining's rmse: 175.393\tvalid_1's rmse: 182.514\n",
      "[60]\ttraining's rmse: 106.635\tvalid_1's rmse: 119.254\n",
      "[90]\ttraining's rmse: 69.5978\tvalid_1's rmse: 87.9745\n",
      "[120]\ttraining's rmse: 49.6516\tvalid_1's rmse: 73.4438\n",
      "[150]\ttraining's rmse: 38.8051\tvalid_1's rmse: 66.486\n",
      "[180]\ttraining's rmse: 32.444\tvalid_1's rmse: 62.9613\n",
      "[210]\ttraining's rmse: 28.2448\tvalid_1's rmse: 61.1268\n",
      "[240]\ttraining's rmse: 25.129\tvalid_1's rmse: 59.7436\n",
      "[270]\ttraining's rmse: 22.6525\tvalid_1's rmse: 58.8762\n",
      "[300]\ttraining's rmse: 20.5615\tvalid_1's rmse: 58.2616\n",
      "[330]\ttraining's rmse: 18.8434\tvalid_1's rmse: 57.767\n",
      "[360]\ttraining's rmse: 17.3464\tvalid_1's rmse: 57.4226\n",
      "[390]\ttraining's rmse: 16.0654\tvalid_1's rmse: 57.0966\n",
      "[420]\ttraining's rmse: 14.8948\tvalid_1's rmse: 56.8094\n",
      "[450]\ttraining's rmse: 13.8495\tvalid_1's rmse: 56.6677\n",
      "[480]\ttraining's rmse: 12.9134\tvalid_1's rmse: 56.5266\n",
      "[510]\ttraining's rmse: 12.036\tvalid_1's rmse: 56.3689\n",
      "[540]\ttraining's rmse: 11.2432\tvalid_1's rmse: 56.2315\n",
      "[570]\ttraining's rmse: 10.5181\tvalid_1's rmse: 56.1444\n",
      "[600]\ttraining's rmse: 9.86775\tvalid_1's rmse: 56.0109\n",
      "[630]\ttraining's rmse: 9.25026\tvalid_1's rmse: 55.9562\n",
      "[660]\ttraining's rmse: 8.68447\tvalid_1's rmse: 55.9052\n",
      "[690]\ttraining's rmse: 8.16907\tvalid_1's rmse: 55.838\n",
      "[720]\ttraining's rmse: 7.69329\tvalid_1's rmse: 55.8001\n",
      "[750]\ttraining's rmse: 7.24074\tvalid_1's rmse: 55.7613\n",
      "[780]\ttraining's rmse: 6.82882\tvalid_1's rmse: 55.7133\n",
      "[810]\ttraining's rmse: 6.4399\tvalid_1's rmse: 55.67\n",
      "[840]\ttraining's rmse: 6.08969\tvalid_1's rmse: 55.6306\n",
      "[870]\ttraining's rmse: 5.75073\tvalid_1's rmse: 55.5969\n",
      "[900]\ttraining's rmse: 5.44764\tvalid_1's rmse: 55.5778\n",
      "[930]\ttraining's rmse: 5.15599\tvalid_1's rmse: 55.5484\n",
      "[960]\ttraining's rmse: 4.88756\tvalid_1's rmse: 55.5231\n",
      "[990]\ttraining's rmse: 4.62781\tvalid_1's rmse: 55.4988\n",
      "[1020]\ttraining's rmse: 4.3866\tvalid_1's rmse: 55.4773\n",
      "[1050]\ttraining's rmse: 4.1618\tvalid_1's rmse: 55.4707\n",
      "[1080]\ttraining's rmse: 3.94794\tvalid_1's rmse: 55.4471\n",
      "[1110]\ttraining's rmse: 3.74845\tvalid_1's rmse: 55.43\n",
      "[1140]\ttraining's rmse: 3.56088\tvalid_1's rmse: 55.4254\n",
      "[1170]\ttraining's rmse: 3.38141\tvalid_1's rmse: 55.4196\n",
      "[1200]\ttraining's rmse: 3.21502\tvalid_1's rmse: 55.4158\n",
      "[1230]\ttraining's rmse: 3.0572\tvalid_1's rmse: 55.3996\n",
      "[1260]\ttraining's rmse: 2.90506\tvalid_1's rmse: 55.3865\n",
      "[1290]\ttraining's rmse: 2.76323\tvalid_1's rmse: 55.3819\n",
      "[1320]\ttraining's rmse: 2.62983\tvalid_1's rmse: 55.3784\n",
      "[1350]\ttraining's rmse: 2.50748\tvalid_1's rmse: 55.3748\n",
      "[1380]\ttraining's rmse: 2.38931\tvalid_1's rmse: 55.3682\n",
      "[1410]\ttraining's rmse: 2.27529\tvalid_1's rmse: 55.3593\n",
      "[1440]\ttraining's rmse: 2.1682\tvalid_1's rmse: 55.3509\n",
      "[1470]\ttraining's rmse: 2.06844\tvalid_1's rmse: 55.3492\n",
      "[1500]\ttraining's rmse: 1.97313\tvalid_1's rmse: 55.3446\n",
      "[1530]\ttraining's rmse: 1.88104\tvalid_1's rmse: 55.3409\n",
      "[1560]\ttraining's rmse: 1.79407\tvalid_1's rmse: 55.3411\n",
      "[1590]\ttraining's rmse: 1.71123\tvalid_1's rmse: 55.336\n",
      "[1620]\ttraining's rmse: 1.6339\tvalid_1's rmse: 55.3338\n",
      "[1650]\ttraining's rmse: 1.55978\tvalid_1's rmse: 55.3356\n",
      "[1680]\ttraining's rmse: 1.48889\tvalid_1's rmse: 55.3305\n",
      "[1710]\ttraining's rmse: 1.42274\tvalid_1's rmse: 55.3248\n",
      "[1740]\ttraining's rmse: 1.36086\tvalid_1's rmse: 55.3248\n",
      "[1770]\ttraining's rmse: 1.29859\tvalid_1's rmse: 55.3168\n",
      "[1800]\ttraining's rmse: 1.24156\tvalid_1's rmse: 55.3131\n",
      "[1830]\ttraining's rmse: 1.1868\tvalid_1's rmse: 55.3123\n",
      "[1860]\ttraining's rmse: 1.13386\tvalid_1's rmse: 55.3106\n",
      "[1890]\ttraining's rmse: 1.0843\tvalid_1's rmse: 55.3107\n",
      "[1920]\ttraining's rmse: 1.03673\tvalid_1's rmse: 55.3073\n",
      "[1950]\ttraining's rmse: 0.990609\tvalid_1's rmse: 55.3075\n",
      "[1980]\ttraining's rmse: 0.948479\tvalid_1's rmse: 55.3076\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's rmse: 0.920138\tvalid_1's rmse: 55.3061\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002533 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 20021\n",
      "[LightGBM] [Info] Number of data points in the train set: 9219, number of used features: 79\n",
      "[LightGBM] [Info] Start training from score 370.840749\n",
      "Training until validation scores don't improve for 125 rounds\n",
      "[30]\ttraining's rmse: 175.869\tvalid_1's rmse: 181.131\n",
      "[60]\ttraining's rmse: 106.886\tvalid_1's rmse: 118.941\n",
      "[90]\ttraining's rmse: 69.4522\tvalid_1's rmse: 87.8659\n",
      "[120]\ttraining's rmse: 49.3554\tvalid_1's rmse: 73.2626\n",
      "[150]\ttraining's rmse: 38.4653\tvalid_1's rmse: 66.5151\n",
      "[180]\ttraining's rmse: 32.196\tvalid_1's rmse: 62.9023\n",
      "[210]\ttraining's rmse: 27.934\tvalid_1's rmse: 60.5264\n",
      "[240]\ttraining's rmse: 24.8748\tvalid_1's rmse: 59.2335\n",
      "[270]\ttraining's rmse: 22.376\tvalid_1's rmse: 57.9839\n",
      "[300]\ttraining's rmse: 20.3497\tvalid_1's rmse: 57.1463\n",
      "[330]\ttraining's rmse: 18.6586\tvalid_1's rmse: 56.5971\n",
      "[360]\ttraining's rmse: 17.1969\tvalid_1's rmse: 56.2289\n",
      "[390]\ttraining's rmse: 15.8945\tvalid_1's rmse: 55.8853\n",
      "[420]\ttraining's rmse: 14.7378\tvalid_1's rmse: 55.6376\n",
      "[450]\ttraining's rmse: 13.6814\tvalid_1's rmse: 55.4398\n",
      "[480]\ttraining's rmse: 12.7356\tvalid_1's rmse: 55.2943\n",
      "[510]\ttraining's rmse: 11.8835\tvalid_1's rmse: 55.1793\n",
      "[540]\ttraining's rmse: 11.1159\tvalid_1's rmse: 55.0155\n",
      "[570]\ttraining's rmse: 10.4064\tvalid_1's rmse: 54.9217\n",
      "[600]\ttraining's rmse: 9.76349\tvalid_1's rmse: 54.832\n",
      "[630]\ttraining's rmse: 9.16697\tvalid_1's rmse: 54.7472\n",
      "[660]\ttraining's rmse: 8.6309\tvalid_1's rmse: 54.6786\n",
      "[690]\ttraining's rmse: 8.11767\tvalid_1's rmse: 54.6268\n",
      "[720]\ttraining's rmse: 7.64529\tvalid_1's rmse: 54.5596\n",
      "[750]\ttraining's rmse: 7.21042\tvalid_1's rmse: 54.5397\n",
      "[780]\ttraining's rmse: 6.79759\tvalid_1's rmse: 54.4751\n",
      "[810]\ttraining's rmse: 6.42222\tvalid_1's rmse: 54.4231\n",
      "[840]\ttraining's rmse: 6.07136\tvalid_1's rmse: 54.3971\n",
      "[870]\ttraining's rmse: 5.74088\tvalid_1's rmse: 54.3709\n",
      "[900]\ttraining's rmse: 5.43302\tvalid_1's rmse: 54.3663\n",
      "[930]\ttraining's rmse: 5.14007\tvalid_1's rmse: 54.341\n",
      "[960]\ttraining's rmse: 4.86324\tvalid_1's rmse: 54.3254\n",
      "[990]\ttraining's rmse: 4.60571\tvalid_1's rmse: 54.3024\n",
      "[1020]\ttraining's rmse: 4.36838\tvalid_1's rmse: 54.2893\n",
      "[1050]\ttraining's rmse: 4.14224\tvalid_1's rmse: 54.2717\n",
      "[1080]\ttraining's rmse: 3.92753\tvalid_1's rmse: 54.2542\n",
      "[1110]\ttraining's rmse: 3.72621\tvalid_1's rmse: 54.2402\n",
      "[1140]\ttraining's rmse: 3.535\tvalid_1's rmse: 54.2269\n",
      "[1170]\ttraining's rmse: 3.35425\tvalid_1's rmse: 54.2097\n",
      "[1200]\ttraining's rmse: 3.18912\tvalid_1's rmse: 54.2018\n",
      "[1230]\ttraining's rmse: 3.03364\tvalid_1's rmse: 54.191\n",
      "[1260]\ttraining's rmse: 2.88323\tvalid_1's rmse: 54.1805\n",
      "[1290]\ttraining's rmse: 2.74147\tvalid_1's rmse: 54.1757\n",
      "[1320]\ttraining's rmse: 2.60929\tvalid_1's rmse: 54.1689\n",
      "[1350]\ttraining's rmse: 2.48591\tvalid_1's rmse: 54.1594\n",
      "[1380]\ttraining's rmse: 2.36734\tvalid_1's rmse: 54.1514\n",
      "[1410]\ttraining's rmse: 2.2528\tvalid_1's rmse: 54.1442\n",
      "[1440]\ttraining's rmse: 2.14492\tvalid_1's rmse: 54.1381\n",
      "[1470]\ttraining's rmse: 2.04333\tvalid_1's rmse: 54.1299\n",
      "[1500]\ttraining's rmse: 1.94666\tvalid_1's rmse: 54.127\n",
      "[1530]\ttraining's rmse: 1.85543\tvalid_1's rmse: 54.1225\n",
      "[1560]\ttraining's rmse: 1.76866\tvalid_1's rmse: 54.1176\n",
      "[1590]\ttraining's rmse: 1.68679\tvalid_1's rmse: 54.1165\n",
      "[1620]\ttraining's rmse: 1.60776\tvalid_1's rmse: 54.1144\n",
      "[1650]\ttraining's rmse: 1.53364\tvalid_1's rmse: 54.1115\n",
      "[1680]\ttraining's rmse: 1.46299\tvalid_1's rmse: 54.1093\n",
      "[1710]\ttraining's rmse: 1.39653\tvalid_1's rmse: 54.1068\n",
      "[1740]\ttraining's rmse: 1.33323\tvalid_1's rmse: 54.1067\n",
      "[1770]\ttraining's rmse: 1.27298\tvalid_1's rmse: 54.1061\n",
      "[1800]\ttraining's rmse: 1.21742\tvalid_1's rmse: 54.1048\n",
      "[1830]\ttraining's rmse: 1.1626\tvalid_1's rmse: 54.1038\n",
      "[1860]\ttraining's rmse: 1.11028\tvalid_1's rmse: 54.1026\n",
      "[1890]\ttraining's rmse: 1.06102\tvalid_1's rmse: 54.1014\n",
      "[1920]\ttraining's rmse: 1.01298\tvalid_1's rmse: 54.0993\n",
      "[1950]\ttraining's rmse: 0.968646\tvalid_1's rmse: 54.0983\n",
      "[1980]\ttraining's rmse: 0.926044\tvalid_1's rmse: 54.0973\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's rmse: 0.900025\tvalid_1's rmse: 54.0968\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002526 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 20021\n",
      "[LightGBM] [Info] Number of data points in the train set: 9219, number of used features: 79\n",
      "[LightGBM] [Info] Start training from score 373.489213\n",
      "Training until validation scores don't improve for 125 rounds\n",
      "[30]\ttraining's rmse: 176.6\tvalid_1's rmse: 181.085\n",
      "[60]\ttraining's rmse: 108.3\tvalid_1's rmse: 119.212\n",
      "[90]\ttraining's rmse: 70.9894\tvalid_1's rmse: 87.9062\n",
      "[120]\ttraining's rmse: 50.8238\tvalid_1's rmse: 73.2859\n",
      "[150]\ttraining's rmse: 39.7087\tvalid_1's rmse: 66.3646\n",
      "[180]\ttraining's rmse: 33.2177\tvalid_1's rmse: 63.056\n",
      "[210]\ttraining's rmse: 28.9285\tvalid_1's rmse: 61.0597\n",
      "[240]\ttraining's rmse: 25.5505\tvalid_1's rmse: 59.806\n",
      "[270]\ttraining's rmse: 22.9962\tvalid_1's rmse: 58.9742\n",
      "[300]\ttraining's rmse: 20.8839\tvalid_1's rmse: 58.4635\n",
      "[330]\ttraining's rmse: 19.1033\tvalid_1's rmse: 58.079\n",
      "[360]\ttraining's rmse: 17.5791\tvalid_1's rmse: 57.7524\n",
      "[390]\ttraining's rmse: 16.2527\tvalid_1's rmse: 57.526\n",
      "[420]\ttraining's rmse: 15.0683\tvalid_1's rmse: 57.3229\n",
      "[450]\ttraining's rmse: 14.0043\tvalid_1's rmse: 57.1599\n",
      "[480]\ttraining's rmse: 13.0377\tvalid_1's rmse: 57.0225\n",
      "[510]\ttraining's rmse: 12.1726\tvalid_1's rmse: 56.8839\n",
      "[540]\ttraining's rmse: 11.385\tvalid_1's rmse: 56.7847\n",
      "[570]\ttraining's rmse: 10.6523\tvalid_1's rmse: 56.6854\n",
      "[600]\ttraining's rmse: 9.99063\tvalid_1's rmse: 56.5762\n",
      "[630]\ttraining's rmse: 9.38107\tvalid_1's rmse: 56.4873\n",
      "[660]\ttraining's rmse: 8.82712\tvalid_1's rmse: 56.4432\n",
      "[690]\ttraining's rmse: 8.30453\tvalid_1's rmse: 56.3816\n",
      "[720]\ttraining's rmse: 7.82137\tvalid_1's rmse: 56.3291\n",
      "[750]\ttraining's rmse: 7.38521\tvalid_1's rmse: 56.3065\n",
      "[780]\ttraining's rmse: 6.97052\tvalid_1's rmse: 56.2521\n",
      "[810]\ttraining's rmse: 6.58999\tvalid_1's rmse: 56.2061\n",
      "[840]\ttraining's rmse: 6.23069\tvalid_1's rmse: 56.1656\n",
      "[870]\ttraining's rmse: 5.89581\tvalid_1's rmse: 56.1462\n",
      "[900]\ttraining's rmse: 5.58666\tvalid_1's rmse: 56.1118\n",
      "[930]\ttraining's rmse: 5.29498\tvalid_1's rmse: 56.085\n",
      "[960]\ttraining's rmse: 5.01609\tvalid_1's rmse: 56.0661\n",
      "[990]\ttraining's rmse: 4.74785\tvalid_1's rmse: 56.0452\n",
      "[1020]\ttraining's rmse: 4.50603\tvalid_1's rmse: 56.0319\n",
      "[1050]\ttraining's rmse: 4.2746\tvalid_1's rmse: 56.011\n",
      "[1080]\ttraining's rmse: 4.06126\tvalid_1's rmse: 55.9991\n",
      "[1110]\ttraining's rmse: 3.85778\tvalid_1's rmse: 55.9847\n",
      "[1140]\ttraining's rmse: 3.66197\tvalid_1's rmse: 55.9741\n",
      "[1170]\ttraining's rmse: 3.48323\tvalid_1's rmse: 55.9651\n",
      "[1200]\ttraining's rmse: 3.31231\tvalid_1's rmse: 55.9557\n",
      "[1230]\ttraining's rmse: 3.14847\tvalid_1's rmse: 55.9483\n",
      "[1260]\ttraining's rmse: 2.99534\tvalid_1's rmse: 55.9452\n",
      "[1290]\ttraining's rmse: 2.85267\tvalid_1's rmse: 55.9388\n",
      "[1320]\ttraining's rmse: 2.71372\tvalid_1's rmse: 55.9234\n",
      "[1350]\ttraining's rmse: 2.58619\tvalid_1's rmse: 55.9155\n",
      "[1380]\ttraining's rmse: 2.46455\tvalid_1's rmse: 55.9118\n",
      "[1410]\ttraining's rmse: 2.3513\tvalid_1's rmse: 55.9065\n",
      "[1440]\ttraining's rmse: 2.23804\tvalid_1's rmse: 55.8999\n",
      "[1470]\ttraining's rmse: 2.13791\tvalid_1's rmse: 55.8949\n",
      "[1500]\ttraining's rmse: 2.042\tvalid_1's rmse: 55.8917\n",
      "[1530]\ttraining's rmse: 1.94999\tvalid_1's rmse: 55.8868\n",
      "[1560]\ttraining's rmse: 1.86286\tvalid_1's rmse: 55.8839\n",
      "[1590]\ttraining's rmse: 1.77887\tvalid_1's rmse: 55.8786\n",
      "[1620]\ttraining's rmse: 1.69735\tvalid_1's rmse: 55.8748\n",
      "[1650]\ttraining's rmse: 1.62045\tvalid_1's rmse: 55.8736\n",
      "[1680]\ttraining's rmse: 1.54989\tvalid_1's rmse: 55.8715\n",
      "[1710]\ttraining's rmse: 1.48113\tvalid_1's rmse: 55.8655\n",
      "[1740]\ttraining's rmse: 1.4161\tvalid_1's rmse: 55.8627\n",
      "[1770]\ttraining's rmse: 1.35411\tvalid_1's rmse: 55.8625\n",
      "[1800]\ttraining's rmse: 1.29359\tvalid_1's rmse: 55.8613\n",
      "[1830]\ttraining's rmse: 1.23717\tvalid_1's rmse: 55.8576\n",
      "[1860]\ttraining's rmse: 1.1838\tvalid_1's rmse: 55.8572\n",
      "[1890]\ttraining's rmse: 1.13143\tvalid_1's rmse: 55.8526\n",
      "[1920]\ttraining's rmse: 1.08095\tvalid_1's rmse: 55.8519\n",
      "[1950]\ttraining's rmse: 1.03343\tvalid_1's rmse: 55.8499\n",
      "[1980]\ttraining's rmse: 0.989743\tvalid_1's rmse: 55.8492\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's rmse: 0.961275\tvalid_1's rmse: 55.8478\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003359 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 20021\n",
      "[LightGBM] [Info] Number of data points in the train set: 9219, number of used features: 79\n",
      "[LightGBM] [Info] Start training from score 372.203804\n",
      "Training until validation scores don't improve for 125 rounds\n",
      "[30]\ttraining's rmse: 175.605\tvalid_1's rmse: 180.665\n",
      "[60]\ttraining's rmse: 107.013\tvalid_1's rmse: 118.175\n",
      "[90]\ttraining's rmse: 69.8436\tvalid_1's rmse: 87.1802\n",
      "[120]\ttraining's rmse: 49.76\tvalid_1's rmse: 72.4275\n",
      "[150]\ttraining's rmse: 38.801\tvalid_1's rmse: 65.9463\n",
      "[180]\ttraining's rmse: 32.4082\tvalid_1's rmse: 62.783\n",
      "[210]\ttraining's rmse: 28.0957\tvalid_1's rmse: 60.8387\n",
      "[240]\ttraining's rmse: 24.9287\tvalid_1's rmse: 59.5913\n",
      "[270]\ttraining's rmse: 22.4233\tvalid_1's rmse: 58.7156\n",
      "[300]\ttraining's rmse: 20.3705\tvalid_1's rmse: 58.0389\n",
      "[330]\ttraining's rmse: 18.6226\tvalid_1's rmse: 57.6306\n",
      "[360]\ttraining's rmse: 17.1245\tvalid_1's rmse: 57.4459\n",
      "[390]\ttraining's rmse: 15.8454\tvalid_1's rmse: 57.2887\n",
      "[420]\ttraining's rmse: 14.6955\tvalid_1's rmse: 57.1664\n",
      "[450]\ttraining's rmse: 13.6381\tvalid_1's rmse: 57.0398\n",
      "[480]\ttraining's rmse: 12.6945\tvalid_1's rmse: 56.8919\n",
      "[510]\ttraining's rmse: 11.8485\tvalid_1's rmse: 56.828\n",
      "[540]\ttraining's rmse: 11.0739\tvalid_1's rmse: 56.7853\n",
      "[570]\ttraining's rmse: 10.3581\tvalid_1's rmse: 56.6987\n",
      "[600]\ttraining's rmse: 9.69837\tvalid_1's rmse: 56.6337\n",
      "[630]\ttraining's rmse: 9.09647\tvalid_1's rmse: 56.5805\n",
      "[660]\ttraining's rmse: 8.55299\tvalid_1's rmse: 56.5669\n",
      "[690]\ttraining's rmse: 8.041\tvalid_1's rmse: 56.5523\n",
      "[720]\ttraining's rmse: 7.5725\tvalid_1's rmse: 56.5281\n",
      "[750]\ttraining's rmse: 7.13114\tvalid_1's rmse: 56.4901\n",
      "[780]\ttraining's rmse: 6.71144\tvalid_1's rmse: 56.4661\n",
      "[810]\ttraining's rmse: 6.33618\tvalid_1's rmse: 56.4397\n",
      "[840]\ttraining's rmse: 5.9829\tvalid_1's rmse: 56.4271\n",
      "[870]\ttraining's rmse: 5.65175\tvalid_1's rmse: 56.3906\n",
      "[900]\ttraining's rmse: 5.35407\tvalid_1's rmse: 56.3837\n",
      "[930]\ttraining's rmse: 5.06308\tvalid_1's rmse: 56.366\n",
      "[960]\ttraining's rmse: 4.78952\tvalid_1's rmse: 56.3555\n",
      "[990]\ttraining's rmse: 4.5413\tvalid_1's rmse: 56.3511\n",
      "[1020]\ttraining's rmse: 4.30315\tvalid_1's rmse: 56.3328\n",
      "[1050]\ttraining's rmse: 4.08129\tvalid_1's rmse: 56.3177\n",
      "[1080]\ttraining's rmse: 3.86343\tvalid_1's rmse: 56.3219\n",
      "[1110]\ttraining's rmse: 3.66162\tvalid_1's rmse: 56.3235\n",
      "[1140]\ttraining's rmse: 3.47403\tvalid_1's rmse: 56.3098\n",
      "[1170]\ttraining's rmse: 3.29946\tvalid_1's rmse: 56.3022\n",
      "[1200]\ttraining's rmse: 3.12966\tvalid_1's rmse: 56.2936\n",
      "[1230]\ttraining's rmse: 2.97227\tvalid_1's rmse: 56.2944\n",
      "[1260]\ttraining's rmse: 2.82198\tvalid_1's rmse: 56.2886\n",
      "[1290]\ttraining's rmse: 2.68243\tvalid_1's rmse: 56.2822\n",
      "[1320]\ttraining's rmse: 2.54967\tvalid_1's rmse: 56.2809\n",
      "[1350]\ttraining's rmse: 2.42064\tvalid_1's rmse: 56.2766\n",
      "[1380]\ttraining's rmse: 2.3012\tvalid_1's rmse: 56.272\n",
      "[1410]\ttraining's rmse: 2.18757\tvalid_1's rmse: 56.2671\n",
      "[1440]\ttraining's rmse: 2.07985\tvalid_1's rmse: 56.263\n",
      "[1470]\ttraining's rmse: 1.97909\tvalid_1's rmse: 56.2621\n",
      "[1500]\ttraining's rmse: 1.88236\tvalid_1's rmse: 56.2584\n",
      "[1530]\ttraining's rmse: 1.7904\tvalid_1's rmse: 56.2542\n",
      "[1560]\ttraining's rmse: 1.70436\tvalid_1's rmse: 56.2516\n",
      "[1590]\ttraining's rmse: 1.62188\tvalid_1's rmse: 56.2474\n",
      "[1620]\ttraining's rmse: 1.54544\tvalid_1's rmse: 56.2457\n",
      "[1650]\ttraining's rmse: 1.47322\tvalid_1's rmse: 56.2438\n",
      "[1680]\ttraining's rmse: 1.4038\tvalid_1's rmse: 56.2403\n",
      "[1710]\ttraining's rmse: 1.33741\tvalid_1's rmse: 56.2377\n",
      "[1740]\ttraining's rmse: 1.27423\tvalid_1's rmse: 56.2357\n",
      "[1770]\ttraining's rmse: 1.21449\tvalid_1's rmse: 56.2308\n",
      "[1800]\ttraining's rmse: 1.15851\tvalid_1's rmse: 56.2273\n",
      "[1830]\ttraining's rmse: 1.10421\tvalid_1's rmse: 56.2247\n",
      "[1860]\ttraining's rmse: 1.05365\tvalid_1's rmse: 56.2244\n",
      "[1890]\ttraining's rmse: 1.0052\tvalid_1's rmse: 56.2219\n",
      "[1920]\ttraining's rmse: 0.957892\tvalid_1's rmse: 56.2202\n",
      "[1950]\ttraining's rmse: 0.913991\tvalid_1's rmse: 56.2195\n",
      "[1980]\ttraining's rmse: 0.872375\tvalid_1's rmse: 56.2187\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's rmse: 0.846142\tvalid_1's rmse: 56.2181\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003801 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 20021\n",
      "[LightGBM] [Info] Number of data points in the train set: 9219, number of used features: 79\n",
      "[LightGBM] [Info] Start training from score 374.774056\n",
      "Training until validation scores don't improve for 125 rounds\n",
      "[30]\ttraining's rmse: 178.218\tvalid_1's rmse: 178.44\n",
      "[60]\ttraining's rmse: 109.336\tvalid_1's rmse: 114.508\n",
      "[90]\ttraining's rmse: 71.7111\tvalid_1's rmse: 82.2227\n",
      "[120]\ttraining's rmse: 51.3474\tvalid_1's rmse: 66.9223\n",
      "[150]\ttraining's rmse: 40.167\tvalid_1's rmse: 59.96\n",
      "[180]\ttraining's rmse: 33.5784\tvalid_1's rmse: 56.6253\n",
      "[210]\ttraining's rmse: 29.1118\tvalid_1's rmse: 54.6705\n",
      "[240]\ttraining's rmse: 25.8541\tvalid_1's rmse: 53.3935\n",
      "[270]\ttraining's rmse: 23.2943\tvalid_1's rmse: 52.3925\n",
      "[300]\ttraining's rmse: 21.1605\tvalid_1's rmse: 51.7311\n",
      "[330]\ttraining's rmse: 19.3961\tvalid_1's rmse: 51.3995\n",
      "[360]\ttraining's rmse: 17.8785\tvalid_1's rmse: 51.0936\n",
      "[390]\ttraining's rmse: 16.5362\tvalid_1's rmse: 50.8388\n",
      "[420]\ttraining's rmse: 15.3052\tvalid_1's rmse: 50.6459\n",
      "[450]\ttraining's rmse: 14.2351\tvalid_1's rmse: 50.4889\n",
      "[480]\ttraining's rmse: 13.2764\tvalid_1's rmse: 50.3451\n",
      "[510]\ttraining's rmse: 12.4114\tvalid_1's rmse: 50.2459\n",
      "[540]\ttraining's rmse: 11.6079\tvalid_1's rmse: 50.1839\n",
      "[570]\ttraining's rmse: 10.8747\tvalid_1's rmse: 50.0973\n",
      "[600]\ttraining's rmse: 10.2158\tvalid_1's rmse: 50.0342\n",
      "[630]\ttraining's rmse: 9.60522\tvalid_1's rmse: 49.9715\n",
      "[660]\ttraining's rmse: 9.0208\tvalid_1's rmse: 49.9123\n",
      "[690]\ttraining's rmse: 8.473\tvalid_1's rmse: 49.8728\n",
      "[720]\ttraining's rmse: 7.9758\tvalid_1's rmse: 49.8232\n",
      "[750]\ttraining's rmse: 7.5142\tvalid_1's rmse: 49.7891\n",
      "[780]\ttraining's rmse: 7.0889\tvalid_1's rmse: 49.7707\n",
      "[810]\ttraining's rmse: 6.68917\tvalid_1's rmse: 49.7518\n",
      "[840]\ttraining's rmse: 6.32503\tvalid_1's rmse: 49.7496\n",
      "[870]\ttraining's rmse: 5.97321\tvalid_1's rmse: 49.7292\n",
      "[900]\ttraining's rmse: 5.65304\tvalid_1's rmse: 49.712\n",
      "[930]\ttraining's rmse: 5.36364\tvalid_1's rmse: 49.7006\n",
      "[960]\ttraining's rmse: 5.08041\tvalid_1's rmse: 49.6742\n",
      "[990]\ttraining's rmse: 4.81208\tvalid_1's rmse: 49.6654\n",
      "[1020]\ttraining's rmse: 4.56154\tvalid_1's rmse: 49.6576\n",
      "[1050]\ttraining's rmse: 4.32585\tvalid_1's rmse: 49.6473\n",
      "[1080]\ttraining's rmse: 4.10382\tvalid_1's rmse: 49.6477\n",
      "[1110]\ttraining's rmse: 3.89792\tvalid_1's rmse: 49.6431\n",
      "[1140]\ttraining's rmse: 3.70176\tvalid_1's rmse: 49.6322\n",
      "[1170]\ttraining's rmse: 3.51828\tvalid_1's rmse: 49.6269\n",
      "[1200]\ttraining's rmse: 3.33862\tvalid_1's rmse: 49.6158\n",
      "[1230]\ttraining's rmse: 3.17612\tvalid_1's rmse: 49.5977\n",
      "[1260]\ttraining's rmse: 3.01546\tvalid_1's rmse: 49.5926\n",
      "[1290]\ttraining's rmse: 2.86624\tvalid_1's rmse: 49.5917\n",
      "[1320]\ttraining's rmse: 2.72565\tvalid_1's rmse: 49.5828\n",
      "[1350]\ttraining's rmse: 2.59458\tvalid_1's rmse: 49.5768\n",
      "[1380]\ttraining's rmse: 2.4665\tvalid_1's rmse: 49.5684\n",
      "[1410]\ttraining's rmse: 2.34965\tvalid_1's rmse: 49.5587\n",
      "[1440]\ttraining's rmse: 2.24237\tvalid_1's rmse: 49.5515\n",
      "[1470]\ttraining's rmse: 2.13624\tvalid_1's rmse: 49.5529\n",
      "[1500]\ttraining's rmse: 2.03691\tvalid_1's rmse: 49.5472\n",
      "[1530]\ttraining's rmse: 1.94228\tvalid_1's rmse: 49.5473\n",
      "[1560]\ttraining's rmse: 1.85157\tvalid_1's rmse: 49.5459\n",
      "[1590]\ttraining's rmse: 1.76905\tvalid_1's rmse: 49.5451\n",
      "[1620]\ttraining's rmse: 1.68895\tvalid_1's rmse: 49.5435\n",
      "[1650]\ttraining's rmse: 1.61529\tvalid_1's rmse: 49.5391\n",
      "[1680]\ttraining's rmse: 1.54138\tvalid_1's rmse: 49.5361\n",
      "[1710]\ttraining's rmse: 1.47119\tvalid_1's rmse: 49.5311\n",
      "[1740]\ttraining's rmse: 1.40713\tvalid_1's rmse: 49.5268\n",
      "[1770]\ttraining's rmse: 1.34366\tvalid_1's rmse: 49.5262\n",
      "[1800]\ttraining's rmse: 1.28572\tvalid_1's rmse: 49.5258\n",
      "[1830]\ttraining's rmse: 1.22856\tvalid_1's rmse: 49.5233\n",
      "[1860]\ttraining's rmse: 1.1731\tvalid_1's rmse: 49.5251\n",
      "[1890]\ttraining's rmse: 1.11919\tvalid_1's rmse: 49.5197\n",
      "[1920]\ttraining's rmse: 1.0722\tvalid_1's rmse: 49.5164\n",
      "[1950]\ttraining's rmse: 1.02697\tvalid_1's rmse: 49.5117\n",
      "[1980]\ttraining's rmse: 0.981966\tvalid_1's rmse: 49.5091\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's rmse: 0.954737\tvalid_1's rmse: 49.5066\n",
      "2\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002949 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 20022\n",
      "[LightGBM] [Info] Number of data points in the train set: 9219, number of used features: 79\n",
      "[LightGBM] [Info] Start training from score 374.635276\n",
      "Training until validation scores don't improve for 125 rounds\n",
      "[30]\ttraining's rmse: 175.219\tvalid_1's rmse: 179.315\n",
      "[60]\ttraining's rmse: 105.842\tvalid_1's rmse: 114.229\n",
      "[90]\ttraining's rmse: 68.4453\tvalid_1's rmse: 81.3827\n",
      "[120]\ttraining's rmse: 48.1905\tvalid_1's rmse: 65.7909\n",
      "[150]\ttraining's rmse: 37.2545\tvalid_1's rmse: 58.3931\n",
      "[180]\ttraining's rmse: 30.9572\tvalid_1's rmse: 54.8062\n",
      "[210]\ttraining's rmse: 26.8686\tvalid_1's rmse: 52.8031\n",
      "[240]\ttraining's rmse: 23.8192\tvalid_1's rmse: 51.4886\n",
      "[270]\ttraining's rmse: 21.483\tvalid_1's rmse: 50.7609\n",
      "[300]\ttraining's rmse: 19.5458\tvalid_1's rmse: 50.1909\n",
      "[330]\ttraining's rmse: 17.9374\tvalid_1's rmse: 49.8176\n",
      "[360]\ttraining's rmse: 16.5616\tvalid_1's rmse: 49.5294\n",
      "[390]\ttraining's rmse: 15.3227\tvalid_1's rmse: 49.2952\n",
      "[420]\ttraining's rmse: 14.1942\tvalid_1's rmse: 49.1077\n",
      "[450]\ttraining's rmse: 13.1956\tvalid_1's rmse: 48.9607\n",
      "[480]\ttraining's rmse: 12.286\tvalid_1's rmse: 48.8672\n",
      "[510]\ttraining's rmse: 11.4893\tvalid_1's rmse: 48.7472\n",
      "[540]\ttraining's rmse: 10.7427\tvalid_1's rmse: 48.7005\n",
      "[570]\ttraining's rmse: 10.0637\tvalid_1's rmse: 48.6761\n",
      "[600]\ttraining's rmse: 9.42936\tvalid_1's rmse: 48.616\n",
      "[630]\ttraining's rmse: 8.85721\tvalid_1's rmse: 48.5442\n",
      "[660]\ttraining's rmse: 8.31705\tvalid_1's rmse: 48.4881\n",
      "[690]\ttraining's rmse: 7.82692\tvalid_1's rmse: 48.468\n",
      "[720]\ttraining's rmse: 7.36944\tvalid_1's rmse: 48.4545\n",
      "[750]\ttraining's rmse: 6.93083\tvalid_1's rmse: 48.4542\n",
      "[780]\ttraining's rmse: 6.53093\tvalid_1's rmse: 48.4577\n",
      "[810]\ttraining's rmse: 6.15786\tvalid_1's rmse: 48.4376\n",
      "[840]\ttraining's rmse: 5.81392\tvalid_1's rmse: 48.4192\n",
      "[870]\ttraining's rmse: 5.49398\tvalid_1's rmse: 48.3987\n",
      "[900]\ttraining's rmse: 5.19564\tvalid_1's rmse: 48.3785\n",
      "[930]\ttraining's rmse: 4.91559\tvalid_1's rmse: 48.3786\n",
      "[960]\ttraining's rmse: 4.65094\tvalid_1's rmse: 48.3818\n",
      "[990]\ttraining's rmse: 4.40359\tvalid_1's rmse: 48.3642\n",
      "[1020]\ttraining's rmse: 4.17191\tvalid_1's rmse: 48.3608\n",
      "[1050]\ttraining's rmse: 3.95643\tvalid_1's rmse: 48.3557\n",
      "[1080]\ttraining's rmse: 3.74828\tvalid_1's rmse: 48.3457\n",
      "[1110]\ttraining's rmse: 3.55394\tvalid_1's rmse: 48.346\n",
      "[1140]\ttraining's rmse: 3.36914\tvalid_1's rmse: 48.3431\n",
      "[1170]\ttraining's rmse: 3.1975\tvalid_1's rmse: 48.3403\n",
      "[1200]\ttraining's rmse: 3.03588\tvalid_1's rmse: 48.3427\n",
      "[1230]\ttraining's rmse: 2.88306\tvalid_1's rmse: 48.3343\n",
      "[1260]\ttraining's rmse: 2.7381\tvalid_1's rmse: 48.3332\n",
      "[1290]\ttraining's rmse: 2.60097\tvalid_1's rmse: 48.3276\n",
      "[1320]\ttraining's rmse: 2.46914\tvalid_1's rmse: 48.3264\n",
      "[1350]\ttraining's rmse: 2.34587\tvalid_1's rmse: 48.3249\n",
      "[1380]\ttraining's rmse: 2.23144\tvalid_1's rmse: 48.3263\n",
      "[1410]\ttraining's rmse: 2.12207\tvalid_1's rmse: 48.3274\n",
      "[1440]\ttraining's rmse: 2.01863\tvalid_1's rmse: 48.3277\n",
      "[1470]\ttraining's rmse: 1.92023\tvalid_1's rmse: 48.3234\n",
      "[1500]\ttraining's rmse: 1.82834\tvalid_1's rmse: 48.3235\n",
      "[1530]\ttraining's rmse: 1.74047\tvalid_1's rmse: 48.3276\n",
      "[1560]\ttraining's rmse: 1.65482\tvalid_1's rmse: 48.325\n",
      "[1590]\ttraining's rmse: 1.5754\tvalid_1's rmse: 48.3221\n",
      "[1620]\ttraining's rmse: 1.50035\tvalid_1's rmse: 48.3241\n",
      "[1650]\ttraining's rmse: 1.42813\tvalid_1's rmse: 48.3242\n",
      "[1680]\ttraining's rmse: 1.36051\tvalid_1's rmse: 48.3235\n",
      "[1710]\ttraining's rmse: 1.29652\tvalid_1's rmse: 48.3237\n",
      "Early stopping, best iteration is:\n",
      "[1612]\ttraining's rmse: 1.51943\tvalid_1's rmse: 48.321\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003032 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 20022\n",
      "[LightGBM] [Info] Number of data points in the train set: 9219, number of used features: 79\n",
      "[LightGBM] [Info] Start training from score 375.079039\n",
      "Training until validation scores don't improve for 125 rounds\n",
      "[30]\ttraining's rmse: 175.664\tvalid_1's rmse: 184.58\n",
      "[60]\ttraining's rmse: 107.805\tvalid_1's rmse: 121.122\n",
      "[90]\ttraining's rmse: 71.0627\tvalid_1's rmse: 89.3533\n",
      "[120]\ttraining's rmse: 51.2596\tvalid_1's rmse: 74.1922\n",
      "[150]\ttraining's rmse: 40.2569\tvalid_1's rmse: 67.0173\n",
      "[180]\ttraining's rmse: 33.6598\tvalid_1's rmse: 63.4118\n",
      "[210]\ttraining's rmse: 29.2684\tvalid_1's rmse: 61.37\n",
      "[240]\ttraining's rmse: 25.9642\tvalid_1's rmse: 60.1367\n",
      "[270]\ttraining's rmse: 23.3894\tvalid_1's rmse: 59.4642\n",
      "[300]\ttraining's rmse: 21.2739\tvalid_1's rmse: 58.9571\n",
      "[330]\ttraining's rmse: 19.453\tvalid_1's rmse: 58.599\n",
      "[360]\ttraining's rmse: 17.8999\tvalid_1's rmse: 58.2699\n",
      "[390]\ttraining's rmse: 16.5388\tvalid_1's rmse: 57.9448\n",
      "[420]\ttraining's rmse: 15.324\tvalid_1's rmse: 57.7536\n",
      "[450]\ttraining's rmse: 14.2366\tvalid_1's rmse: 57.6109\n",
      "[480]\ttraining's rmse: 13.2602\tvalid_1's rmse: 57.4668\n",
      "[510]\ttraining's rmse: 12.3716\tvalid_1's rmse: 57.389\n",
      "[540]\ttraining's rmse: 11.5545\tvalid_1's rmse: 57.3247\n",
      "[570]\ttraining's rmse: 10.8194\tvalid_1's rmse: 57.2656\n",
      "[600]\ttraining's rmse: 10.136\tvalid_1's rmse: 57.1686\n",
      "[630]\ttraining's rmse: 9.51286\tvalid_1's rmse: 57.1327\n",
      "[660]\ttraining's rmse: 8.94203\tvalid_1's rmse: 57.0603\n",
      "[690]\ttraining's rmse: 8.40822\tvalid_1's rmse: 57.0389\n",
      "[720]\ttraining's rmse: 7.90516\tvalid_1's rmse: 57.0153\n",
      "[750]\ttraining's rmse: 7.44553\tvalid_1's rmse: 56.9848\n",
      "[780]\ttraining's rmse: 7.02073\tvalid_1's rmse: 56.9435\n",
      "[810]\ttraining's rmse: 6.62205\tvalid_1's rmse: 56.9055\n",
      "[840]\ttraining's rmse: 6.26523\tvalid_1's rmse: 56.869\n",
      "[870]\ttraining's rmse: 5.91959\tvalid_1's rmse: 56.8406\n",
      "[900]\ttraining's rmse: 5.59789\tvalid_1's rmse: 56.7979\n",
      "[930]\ttraining's rmse: 5.29603\tvalid_1's rmse: 56.7694\n",
      "[960]\ttraining's rmse: 5.01309\tvalid_1's rmse: 56.7537\n",
      "[990]\ttraining's rmse: 4.74911\tvalid_1's rmse: 56.7429\n",
      "[1020]\ttraining's rmse: 4.50837\tvalid_1's rmse: 56.7169\n",
      "[1050]\ttraining's rmse: 4.27859\tvalid_1's rmse: 56.688\n",
      "[1080]\ttraining's rmse: 4.05907\tvalid_1's rmse: 56.6738\n",
      "[1110]\ttraining's rmse: 3.85351\tvalid_1's rmse: 56.6627\n",
      "[1140]\ttraining's rmse: 3.66056\tvalid_1's rmse: 56.643\n",
      "[1170]\ttraining's rmse: 3.48076\tvalid_1's rmse: 56.6254\n",
      "[1200]\ttraining's rmse: 3.30444\tvalid_1's rmse: 56.6115\n",
      "[1230]\ttraining's rmse: 3.14139\tvalid_1's rmse: 56.6101\n",
      "[1260]\ttraining's rmse: 2.98811\tvalid_1's rmse: 56.593\n",
      "[1290]\ttraining's rmse: 2.83903\tvalid_1's rmse: 56.5819\n",
      "[1320]\ttraining's rmse: 2.70081\tvalid_1's rmse: 56.5737\n",
      "[1350]\ttraining's rmse: 2.5704\tvalid_1's rmse: 56.5599\n",
      "[1380]\ttraining's rmse: 2.4453\tvalid_1's rmse: 56.5599\n",
      "[1410]\ttraining's rmse: 2.3261\tvalid_1's rmse: 56.5525\n",
      "[1440]\ttraining's rmse: 2.21577\tvalid_1's rmse: 56.5472\n",
      "[1470]\ttraining's rmse: 2.11105\tvalid_1's rmse: 56.5391\n",
      "[1500]\ttraining's rmse: 2.01198\tvalid_1's rmse: 56.53\n",
      "[1530]\ttraining's rmse: 1.91979\tvalid_1's rmse: 56.5242\n",
      "[1560]\ttraining's rmse: 1.83309\tvalid_1's rmse: 56.5194\n",
      "[1590]\ttraining's rmse: 1.74944\tvalid_1's rmse: 56.5176\n",
      "[1620]\ttraining's rmse: 1.67016\tvalid_1's rmse: 56.5156\n",
      "[1650]\ttraining's rmse: 1.59615\tvalid_1's rmse: 56.5122\n",
      "[1680]\ttraining's rmse: 1.52468\tvalid_1's rmse: 56.5089\n",
      "[1710]\ttraining's rmse: 1.45539\tvalid_1's rmse: 56.5071\n",
      "[1740]\ttraining's rmse: 1.38942\tvalid_1's rmse: 56.5039\n",
      "[1770]\ttraining's rmse: 1.32721\tvalid_1's rmse: 56.5017\n",
      "[1800]\ttraining's rmse: 1.27012\tvalid_1's rmse: 56.4991\n",
      "[1830]\ttraining's rmse: 1.21311\tvalid_1's rmse: 56.4966\n",
      "[1860]\ttraining's rmse: 1.15972\tvalid_1's rmse: 56.4932\n",
      "[1890]\ttraining's rmse: 1.10905\tvalid_1's rmse: 56.49\n",
      "[1920]\ttraining's rmse: 1.06114\tvalid_1's rmse: 56.4871\n",
      "[1950]\ttraining's rmse: 1.01529\tvalid_1's rmse: 56.4836\n",
      "[1980]\ttraining's rmse: 0.969861\tvalid_1's rmse: 56.4826\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's rmse: 0.94158\tvalid_1's rmse: 56.4806\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004122 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 20022\n",
      "[LightGBM] [Info] Number of data points in the train set: 9219, number of used features: 79\n",
      "[LightGBM] [Info] Start training from score 371.342398\n",
      "Training until validation scores don't improve for 125 rounds\n",
      "[30]\ttraining's rmse: 175.886\tvalid_1's rmse: 184.667\n",
      "[60]\ttraining's rmse: 107.316\tvalid_1's rmse: 119.704\n",
      "[90]\ttraining's rmse: 70.215\tvalid_1's rmse: 87.1717\n",
      "[120]\ttraining's rmse: 50.229\tvalid_1's rmse: 71.3401\n",
      "[150]\ttraining's rmse: 39.2911\tvalid_1's rmse: 63.7823\n",
      "[180]\ttraining's rmse: 32.9009\tvalid_1's rmse: 60.2662\n",
      "[210]\ttraining's rmse: 28.6324\tvalid_1's rmse: 58.2513\n",
      "[240]\ttraining's rmse: 25.4445\tvalid_1's rmse: 56.9491\n",
      "[270]\ttraining's rmse: 22.9542\tvalid_1's rmse: 55.9429\n",
      "[300]\ttraining's rmse: 20.8748\tvalid_1's rmse: 55.3442\n",
      "[330]\ttraining's rmse: 19.1167\tvalid_1's rmse: 54.8257\n",
      "[360]\ttraining's rmse: 17.6166\tvalid_1's rmse: 54.5022\n",
      "[390]\ttraining's rmse: 16.2777\tvalid_1's rmse: 54.1576\n",
      "[420]\ttraining's rmse: 15.072\tvalid_1's rmse: 53.9303\n",
      "[450]\ttraining's rmse: 14.0133\tvalid_1's rmse: 53.7032\n",
      "[480]\ttraining's rmse: 13.0748\tvalid_1's rmse: 53.5308\n",
      "[510]\ttraining's rmse: 12.2197\tvalid_1's rmse: 53.4322\n",
      "[540]\ttraining's rmse: 11.4196\tvalid_1's rmse: 53.3459\n",
      "[570]\ttraining's rmse: 10.691\tvalid_1's rmse: 53.246\n",
      "[600]\ttraining's rmse: 10.0196\tvalid_1's rmse: 53.1952\n",
      "[630]\ttraining's rmse: 9.40668\tvalid_1's rmse: 53.1165\n",
      "[660]\ttraining's rmse: 8.84873\tvalid_1's rmse: 53.0457\n",
      "[690]\ttraining's rmse: 8.33666\tvalid_1's rmse: 52.9847\n",
      "[720]\ttraining's rmse: 7.87341\tvalid_1's rmse: 52.9473\n",
      "[750]\ttraining's rmse: 7.42128\tvalid_1's rmse: 52.8956\n",
      "[780]\ttraining's rmse: 7.00127\tvalid_1's rmse: 52.8519\n",
      "[810]\ttraining's rmse: 6.61192\tvalid_1's rmse: 52.7861\n",
      "[840]\ttraining's rmse: 6.24535\tvalid_1's rmse: 52.7578\n",
      "[870]\ttraining's rmse: 5.90555\tvalid_1's rmse: 52.7181\n",
      "[900]\ttraining's rmse: 5.59387\tvalid_1's rmse: 52.7011\n",
      "[930]\ttraining's rmse: 5.30194\tvalid_1's rmse: 52.6789\n",
      "[960]\ttraining's rmse: 5.03271\tvalid_1's rmse: 52.6573\n",
      "[990]\ttraining's rmse: 4.77393\tvalid_1's rmse: 52.6496\n",
      "[1020]\ttraining's rmse: 4.53111\tvalid_1's rmse: 52.6368\n",
      "[1050]\ttraining's rmse: 4.30094\tvalid_1's rmse: 52.6162\n",
      "[1080]\ttraining's rmse: 4.09025\tvalid_1's rmse: 52.6121\n",
      "[1110]\ttraining's rmse: 3.89036\tvalid_1's rmse: 52.5912\n",
      "[1140]\ttraining's rmse: 3.69571\tvalid_1's rmse: 52.5718\n",
      "[1170]\ttraining's rmse: 3.51815\tvalid_1's rmse: 52.5661\n",
      "[1200]\ttraining's rmse: 3.34783\tvalid_1's rmse: 52.5574\n",
      "[1230]\ttraining's rmse: 3.18488\tvalid_1's rmse: 52.5496\n",
      "[1260]\ttraining's rmse: 3.02971\tvalid_1's rmse: 52.5368\n",
      "[1290]\ttraining's rmse: 2.88425\tvalid_1's rmse: 52.5287\n",
      "[1320]\ttraining's rmse: 2.74443\tvalid_1's rmse: 52.5252\n",
      "[1350]\ttraining's rmse: 2.61343\tvalid_1's rmse: 52.5185\n",
      "[1380]\ttraining's rmse: 2.49169\tvalid_1's rmse: 52.5153\n",
      "[1410]\ttraining's rmse: 2.37448\tvalid_1's rmse: 52.5044\n",
      "[1440]\ttraining's rmse: 2.26534\tvalid_1's rmse: 52.4959\n",
      "[1470]\ttraining's rmse: 2.16208\tvalid_1's rmse: 52.4926\n",
      "[1500]\ttraining's rmse: 2.06317\tvalid_1's rmse: 52.4856\n",
      "[1530]\ttraining's rmse: 1.96887\tvalid_1's rmse: 52.4766\n",
      "[1560]\ttraining's rmse: 1.88067\tvalid_1's rmse: 52.4703\n",
      "[1590]\ttraining's rmse: 1.79707\tvalid_1's rmse: 52.4613\n",
      "[1620]\ttraining's rmse: 1.71609\tvalid_1's rmse: 52.4575\n",
      "[1650]\ttraining's rmse: 1.63994\tvalid_1's rmse: 52.4529\n",
      "[1680]\ttraining's rmse: 1.56437\tvalid_1's rmse: 52.447\n",
      "[1710]\ttraining's rmse: 1.49648\tvalid_1's rmse: 52.4438\n",
      "[1740]\ttraining's rmse: 1.43276\tvalid_1's rmse: 52.4389\n",
      "[1770]\ttraining's rmse: 1.36909\tvalid_1's rmse: 52.436\n",
      "[1800]\ttraining's rmse: 1.31048\tvalid_1's rmse: 52.4339\n",
      "[1830]\ttraining's rmse: 1.25294\tvalid_1's rmse: 52.4294\n",
      "[1860]\ttraining's rmse: 1.19949\tvalid_1's rmse: 52.4263\n",
      "[1890]\ttraining's rmse: 1.14718\tvalid_1's rmse: 52.4239\n",
      "[1920]\ttraining's rmse: 1.09853\tvalid_1's rmse: 52.4231\n",
      "[1950]\ttraining's rmse: 1.05256\tvalid_1's rmse: 52.4205\n",
      "[1980]\ttraining's rmse: 1.00833\tvalid_1's rmse: 52.4203\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's rmse: 0.980574\tvalid_1's rmse: 52.4188\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003624 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 20022\n",
      "[LightGBM] [Info] Number of data points in the train set: 9219, number of used features: 79\n",
      "[LightGBM] [Info] Start training from score 372.672896\n",
      "Training until validation scores don't improve for 125 rounds\n",
      "[30]\ttraining's rmse: 175.152\tvalid_1's rmse: 185.096\n",
      "[60]\ttraining's rmse: 107.012\tvalid_1's rmse: 119.757\n",
      "[90]\ttraining's rmse: 70.1361\tvalid_1's rmse: 87.0436\n",
      "[120]\ttraining's rmse: 50.2899\tvalid_1's rmse: 71.128\n",
      "[150]\ttraining's rmse: 39.5436\tvalid_1's rmse: 63.4611\n",
      "[180]\ttraining's rmse: 33.095\tvalid_1's rmse: 59.6049\n",
      "[210]\ttraining's rmse: 28.8009\tvalid_1's rmse: 57.5079\n",
      "[240]\ttraining's rmse: 25.6601\tvalid_1's rmse: 56.1135\n",
      "[270]\ttraining's rmse: 23.1076\tvalid_1's rmse: 55.1742\n",
      "[300]\ttraining's rmse: 21.0273\tvalid_1's rmse: 54.4231\n",
      "[330]\ttraining's rmse: 19.2656\tvalid_1's rmse: 53.9857\n",
      "[360]\ttraining's rmse: 17.7444\tvalid_1's rmse: 53.6833\n",
      "[390]\ttraining's rmse: 16.4041\tvalid_1's rmse: 53.3497\n",
      "[420]\ttraining's rmse: 15.1942\tvalid_1's rmse: 53.1444\n",
      "[450]\ttraining's rmse: 14.0953\tvalid_1's rmse: 52.9183\n",
      "[480]\ttraining's rmse: 13.1181\tvalid_1's rmse: 52.7398\n",
      "[510]\ttraining's rmse: 12.2422\tvalid_1's rmse: 52.6365\n",
      "[540]\ttraining's rmse: 11.4336\tvalid_1's rmse: 52.5213\n",
      "[570]\ttraining's rmse: 10.7131\tvalid_1's rmse: 52.4037\n",
      "[600]\ttraining's rmse: 10.0435\tvalid_1's rmse: 52.3471\n",
      "[630]\ttraining's rmse: 9.42303\tvalid_1's rmse: 52.2623\n",
      "[660]\ttraining's rmse: 8.84804\tvalid_1's rmse: 52.2078\n",
      "[690]\ttraining's rmse: 8.31587\tvalid_1's rmse: 52.165\n",
      "[720]\ttraining's rmse: 7.83013\tvalid_1's rmse: 52.1411\n",
      "[750]\ttraining's rmse: 7.37136\tvalid_1's rmse: 52.0986\n",
      "[780]\ttraining's rmse: 6.95407\tvalid_1's rmse: 52.0551\n",
      "[810]\ttraining's rmse: 6.56033\tvalid_1's rmse: 52.0355\n",
      "[840]\ttraining's rmse: 6.1877\tvalid_1's rmse: 52.0192\n",
      "[870]\ttraining's rmse: 5.84629\tvalid_1's rmse: 52.0027\n",
      "[900]\ttraining's rmse: 5.52287\tvalid_1's rmse: 51.9693\n",
      "[930]\ttraining's rmse: 5.2189\tvalid_1's rmse: 51.9319\n",
      "[960]\ttraining's rmse: 4.93778\tvalid_1's rmse: 51.9034\n",
      "[990]\ttraining's rmse: 4.67831\tvalid_1's rmse: 51.9176\n",
      "[1020]\ttraining's rmse: 4.43204\tvalid_1's rmse: 51.8891\n",
      "[1050]\ttraining's rmse: 4.1958\tvalid_1's rmse: 51.8726\n",
      "[1080]\ttraining's rmse: 3.97446\tvalid_1's rmse: 51.8541\n",
      "[1110]\ttraining's rmse: 3.76752\tvalid_1's rmse: 51.8365\n",
      "[1140]\ttraining's rmse: 3.56919\tvalid_1's rmse: 51.8299\n",
      "[1170]\ttraining's rmse: 3.39184\tvalid_1's rmse: 51.8191\n",
      "[1200]\ttraining's rmse: 3.21911\tvalid_1's rmse: 51.8087\n",
      "[1230]\ttraining's rmse: 3.05949\tvalid_1's rmse: 51.8034\n",
      "[1260]\ttraining's rmse: 2.90123\tvalid_1's rmse: 51.8025\n",
      "[1290]\ttraining's rmse: 2.75635\tvalid_1's rmse: 51.7884\n",
      "[1320]\ttraining's rmse: 2.61975\tvalid_1's rmse: 51.7846\n",
      "[1350]\ttraining's rmse: 2.48729\tvalid_1's rmse: 51.7733\n",
      "[1380]\ttraining's rmse: 2.36626\tvalid_1's rmse: 51.7642\n",
      "[1410]\ttraining's rmse: 2.25081\tvalid_1's rmse: 51.7595\n",
      "[1440]\ttraining's rmse: 2.14191\tvalid_1's rmse: 51.7526\n",
      "[1470]\ttraining's rmse: 2.03997\tvalid_1's rmse: 51.7468\n",
      "[1500]\ttraining's rmse: 1.93937\tvalid_1's rmse: 51.7402\n",
      "[1530]\ttraining's rmse: 1.84469\tvalid_1's rmse: 51.7354\n",
      "[1560]\ttraining's rmse: 1.7567\tvalid_1's rmse: 51.7297\n",
      "[1590]\ttraining's rmse: 1.67349\tvalid_1's rmse: 51.724\n",
      "[1620]\ttraining's rmse: 1.5949\tvalid_1's rmse: 51.7231\n",
      "[1650]\ttraining's rmse: 1.51918\tvalid_1's rmse: 51.7235\n",
      "[1680]\ttraining's rmse: 1.44667\tvalid_1's rmse: 51.7187\n",
      "[1710]\ttraining's rmse: 1.37804\tvalid_1's rmse: 51.7175\n",
      "[1740]\ttraining's rmse: 1.31293\tvalid_1's rmse: 51.7167\n",
      "[1770]\ttraining's rmse: 1.25093\tvalid_1's rmse: 51.7154\n",
      "[1800]\ttraining's rmse: 1.19328\tvalid_1's rmse: 51.7121\n",
      "[1830]\ttraining's rmse: 1.13701\tvalid_1's rmse: 51.7084\n",
      "[1860]\ttraining's rmse: 1.08444\tvalid_1's rmse: 51.7056\n",
      "[1890]\ttraining's rmse: 1.03565\tvalid_1's rmse: 51.7027\n",
      "[1920]\ttraining's rmse: 0.988468\tvalid_1's rmse: 51.7008\n",
      "[1950]\ttraining's rmse: 0.94237\tvalid_1's rmse: 51.7\n",
      "[1980]\ttraining's rmse: 0.899318\tvalid_1's rmse: 51.6972\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's rmse: 0.87165\tvalid_1's rmse: 51.6967\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003779 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 20022\n",
      "[LightGBM] [Info] Number of data points in the train set: 9219, number of used features: 79\n",
      "[LightGBM] [Info] Start training from score 368.883862\n",
      "Training until validation scores don't improve for 125 rounds\n",
      "[30]\ttraining's rmse: 176.221\tvalid_1's rmse: 183.663\n",
      "[60]\ttraining's rmse: 108.015\tvalid_1's rmse: 120.717\n",
      "[90]\ttraining's rmse: 70.9631\tvalid_1's rmse: 89.1466\n",
      "[120]\ttraining's rmse: 50.7602\tvalid_1's rmse: 74.0783\n",
      "[150]\ttraining's rmse: 39.9407\tvalid_1's rmse: 67.0427\n",
      "[180]\ttraining's rmse: 33.5339\tvalid_1's rmse: 63.6156\n",
      "[210]\ttraining's rmse: 29.2006\tvalid_1's rmse: 61.5099\n",
      "[240]\ttraining's rmse: 25.9674\tvalid_1's rmse: 60.096\n",
      "[270]\ttraining's rmse: 23.3455\tvalid_1's rmse: 59.023\n",
      "[300]\ttraining's rmse: 21.2386\tvalid_1's rmse: 58.3051\n",
      "[330]\ttraining's rmse: 19.4454\tvalid_1's rmse: 57.7741\n",
      "[360]\ttraining's rmse: 17.9027\tvalid_1's rmse: 57.482\n",
      "[390]\ttraining's rmse: 16.5337\tvalid_1's rmse: 57.184\n",
      "[420]\ttraining's rmse: 15.3354\tvalid_1's rmse: 56.9413\n",
      "[450]\ttraining's rmse: 14.2431\tvalid_1's rmse: 56.7934\n",
      "[480]\ttraining's rmse: 13.2646\tvalid_1's rmse: 56.6161\n",
      "[510]\ttraining's rmse: 12.3945\tvalid_1's rmse: 56.4549\n",
      "[540]\ttraining's rmse: 11.5874\tvalid_1's rmse: 56.3274\n",
      "[570]\ttraining's rmse: 10.8596\tvalid_1's rmse: 56.2191\n",
      "[600]\ttraining's rmse: 10.1771\tvalid_1's rmse: 56.1516\n",
      "[630]\ttraining's rmse: 9.55983\tvalid_1's rmse: 56.0953\n",
      "[660]\ttraining's rmse: 8.97392\tvalid_1's rmse: 56.0163\n",
      "[690]\ttraining's rmse: 8.44133\tvalid_1's rmse: 55.9696\n",
      "[720]\ttraining's rmse: 7.96381\tvalid_1's rmse: 55.923\n",
      "[750]\ttraining's rmse: 7.50869\tvalid_1's rmse: 55.8662\n",
      "[780]\ttraining's rmse: 7.0801\tvalid_1's rmse: 55.8271\n",
      "[810]\ttraining's rmse: 6.68333\tvalid_1's rmse: 55.7858\n",
      "[840]\ttraining's rmse: 6.32347\tvalid_1's rmse: 55.7744\n",
      "[870]\ttraining's rmse: 5.98197\tvalid_1's rmse: 55.7431\n",
      "[900]\ttraining's rmse: 5.66209\tvalid_1's rmse: 55.7065\n",
      "[930]\ttraining's rmse: 5.36192\tvalid_1's rmse: 55.692\n",
      "[960]\ttraining's rmse: 5.08444\tvalid_1's rmse: 55.6626\n",
      "[990]\ttraining's rmse: 4.81843\tvalid_1's rmse: 55.6446\n",
      "[1020]\ttraining's rmse: 4.56902\tvalid_1's rmse: 55.6312\n",
      "[1050]\ttraining's rmse: 4.33855\tvalid_1's rmse: 55.6224\n",
      "[1080]\ttraining's rmse: 4.11663\tvalid_1's rmse: 55.6197\n",
      "[1110]\ttraining's rmse: 3.91494\tvalid_1's rmse: 55.6027\n",
      "[1140]\ttraining's rmse: 3.72066\tvalid_1's rmse: 55.5983\n",
      "[1170]\ttraining's rmse: 3.53635\tvalid_1's rmse: 55.5827\n",
      "[1200]\ttraining's rmse: 3.36673\tvalid_1's rmse: 55.5733\n",
      "[1230]\ttraining's rmse: 3.20134\tvalid_1's rmse: 55.564\n",
      "[1260]\ttraining's rmse: 3.04736\tvalid_1's rmse: 55.5599\n",
      "[1290]\ttraining's rmse: 2.8996\tvalid_1's rmse: 55.5569\n",
      "[1320]\ttraining's rmse: 2.76073\tvalid_1's rmse: 55.5481\n",
      "[1350]\ttraining's rmse: 2.63343\tvalid_1's rmse: 55.5434\n",
      "[1380]\ttraining's rmse: 2.51149\tvalid_1's rmse: 55.5451\n",
      "[1410]\ttraining's rmse: 2.39537\tvalid_1's rmse: 55.5458\n",
      "[1440]\ttraining's rmse: 2.28304\tvalid_1's rmse: 55.5455\n",
      "[1470]\ttraining's rmse: 2.17926\tvalid_1's rmse: 55.5389\n",
      "[1500]\ttraining's rmse: 2.08207\tvalid_1's rmse: 55.5315\n",
      "[1530]\ttraining's rmse: 1.98582\tvalid_1's rmse: 55.5251\n",
      "[1560]\ttraining's rmse: 1.89662\tvalid_1's rmse: 55.5229\n",
      "[1590]\ttraining's rmse: 1.81179\tvalid_1's rmse: 55.5181\n",
      "[1620]\ttraining's rmse: 1.73041\tvalid_1's rmse: 55.5137\n",
      "[1650]\ttraining's rmse: 1.65416\tvalid_1's rmse: 55.51\n",
      "[1680]\ttraining's rmse: 1.58205\tvalid_1's rmse: 55.508\n",
      "[1710]\ttraining's rmse: 1.51373\tvalid_1's rmse: 55.5073\n",
      "[1740]\ttraining's rmse: 1.44759\tvalid_1's rmse: 55.505\n",
      "[1770]\ttraining's rmse: 1.38563\tvalid_1's rmse: 55.5046\n",
      "[1800]\ttraining's rmse: 1.32628\tvalid_1's rmse: 55.5017\n",
      "[1830]\ttraining's rmse: 1.26913\tvalid_1's rmse: 55.5005\n",
      "[1860]\ttraining's rmse: 1.21236\tvalid_1's rmse: 55.4977\n",
      "[1890]\ttraining's rmse: 1.16035\tvalid_1's rmse: 55.4961\n",
      "[1920]\ttraining's rmse: 1.11238\tvalid_1's rmse: 55.4917\n",
      "[1950]\ttraining's rmse: 1.06402\tvalid_1's rmse: 55.4911\n",
      "[1980]\ttraining's rmse: 1.01911\tvalid_1's rmse: 55.4896\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's rmse: 0.990375\tvalid_1's rmse: 55.4885\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003516 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 20022\n",
      "[LightGBM] [Info] Number of data points in the train set: 9219, number of used features: 79\n",
      "[LightGBM] [Info] Start training from score 370.840749\n",
      "Training until validation scores don't improve for 125 rounds\n",
      "[30]\ttraining's rmse: 176.282\tvalid_1's rmse: 181.241\n",
      "[60]\ttraining's rmse: 107.32\tvalid_1's rmse: 118.818\n",
      "[90]\ttraining's rmse: 69.7813\tvalid_1's rmse: 87.6624\n",
      "[120]\ttraining's rmse: 49.6111\tvalid_1's rmse: 72.7087\n",
      "[150]\ttraining's rmse: 38.7076\tvalid_1's rmse: 65.6142\n",
      "[180]\ttraining's rmse: 32.4283\tvalid_1's rmse: 61.8372\n",
      "[210]\ttraining's rmse: 28.2489\tvalid_1's rmse: 59.6315\n",
      "[240]\ttraining's rmse: 25.2078\tvalid_1's rmse: 58.1141\n",
      "[270]\ttraining's rmse: 22.6812\tvalid_1's rmse: 57.1195\n",
      "[300]\ttraining's rmse: 20.6492\tvalid_1's rmse: 56.3815\n",
      "[330]\ttraining's rmse: 18.9742\tvalid_1's rmse: 55.8219\n",
      "[360]\ttraining's rmse: 17.4898\tvalid_1's rmse: 55.4877\n",
      "[390]\ttraining's rmse: 16.1663\tvalid_1's rmse: 55.1585\n",
      "[420]\ttraining's rmse: 15\tvalid_1's rmse: 54.9551\n",
      "[450]\ttraining's rmse: 13.9555\tvalid_1's rmse: 54.7262\n",
      "[480]\ttraining's rmse: 12.9986\tvalid_1's rmse: 54.6066\n",
      "[510]\ttraining's rmse: 12.1335\tvalid_1's rmse: 54.5097\n",
      "[540]\ttraining's rmse: 11.3426\tvalid_1's rmse: 54.3927\n",
      "[570]\ttraining's rmse: 10.6195\tvalid_1's rmse: 54.3072\n",
      "[600]\ttraining's rmse: 9.96229\tvalid_1's rmse: 54.2171\n",
      "[630]\ttraining's rmse: 9.35161\tvalid_1's rmse: 54.115\n",
      "[660]\ttraining's rmse: 8.79085\tvalid_1's rmse: 54.0681\n",
      "[690]\ttraining's rmse: 8.26799\tvalid_1's rmse: 54.0269\n",
      "[720]\ttraining's rmse: 7.7891\tvalid_1's rmse: 53.985\n",
      "[750]\ttraining's rmse: 7.34337\tvalid_1's rmse: 53.9404\n",
      "[780]\ttraining's rmse: 6.92399\tvalid_1's rmse: 53.8995\n",
      "[810]\ttraining's rmse: 6.54067\tvalid_1's rmse: 53.8734\n",
      "[840]\ttraining's rmse: 6.17884\tvalid_1's rmse: 53.8491\n",
      "[870]\ttraining's rmse: 5.84492\tvalid_1's rmse: 53.8111\n",
      "[900]\ttraining's rmse: 5.52917\tvalid_1's rmse: 53.7859\n",
      "[930]\ttraining's rmse: 5.2413\tvalid_1's rmse: 53.7581\n",
      "[960]\ttraining's rmse: 4.95535\tvalid_1's rmse: 53.7414\n",
      "[990]\ttraining's rmse: 4.69628\tvalid_1's rmse: 53.7124\n",
      "[1020]\ttraining's rmse: 4.44469\tvalid_1's rmse: 53.6911\n",
      "[1050]\ttraining's rmse: 4.21684\tvalid_1's rmse: 53.6728\n",
      "[1080]\ttraining's rmse: 3.99944\tvalid_1's rmse: 53.6589\n",
      "[1110]\ttraining's rmse: 3.79865\tvalid_1's rmse: 53.6458\n",
      "[1140]\ttraining's rmse: 3.60586\tvalid_1's rmse: 53.6335\n",
      "[1170]\ttraining's rmse: 3.4199\tvalid_1's rmse: 53.6227\n",
      "[1200]\ttraining's rmse: 3.25301\tvalid_1's rmse: 53.6166\n",
      "[1230]\ttraining's rmse: 3.09095\tvalid_1's rmse: 53.6057\n",
      "[1260]\ttraining's rmse: 2.9435\tvalid_1's rmse: 53.5991\n",
      "[1290]\ttraining's rmse: 2.80166\tvalid_1's rmse: 53.5906\n",
      "[1320]\ttraining's rmse: 2.66295\tvalid_1's rmse: 53.5846\n",
      "[1350]\ttraining's rmse: 2.53533\tvalid_1's rmse: 53.5766\n",
      "[1380]\ttraining's rmse: 2.41434\tvalid_1's rmse: 53.5677\n",
      "[1410]\ttraining's rmse: 2.29716\tvalid_1's rmse: 53.5636\n",
      "[1440]\ttraining's rmse: 2.18742\tvalid_1's rmse: 53.555\n",
      "[1470]\ttraining's rmse: 2.08447\tvalid_1's rmse: 53.5504\n",
      "[1500]\ttraining's rmse: 1.98574\tvalid_1's rmse: 53.5442\n",
      "[1530]\ttraining's rmse: 1.89372\tvalid_1's rmse: 53.5323\n",
      "[1560]\ttraining's rmse: 1.80508\tvalid_1's rmse: 53.5284\n",
      "[1590]\ttraining's rmse: 1.72364\tvalid_1's rmse: 53.5251\n",
      "[1620]\ttraining's rmse: 1.64404\tvalid_1's rmse: 53.5183\n",
      "[1650]\ttraining's rmse: 1.56875\tvalid_1's rmse: 53.5138\n",
      "[1680]\ttraining's rmse: 1.49761\tvalid_1's rmse: 53.5127\n",
      "[1710]\ttraining's rmse: 1.43084\tvalid_1's rmse: 53.5075\n",
      "[1740]\ttraining's rmse: 1.36804\tvalid_1's rmse: 53.5052\n",
      "[1770]\ttraining's rmse: 1.30687\tvalid_1's rmse: 53.5038\n",
      "[1800]\ttraining's rmse: 1.24914\tvalid_1's rmse: 53.5028\n",
      "[1830]\ttraining's rmse: 1.192\tvalid_1's rmse: 53.5025\n",
      "[1860]\ttraining's rmse: 1.13832\tvalid_1's rmse: 53.5017\n",
      "[1890]\ttraining's rmse: 1.08956\tvalid_1's rmse: 53.5013\n",
      "[1920]\ttraining's rmse: 1.04249\tvalid_1's rmse: 53.5013\n",
      "[1950]\ttraining's rmse: 0.997285\tvalid_1's rmse: 53.4988\n",
      "[1980]\ttraining's rmse: 0.954575\tvalid_1's rmse: 53.496\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's rmse: 0.927358\tvalid_1's rmse: 53.4952\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003555 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 20022\n",
      "[LightGBM] [Info] Number of data points in the train set: 9219, number of used features: 79\n",
      "[LightGBM] [Info] Start training from score 373.489213\n",
      "Training until validation scores don't improve for 125 rounds\n",
      "[30]\ttraining's rmse: 176.956\tvalid_1's rmse: 181.418\n",
      "[60]\ttraining's rmse: 108.337\tvalid_1's rmse: 119.083\n",
      "[90]\ttraining's rmse: 70.8828\tvalid_1's rmse: 87.1438\n",
      "[120]\ttraining's rmse: 50.7639\tvalid_1's rmse: 71.7702\n",
      "[150]\ttraining's rmse: 39.762\tvalid_1's rmse: 64.438\n",
      "[180]\ttraining's rmse: 33.2674\tvalid_1's rmse: 60.9941\n",
      "[210]\ttraining's rmse: 28.9182\tvalid_1's rmse: 59.0193\n",
      "[240]\ttraining's rmse: 25.6676\tvalid_1's rmse: 57.9673\n",
      "[270]\ttraining's rmse: 23.1128\tvalid_1's rmse: 57.1972\n",
      "[300]\ttraining's rmse: 21.0211\tvalid_1's rmse: 56.8027\n",
      "[330]\ttraining's rmse: 19.245\tvalid_1's rmse: 56.543\n",
      "[360]\ttraining's rmse: 17.7338\tvalid_1's rmse: 56.2785\n",
      "[390]\ttraining's rmse: 16.4059\tvalid_1's rmse: 56.1894\n",
      "[420]\ttraining's rmse: 15.2013\tvalid_1's rmse: 56.0428\n",
      "[450]\ttraining's rmse: 14.1163\tvalid_1's rmse: 55.9339\n",
      "[480]\ttraining's rmse: 13.1198\tvalid_1's rmse: 55.8054\n",
      "[510]\ttraining's rmse: 12.2447\tvalid_1's rmse: 55.7096\n",
      "[540]\ttraining's rmse: 11.4513\tvalid_1's rmse: 55.6468\n",
      "[570]\ttraining's rmse: 10.7213\tvalid_1's rmse: 55.5695\n",
      "[600]\ttraining's rmse: 10.057\tvalid_1's rmse: 55.5149\n",
      "[630]\ttraining's rmse: 9.42981\tvalid_1's rmse: 55.4739\n",
      "[660]\ttraining's rmse: 8.86867\tvalid_1's rmse: 55.4328\n",
      "[690]\ttraining's rmse: 8.34142\tvalid_1's rmse: 55.4051\n",
      "[720]\ttraining's rmse: 7.85253\tvalid_1's rmse: 55.3758\n",
      "[750]\ttraining's rmse: 7.3943\tvalid_1's rmse: 55.35\n",
      "[780]\ttraining's rmse: 6.97577\tvalid_1's rmse: 55.3397\n",
      "[810]\ttraining's rmse: 6.58462\tvalid_1's rmse: 55.315\n",
      "[840]\ttraining's rmse: 6.22094\tvalid_1's rmse: 55.2929\n",
      "[870]\ttraining's rmse: 5.87991\tvalid_1's rmse: 55.2728\n",
      "[900]\ttraining's rmse: 5.56065\tvalid_1's rmse: 55.2613\n",
      "[930]\ttraining's rmse: 5.25756\tvalid_1's rmse: 55.2475\n",
      "[960]\ttraining's rmse: 4.97433\tvalid_1's rmse: 55.2456\n",
      "[990]\ttraining's rmse: 4.71271\tvalid_1's rmse: 55.2327\n",
      "[1020]\ttraining's rmse: 4.46413\tvalid_1's rmse: 55.2215\n",
      "[1050]\ttraining's rmse: 4.23692\tvalid_1's rmse: 55.2098\n",
      "[1080]\ttraining's rmse: 4.02062\tvalid_1's rmse: 55.2019\n",
      "[1110]\ttraining's rmse: 3.818\tvalid_1's rmse: 55.1989\n",
      "[1140]\ttraining's rmse: 3.6218\tvalid_1's rmse: 55.1919\n",
      "[1170]\ttraining's rmse: 3.44084\tvalid_1's rmse: 55.1857\n",
      "[1200]\ttraining's rmse: 3.26686\tvalid_1's rmse: 55.1815\n",
      "[1230]\ttraining's rmse: 3.10276\tvalid_1's rmse: 55.1812\n",
      "[1260]\ttraining's rmse: 2.95005\tvalid_1's rmse: 55.1741\n",
      "[1290]\ttraining's rmse: 2.80141\tvalid_1's rmse: 55.1627\n",
      "[1320]\ttraining's rmse: 2.66323\tvalid_1's rmse: 55.1592\n",
      "[1350]\ttraining's rmse: 2.53548\tvalid_1's rmse: 55.16\n",
      "[1380]\ttraining's rmse: 2.41199\tvalid_1's rmse: 55.1586\n",
      "[1410]\ttraining's rmse: 2.29557\tvalid_1's rmse: 55.157\n",
      "[1440]\ttraining's rmse: 2.18393\tvalid_1's rmse: 55.1523\n",
      "[1470]\ttraining's rmse: 2.08008\tvalid_1's rmse: 55.1483\n",
      "[1500]\ttraining's rmse: 1.98273\tvalid_1's rmse: 55.1493\n",
      "[1530]\ttraining's rmse: 1.8904\tvalid_1's rmse: 55.1489\n",
      "[1560]\ttraining's rmse: 1.80003\tvalid_1's rmse: 55.1472\n",
      "[1590]\ttraining's rmse: 1.71653\tvalid_1's rmse: 55.1444\n",
      "[1620]\ttraining's rmse: 1.63573\tvalid_1's rmse: 55.1434\n",
      "[1650]\ttraining's rmse: 1.55954\tvalid_1's rmse: 55.1413\n",
      "[1680]\ttraining's rmse: 1.48849\tvalid_1's rmse: 55.1368\n",
      "[1710]\ttraining's rmse: 1.42125\tvalid_1's rmse: 55.136\n",
      "[1740]\ttraining's rmse: 1.35833\tvalid_1's rmse: 55.1363\n",
      "[1770]\ttraining's rmse: 1.2966\tvalid_1's rmse: 55.1359\n",
      "[1800]\ttraining's rmse: 1.23926\tvalid_1's rmse: 55.1366\n",
      "Early stopping, best iteration is:\n",
      "[1693]\ttraining's rmse: 1.45798\tvalid_1's rmse: 55.1339\n",
      "3\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003880 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 20023\n",
      "[LightGBM] [Info] Number of data points in the train set: 9219, number of used features: 79\n",
      "[LightGBM] [Info] Start training from score 372.605724\n",
      "Training until validation scores don't improve for 125 rounds\n",
      "[30]\ttraining's rmse: 174.574\tvalid_1's rmse: 180.552\n",
      "[60]\ttraining's rmse: 105.538\tvalid_1's rmse: 114.638\n",
      "[90]\ttraining's rmse: 68.2775\tvalid_1's rmse: 82.2516\n",
      "[120]\ttraining's rmse: 48.2662\tvalid_1's rmse: 66.7494\n",
      "[150]\ttraining's rmse: 37.3825\tvalid_1's rmse: 59.4505\n",
      "[180]\ttraining's rmse: 31.1379\tvalid_1's rmse: 55.9849\n",
      "[210]\ttraining's rmse: 26.9097\tvalid_1's rmse: 54.0455\n",
      "[240]\ttraining's rmse: 23.8558\tvalid_1's rmse: 52.9536\n",
      "[270]\ttraining's rmse: 21.4749\tvalid_1's rmse: 52.3159\n",
      "[300]\ttraining's rmse: 19.5326\tvalid_1's rmse: 51.9144\n",
      "[330]\ttraining's rmse: 17.8992\tvalid_1's rmse: 51.5531\n",
      "[360]\ttraining's rmse: 16.5082\tvalid_1's rmse: 51.3226\n",
      "[390]\ttraining's rmse: 15.2311\tvalid_1's rmse: 51.0946\n",
      "[420]\ttraining's rmse: 14.12\tvalid_1's rmse: 50.9045\n",
      "[450]\ttraining's rmse: 13.1246\tvalid_1's rmse: 50.7816\n",
      "[480]\ttraining's rmse: 12.2156\tvalid_1's rmse: 50.6846\n",
      "[510]\ttraining's rmse: 11.3943\tvalid_1's rmse: 50.6235\n",
      "[540]\ttraining's rmse: 10.644\tvalid_1's rmse: 50.562\n",
      "[570]\ttraining's rmse: 9.9594\tvalid_1's rmse: 50.51\n",
      "[600]\ttraining's rmse: 9.33199\tvalid_1's rmse: 50.4545\n",
      "[630]\ttraining's rmse: 8.74229\tvalid_1's rmse: 50.4224\n",
      "[660]\ttraining's rmse: 8.20685\tvalid_1's rmse: 50.4048\n",
      "[690]\ttraining's rmse: 7.71432\tvalid_1's rmse: 50.3818\n",
      "[720]\ttraining's rmse: 7.24741\tvalid_1's rmse: 50.367\n",
      "[750]\ttraining's rmse: 6.81837\tvalid_1's rmse: 50.3232\n",
      "[780]\ttraining's rmse: 6.42359\tvalid_1's rmse: 50.2905\n",
      "[810]\ttraining's rmse: 6.05649\tvalid_1's rmse: 50.289\n",
      "[840]\ttraining's rmse: 5.71459\tvalid_1's rmse: 50.2701\n",
      "[870]\ttraining's rmse: 5.39748\tvalid_1's rmse: 50.2417\n",
      "[900]\ttraining's rmse: 5.10342\tvalid_1's rmse: 50.2174\n",
      "[930]\ttraining's rmse: 4.81791\tvalid_1's rmse: 50.2064\n",
      "[960]\ttraining's rmse: 4.55572\tvalid_1's rmse: 50.1963\n",
      "[990]\ttraining's rmse: 4.31194\tvalid_1's rmse: 50.1878\n",
      "[1020]\ttraining's rmse: 4.08331\tvalid_1's rmse: 50.1715\n",
      "[1050]\ttraining's rmse: 3.86448\tvalid_1's rmse: 50.1694\n",
      "[1080]\ttraining's rmse: 3.65875\tvalid_1's rmse: 50.156\n",
      "[1110]\ttraining's rmse: 3.4696\tvalid_1's rmse: 50.1505\n",
      "[1140]\ttraining's rmse: 3.28803\tvalid_1's rmse: 50.138\n",
      "[1170]\ttraining's rmse: 3.11736\tvalid_1's rmse: 50.1275\n",
      "[1200]\ttraining's rmse: 2.95478\tvalid_1's rmse: 50.1219\n",
      "[1230]\ttraining's rmse: 2.80264\tvalid_1's rmse: 50.1122\n",
      "[1260]\ttraining's rmse: 2.66355\tvalid_1's rmse: 50.1032\n",
      "[1290]\ttraining's rmse: 2.53021\tvalid_1's rmse: 50.0958\n",
      "[1320]\ttraining's rmse: 2.4014\tvalid_1's rmse: 50.0875\n",
      "[1350]\ttraining's rmse: 2.28247\tvalid_1's rmse: 50.0807\n",
      "[1380]\ttraining's rmse: 2.16932\tvalid_1's rmse: 50.0761\n",
      "[1410]\ttraining's rmse: 2.06323\tvalid_1's rmse: 50.0712\n",
      "[1440]\ttraining's rmse: 1.95958\tvalid_1's rmse: 50.068\n",
      "[1470]\ttraining's rmse: 1.86232\tvalid_1's rmse: 50.0639\n",
      "[1500]\ttraining's rmse: 1.77223\tvalid_1's rmse: 50.0642\n",
      "[1530]\ttraining's rmse: 1.68407\tvalid_1's rmse: 50.0613\n",
      "[1560]\ttraining's rmse: 1.60389\tvalid_1's rmse: 50.0582\n",
      "[1590]\ttraining's rmse: 1.52671\tvalid_1's rmse: 50.0551\n",
      "[1620]\ttraining's rmse: 1.45307\tvalid_1's rmse: 50.0552\n",
      "[1650]\ttraining's rmse: 1.38303\tvalid_1's rmse: 50.0521\n",
      "[1680]\ttraining's rmse: 1.31636\tvalid_1's rmse: 50.0479\n",
      "[1710]\ttraining's rmse: 1.25378\tvalid_1's rmse: 50.0478\n",
      "[1740]\ttraining's rmse: 1.19431\tvalid_1's rmse: 50.0471\n",
      "[1770]\ttraining's rmse: 1.13773\tvalid_1's rmse: 50.0445\n",
      "[1800]\ttraining's rmse: 1.08444\tvalid_1's rmse: 50.0419\n",
      "[1830]\ttraining's rmse: 1.03197\tvalid_1's rmse: 50.0408\n",
      "[1860]\ttraining's rmse: 0.983482\tvalid_1's rmse: 50.0402\n",
      "[1890]\ttraining's rmse: 0.937998\tvalid_1's rmse: 50.0396\n",
      "[1920]\ttraining's rmse: 0.895152\tvalid_1's rmse: 50.0374\n",
      "[1950]\ttraining's rmse: 0.853896\tvalid_1's rmse: 50.0365\n",
      "[1980]\ttraining's rmse: 0.814213\tvalid_1's rmse: 50.035\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's rmse: 0.789585\tvalid_1's rmse: 50.0348\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003152 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 20023\n",
      "[LightGBM] [Info] Number of data points in the train set: 9219, number of used features: 79\n",
      "[LightGBM] [Info] Start training from score 375.725620\n",
      "Training until validation scores don't improve for 125 rounds\n",
      "[30]\ttraining's rmse: 175.218\tvalid_1's rmse: 182.647\n",
      "[60]\ttraining's rmse: 107.686\tvalid_1's rmse: 120.182\n",
      "[90]\ttraining's rmse: 71.0398\tvalid_1's rmse: 89.0718\n",
      "[120]\ttraining's rmse: 51.4443\tvalid_1's rmse: 74.6601\n",
      "[150]\ttraining's rmse: 40.6276\tvalid_1's rmse: 67.7581\n",
      "[180]\ttraining's rmse: 34.2446\tvalid_1's rmse: 64.1296\n",
      "[210]\ttraining's rmse: 29.8764\tvalid_1's rmse: 62.1209\n",
      "[240]\ttraining's rmse: 26.6552\tvalid_1's rmse: 60.907\n",
      "[270]\ttraining's rmse: 24.0965\tvalid_1's rmse: 59.9857\n",
      "[300]\ttraining's rmse: 21.9533\tvalid_1's rmse: 59.4206\n",
      "[330]\ttraining's rmse: 20.101\tvalid_1's rmse: 59.0088\n",
      "[360]\ttraining's rmse: 18.5125\tvalid_1's rmse: 58.7306\n",
      "[390]\ttraining's rmse: 17.079\tvalid_1's rmse: 58.468\n",
      "[420]\ttraining's rmse: 15.8122\tvalid_1's rmse: 58.2695\n",
      "[450]\ttraining's rmse: 14.6837\tvalid_1's rmse: 58.0995\n",
      "[480]\ttraining's rmse: 13.6609\tvalid_1's rmse: 57.8997\n",
      "[510]\ttraining's rmse: 12.728\tvalid_1's rmse: 57.7766\n",
      "[540]\ttraining's rmse: 11.8859\tvalid_1's rmse: 57.6875\n",
      "[570]\ttraining's rmse: 11.1206\tvalid_1's rmse: 57.5945\n",
      "[600]\ttraining's rmse: 10.4076\tvalid_1's rmse: 57.5146\n",
      "[630]\ttraining's rmse: 9.74754\tvalid_1's rmse: 57.4225\n",
      "[660]\ttraining's rmse: 9.14344\tvalid_1's rmse: 57.367\n",
      "[690]\ttraining's rmse: 8.59981\tvalid_1's rmse: 57.2899\n",
      "[720]\ttraining's rmse: 8.08489\tvalid_1's rmse: 57.2329\n",
      "[750]\ttraining's rmse: 7.60171\tvalid_1's rmse: 57.1908\n",
      "[780]\ttraining's rmse: 7.16429\tvalid_1's rmse: 57.1583\n",
      "[810]\ttraining's rmse: 6.75943\tvalid_1's rmse: 57.1125\n",
      "[840]\ttraining's rmse: 6.37821\tvalid_1's rmse: 57.1036\n",
      "[870]\ttraining's rmse: 6.01197\tvalid_1's rmse: 57.0827\n",
      "[900]\ttraining's rmse: 5.6751\tvalid_1's rmse: 57.0624\n",
      "[930]\ttraining's rmse: 5.36086\tvalid_1's rmse: 57.0398\n",
      "[960]\ttraining's rmse: 5.06446\tvalid_1's rmse: 57.0262\n",
      "[990]\ttraining's rmse: 4.78297\tvalid_1's rmse: 57.0048\n",
      "[1020]\ttraining's rmse: 4.52176\tvalid_1's rmse: 56.9941\n",
      "[1050]\ttraining's rmse: 4.28348\tvalid_1's rmse: 56.977\n",
      "[1080]\ttraining's rmse: 4.05714\tvalid_1's rmse: 56.9603\n",
      "[1110]\ttraining's rmse: 3.85024\tvalid_1's rmse: 56.9431\n",
      "[1140]\ttraining's rmse: 3.65359\tvalid_1's rmse: 56.9332\n",
      "[1170]\ttraining's rmse: 3.46621\tvalid_1's rmse: 56.924\n",
      "[1200]\ttraining's rmse: 3.28479\tvalid_1's rmse: 56.9226\n",
      "[1230]\ttraining's rmse: 3.11909\tvalid_1's rmse: 56.9164\n",
      "[1260]\ttraining's rmse: 2.95959\tvalid_1's rmse: 56.9064\n",
      "[1290]\ttraining's rmse: 2.81399\tvalid_1's rmse: 56.901\n",
      "[1320]\ttraining's rmse: 2.67203\tvalid_1's rmse: 56.9022\n",
      "[1350]\ttraining's rmse: 2.53616\tvalid_1's rmse: 56.894\n",
      "[1380]\ttraining's rmse: 2.40984\tvalid_1's rmse: 56.8921\n",
      "[1410]\ttraining's rmse: 2.29213\tvalid_1's rmse: 56.8907\n",
      "[1440]\ttraining's rmse: 2.18141\tvalid_1's rmse: 56.8842\n",
      "[1470]\ttraining's rmse: 2.0746\tvalid_1's rmse: 56.8813\n",
      "[1500]\ttraining's rmse: 1.97426\tvalid_1's rmse: 56.8784\n",
      "[1530]\ttraining's rmse: 1.87654\tvalid_1's rmse: 56.8753\n",
      "[1560]\ttraining's rmse: 1.78781\tvalid_1's rmse: 56.875\n",
      "[1590]\ttraining's rmse: 1.70149\tvalid_1's rmse: 56.8741\n",
      "[1620]\ttraining's rmse: 1.61957\tvalid_1's rmse: 56.8734\n",
      "[1650]\ttraining's rmse: 1.54471\tvalid_1's rmse: 56.872\n",
      "[1680]\ttraining's rmse: 1.47113\tvalid_1's rmse: 56.8724\n",
      "[1710]\ttraining's rmse: 1.40366\tvalid_1's rmse: 56.8666\n",
      "[1740]\ttraining's rmse: 1.33676\tvalid_1's rmse: 56.867\n",
      "[1770]\ttraining's rmse: 1.27478\tvalid_1's rmse: 56.867\n",
      "[1800]\ttraining's rmse: 1.21451\tvalid_1's rmse: 56.8645\n",
      "[1830]\ttraining's rmse: 1.15887\tvalid_1's rmse: 56.8606\n",
      "[1860]\ttraining's rmse: 1.10596\tvalid_1's rmse: 56.8615\n",
      "[1890]\ttraining's rmse: 1.05547\tvalid_1's rmse: 56.8581\n",
      "[1920]\ttraining's rmse: 1.00745\tvalid_1's rmse: 56.8587\n",
      "[1950]\ttraining's rmse: 0.961271\tvalid_1's rmse: 56.858\n",
      "[1980]\ttraining's rmse: 0.917085\tvalid_1's rmse: 56.8575\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's rmse: 0.888488\tvalid_1's rmse: 56.8569\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003400 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 20023\n",
      "[LightGBM] [Info] Number of data points in the train set: 9219, number of used features: 79\n",
      "[LightGBM] [Info] Start training from score 374.635276\n",
      "Training until validation scores don't improve for 125 rounds\n",
      "[30]\ttraining's rmse: 176.401\tvalid_1's rmse: 180.385\n",
      "[60]\ttraining's rmse: 107.771\tvalid_1's rmse: 116.766\n",
      "[90]\ttraining's rmse: 70.6295\tvalid_1's rmse: 84.7213\n",
      "[120]\ttraining's rmse: 50.5593\tvalid_1's rmse: 69.7791\n",
      "[150]\ttraining's rmse: 39.6243\tvalid_1's rmse: 62.8011\n",
      "[180]\ttraining's rmse: 33.219\tvalid_1's rmse: 59.4157\n",
      "[210]\ttraining's rmse: 28.8799\tvalid_1's rmse: 57.3855\n",
      "[240]\ttraining's rmse: 25.758\tvalid_1's rmse: 56.1079\n",
      "[270]\ttraining's rmse: 23.2226\tvalid_1's rmse: 55.1807\n",
      "[300]\ttraining's rmse: 21.1004\tvalid_1's rmse: 54.6319\n",
      "[330]\ttraining's rmse: 19.3419\tvalid_1's rmse: 54.1816\n",
      "[360]\ttraining's rmse: 17.8233\tvalid_1's rmse: 53.8235\n",
      "[390]\ttraining's rmse: 16.4947\tvalid_1's rmse: 53.7119\n",
      "[420]\ttraining's rmse: 15.2962\tvalid_1's rmse: 53.4682\n",
      "[450]\ttraining's rmse: 14.2186\tvalid_1's rmse: 53.3265\n",
      "[480]\ttraining's rmse: 13.2525\tvalid_1's rmse: 53.223\n",
      "[510]\ttraining's rmse: 12.3661\tvalid_1's rmse: 53.0129\n",
      "[540]\ttraining's rmse: 11.5559\tvalid_1's rmse: 52.8724\n",
      "[570]\ttraining's rmse: 10.8421\tvalid_1's rmse: 52.7638\n",
      "[600]\ttraining's rmse: 10.1645\tvalid_1's rmse: 52.7212\n",
      "[630]\ttraining's rmse: 9.53557\tvalid_1's rmse: 52.6366\n",
      "[660]\ttraining's rmse: 8.95003\tvalid_1's rmse: 52.5439\n",
      "[690]\ttraining's rmse: 8.41639\tvalid_1's rmse: 52.4868\n",
      "[720]\ttraining's rmse: 7.90822\tvalid_1's rmse: 52.4231\n",
      "[750]\ttraining's rmse: 7.4406\tvalid_1's rmse: 52.3402\n",
      "[780]\ttraining's rmse: 7.0157\tvalid_1's rmse: 52.3218\n",
      "[810]\ttraining's rmse: 6.6272\tvalid_1's rmse: 52.288\n",
      "[840]\ttraining's rmse: 6.25668\tvalid_1's rmse: 52.2618\n",
      "[870]\ttraining's rmse: 5.90214\tvalid_1's rmse: 52.2415\n",
      "[900]\ttraining's rmse: 5.57404\tvalid_1's rmse: 52.2095\n",
      "[930]\ttraining's rmse: 5.27542\tvalid_1's rmse: 52.1768\n",
      "[960]\ttraining's rmse: 4.99281\tvalid_1's rmse: 52.1503\n",
      "[990]\ttraining's rmse: 4.72692\tvalid_1's rmse: 52.1326\n",
      "[1020]\ttraining's rmse: 4.47257\tvalid_1's rmse: 52.1239\n",
      "[1050]\ttraining's rmse: 4.24202\tvalid_1's rmse: 52.0964\n",
      "[1080]\ttraining's rmse: 4.01729\tvalid_1's rmse: 52.0876\n",
      "[1110]\ttraining's rmse: 3.80803\tvalid_1's rmse: 52.0763\n",
      "[1140]\ttraining's rmse: 3.61301\tvalid_1's rmse: 52.0514\n",
      "[1170]\ttraining's rmse: 3.42879\tvalid_1's rmse: 52.0351\n",
      "[1200]\ttraining's rmse: 3.25588\tvalid_1's rmse: 52.0264\n",
      "[1230]\ttraining's rmse: 3.09748\tvalid_1's rmse: 52.0275\n",
      "[1260]\ttraining's rmse: 2.94661\tvalid_1's rmse: 52.0262\n",
      "[1290]\ttraining's rmse: 2.80238\tvalid_1's rmse: 52.0219\n",
      "[1320]\ttraining's rmse: 2.66687\tvalid_1's rmse: 52.0118\n",
      "[1350]\ttraining's rmse: 2.53849\tvalid_1's rmse: 52.0045\n",
      "[1380]\ttraining's rmse: 2.41212\tvalid_1's rmse: 52.0003\n",
      "[1410]\ttraining's rmse: 2.29504\tvalid_1's rmse: 51.992\n",
      "[1440]\ttraining's rmse: 2.18411\tvalid_1's rmse: 51.9815\n",
      "[1470]\ttraining's rmse: 2.07951\tvalid_1's rmse: 51.9773\n",
      "[1500]\ttraining's rmse: 1.9813\tvalid_1's rmse: 51.97\n",
      "[1530]\ttraining's rmse: 1.8867\tvalid_1's rmse: 51.9629\n",
      "[1560]\ttraining's rmse: 1.7977\tvalid_1's rmse: 51.9523\n",
      "[1590]\ttraining's rmse: 1.71378\tvalid_1's rmse: 51.9511\n",
      "[1620]\ttraining's rmse: 1.63475\tvalid_1's rmse: 51.9466\n",
      "[1650]\ttraining's rmse: 1.55935\tvalid_1's rmse: 51.9406\n",
      "[1680]\ttraining's rmse: 1.48489\tvalid_1's rmse: 51.9373\n",
      "[1710]\ttraining's rmse: 1.41561\tvalid_1's rmse: 51.9317\n",
      "[1740]\ttraining's rmse: 1.34885\tvalid_1's rmse: 51.9286\n",
      "[1770]\ttraining's rmse: 1.28654\tvalid_1's rmse: 51.9232\n",
      "[1800]\ttraining's rmse: 1.22787\tvalid_1's rmse: 51.9207\n",
      "[1830]\ttraining's rmse: 1.17039\tvalid_1's rmse: 51.9162\n",
      "[1860]\ttraining's rmse: 1.11665\tvalid_1's rmse: 51.9129\n",
      "[1890]\ttraining's rmse: 1.06761\tvalid_1's rmse: 51.9118\n",
      "[1920]\ttraining's rmse: 1.02244\tvalid_1's rmse: 51.9117\n",
      "[1950]\ttraining's rmse: 0.976348\tvalid_1's rmse: 51.91\n",
      "[1980]\ttraining's rmse: 0.933135\tvalid_1's rmse: 51.9113\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's rmse: 0.905227\tvalid_1's rmse: 51.9103\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002382 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 20023\n",
      "[LightGBM] [Info] Number of data points in the train set: 9219, number of used features: 79\n",
      "[LightGBM] [Info] Start training from score 375.079039\n",
      "Training until validation scores don't improve for 125 rounds\n",
      "[30]\ttraining's rmse: 175.368\tvalid_1's rmse: 184.055\n",
      "[60]\ttraining's rmse: 107.271\tvalid_1's rmse: 120.253\n",
      "[90]\ttraining's rmse: 70.3932\tvalid_1's rmse: 88.8695\n",
      "[120]\ttraining's rmse: 50.5145\tvalid_1's rmse: 74.3035\n",
      "[150]\ttraining's rmse: 39.5508\tvalid_1's rmse: 67.319\n",
      "[180]\ttraining's rmse: 32.9683\tvalid_1's rmse: 63.7511\n",
      "[210]\ttraining's rmse: 28.5982\tvalid_1's rmse: 61.8292\n",
      "[240]\ttraining's rmse: 25.3948\tvalid_1's rmse: 60.3977\n",
      "[270]\ttraining's rmse: 22.9235\tvalid_1's rmse: 59.4976\n",
      "[300]\ttraining's rmse: 20.833\tvalid_1's rmse: 58.9348\n",
      "[330]\ttraining's rmse: 19.1042\tvalid_1's rmse: 58.5446\n",
      "[360]\ttraining's rmse: 17.6014\tvalid_1's rmse: 58.1911\n",
      "[390]\ttraining's rmse: 16.2957\tvalid_1's rmse: 57.9809\n",
      "[420]\ttraining's rmse: 15.1373\tvalid_1's rmse: 57.7379\n",
      "[450]\ttraining's rmse: 14.0763\tvalid_1's rmse: 57.5342\n",
      "[480]\ttraining's rmse: 13.0999\tvalid_1's rmse: 57.3457\n",
      "[510]\ttraining's rmse: 12.2428\tvalid_1's rmse: 57.1734\n",
      "[540]\ttraining's rmse: 11.4504\tvalid_1's rmse: 57.0872\n",
      "[570]\ttraining's rmse: 10.7331\tvalid_1's rmse: 56.987\n",
      "[600]\ttraining's rmse: 10.072\tvalid_1's rmse: 56.902\n",
      "[630]\ttraining's rmse: 9.45703\tvalid_1's rmse: 56.8033\n",
      "[660]\ttraining's rmse: 8.89426\tvalid_1's rmse: 56.757\n",
      "[690]\ttraining's rmse: 8.37274\tvalid_1's rmse: 56.6726\n",
      "[720]\ttraining's rmse: 7.88407\tvalid_1's rmse: 56.6238\n",
      "[750]\ttraining's rmse: 7.44132\tvalid_1's rmse: 56.5683\n",
      "[780]\ttraining's rmse: 7.02406\tvalid_1's rmse: 56.5315\n",
      "[810]\ttraining's rmse: 6.6368\tvalid_1's rmse: 56.5027\n",
      "[840]\ttraining's rmse: 6.27139\tvalid_1's rmse: 56.4771\n",
      "[870]\ttraining's rmse: 5.92859\tvalid_1's rmse: 56.4568\n",
      "[900]\ttraining's rmse: 5.61462\tvalid_1's rmse: 56.4391\n",
      "[930]\ttraining's rmse: 5.31518\tvalid_1's rmse: 56.4176\n",
      "[960]\ttraining's rmse: 5.03533\tvalid_1's rmse: 56.4098\n",
      "[990]\ttraining's rmse: 4.78333\tvalid_1's rmse: 56.3971\n",
      "[1020]\ttraining's rmse: 4.54327\tvalid_1's rmse: 56.3833\n",
      "[1050]\ttraining's rmse: 4.30975\tvalid_1's rmse: 56.3714\n",
      "[1080]\ttraining's rmse: 4.09033\tvalid_1's rmse: 56.3567\n",
      "[1110]\ttraining's rmse: 3.88744\tvalid_1's rmse: 56.3556\n",
      "[1140]\ttraining's rmse: 3.69547\tvalid_1's rmse: 56.3433\n",
      "[1170]\ttraining's rmse: 3.51567\tvalid_1's rmse: 56.3393\n",
      "[1200]\ttraining's rmse: 3.34185\tvalid_1's rmse: 56.3335\n",
      "[1230]\ttraining's rmse: 3.18316\tvalid_1's rmse: 56.3191\n",
      "[1260]\ttraining's rmse: 3.02681\tvalid_1's rmse: 56.3118\n",
      "[1290]\ttraining's rmse: 2.88321\tvalid_1's rmse: 56.3013\n",
      "[1320]\ttraining's rmse: 2.75013\tvalid_1's rmse: 56.2975\n",
      "[1350]\ttraining's rmse: 2.62167\tvalid_1's rmse: 56.2903\n",
      "[1380]\ttraining's rmse: 2.5039\tvalid_1's rmse: 56.2862\n",
      "[1410]\ttraining's rmse: 2.38867\tvalid_1's rmse: 56.2861\n",
      "[1440]\ttraining's rmse: 2.27798\tvalid_1's rmse: 56.2874\n",
      "[1470]\ttraining's rmse: 2.17412\tvalid_1's rmse: 56.2812\n",
      "[1500]\ttraining's rmse: 2.0761\tvalid_1's rmse: 56.279\n",
      "[1530]\ttraining's rmse: 1.98154\tvalid_1's rmse: 56.2775\n",
      "[1560]\ttraining's rmse: 1.89247\tvalid_1's rmse: 56.272\n",
      "[1590]\ttraining's rmse: 1.80919\tvalid_1's rmse: 56.2707\n",
      "[1620]\ttraining's rmse: 1.73324\tvalid_1's rmse: 56.2702\n",
      "[1650]\ttraining's rmse: 1.65501\tvalid_1's rmse: 56.2688\n",
      "[1680]\ttraining's rmse: 1.58372\tvalid_1's rmse: 56.2616\n",
      "[1710]\ttraining's rmse: 1.51451\tvalid_1's rmse: 56.259\n",
      "[1740]\ttraining's rmse: 1.44827\tvalid_1's rmse: 56.2551\n",
      "[1770]\ttraining's rmse: 1.38426\tvalid_1's rmse: 56.2524\n",
      "[1800]\ttraining's rmse: 1.32525\tvalid_1's rmse: 56.2478\n",
      "[1830]\ttraining's rmse: 1.26613\tvalid_1's rmse: 56.2498\n",
      "[1860]\ttraining's rmse: 1.21262\tvalid_1's rmse: 56.25\n",
      "[1890]\ttraining's rmse: 1.16184\tvalid_1's rmse: 56.2485\n",
      "[1920]\ttraining's rmse: 1.1113\tvalid_1's rmse: 56.2469\n",
      "[1950]\ttraining's rmse: 1.0644\tvalid_1's rmse: 56.2453\n",
      "[1980]\ttraining's rmse: 1.01999\tvalid_1's rmse: 56.2462\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's rmse: 0.99071\tvalid_1's rmse: 56.2483\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003109 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 20023\n",
      "[LightGBM] [Info] Number of data points in the train set: 9219, number of used features: 79\n",
      "[LightGBM] [Info] Start training from score 371.342398\n",
      "Training until validation scores don't improve for 125 rounds\n",
      "[30]\ttraining's rmse: 176.45\tvalid_1's rmse: 185.112\n",
      "[60]\ttraining's rmse: 108.17\tvalid_1's rmse: 120.374\n",
      "[90]\ttraining's rmse: 71.0563\tvalid_1's rmse: 88.1447\n",
      "[120]\ttraining's rmse: 51.0221\tvalid_1's rmse: 73.0985\n",
      "[150]\ttraining's rmse: 40.0361\tvalid_1's rmse: 65.7515\n",
      "[180]\ttraining's rmse: 33.5135\tvalid_1's rmse: 62.125\n",
      "[210]\ttraining's rmse: 29.1728\tvalid_1's rmse: 59.9641\n",
      "[240]\ttraining's rmse: 25.8832\tvalid_1's rmse: 58.6184\n",
      "[270]\ttraining's rmse: 23.3599\tvalid_1's rmse: 57.5782\n",
      "[300]\ttraining's rmse: 21.2873\tvalid_1's rmse: 56.9105\n",
      "[330]\ttraining's rmse: 19.5209\tvalid_1's rmse: 56.3385\n",
      "[360]\ttraining's rmse: 18.0276\tvalid_1's rmse: 55.9746\n",
      "[390]\ttraining's rmse: 16.6762\tvalid_1's rmse: 55.6546\n",
      "[420]\ttraining's rmse: 15.4688\tvalid_1's rmse: 55.4518\n",
      "[450]\ttraining's rmse: 14.388\tvalid_1's rmse: 55.2441\n",
      "[480]\ttraining's rmse: 13.4179\tvalid_1's rmse: 55.08\n",
      "[510]\ttraining's rmse: 12.5301\tvalid_1's rmse: 54.8932\n",
      "[540]\ttraining's rmse: 11.7115\tvalid_1's rmse: 54.7438\n",
      "[570]\ttraining's rmse: 10.9747\tvalid_1's rmse: 54.6169\n",
      "[600]\ttraining's rmse: 10.3044\tvalid_1's rmse: 54.5098\n",
      "[630]\ttraining's rmse: 9.67805\tvalid_1's rmse: 54.422\n",
      "[660]\ttraining's rmse: 9.10688\tvalid_1's rmse: 54.3522\n",
      "[690]\ttraining's rmse: 8.5816\tvalid_1's rmse: 54.3082\n",
      "[720]\ttraining's rmse: 8.09056\tvalid_1's rmse: 54.2573\n",
      "[750]\ttraining's rmse: 7.63261\tvalid_1's rmse: 54.1972\n",
      "[780]\ttraining's rmse: 7.202\tvalid_1's rmse: 54.1265\n",
      "[810]\ttraining's rmse: 6.79825\tvalid_1's rmse: 54.0873\n",
      "[840]\ttraining's rmse: 6.42825\tvalid_1's rmse: 54.0483\n",
      "[870]\ttraining's rmse: 6.06814\tvalid_1's rmse: 54.0339\n",
      "[900]\ttraining's rmse: 5.74179\tvalid_1's rmse: 53.9986\n",
      "[930]\ttraining's rmse: 5.42857\tvalid_1's rmse: 53.9785\n",
      "[960]\ttraining's rmse: 5.13835\tvalid_1's rmse: 53.9537\n",
      "[990]\ttraining's rmse: 4.8747\tvalid_1's rmse: 53.9386\n",
      "[1020]\ttraining's rmse: 4.62615\tvalid_1's rmse: 53.9202\n",
      "[1050]\ttraining's rmse: 4.39031\tvalid_1's rmse: 53.914\n",
      "[1080]\ttraining's rmse: 4.16509\tvalid_1's rmse: 53.8897\n",
      "[1110]\ttraining's rmse: 3.95233\tvalid_1's rmse: 53.8717\n",
      "[1140]\ttraining's rmse: 3.75043\tvalid_1's rmse: 53.8582\n",
      "[1170]\ttraining's rmse: 3.56294\tvalid_1's rmse: 53.8541\n",
      "[1200]\ttraining's rmse: 3.38689\tvalid_1's rmse: 53.8444\n",
      "[1230]\ttraining's rmse: 3.21671\tvalid_1's rmse: 53.8409\n",
      "[1260]\ttraining's rmse: 3.0576\tvalid_1's rmse: 53.8273\n",
      "[1290]\ttraining's rmse: 2.90732\tvalid_1's rmse: 53.8163\n",
      "[1320]\ttraining's rmse: 2.76524\tvalid_1's rmse: 53.8088\n",
      "[1350]\ttraining's rmse: 2.62994\tvalid_1's rmse: 53.797\n",
      "[1380]\ttraining's rmse: 2.50298\tvalid_1's rmse: 53.7865\n",
      "[1410]\ttraining's rmse: 2.38301\tvalid_1's rmse: 53.7829\n",
      "[1440]\ttraining's rmse: 2.26545\tvalid_1's rmse: 53.7714\n",
      "[1470]\ttraining's rmse: 2.15747\tvalid_1's rmse: 53.767\n",
      "[1500]\ttraining's rmse: 2.05626\tvalid_1's rmse: 53.7602\n",
      "[1530]\ttraining's rmse: 1.96002\tvalid_1's rmse: 53.7562\n",
      "[1560]\ttraining's rmse: 1.8697\tvalid_1's rmse: 53.7494\n",
      "[1590]\ttraining's rmse: 1.78039\tvalid_1's rmse: 53.7398\n",
      "[1620]\ttraining's rmse: 1.69794\tvalid_1's rmse: 53.7362\n",
      "[1650]\ttraining's rmse: 1.61971\tvalid_1's rmse: 53.7355\n",
      "[1680]\ttraining's rmse: 1.54596\tvalid_1's rmse: 53.7334\n",
      "[1710]\ttraining's rmse: 1.47477\tvalid_1's rmse: 53.7295\n",
      "[1740]\ttraining's rmse: 1.40925\tvalid_1's rmse: 53.7252\n",
      "[1770]\ttraining's rmse: 1.3445\tvalid_1's rmse: 53.7239\n",
      "[1800]\ttraining's rmse: 1.28385\tvalid_1's rmse: 53.723\n",
      "[1830]\ttraining's rmse: 1.22569\tvalid_1's rmse: 53.7219\n",
      "[1860]\ttraining's rmse: 1.17015\tvalid_1's rmse: 53.7175\n",
      "[1890]\ttraining's rmse: 1.11796\tvalid_1's rmse: 53.7138\n",
      "[1920]\ttraining's rmse: 1.06796\tvalid_1's rmse: 53.7136\n",
      "[1950]\ttraining's rmse: 1.02056\tvalid_1's rmse: 53.712\n",
      "[1980]\ttraining's rmse: 0.97544\tvalid_1's rmse: 53.7097\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's rmse: 0.946386\tvalid_1's rmse: 53.7085\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003522 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 20023\n",
      "[LightGBM] [Info] Number of data points in the train set: 9219, number of used features: 79\n",
      "[LightGBM] [Info] Start training from score 372.672896\n",
      "Training until validation scores don't improve for 125 rounds\n",
      "[30]\ttraining's rmse: 175.837\tvalid_1's rmse: 185.715\n",
      "[60]\ttraining's rmse: 107.89\tvalid_1's rmse: 120.327\n",
      "[90]\ttraining's rmse: 71.0592\tvalid_1's rmse: 87.8497\n",
      "[120]\ttraining's rmse: 51.2367\tvalid_1's rmse: 72.2735\n",
      "[150]\ttraining's rmse: 40.3904\tvalid_1's rmse: 64.8655\n",
      "[180]\ttraining's rmse: 33.8734\tvalid_1's rmse: 61.0217\n",
      "[210]\ttraining's rmse: 29.5045\tvalid_1's rmse: 58.9014\n",
      "[240]\ttraining's rmse: 26.2206\tvalid_1's rmse: 57.4383\n",
      "[270]\ttraining's rmse: 23.6191\tvalid_1's rmse: 56.4576\n",
      "[300]\ttraining's rmse: 21.4625\tvalid_1's rmse: 55.8038\n",
      "[330]\ttraining's rmse: 19.6635\tvalid_1's rmse: 55.3639\n",
      "[360]\ttraining's rmse: 18.0602\tvalid_1's rmse: 55.0524\n",
      "[390]\ttraining's rmse: 16.6609\tvalid_1's rmse: 54.7313\n",
      "[420]\ttraining's rmse: 15.4473\tvalid_1's rmse: 54.5145\n",
      "[450]\ttraining's rmse: 14.3322\tvalid_1's rmse: 54.362\n",
      "[480]\ttraining's rmse: 13.3403\tvalid_1's rmse: 54.2105\n",
      "[510]\ttraining's rmse: 12.4592\tvalid_1's rmse: 54.0894\n",
      "[540]\ttraining's rmse: 11.6583\tvalid_1's rmse: 53.9869\n",
      "[570]\ttraining's rmse: 10.9294\tvalid_1's rmse: 53.8927\n",
      "[600]\ttraining's rmse: 10.262\tvalid_1's rmse: 53.7926\n",
      "[630]\ttraining's rmse: 9.6097\tvalid_1's rmse: 53.7043\n",
      "[660]\ttraining's rmse: 9.02878\tvalid_1's rmse: 53.6124\n",
      "[690]\ttraining's rmse: 8.4926\tvalid_1's rmse: 53.5925\n",
      "[720]\ttraining's rmse: 7.99488\tvalid_1's rmse: 53.5534\n",
      "[750]\ttraining's rmse: 7.52829\tvalid_1's rmse: 53.4928\n",
      "[780]\ttraining's rmse: 7.09503\tvalid_1's rmse: 53.4388\n",
      "[810]\ttraining's rmse: 6.69189\tvalid_1's rmse: 53.4255\n",
      "[840]\ttraining's rmse: 6.32658\tvalid_1's rmse: 53.3869\n",
      "[870]\ttraining's rmse: 5.98365\tvalid_1's rmse: 53.3563\n",
      "[900]\ttraining's rmse: 5.65858\tvalid_1's rmse: 53.3164\n",
      "[930]\ttraining's rmse: 5.34943\tvalid_1's rmse: 53.3025\n",
      "[960]\ttraining's rmse: 5.06221\tvalid_1's rmse: 53.2761\n",
      "[990]\ttraining's rmse: 4.79408\tvalid_1's rmse: 53.2763\n",
      "[1020]\ttraining's rmse: 4.54455\tvalid_1's rmse: 53.2566\n",
      "[1050]\ttraining's rmse: 4.306\tvalid_1's rmse: 53.2468\n",
      "[1080]\ttraining's rmse: 4.08486\tvalid_1's rmse: 53.229\n",
      "[1110]\ttraining's rmse: 3.87377\tvalid_1's rmse: 53.2232\n",
      "[1140]\ttraining's rmse: 3.67807\tvalid_1's rmse: 53.2182\n",
      "[1170]\ttraining's rmse: 3.49558\tvalid_1's rmse: 53.219\n",
      "[1200]\ttraining's rmse: 3.31974\tvalid_1's rmse: 53.2069\n",
      "[1230]\ttraining's rmse: 3.15509\tvalid_1's rmse: 53.2021\n",
      "[1260]\ttraining's rmse: 2.99802\tvalid_1's rmse: 53.1929\n",
      "[1290]\ttraining's rmse: 2.84864\tvalid_1's rmse: 53.1843\n",
      "[1320]\ttraining's rmse: 2.70837\tvalid_1's rmse: 53.179\n",
      "[1350]\ttraining's rmse: 2.57473\tvalid_1's rmse: 53.1633\n",
      "[1380]\ttraining's rmse: 2.44954\tvalid_1's rmse: 53.1581\n",
      "[1410]\ttraining's rmse: 2.32783\tvalid_1's rmse: 53.154\n",
      "[1440]\ttraining's rmse: 2.21497\tvalid_1's rmse: 53.1422\n",
      "[1470]\ttraining's rmse: 2.10762\tvalid_1's rmse: 53.1421\n",
      "[1500]\ttraining's rmse: 2.00658\tvalid_1's rmse: 53.1431\n",
      "[1530]\ttraining's rmse: 1.91084\tvalid_1's rmse: 53.1382\n",
      "[1560]\ttraining's rmse: 1.81879\tvalid_1's rmse: 53.1354\n",
      "[1590]\ttraining's rmse: 1.73375\tvalid_1's rmse: 53.1314\n",
      "[1620]\ttraining's rmse: 1.65522\tvalid_1's rmse: 53.1272\n",
      "[1650]\ttraining's rmse: 1.57836\tvalid_1's rmse: 53.1262\n",
      "[1680]\ttraining's rmse: 1.50581\tvalid_1's rmse: 53.1249\n",
      "[1710]\ttraining's rmse: 1.43539\tvalid_1's rmse: 53.1217\n",
      "[1740]\ttraining's rmse: 1.36987\tvalid_1's rmse: 53.1199\n",
      "[1770]\ttraining's rmse: 1.30791\tvalid_1's rmse: 53.1186\n",
      "[1800]\ttraining's rmse: 1.2493\tvalid_1's rmse: 53.1187\n",
      "[1830]\ttraining's rmse: 1.1912\tvalid_1's rmse: 53.1195\n",
      "[1860]\ttraining's rmse: 1.13589\tvalid_1's rmse: 53.1177\n",
      "[1890]\ttraining's rmse: 1.08485\tvalid_1's rmse: 53.1151\n",
      "[1920]\ttraining's rmse: 1.03627\tvalid_1's rmse: 53.1137\n",
      "[1950]\ttraining's rmse: 0.991201\tvalid_1's rmse: 53.1133\n",
      "[1980]\ttraining's rmse: 0.946316\tvalid_1's rmse: 53.1127\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's rmse: 0.918376\tvalid_1's rmse: 53.1116\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002328 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 20023\n",
      "[LightGBM] [Info] Number of data points in the train set: 9219, number of used features: 79\n",
      "[LightGBM] [Info] Start training from score 368.883862\n",
      "Training until validation scores don't improve for 125 rounds\n",
      "[30]\ttraining's rmse: 176.485\tvalid_1's rmse: 183.933\n",
      "[60]\ttraining's rmse: 108.206\tvalid_1's rmse: 120.698\n",
      "[90]\ttraining's rmse: 70.8776\tvalid_1's rmse: 89.1394\n",
      "[120]\ttraining's rmse: 50.7343\tvalid_1's rmse: 74.5725\n",
      "[150]\ttraining's rmse: 39.7327\tvalid_1's rmse: 67.59\n",
      "[180]\ttraining's rmse: 33.3564\tvalid_1's rmse: 64.3512\n",
      "[210]\ttraining's rmse: 29.1244\tvalid_1's rmse: 62.4196\n",
      "[240]\ttraining's rmse: 25.9444\tvalid_1's rmse: 61.2291\n",
      "[270]\ttraining's rmse: 23.3411\tvalid_1's rmse: 60.1759\n",
      "[300]\ttraining's rmse: 21.2196\tvalid_1's rmse: 59.5241\n",
      "[330]\ttraining's rmse: 19.432\tvalid_1's rmse: 59.0746\n",
      "[360]\ttraining's rmse: 17.8987\tvalid_1's rmse: 58.715\n",
      "[390]\ttraining's rmse: 16.5653\tvalid_1's rmse: 58.4099\n",
      "[420]\ttraining's rmse: 15.3713\tvalid_1's rmse: 58.1525\n",
      "[450]\ttraining's rmse: 14.2774\tvalid_1's rmse: 57.9552\n",
      "[480]\ttraining's rmse: 13.2813\tvalid_1's rmse: 57.8082\n",
      "[510]\ttraining's rmse: 12.4014\tvalid_1's rmse: 57.6761\n",
      "[540]\ttraining's rmse: 11.598\tvalid_1's rmse: 57.584\n",
      "[570]\ttraining's rmse: 10.8681\tvalid_1's rmse: 57.4956\n",
      "[600]\ttraining's rmse: 10.1877\tvalid_1's rmse: 57.4217\n",
      "[630]\ttraining's rmse: 9.55297\tvalid_1's rmse: 57.3293\n",
      "[660]\ttraining's rmse: 8.97147\tvalid_1's rmse: 57.2548\n",
      "[690]\ttraining's rmse: 8.42914\tvalid_1's rmse: 57.2056\n",
      "[720]\ttraining's rmse: 7.92887\tvalid_1's rmse: 57.1809\n",
      "[750]\ttraining's rmse: 7.46215\tvalid_1's rmse: 57.141\n",
      "[780]\ttraining's rmse: 7.03763\tvalid_1's rmse: 57.0936\n",
      "[810]\ttraining's rmse: 6.63284\tvalid_1's rmse: 57.0643\n",
      "[840]\ttraining's rmse: 6.25771\tvalid_1's rmse: 57.0466\n",
      "[870]\ttraining's rmse: 5.91274\tvalid_1's rmse: 57.0159\n",
      "[900]\ttraining's rmse: 5.58868\tvalid_1's rmse: 56.9873\n",
      "[930]\ttraining's rmse: 5.28925\tvalid_1's rmse: 56.9662\n",
      "[960]\ttraining's rmse: 5.00773\tvalid_1's rmse: 56.945\n",
      "[990]\ttraining's rmse: 4.7376\tvalid_1's rmse: 56.9279\n",
      "[1020]\ttraining's rmse: 4.49032\tvalid_1's rmse: 56.91\n",
      "[1050]\ttraining's rmse: 4.26052\tvalid_1's rmse: 56.9\n",
      "[1080]\ttraining's rmse: 4.04111\tvalid_1's rmse: 56.8856\n",
      "[1110]\ttraining's rmse: 3.83654\tvalid_1's rmse: 56.888\n",
      "[1140]\ttraining's rmse: 3.64072\tvalid_1's rmse: 56.8818\n",
      "[1170]\ttraining's rmse: 3.45965\tvalid_1's rmse: 56.8733\n",
      "[1200]\ttraining's rmse: 3.28846\tvalid_1's rmse: 56.8677\n",
      "[1230]\ttraining's rmse: 3.12495\tvalid_1's rmse: 56.8625\n",
      "[1260]\ttraining's rmse: 2.97099\tvalid_1's rmse: 56.8447\n",
      "[1290]\ttraining's rmse: 2.82738\tvalid_1's rmse: 56.8397\n",
      "[1320]\ttraining's rmse: 2.68833\tvalid_1's rmse: 56.8324\n",
      "[1350]\ttraining's rmse: 2.56214\tvalid_1's rmse: 56.823\n",
      "[1380]\ttraining's rmse: 2.43677\tvalid_1's rmse: 56.8182\n",
      "[1410]\ttraining's rmse: 2.32122\tvalid_1's rmse: 56.8171\n",
      "[1440]\ttraining's rmse: 2.21015\tvalid_1's rmse: 56.8163\n",
      "[1470]\ttraining's rmse: 2.10493\tvalid_1's rmse: 56.8169\n",
      "[1500]\ttraining's rmse: 2.00565\tvalid_1's rmse: 56.8186\n",
      "[1530]\ttraining's rmse: 1.91119\tvalid_1's rmse: 56.8172\n",
      "[1560]\ttraining's rmse: 1.8208\tvalid_1's rmse: 56.813\n",
      "[1590]\ttraining's rmse: 1.73654\tvalid_1's rmse: 56.8124\n",
      "[1620]\ttraining's rmse: 1.6588\tvalid_1's rmse: 56.8119\n",
      "[1650]\ttraining's rmse: 1.58287\tvalid_1's rmse: 56.8116\n",
      "[1680]\ttraining's rmse: 1.50776\tvalid_1's rmse: 56.8078\n",
      "[1710]\ttraining's rmse: 1.43889\tvalid_1's rmse: 56.8054\n",
      "[1740]\ttraining's rmse: 1.37422\tvalid_1's rmse: 56.8059\n",
      "[1770]\ttraining's rmse: 1.31193\tvalid_1's rmse: 56.8047\n",
      "[1800]\ttraining's rmse: 1.25252\tvalid_1's rmse: 56.8029\n",
      "[1830]\ttraining's rmse: 1.19703\tvalid_1's rmse: 56.8063\n",
      "[1860]\ttraining's rmse: 1.14347\tvalid_1's rmse: 56.8062\n",
      "[1890]\ttraining's rmse: 1.09255\tvalid_1's rmse: 56.8064\n",
      "[1920]\ttraining's rmse: 1.0445\tvalid_1's rmse: 56.8064\n",
      "Early stopping, best iteration is:\n",
      "[1802]\ttraining's rmse: 1.24866\tvalid_1's rmse: 56.8027\n",
      "4\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003865 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 20023\n",
      "[LightGBM] [Info] Number of data points in the train set: 9219, number of used features: 79\n",
      "[LightGBM] [Info] Start training from score 378.889588\n",
      "Training until validation scores don't improve for 125 rounds\n",
      "[30]\ttraining's rmse: 173.729\tvalid_1's rmse: 177.784\n",
      "[60]\ttraining's rmse: 105.487\tvalid_1's rmse: 113.089\n",
      "[90]\ttraining's rmse: 68.3961\tvalid_1's rmse: 80.0383\n",
      "[120]\ttraining's rmse: 48.5365\tvalid_1's rmse: 64.4873\n",
      "[150]\ttraining's rmse: 37.7168\tvalid_1's rmse: 57.1925\n",
      "[180]\ttraining's rmse: 31.4859\tvalid_1's rmse: 53.5582\n",
      "[210]\ttraining's rmse: 27.3487\tvalid_1's rmse: 51.5659\n",
      "[240]\ttraining's rmse: 24.3233\tvalid_1's rmse: 50.3075\n",
      "[270]\ttraining's rmse: 21.9157\tvalid_1's rmse: 49.4512\n",
      "[300]\ttraining's rmse: 19.9861\tvalid_1's rmse: 49.0056\n",
      "[330]\ttraining's rmse: 18.3611\tvalid_1's rmse: 48.6327\n",
      "[360]\ttraining's rmse: 16.8769\tvalid_1's rmse: 48.2844\n",
      "[390]\ttraining's rmse: 15.6099\tvalid_1's rmse: 48.0714\n",
      "[420]\ttraining's rmse: 14.4863\tvalid_1's rmse: 47.853\n",
      "[450]\ttraining's rmse: 13.4634\tvalid_1's rmse: 47.676\n",
      "[480]\ttraining's rmse: 12.5344\tvalid_1's rmse: 47.5377\n",
      "[510]\ttraining's rmse: 11.6999\tvalid_1's rmse: 47.4318\n",
      "[540]\ttraining's rmse: 10.9384\tvalid_1's rmse: 47.3224\n",
      "[570]\ttraining's rmse: 10.2338\tvalid_1's rmse: 47.2587\n",
      "[600]\ttraining's rmse: 9.60444\tvalid_1's rmse: 47.184\n",
      "[630]\ttraining's rmse: 9.01249\tvalid_1's rmse: 47.119\n",
      "[660]\ttraining's rmse: 8.46564\tvalid_1's rmse: 47.0555\n",
      "[690]\ttraining's rmse: 7.95352\tvalid_1's rmse: 47.0122\n",
      "[720]\ttraining's rmse: 7.48734\tvalid_1's rmse: 46.9778\n",
      "[750]\ttraining's rmse: 7.05411\tvalid_1's rmse: 46.9431\n",
      "[780]\ttraining's rmse: 6.64655\tvalid_1's rmse: 46.9094\n",
      "[810]\ttraining's rmse: 6.2587\tvalid_1's rmse: 46.865\n",
      "[840]\ttraining's rmse: 5.90236\tvalid_1's rmse: 46.8463\n",
      "[870]\ttraining's rmse: 5.57467\tvalid_1's rmse: 46.8216\n",
      "[900]\ttraining's rmse: 5.26804\tvalid_1's rmse: 46.8003\n",
      "[930]\ttraining's rmse: 4.9814\tvalid_1's rmse: 46.7779\n",
      "[960]\ttraining's rmse: 4.70946\tvalid_1's rmse: 46.7616\n",
      "[990]\ttraining's rmse: 4.4545\tvalid_1's rmse: 46.7492\n",
      "[1020]\ttraining's rmse: 4.21609\tvalid_1's rmse: 46.7367\n",
      "[1050]\ttraining's rmse: 4.00163\tvalid_1's rmse: 46.7271\n",
      "[1080]\ttraining's rmse: 3.7937\tvalid_1's rmse: 46.7022\n",
      "[1110]\ttraining's rmse: 3.60186\tvalid_1's rmse: 46.6807\n",
      "[1140]\ttraining's rmse: 3.42016\tvalid_1's rmse: 46.6732\n",
      "[1170]\ttraining's rmse: 3.2457\tvalid_1's rmse: 46.6663\n",
      "[1200]\ttraining's rmse: 3.08011\tvalid_1's rmse: 46.6574\n",
      "[1230]\ttraining's rmse: 2.92261\tvalid_1's rmse: 46.6516\n",
      "[1260]\ttraining's rmse: 2.77901\tvalid_1's rmse: 46.6441\n",
      "[1290]\ttraining's rmse: 2.64178\tvalid_1's rmse: 46.6364\n",
      "[1320]\ttraining's rmse: 2.51156\tvalid_1's rmse: 46.635\n",
      "[1350]\ttraining's rmse: 2.38877\tvalid_1's rmse: 46.6324\n",
      "[1380]\ttraining's rmse: 2.27068\tvalid_1's rmse: 46.6295\n",
      "[1410]\ttraining's rmse: 2.16034\tvalid_1's rmse: 46.6264\n",
      "[1440]\ttraining's rmse: 2.05566\tvalid_1's rmse: 46.6264\n",
      "[1470]\ttraining's rmse: 1.95775\tvalid_1's rmse: 46.6221\n",
      "[1500]\ttraining's rmse: 1.86495\tvalid_1's rmse: 46.6207\n",
      "[1530]\ttraining's rmse: 1.77376\tvalid_1's rmse: 46.6138\n",
      "[1560]\ttraining's rmse: 1.69018\tvalid_1's rmse: 46.6103\n",
      "[1590]\ttraining's rmse: 1.61153\tvalid_1's rmse: 46.6098\n",
      "[1620]\ttraining's rmse: 1.53541\tvalid_1's rmse: 46.6103\n",
      "[1650]\ttraining's rmse: 1.46375\tvalid_1's rmse: 46.609\n",
      "[1680]\ttraining's rmse: 1.39507\tvalid_1's rmse: 46.6028\n",
      "[1710]\ttraining's rmse: 1.32965\tvalid_1's rmse: 46.6008\n",
      "[1740]\ttraining's rmse: 1.26711\tvalid_1's rmse: 46.5997\n",
      "[1770]\ttraining's rmse: 1.20918\tvalid_1's rmse: 46.598\n",
      "[1800]\ttraining's rmse: 1.15308\tvalid_1's rmse: 46.5973\n",
      "[1830]\ttraining's rmse: 1.09981\tvalid_1's rmse: 46.595\n",
      "[1860]\ttraining's rmse: 1.04921\tvalid_1's rmse: 46.5951\n",
      "[1890]\ttraining's rmse: 1.00146\tvalid_1's rmse: 46.5959\n",
      "[1920]\ttraining's rmse: 0.956822\tvalid_1's rmse: 46.5936\n",
      "[1950]\ttraining's rmse: 0.913809\tvalid_1's rmse: 46.5933\n",
      "[1980]\ttraining's rmse: 0.872485\tvalid_1's rmse: 46.593\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's rmse: 0.84664\tvalid_1's rmse: 46.5927\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003573 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 20023\n",
      "[LightGBM] [Info] Number of data points in the train set: 9219, number of used features: 79\n",
      "[LightGBM] [Info] Start training from score 374.696673\n",
      "Training until validation scores don't improve for 125 rounds\n",
      "[30]\ttraining's rmse: 177.278\tvalid_1's rmse: 183.171\n",
      "[60]\ttraining's rmse: 110.138\tvalid_1's rmse: 120.822\n",
      "[90]\ttraining's rmse: 73.5353\tvalid_1's rmse: 89.1347\n",
      "[120]\ttraining's rmse: 53.6003\tvalid_1's rmse: 73.6927\n",
      "[150]\ttraining's rmse: 42.4085\tvalid_1's rmse: 66.327\n",
      "[180]\ttraining's rmse: 35.6493\tvalid_1's rmse: 62.7151\n",
      "[210]\ttraining's rmse: 31.0186\tvalid_1's rmse: 60.8244\n",
      "[240]\ttraining's rmse: 27.6412\tvalid_1's rmse: 59.6458\n",
      "[270]\ttraining's rmse: 24.9047\tvalid_1's rmse: 59.0256\n",
      "[300]\ttraining's rmse: 22.6515\tvalid_1's rmse: 58.5086\n",
      "[330]\ttraining's rmse: 20.7099\tvalid_1's rmse: 58.1338\n",
      "[360]\ttraining's rmse: 19.0294\tvalid_1's rmse: 57.8398\n",
      "[390]\ttraining's rmse: 17.5366\tvalid_1's rmse: 57.6141\n",
      "[420]\ttraining's rmse: 16.2448\tvalid_1's rmse: 57.3462\n",
      "[450]\ttraining's rmse: 15.0791\tvalid_1's rmse: 57.2161\n",
      "[480]\ttraining's rmse: 14.0308\tvalid_1's rmse: 57.0893\n",
      "[510]\ttraining's rmse: 13.0805\tvalid_1's rmse: 56.9586\n",
      "[540]\ttraining's rmse: 12.2142\tvalid_1's rmse: 56.8928\n",
      "[570]\ttraining's rmse: 11.4209\tvalid_1's rmse: 56.8289\n",
      "[600]\ttraining's rmse: 10.7053\tvalid_1's rmse: 56.7512\n",
      "[630]\ttraining's rmse: 10.0472\tvalid_1's rmse: 56.6997\n",
      "[660]\ttraining's rmse: 9.42278\tvalid_1's rmse: 56.6386\n",
      "[690]\ttraining's rmse: 8.83963\tvalid_1's rmse: 56.5994\n",
      "[720]\ttraining's rmse: 8.31634\tvalid_1's rmse: 56.5537\n",
      "[750]\ttraining's rmse: 7.81812\tvalid_1's rmse: 56.5441\n",
      "[780]\ttraining's rmse: 7.35913\tvalid_1's rmse: 56.5109\n",
      "[810]\ttraining's rmse: 6.93398\tvalid_1's rmse: 56.4659\n",
      "[840]\ttraining's rmse: 6.54763\tvalid_1's rmse: 56.4539\n",
      "[870]\ttraining's rmse: 6.17803\tvalid_1's rmse: 56.4313\n",
      "[900]\ttraining's rmse: 5.83784\tvalid_1's rmse: 56.4175\n",
      "[930]\ttraining's rmse: 5.52482\tvalid_1's rmse: 56.4095\n",
      "[960]\ttraining's rmse: 5.21861\tvalid_1's rmse: 56.3864\n",
      "[990]\ttraining's rmse: 4.93789\tvalid_1's rmse: 56.3703\n",
      "[1020]\ttraining's rmse: 4.67915\tvalid_1's rmse: 56.369\n",
      "[1050]\ttraining's rmse: 4.43324\tvalid_1's rmse: 56.3638\n",
      "[1080]\ttraining's rmse: 4.19917\tvalid_1's rmse: 56.3407\n",
      "[1110]\ttraining's rmse: 3.98445\tvalid_1's rmse: 56.3341\n",
      "[1140]\ttraining's rmse: 3.77662\tvalid_1's rmse: 56.3282\n",
      "[1170]\ttraining's rmse: 3.58575\tvalid_1's rmse: 56.3134\n",
      "[1200]\ttraining's rmse: 3.40318\tvalid_1's rmse: 56.2992\n",
      "[1230]\ttraining's rmse: 3.23229\tvalid_1's rmse: 56.289\n",
      "[1260]\ttraining's rmse: 3.07064\tvalid_1's rmse: 56.284\n",
      "[1290]\ttraining's rmse: 2.91863\tvalid_1's rmse: 56.2863\n",
      "[1320]\ttraining's rmse: 2.77229\tvalid_1's rmse: 56.2798\n",
      "[1350]\ttraining's rmse: 2.63166\tvalid_1's rmse: 56.2769\n",
      "[1380]\ttraining's rmse: 2.50381\tvalid_1's rmse: 56.2751\n",
      "[1410]\ttraining's rmse: 2.38025\tvalid_1's rmse: 56.2722\n",
      "[1440]\ttraining's rmse: 2.2651\tvalid_1's rmse: 56.2726\n",
      "[1470]\ttraining's rmse: 2.15473\tvalid_1's rmse: 56.2625\n",
      "[1500]\ttraining's rmse: 2.04783\tvalid_1's rmse: 56.2547\n",
      "[1530]\ttraining's rmse: 1.94843\tvalid_1's rmse: 56.2482\n",
      "[1560]\ttraining's rmse: 1.85457\tvalid_1's rmse: 56.247\n",
      "[1590]\ttraining's rmse: 1.76592\tvalid_1's rmse: 56.244\n",
      "[1620]\ttraining's rmse: 1.68224\tvalid_1's rmse: 56.2458\n",
      "[1650]\ttraining's rmse: 1.60394\tvalid_1's rmse: 56.245\n",
      "[1680]\ttraining's rmse: 1.52966\tvalid_1's rmse: 56.2445\n",
      "Early stopping, best iteration is:\n",
      "[1584]\ttraining's rmse: 1.7839\tvalid_1's rmse: 56.2425\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002455 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 20023\n",
      "[LightGBM] [Info] Number of data points in the train set: 9219, number of used features: 79\n",
      "[LightGBM] [Info] Start training from score 372.605724\n",
      "Training until validation scores don't improve for 125 rounds\n",
      "[30]\ttraining's rmse: 175.804\tvalid_1's rmse: 183.39\n",
      "[60]\ttraining's rmse: 107.437\tvalid_1's rmse: 118.287\n",
      "[90]\ttraining's rmse: 70.3757\tvalid_1's rmse: 85.8318\n",
      "[120]\ttraining's rmse: 50.5255\tvalid_1's rmse: 70.6146\n",
      "[150]\ttraining's rmse: 39.6023\tvalid_1's rmse: 63.6652\n",
      "[180]\ttraining's rmse: 33.1998\tvalid_1's rmse: 60.2447\n",
      "[210]\ttraining's rmse: 28.8992\tvalid_1's rmse: 58.317\n",
      "[240]\ttraining's rmse: 25.6991\tvalid_1's rmse: 57.1079\n",
      "[270]\ttraining's rmse: 23.1509\tvalid_1's rmse: 56.4273\n",
      "[300]\ttraining's rmse: 21.0964\tvalid_1's rmse: 55.8439\n",
      "[330]\ttraining's rmse: 19.3612\tvalid_1's rmse: 55.4838\n",
      "[360]\ttraining's rmse: 17.8702\tvalid_1's rmse: 55.2243\n",
      "[390]\ttraining's rmse: 16.5158\tvalid_1's rmse: 54.9694\n",
      "[420]\ttraining's rmse: 15.3272\tvalid_1's rmse: 54.8041\n",
      "[450]\ttraining's rmse: 14.2469\tvalid_1's rmse: 54.6594\n",
      "[480]\ttraining's rmse: 13.2767\tvalid_1's rmse: 54.5259\n",
      "[510]\ttraining's rmse: 12.4114\tvalid_1's rmse: 54.4367\n",
      "[540]\ttraining's rmse: 11.5889\tvalid_1's rmse: 54.3802\n",
      "[570]\ttraining's rmse: 10.8521\tvalid_1's rmse: 54.3261\n",
      "[600]\ttraining's rmse: 10.1939\tvalid_1's rmse: 54.2802\n",
      "[630]\ttraining's rmse: 9.5663\tvalid_1's rmse: 54.2096\n",
      "[660]\ttraining's rmse: 8.99848\tvalid_1's rmse: 54.1609\n",
      "[690]\ttraining's rmse: 8.47078\tvalid_1's rmse: 54.1158\n",
      "[720]\ttraining's rmse: 7.98863\tvalid_1's rmse: 54.088\n",
      "[750]\ttraining's rmse: 7.53287\tvalid_1's rmse: 54.0701\n",
      "[780]\ttraining's rmse: 7.09825\tvalid_1's rmse: 54.0373\n",
      "[810]\ttraining's rmse: 6.69956\tvalid_1's rmse: 54.0054\n",
      "[840]\ttraining's rmse: 6.32897\tvalid_1's rmse: 53.9707\n",
      "[870]\ttraining's rmse: 5.97931\tvalid_1's rmse: 53.9346\n",
      "[900]\ttraining's rmse: 5.65222\tvalid_1's rmse: 53.9124\n",
      "[930]\ttraining's rmse: 5.35023\tvalid_1's rmse: 53.8962\n",
      "[960]\ttraining's rmse: 5.06228\tvalid_1's rmse: 53.8636\n",
      "[990]\ttraining's rmse: 4.79909\tvalid_1's rmse: 53.8394\n",
      "[1020]\ttraining's rmse: 4.54638\tvalid_1's rmse: 53.8253\n",
      "[1050]\ttraining's rmse: 4.31106\tvalid_1's rmse: 53.8083\n",
      "[1080]\ttraining's rmse: 4.0934\tvalid_1's rmse: 53.8073\n",
      "[1110]\ttraining's rmse: 3.88797\tvalid_1's rmse: 53.7962\n",
      "[1140]\ttraining's rmse: 3.69567\tvalid_1's rmse: 53.7851\n",
      "[1170]\ttraining's rmse: 3.5065\tvalid_1's rmse: 53.7741\n",
      "[1200]\ttraining's rmse: 3.33471\tvalid_1's rmse: 53.7662\n",
      "[1230]\ttraining's rmse: 3.16945\tvalid_1's rmse: 53.7535\n",
      "[1260]\ttraining's rmse: 3.01257\tvalid_1's rmse: 53.7476\n",
      "[1290]\ttraining's rmse: 2.86601\tvalid_1's rmse: 53.7391\n",
      "[1320]\ttraining's rmse: 2.72942\tvalid_1's rmse: 53.7372\n",
      "[1350]\ttraining's rmse: 2.60038\tvalid_1's rmse: 53.7297\n",
      "[1380]\ttraining's rmse: 2.47529\tvalid_1's rmse: 53.7299\n",
      "[1410]\ttraining's rmse: 2.35737\tvalid_1's rmse: 53.7256\n",
      "[1440]\ttraining's rmse: 2.24624\tvalid_1's rmse: 53.7193\n",
      "[1470]\ttraining's rmse: 2.1425\tvalid_1's rmse: 53.7123\n",
      "[1500]\ttraining's rmse: 2.04119\tvalid_1's rmse: 53.7101\n",
      "[1530]\ttraining's rmse: 1.94609\tvalid_1's rmse: 53.7078\n",
      "[1560]\ttraining's rmse: 1.85601\tvalid_1's rmse: 53.7047\n",
      "[1590]\ttraining's rmse: 1.77314\tvalid_1's rmse: 53.7022\n",
      "[1620]\ttraining's rmse: 1.6933\tvalid_1's rmse: 53.6993\n",
      "[1650]\ttraining's rmse: 1.61914\tvalid_1's rmse: 53.6936\n",
      "[1680]\ttraining's rmse: 1.54676\tvalid_1's rmse: 53.6886\n",
      "[1710]\ttraining's rmse: 1.4774\tvalid_1's rmse: 53.6867\n",
      "[1740]\ttraining's rmse: 1.41166\tvalid_1's rmse: 53.6845\n",
      "[1770]\ttraining's rmse: 1.34946\tvalid_1's rmse: 53.681\n",
      "[1800]\ttraining's rmse: 1.29003\tvalid_1's rmse: 53.6777\n",
      "[1830]\ttraining's rmse: 1.23372\tvalid_1's rmse: 53.6744\n",
      "[1860]\ttraining's rmse: 1.17902\tvalid_1's rmse: 53.6699\n",
      "[1890]\ttraining's rmse: 1.12744\tvalid_1's rmse: 53.6682\n",
      "[1920]\ttraining's rmse: 1.07943\tvalid_1's rmse: 53.6651\n",
      "[1950]\ttraining's rmse: 1.03335\tvalid_1's rmse: 53.6646\n",
      "[1980]\ttraining's rmse: 0.990109\tvalid_1's rmse: 53.6633\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's rmse: 0.960957\tvalid_1's rmse: 53.6618\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003497 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 20023\n",
      "[LightGBM] [Info] Number of data points in the train set: 9219, number of used features: 79\n",
      "[LightGBM] [Info] Start training from score 375.725620\n",
      "Training until validation scores don't improve for 125 rounds\n",
      "[30]\ttraining's rmse: 175.311\tvalid_1's rmse: 182.264\n",
      "[60]\ttraining's rmse: 107.239\tvalid_1's rmse: 118.926\n",
      "[90]\ttraining's rmse: 70.535\tvalid_1's rmse: 87.7846\n",
      "[120]\ttraining's rmse: 50.9832\tvalid_1's rmse: 73.4984\n",
      "[150]\ttraining's rmse: 40.1387\tvalid_1's rmse: 66.7773\n",
      "[180]\ttraining's rmse: 33.6696\tvalid_1's rmse: 63.1658\n",
      "[210]\ttraining's rmse: 29.3939\tvalid_1's rmse: 61.1247\n",
      "[240]\ttraining's rmse: 26.0683\tvalid_1's rmse: 59.6989\n",
      "[270]\ttraining's rmse: 23.4573\tvalid_1's rmse: 58.6369\n",
      "[300]\ttraining's rmse: 21.3483\tvalid_1's rmse: 58.0262\n",
      "[330]\ttraining's rmse: 19.5908\tvalid_1's rmse: 57.613\n",
      "[360]\ttraining's rmse: 18.0733\tvalid_1's rmse: 57.2987\n",
      "[390]\ttraining's rmse: 16.7145\tvalid_1's rmse: 56.9714\n",
      "[420]\ttraining's rmse: 15.5027\tvalid_1's rmse: 56.7298\n",
      "[450]\ttraining's rmse: 14.4094\tvalid_1's rmse: 56.5381\n",
      "[480]\ttraining's rmse: 13.4341\tvalid_1's rmse: 56.3728\n",
      "[510]\ttraining's rmse: 12.5274\tvalid_1's rmse: 56.2457\n",
      "[540]\ttraining's rmse: 11.6912\tvalid_1's rmse: 56.1455\n",
      "[570]\ttraining's rmse: 10.9628\tvalid_1's rmse: 56.0505\n",
      "[600]\ttraining's rmse: 10.2942\tvalid_1's rmse: 55.955\n",
      "[630]\ttraining's rmse: 9.65449\tvalid_1's rmse: 55.8408\n",
      "[660]\ttraining's rmse: 9.08625\tvalid_1's rmse: 55.7747\n",
      "[690]\ttraining's rmse: 8.54863\tvalid_1's rmse: 55.7207\n",
      "[720]\ttraining's rmse: 8.0486\tvalid_1's rmse: 55.6701\n",
      "[750]\ttraining's rmse: 7.58053\tvalid_1's rmse: 55.6288\n",
      "[780]\ttraining's rmse: 7.14687\tvalid_1's rmse: 55.6024\n",
      "[810]\ttraining's rmse: 6.74289\tvalid_1's rmse: 55.563\n",
      "[840]\ttraining's rmse: 6.373\tvalid_1's rmse: 55.5226\n",
      "[870]\ttraining's rmse: 6.01313\tvalid_1's rmse: 55.5005\n",
      "[900]\ttraining's rmse: 5.68532\tvalid_1's rmse: 55.4598\n",
      "[930]\ttraining's rmse: 5.38059\tvalid_1's rmse: 55.4278\n",
      "[960]\ttraining's rmse: 5.09299\tvalid_1's rmse: 55.403\n",
      "[990]\ttraining's rmse: 4.81432\tvalid_1's rmse: 55.3719\n",
      "[1020]\ttraining's rmse: 4.56219\tvalid_1's rmse: 55.3446\n",
      "[1050]\ttraining's rmse: 4.32071\tvalid_1's rmse: 55.3157\n",
      "[1080]\ttraining's rmse: 4.09603\tvalid_1's rmse: 55.2946\n",
      "[1110]\ttraining's rmse: 3.8854\tvalid_1's rmse: 55.2829\n",
      "[1140]\ttraining's rmse: 3.69176\tvalid_1's rmse: 55.2741\n",
      "[1170]\ttraining's rmse: 3.50154\tvalid_1's rmse: 55.2666\n",
      "[1200]\ttraining's rmse: 3.32341\tvalid_1's rmse: 55.2628\n",
      "[1230]\ttraining's rmse: 3.15707\tvalid_1's rmse: 55.2519\n",
      "[1260]\ttraining's rmse: 3.00163\tvalid_1's rmse: 55.2434\n",
      "[1290]\ttraining's rmse: 2.85765\tvalid_1's rmse: 55.2391\n",
      "[1320]\ttraining's rmse: 2.71563\tvalid_1's rmse: 55.2325\n",
      "[1350]\ttraining's rmse: 2.58648\tvalid_1's rmse: 55.2261\n",
      "[1380]\ttraining's rmse: 2.4576\tvalid_1's rmse: 55.219\n",
      "[1410]\ttraining's rmse: 2.33816\tvalid_1's rmse: 55.2136\n",
      "[1440]\ttraining's rmse: 2.22437\tvalid_1's rmse: 55.2117\n",
      "[1470]\ttraining's rmse: 2.11936\tvalid_1's rmse: 55.2024\n",
      "[1500]\ttraining's rmse: 2.01963\tvalid_1's rmse: 55.1932\n",
      "[1530]\ttraining's rmse: 1.92582\tvalid_1's rmse: 55.1919\n",
      "[1560]\ttraining's rmse: 1.83596\tvalid_1's rmse: 55.1869\n",
      "[1590]\ttraining's rmse: 1.74993\tvalid_1's rmse: 55.1823\n",
      "[1620]\ttraining's rmse: 1.66829\tvalid_1's rmse: 55.1774\n",
      "[1650]\ttraining's rmse: 1.5925\tvalid_1's rmse: 55.1786\n",
      "[1680]\ttraining's rmse: 1.52056\tvalid_1's rmse: 55.1753\n",
      "[1710]\ttraining's rmse: 1.4498\tvalid_1's rmse: 55.1721\n",
      "[1740]\ttraining's rmse: 1.38357\tvalid_1's rmse: 55.1691\n",
      "[1770]\ttraining's rmse: 1.31909\tvalid_1's rmse: 55.1626\n",
      "[1800]\ttraining's rmse: 1.26\tvalid_1's rmse: 55.1605\n",
      "[1830]\ttraining's rmse: 1.202\tvalid_1's rmse: 55.1576\n",
      "[1860]\ttraining's rmse: 1.14783\tvalid_1's rmse: 55.1541\n",
      "[1890]\ttraining's rmse: 1.0968\tvalid_1's rmse: 55.1505\n",
      "[1920]\ttraining's rmse: 1.04895\tvalid_1's rmse: 55.1493\n",
      "[1950]\ttraining's rmse: 1.00053\tvalid_1's rmse: 55.1447\n",
      "[1980]\ttraining's rmse: 0.954655\tvalid_1's rmse: 55.1433\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's rmse: 0.925477\tvalid_1's rmse: 55.1431\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003400 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 20023\n",
      "[LightGBM] [Info] Number of data points in the train set: 9219, number of used features: 79\n",
      "[LightGBM] [Info] Start training from score 374.635276\n",
      "Training until validation scores don't improve for 125 rounds\n",
      "[30]\ttraining's rmse: 177.322\tvalid_1's rmse: 182.065\n",
      "[60]\ttraining's rmse: 108.967\tvalid_1's rmse: 119.501\n",
      "[90]\ttraining's rmse: 71.9403\tvalid_1's rmse: 88.7275\n",
      "[120]\ttraining's rmse: 51.9248\tvalid_1's rmse: 74.2419\n",
      "[150]\ttraining's rmse: 40.8871\tvalid_1's rmse: 67.7862\n",
      "[180]\ttraining's rmse: 34.4182\tvalid_1's rmse: 64.8527\n",
      "[210]\ttraining's rmse: 30.0294\tvalid_1's rmse: 63.0899\n",
      "[240]\ttraining's rmse: 26.6737\tvalid_1's rmse: 61.7321\n",
      "[270]\ttraining's rmse: 24.0579\tvalid_1's rmse: 60.733\n",
      "[300]\ttraining's rmse: 21.9088\tvalid_1's rmse: 60.1614\n",
      "[330]\ttraining's rmse: 20.0936\tvalid_1's rmse: 59.7626\n",
      "[360]\ttraining's rmse: 18.5201\tvalid_1's rmse: 59.4278\n",
      "[390]\ttraining's rmse: 17.1311\tvalid_1's rmse: 59.1606\n",
      "[420]\ttraining's rmse: 15.9067\tvalid_1's rmse: 58.9299\n",
      "[450]\ttraining's rmse: 14.773\tvalid_1's rmse: 58.7262\n",
      "[480]\ttraining's rmse: 13.7657\tvalid_1's rmse: 58.5914\n",
      "[510]\ttraining's rmse: 12.8214\tvalid_1's rmse: 58.469\n",
      "[540]\ttraining's rmse: 11.9803\tvalid_1's rmse: 58.3497\n",
      "[570]\ttraining's rmse: 11.2114\tvalid_1's rmse: 58.2384\n",
      "[600]\ttraining's rmse: 10.5157\tvalid_1's rmse: 58.185\n",
      "[630]\ttraining's rmse: 9.87305\tvalid_1's rmse: 58.1352\n",
      "[660]\ttraining's rmse: 9.27421\tvalid_1's rmse: 58.0547\n",
      "[690]\ttraining's rmse: 8.72258\tvalid_1's rmse: 58.0307\n",
      "[720]\ttraining's rmse: 8.19746\tvalid_1's rmse: 57.9769\n",
      "[750]\ttraining's rmse: 7.71156\tvalid_1's rmse: 57.9298\n",
      "[780]\ttraining's rmse: 7.26781\tvalid_1's rmse: 57.9146\n",
      "[810]\ttraining's rmse: 6.86127\tvalid_1's rmse: 57.8954\n",
      "[840]\ttraining's rmse: 6.47302\tvalid_1's rmse: 57.8496\n",
      "[870]\ttraining's rmse: 6.10949\tvalid_1's rmse: 57.8182\n",
      "[900]\ttraining's rmse: 5.77667\tvalid_1's rmse: 57.7743\n",
      "[930]\ttraining's rmse: 5.4607\tvalid_1's rmse: 57.7495\n",
      "[960]\ttraining's rmse: 5.16407\tvalid_1's rmse: 57.7365\n",
      "[990]\ttraining's rmse: 4.89176\tvalid_1's rmse: 57.7257\n",
      "[1020]\ttraining's rmse: 4.63381\tvalid_1's rmse: 57.7115\n",
      "[1050]\ttraining's rmse: 4.3919\tvalid_1's rmse: 57.6781\n",
      "[1080]\ttraining's rmse: 4.16315\tvalid_1's rmse: 57.6716\n",
      "[1110]\ttraining's rmse: 3.94734\tvalid_1's rmse: 57.6717\n",
      "[1140]\ttraining's rmse: 3.74737\tvalid_1's rmse: 57.6545\n",
      "[1170]\ttraining's rmse: 3.55498\tvalid_1's rmse: 57.6378\n",
      "[1200]\ttraining's rmse: 3.37421\tvalid_1's rmse: 57.6315\n",
      "[1230]\ttraining's rmse: 3.20501\tvalid_1's rmse: 57.622\n",
      "[1260]\ttraining's rmse: 3.04549\tvalid_1's rmse: 57.6107\n",
      "[1290]\ttraining's rmse: 2.8933\tvalid_1's rmse: 57.6068\n",
      "[1320]\ttraining's rmse: 2.75205\tvalid_1's rmse: 57.5971\n",
      "[1350]\ttraining's rmse: 2.62003\tvalid_1's rmse: 57.5948\n",
      "[1380]\ttraining's rmse: 2.49259\tvalid_1's rmse: 57.5834\n",
      "[1410]\ttraining's rmse: 2.36998\tvalid_1's rmse: 57.5775\n",
      "[1440]\ttraining's rmse: 2.25406\tvalid_1's rmse: 57.5748\n",
      "[1470]\ttraining's rmse: 2.14787\tvalid_1's rmse: 57.572\n",
      "[1500]\ttraining's rmse: 2.04568\tvalid_1's rmse: 57.5646\n",
      "[1530]\ttraining's rmse: 1.94829\tvalid_1's rmse: 57.5608\n",
      "[1560]\ttraining's rmse: 1.85593\tvalid_1's rmse: 57.5513\n",
      "[1590]\ttraining's rmse: 1.76773\tvalid_1's rmse: 57.5498\n",
      "[1620]\ttraining's rmse: 1.68445\tvalid_1's rmse: 57.5489\n",
      "[1650]\ttraining's rmse: 1.602\tvalid_1's rmse: 57.5463\n",
      "[1680]\ttraining's rmse: 1.52522\tvalid_1's rmse: 57.5435\n",
      "[1710]\ttraining's rmse: 1.45173\tvalid_1's rmse: 57.5398\n",
      "[1740]\ttraining's rmse: 1.38464\tvalid_1's rmse: 57.5371\n",
      "[1770]\ttraining's rmse: 1.31994\tvalid_1's rmse: 57.5373\n",
      "[1800]\ttraining's rmse: 1.25919\tvalid_1's rmse: 57.5379\n",
      "[1830]\ttraining's rmse: 1.2016\tvalid_1's rmse: 57.5363\n",
      "[1860]\ttraining's rmse: 1.14746\tvalid_1's rmse: 57.5332\n",
      "[1890]\ttraining's rmse: 1.09448\tvalid_1's rmse: 57.5336\n",
      "[1920]\ttraining's rmse: 1.04419\tvalid_1's rmse: 57.5318\n",
      "[1950]\ttraining's rmse: 0.996807\tvalid_1's rmse: 57.5309\n",
      "[1980]\ttraining's rmse: 0.952124\tvalid_1's rmse: 57.531\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's rmse: 0.923658\tvalid_1's rmse: 57.5315\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003322 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 20023\n",
      "[LightGBM] [Info] Number of data points in the train set: 9219, number of used features: 79\n",
      "[LightGBM] [Info] Start training from score 375.079039\n",
      "Training until validation scores don't improve for 125 rounds\n",
      "[30]\ttraining's rmse: 176.269\tvalid_1's rmse: 185.175\n",
      "[60]\ttraining's rmse: 108.064\tvalid_1's rmse: 121.425\n",
      "[90]\ttraining's rmse: 71.0322\tvalid_1's rmse: 89.7881\n",
      "[120]\ttraining's rmse: 50.9817\tvalid_1's rmse: 74.9147\n",
      "[150]\ttraining's rmse: 39.8988\tvalid_1's rmse: 67.8521\n",
      "[180]\ttraining's rmse: 33.3719\tvalid_1's rmse: 64.335\n",
      "[210]\ttraining's rmse: 29.05\tvalid_1's rmse: 62.234\n",
      "[240]\ttraining's rmse: 25.8527\tvalid_1's rmse: 61.0041\n",
      "[270]\ttraining's rmse: 23.3368\tvalid_1's rmse: 60.1102\n",
      "[300]\ttraining's rmse: 21.2253\tvalid_1's rmse: 59.52\n",
      "[330]\ttraining's rmse: 19.4719\tvalid_1's rmse: 59.0428\n",
      "[360]\ttraining's rmse: 17.9716\tvalid_1's rmse: 58.7511\n",
      "[390]\ttraining's rmse: 16.6198\tvalid_1's rmse: 58.4649\n",
      "[420]\ttraining's rmse: 15.4091\tvalid_1's rmse: 58.2385\n",
      "[450]\ttraining's rmse: 14.3475\tvalid_1's rmse: 58.0286\n",
      "[480]\ttraining's rmse: 13.371\tvalid_1's rmse: 57.895\n",
      "[510]\ttraining's rmse: 12.4873\tvalid_1's rmse: 57.7784\n",
      "[540]\ttraining's rmse: 11.6833\tvalid_1's rmse: 57.6674\n",
      "[570]\ttraining's rmse: 10.9467\tvalid_1's rmse: 57.5818\n",
      "[600]\ttraining's rmse: 10.2659\tvalid_1's rmse: 57.4846\n",
      "[630]\ttraining's rmse: 9.64038\tvalid_1's rmse: 57.4129\n",
      "[660]\ttraining's rmse: 9.06868\tvalid_1's rmse: 57.3574\n",
      "[690]\ttraining's rmse: 8.53008\tvalid_1's rmse: 57.3282\n",
      "[720]\ttraining's rmse: 8.02864\tvalid_1's rmse: 57.278\n",
      "[750]\ttraining's rmse: 7.57443\tvalid_1's rmse: 57.2161\n",
      "[780]\ttraining's rmse: 7.14685\tvalid_1's rmse: 57.2032\n",
      "[810]\ttraining's rmse: 6.73996\tvalid_1's rmse: 57.1582\n",
      "[840]\ttraining's rmse: 6.37289\tvalid_1's rmse: 57.1319\n",
      "[870]\ttraining's rmse: 6.02202\tvalid_1's rmse: 57.0984\n",
      "[900]\ttraining's rmse: 5.70283\tvalid_1's rmse: 57.0819\n",
      "[930]\ttraining's rmse: 5.40072\tvalid_1's rmse: 57.0508\n",
      "[960]\ttraining's rmse: 5.11552\tvalid_1's rmse: 57.0318\n",
      "[990]\ttraining's rmse: 4.8531\tvalid_1's rmse: 57.0119\n",
      "[1020]\ttraining's rmse: 4.59981\tvalid_1's rmse: 56.9891\n",
      "[1050]\ttraining's rmse: 4.36461\tvalid_1's rmse: 56.98\n",
      "[1080]\ttraining's rmse: 4.14333\tvalid_1's rmse: 56.9743\n",
      "[1110]\ttraining's rmse: 3.93434\tvalid_1's rmse: 56.9616\n",
      "[1140]\ttraining's rmse: 3.73809\tvalid_1's rmse: 56.961\n",
      "[1170]\ttraining's rmse: 3.55495\tvalid_1's rmse: 56.9523\n",
      "[1200]\ttraining's rmse: 3.38563\tvalid_1's rmse: 56.9477\n",
      "[1230]\ttraining's rmse: 3.22483\tvalid_1's rmse: 56.9354\n",
      "[1260]\ttraining's rmse: 3.06842\tvalid_1's rmse: 56.9354\n",
      "[1290]\ttraining's rmse: 2.92042\tvalid_1's rmse: 56.9222\n",
      "[1320]\ttraining's rmse: 2.78352\tvalid_1's rmse: 56.9179\n",
      "[1350]\ttraining's rmse: 2.65448\tvalid_1's rmse: 56.9082\n",
      "[1380]\ttraining's rmse: 2.52781\tvalid_1's rmse: 56.9048\n",
      "[1410]\ttraining's rmse: 2.40858\tvalid_1's rmse: 56.8965\n",
      "[1440]\ttraining's rmse: 2.2973\tvalid_1's rmse: 56.895\n",
      "[1470]\ttraining's rmse: 2.19186\tvalid_1's rmse: 56.8897\n",
      "[1500]\ttraining's rmse: 2.08716\tvalid_1's rmse: 56.8913\n",
      "[1530]\ttraining's rmse: 1.98995\tvalid_1's rmse: 56.8876\n",
      "[1560]\ttraining's rmse: 1.901\tvalid_1's rmse: 56.8847\n",
      "[1590]\ttraining's rmse: 1.81659\tvalid_1's rmse: 56.8828\n",
      "[1620]\ttraining's rmse: 1.73909\tvalid_1's rmse: 56.8797\n",
      "[1650]\ttraining's rmse: 1.66115\tvalid_1's rmse: 56.8787\n",
      "[1680]\ttraining's rmse: 1.58755\tvalid_1's rmse: 56.873\n",
      "[1710]\ttraining's rmse: 1.51615\tvalid_1's rmse: 56.8699\n",
      "[1740]\ttraining's rmse: 1.44938\tvalid_1's rmse: 56.8681\n",
      "[1770]\ttraining's rmse: 1.38593\tvalid_1's rmse: 56.8664\n",
      "[1800]\ttraining's rmse: 1.32639\tvalid_1's rmse: 56.8606\n",
      "[1830]\ttraining's rmse: 1.26824\tvalid_1's rmse: 56.8606\n",
      "[1860]\ttraining's rmse: 1.21392\tvalid_1's rmse: 56.8592\n",
      "[1890]\ttraining's rmse: 1.1624\tvalid_1's rmse: 56.8591\n",
      "[1920]\ttraining's rmse: 1.11169\tvalid_1's rmse: 56.8564\n",
      "[1950]\ttraining's rmse: 1.06454\tvalid_1's rmse: 56.8534\n",
      "[1980]\ttraining's rmse: 1.01812\tvalid_1's rmse: 56.8535\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's rmse: 0.989055\tvalid_1's rmse: 56.8543\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003644 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 20023\n",
      "[LightGBM] [Info] Number of data points in the train set: 9219, number of used features: 79\n",
      "[LightGBM] [Info] Start training from score 371.342398\n",
      "Training until validation scores don't improve for 125 rounds\n",
      "[30]\ttraining's rmse: 176.715\tvalid_1's rmse: 185.782\n",
      "[60]\ttraining's rmse: 108.261\tvalid_1's rmse: 121.597\n",
      "[90]\ttraining's rmse: 70.9637\tvalid_1's rmse: 89.7083\n",
      "[120]\ttraining's rmse: 50.805\tvalid_1's rmse: 74.4305\n",
      "[150]\ttraining's rmse: 39.7462\tvalid_1's rmse: 66.9527\n",
      "[180]\ttraining's rmse: 33.2883\tvalid_1's rmse: 63.3466\n",
      "[210]\ttraining's rmse: 28.9207\tvalid_1's rmse: 61.094\n",
      "[240]\ttraining's rmse: 25.6604\tvalid_1's rmse: 59.6032\n",
      "[270]\ttraining's rmse: 23.1609\tvalid_1's rmse: 58.6172\n",
      "[300]\ttraining's rmse: 21.1032\tvalid_1's rmse: 57.8813\n",
      "[330]\ttraining's rmse: 19.3346\tvalid_1's rmse: 57.3919\n",
      "[360]\ttraining's rmse: 17.8415\tvalid_1's rmse: 56.9622\n",
      "[390]\ttraining's rmse: 16.5014\tvalid_1's rmse: 56.6697\n",
      "[420]\ttraining's rmse: 15.3001\tvalid_1's rmse: 56.4498\n",
      "[450]\ttraining's rmse: 14.2417\tvalid_1's rmse: 56.2911\n",
      "[480]\ttraining's rmse: 13.2609\tvalid_1's rmse: 56.0967\n",
      "[510]\ttraining's rmse: 12.3835\tvalid_1's rmse: 55.945\n",
      "[540]\ttraining's rmse: 11.5911\tvalid_1's rmse: 55.8199\n",
      "[570]\ttraining's rmse: 10.8648\tvalid_1's rmse: 55.7248\n",
      "[600]\ttraining's rmse: 10.1985\tvalid_1's rmse: 55.6541\n",
      "[630]\ttraining's rmse: 9.58699\tvalid_1's rmse: 55.5693\n",
      "[660]\ttraining's rmse: 9.00877\tvalid_1's rmse: 55.4893\n",
      "[690]\ttraining's rmse: 8.48409\tvalid_1's rmse: 55.4509\n",
      "[720]\ttraining's rmse: 7.99781\tvalid_1's rmse: 55.4049\n",
      "[750]\ttraining's rmse: 7.54323\tvalid_1's rmse: 55.3665\n",
      "[780]\ttraining's rmse: 7.12313\tvalid_1's rmse: 55.3308\n",
      "[810]\ttraining's rmse: 6.7209\tvalid_1's rmse: 55.2966\n",
      "[840]\ttraining's rmse: 6.35511\tvalid_1's rmse: 55.2832\n",
      "[870]\ttraining's rmse: 6.0093\tvalid_1's rmse: 55.2613\n",
      "[900]\ttraining's rmse: 5.67894\tvalid_1's rmse: 55.2315\n",
      "[930]\ttraining's rmse: 5.37227\tvalid_1's rmse: 55.2073\n",
      "[960]\ttraining's rmse: 5.09414\tvalid_1's rmse: 55.1796\n",
      "[990]\ttraining's rmse: 4.81928\tvalid_1's rmse: 55.169\n",
      "[1020]\ttraining's rmse: 4.56882\tvalid_1's rmse: 55.1607\n",
      "[1050]\ttraining's rmse: 4.33717\tvalid_1's rmse: 55.1453\n",
      "[1080]\ttraining's rmse: 4.11206\tvalid_1's rmse: 55.1206\n",
      "[1110]\ttraining's rmse: 3.90616\tvalid_1's rmse: 55.1027\n",
      "[1140]\ttraining's rmse: 3.70388\tvalid_1's rmse: 55.0893\n",
      "[1170]\ttraining's rmse: 3.52198\tvalid_1's rmse: 55.0733\n",
      "[1200]\ttraining's rmse: 3.34922\tvalid_1's rmse: 55.0609\n",
      "[1230]\ttraining's rmse: 3.18293\tvalid_1's rmse: 55.0432\n",
      "[1260]\ttraining's rmse: 3.02282\tvalid_1's rmse: 55.0361\n",
      "[1290]\ttraining's rmse: 2.87157\tvalid_1's rmse: 55.0353\n",
      "[1320]\ttraining's rmse: 2.73391\tvalid_1's rmse: 55.0284\n",
      "[1350]\ttraining's rmse: 2.60188\tvalid_1's rmse: 55.0237\n",
      "[1380]\ttraining's rmse: 2.47944\tvalid_1's rmse: 55.0186\n",
      "[1410]\ttraining's rmse: 2.36165\tvalid_1's rmse: 55.0104\n",
      "[1440]\ttraining's rmse: 2.24875\tvalid_1's rmse: 55.0078\n",
      "[1470]\ttraining's rmse: 2.13779\tvalid_1's rmse: 55.0015\n",
      "[1500]\ttraining's rmse: 2.0382\tvalid_1's rmse: 55.0014\n",
      "[1530]\ttraining's rmse: 1.94357\tvalid_1's rmse: 54.9967\n",
      "[1560]\ttraining's rmse: 1.85335\tvalid_1's rmse: 54.9961\n",
      "[1590]\ttraining's rmse: 1.76645\tvalid_1's rmse: 54.9929\n",
      "[1620]\ttraining's rmse: 1.68633\tvalid_1's rmse: 54.9914\n",
      "[1650]\ttraining's rmse: 1.60887\tvalid_1's rmse: 54.9882\n",
      "[1680]\ttraining's rmse: 1.53648\tvalid_1's rmse: 54.9867\n",
      "[1710]\ttraining's rmse: 1.46881\tvalid_1's rmse: 54.9874\n",
      "[1740]\ttraining's rmse: 1.40288\tvalid_1's rmse: 54.9858\n",
      "[1770]\ttraining's rmse: 1.33955\tvalid_1's rmse: 54.9849\n",
      "[1800]\ttraining's rmse: 1.27928\tvalid_1's rmse: 54.9839\n",
      "[1830]\ttraining's rmse: 1.22277\tvalid_1's rmse: 54.9818\n",
      "[1860]\ttraining's rmse: 1.16826\tvalid_1's rmse: 54.9809\n",
      "[1890]\ttraining's rmse: 1.117\tvalid_1's rmse: 54.9808\n",
      "[1920]\ttraining's rmse: 1.06716\tvalid_1's rmse: 54.9795\n",
      "[1950]\ttraining's rmse: 1.02125\tvalid_1's rmse: 54.9782\n",
      "[1980]\ttraining's rmse: 0.978254\tvalid_1's rmse: 54.9774\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's rmse: 0.950116\tvalid_1's rmse: 54.9776\n",
      "5\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002432 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 20024\n",
      "[LightGBM] [Info] Number of data points in the train set: 9219, number of used features: 79\n",
      "[LightGBM] [Info] Start training from score 378.655421\n",
      "Training until validation scores don't improve for 125 rounds\n",
      "[30]\ttraining's rmse: 173.244\tvalid_1's rmse: 179.521\n",
      "[60]\ttraining's rmse: 104.798\tvalid_1's rmse: 114.835\n",
      "[90]\ttraining's rmse: 67.7878\tvalid_1's rmse: 81.8851\n",
      "[120]\ttraining's rmse: 47.9214\tvalid_1's rmse: 66.0447\n",
      "[150]\ttraining's rmse: 37.2258\tvalid_1's rmse: 58.6104\n",
      "[180]\ttraining's rmse: 31.1128\tvalid_1's rmse: 54.8503\n",
      "[210]\ttraining's rmse: 27.0856\tvalid_1's rmse: 52.7915\n",
      "[240]\ttraining's rmse: 24.0099\tvalid_1's rmse: 51.5294\n",
      "[270]\ttraining's rmse: 21.6986\tvalid_1's rmse: 50.73\n",
      "[300]\ttraining's rmse: 19.7805\tvalid_1's rmse: 50.183\n",
      "[330]\ttraining's rmse: 18.1699\tvalid_1's rmse: 49.8058\n",
      "[360]\ttraining's rmse: 16.752\tvalid_1's rmse: 49.4857\n",
      "[390]\ttraining's rmse: 15.4787\tvalid_1's rmse: 49.2633\n",
      "[420]\ttraining's rmse: 14.3888\tvalid_1's rmse: 49.0856\n",
      "[450]\ttraining's rmse: 13.3803\tvalid_1's rmse: 48.929\n",
      "[480]\ttraining's rmse: 12.4723\tvalid_1's rmse: 48.804\n",
      "[510]\ttraining's rmse: 11.6477\tvalid_1's rmse: 48.7415\n",
      "[540]\ttraining's rmse: 10.8958\tvalid_1's rmse: 48.6415\n",
      "[570]\ttraining's rmse: 10.2088\tvalid_1's rmse: 48.5602\n",
      "[600]\ttraining's rmse: 9.57613\tvalid_1's rmse: 48.5042\n",
      "[630]\ttraining's rmse: 8.98953\tvalid_1's rmse: 48.4389\n",
      "[660]\ttraining's rmse: 8.44052\tvalid_1's rmse: 48.3764\n",
      "[690]\ttraining's rmse: 7.93729\tvalid_1's rmse: 48.343\n",
      "[720]\ttraining's rmse: 7.47417\tvalid_1's rmse: 48.307\n",
      "[750]\ttraining's rmse: 7.03736\tvalid_1's rmse: 48.2421\n",
      "[780]\ttraining's rmse: 6.64002\tvalid_1's rmse: 48.2062\n",
      "[810]\ttraining's rmse: 6.26965\tvalid_1's rmse: 48.1726\n",
      "[840]\ttraining's rmse: 5.91833\tvalid_1's rmse: 48.1431\n",
      "[870]\ttraining's rmse: 5.59092\tvalid_1's rmse: 48.1088\n",
      "[900]\ttraining's rmse: 5.2845\tvalid_1's rmse: 48.0888\n",
      "[930]\ttraining's rmse: 5.00064\tvalid_1's rmse: 48.0798\n",
      "[960]\ttraining's rmse: 4.73324\tvalid_1's rmse: 48.0621\n",
      "[990]\ttraining's rmse: 4.47991\tvalid_1's rmse: 48.0472\n",
      "[1020]\ttraining's rmse: 4.24834\tvalid_1's rmse: 48.0247\n",
      "[1050]\ttraining's rmse: 4.02838\tvalid_1's rmse: 48.0112\n",
      "[1080]\ttraining's rmse: 3.81929\tvalid_1's rmse: 47.9973\n",
      "[1110]\ttraining's rmse: 3.62418\tvalid_1's rmse: 47.9874\n",
      "[1140]\ttraining's rmse: 3.4384\tvalid_1's rmse: 47.9792\n",
      "[1170]\ttraining's rmse: 3.26218\tvalid_1's rmse: 47.9737\n",
      "[1200]\ttraining's rmse: 3.09828\tvalid_1's rmse: 47.9639\n",
      "[1230]\ttraining's rmse: 2.94465\tvalid_1's rmse: 47.9531\n",
      "[1260]\ttraining's rmse: 2.79896\tvalid_1's rmse: 47.9468\n",
      "[1290]\ttraining's rmse: 2.6608\tvalid_1's rmse: 47.9434\n",
      "[1320]\ttraining's rmse: 2.52937\tvalid_1's rmse: 47.9348\n",
      "[1350]\ttraining's rmse: 2.40438\tvalid_1's rmse: 47.9312\n",
      "[1380]\ttraining's rmse: 2.28676\tvalid_1's rmse: 47.9217\n",
      "[1410]\ttraining's rmse: 2.17411\tvalid_1's rmse: 47.9139\n",
      "[1440]\ttraining's rmse: 2.06814\tvalid_1's rmse: 47.9075\n",
      "[1470]\ttraining's rmse: 1.96978\tvalid_1's rmse: 47.9056\n",
      "[1500]\ttraining's rmse: 1.8749\tvalid_1's rmse: 47.8978\n",
      "[1530]\ttraining's rmse: 1.78514\tvalid_1's rmse: 47.8927\n",
      "[1560]\ttraining's rmse: 1.69702\tvalid_1's rmse: 47.8886\n",
      "[1590]\ttraining's rmse: 1.61807\tvalid_1's rmse: 47.8828\n",
      "[1620]\ttraining's rmse: 1.54177\tvalid_1's rmse: 47.8804\n",
      "[1650]\ttraining's rmse: 1.4703\tvalid_1's rmse: 47.8772\n",
      "[1680]\ttraining's rmse: 1.40102\tvalid_1's rmse: 47.8733\n",
      "[1710]\ttraining's rmse: 1.33494\tvalid_1's rmse: 47.8704\n",
      "[1740]\ttraining's rmse: 1.27167\tvalid_1's rmse: 47.8663\n",
      "[1770]\ttraining's rmse: 1.21376\tvalid_1's rmse: 47.8643\n",
      "[1800]\ttraining's rmse: 1.15899\tvalid_1's rmse: 47.8599\n",
      "[1830]\ttraining's rmse: 1.1064\tvalid_1's rmse: 47.8587\n",
      "[1860]\ttraining's rmse: 1.05459\tvalid_1's rmse: 47.8569\n",
      "[1890]\ttraining's rmse: 1.00673\tvalid_1's rmse: 47.8562\n",
      "[1920]\ttraining's rmse: 0.962227\tvalid_1's rmse: 47.8556\n",
      "[1950]\ttraining's rmse: 0.919632\tvalid_1's rmse: 47.8538\n",
      "[1980]\ttraining's rmse: 0.878203\tvalid_1's rmse: 47.8542\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's rmse: 0.851434\tvalid_1's rmse: 47.8524\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002662 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 20024\n",
      "[LightGBM] [Info] Number of data points in the train set: 9219, number of used features: 79\n",
      "[LightGBM] [Info] Start training from score 376.520758\n",
      "Training until validation scores don't improve for 125 rounds\n",
      "[30]\ttraining's rmse: 175.837\tvalid_1's rmse: 183.166\n",
      "[60]\ttraining's rmse: 108.532\tvalid_1's rmse: 119.928\n",
      "[90]\ttraining's rmse: 71.9972\tvalid_1's rmse: 88.1329\n",
      "[120]\ttraining's rmse: 52.2747\tvalid_1's rmse: 72.7934\n",
      "[150]\ttraining's rmse: 41.1742\tvalid_1's rmse: 65.4917\n",
      "[180]\ttraining's rmse: 34.5866\tvalid_1's rmse: 62.0331\n",
      "[210]\ttraining's rmse: 30.0526\tvalid_1's rmse: 60.0084\n",
      "[240]\ttraining's rmse: 26.5983\tvalid_1's rmse: 58.5905\n",
      "[270]\ttraining's rmse: 23.895\tvalid_1's rmse: 57.6483\n",
      "[300]\ttraining's rmse: 21.6863\tvalid_1's rmse: 56.9808\n",
      "[330]\ttraining's rmse: 19.7928\tvalid_1's rmse: 56.5296\n",
      "[360]\ttraining's rmse: 18.1855\tvalid_1's rmse: 56.2046\n",
      "[390]\ttraining's rmse: 16.758\tvalid_1's rmse: 55.9071\n",
      "[420]\ttraining's rmse: 15.4921\tvalid_1's rmse: 55.6948\n",
      "[450]\ttraining's rmse: 14.3872\tvalid_1's rmse: 55.4753\n",
      "[480]\ttraining's rmse: 13.3501\tvalid_1's rmse: 55.3826\n",
      "[510]\ttraining's rmse: 12.4296\tvalid_1's rmse: 55.2965\n",
      "[540]\ttraining's rmse: 11.583\tvalid_1's rmse: 55.1911\n",
      "[570]\ttraining's rmse: 10.8249\tvalid_1's rmse: 55.1028\n",
      "[600]\ttraining's rmse: 10.1275\tvalid_1's rmse: 55.0308\n",
      "[630]\ttraining's rmse: 9.49732\tvalid_1's rmse: 54.9898\n",
      "[660]\ttraining's rmse: 8.92113\tvalid_1's rmse: 54.9644\n",
      "[690]\ttraining's rmse: 8.36403\tvalid_1's rmse: 54.8806\n",
      "[720]\ttraining's rmse: 7.8565\tvalid_1's rmse: 54.8519\n",
      "[750]\ttraining's rmse: 7.38471\tvalid_1's rmse: 54.7998\n",
      "[780]\ttraining's rmse: 6.94971\tvalid_1's rmse: 54.7602\n",
      "[810]\ttraining's rmse: 6.5518\tvalid_1's rmse: 54.7248\n",
      "[840]\ttraining's rmse: 6.17756\tvalid_1's rmse: 54.6971\n",
      "[870]\ttraining's rmse: 5.83365\tvalid_1's rmse: 54.6833\n",
      "[900]\ttraining's rmse: 5.51366\tvalid_1's rmse: 54.6632\n",
      "[930]\ttraining's rmse: 5.20411\tvalid_1's rmse: 54.6389\n",
      "[960]\ttraining's rmse: 4.92176\tvalid_1's rmse: 54.6237\n",
      "[990]\ttraining's rmse: 4.65251\tvalid_1's rmse: 54.5874\n",
      "[1020]\ttraining's rmse: 4.40624\tvalid_1's rmse: 54.5871\n",
      "[1050]\ttraining's rmse: 4.17406\tvalid_1's rmse: 54.5706\n",
      "[1080]\ttraining's rmse: 3.94976\tvalid_1's rmse: 54.5589\n",
      "[1110]\ttraining's rmse: 3.74165\tvalid_1's rmse: 54.5524\n",
      "[1140]\ttraining's rmse: 3.54501\tvalid_1's rmse: 54.5439\n",
      "[1170]\ttraining's rmse: 3.36279\tvalid_1's rmse: 54.5323\n",
      "[1200]\ttraining's rmse: 3.18882\tvalid_1's rmse: 54.5214\n",
      "[1230]\ttraining's rmse: 3.02522\tvalid_1's rmse: 54.5153\n",
      "[1260]\ttraining's rmse: 2.87066\tvalid_1's rmse: 54.506\n",
      "[1290]\ttraining's rmse: 2.72311\tvalid_1's rmse: 54.4988\n",
      "[1320]\ttraining's rmse: 2.58609\tvalid_1's rmse: 54.4942\n",
      "[1350]\ttraining's rmse: 2.4564\tvalid_1's rmse: 54.4895\n",
      "[1380]\ttraining's rmse: 2.33424\tvalid_1's rmse: 54.4846\n",
      "[1410]\ttraining's rmse: 2.22012\tvalid_1's rmse: 54.4819\n",
      "[1440]\ttraining's rmse: 2.10899\tvalid_1's rmse: 54.4743\n",
      "[1470]\ttraining's rmse: 2.0049\tvalid_1's rmse: 54.4744\n",
      "[1500]\ttraining's rmse: 1.90771\tvalid_1's rmse: 54.4692\n",
      "[1530]\ttraining's rmse: 1.81353\tvalid_1's rmse: 54.4674\n",
      "[1560]\ttraining's rmse: 1.72379\tvalid_1's rmse: 54.4684\n",
      "[1590]\ttraining's rmse: 1.63965\tvalid_1's rmse: 54.4692\n",
      "[1620]\ttraining's rmse: 1.5599\tvalid_1's rmse: 54.468\n",
      "[1650]\ttraining's rmse: 1.4857\tvalid_1's rmse: 54.4652\n",
      "[1680]\ttraining's rmse: 1.41393\tvalid_1's rmse: 54.4614\n",
      "[1710]\ttraining's rmse: 1.34527\tvalid_1's rmse: 54.459\n",
      "[1740]\ttraining's rmse: 1.28271\tvalid_1's rmse: 54.4576\n",
      "[1770]\ttraining's rmse: 1.22213\tvalid_1's rmse: 54.4582\n",
      "[1800]\ttraining's rmse: 1.16326\tvalid_1's rmse: 54.4559\n",
      "[1830]\ttraining's rmse: 1.10743\tvalid_1's rmse: 54.4549\n",
      "[1860]\ttraining's rmse: 1.05595\tvalid_1's rmse: 54.4521\n",
      "[1890]\ttraining's rmse: 1.00649\tvalid_1's rmse: 54.4499\n",
      "[1920]\ttraining's rmse: 0.959984\tvalid_1's rmse: 54.4507\n",
      "[1950]\ttraining's rmse: 0.916613\tvalid_1's rmse: 54.451\n",
      "[1980]\ttraining's rmse: 0.873221\tvalid_1's rmse: 54.4501\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's rmse: 0.846099\tvalid_1's rmse: 54.449\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003368 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 20024\n",
      "[LightGBM] [Info] Number of data points in the train set: 9219, number of used features: 79\n",
      "[LightGBM] [Info] Start training from score 378.889588\n",
      "Training until validation scores don't improve for 125 rounds\n",
      "[30]\ttraining's rmse: 175.157\tvalid_1's rmse: 179.622\n",
      "[60]\ttraining's rmse: 107.718\tvalid_1's rmse: 116.199\n",
      "[90]\ttraining's rmse: 71.0662\tvalid_1's rmse: 84.8907\n",
      "[120]\ttraining's rmse: 51.1494\tvalid_1's rmse: 70.0944\n",
      "[150]\ttraining's rmse: 40.156\tvalid_1's rmse: 63.3029\n",
      "[180]\ttraining's rmse: 33.755\tvalid_1's rmse: 59.9208\n",
      "[210]\ttraining's rmse: 29.4083\tvalid_1's rmse: 58.0944\n",
      "[240]\ttraining's rmse: 26.1997\tvalid_1's rmse: 56.8932\n",
      "[270]\ttraining's rmse: 23.6205\tvalid_1's rmse: 56.0804\n",
      "[300]\ttraining's rmse: 21.4926\tvalid_1's rmse: 55.497\n",
      "[330]\ttraining's rmse: 19.7102\tvalid_1's rmse: 55.0888\n",
      "[360]\ttraining's rmse: 18.1698\tvalid_1's rmse: 54.7926\n",
      "[390]\ttraining's rmse: 16.814\tvalid_1's rmse: 54.4751\n",
      "[420]\ttraining's rmse: 15.6062\tvalid_1's rmse: 54.2836\n",
      "[450]\ttraining's rmse: 14.5149\tvalid_1's rmse: 54.1316\n",
      "[480]\ttraining's rmse: 13.5199\tvalid_1's rmse: 54.0461\n",
      "[510]\ttraining's rmse: 12.6074\tvalid_1's rmse: 53.9425\n",
      "[540]\ttraining's rmse: 11.8078\tvalid_1's rmse: 53.873\n",
      "[570]\ttraining's rmse: 11.0516\tvalid_1's rmse: 53.7988\n",
      "[600]\ttraining's rmse: 10.3862\tvalid_1's rmse: 53.7546\n",
      "[630]\ttraining's rmse: 9.75884\tvalid_1's rmse: 53.7006\n",
      "[660]\ttraining's rmse: 9.17644\tvalid_1's rmse: 53.6412\n",
      "[690]\ttraining's rmse: 8.62914\tvalid_1's rmse: 53.6259\n",
      "[720]\ttraining's rmse: 8.12947\tvalid_1's rmse: 53.6068\n",
      "[750]\ttraining's rmse: 7.65568\tvalid_1's rmse: 53.5643\n",
      "[780]\ttraining's rmse: 7.22304\tvalid_1's rmse: 53.5378\n",
      "[810]\ttraining's rmse: 6.8237\tvalid_1's rmse: 53.5218\n",
      "[840]\ttraining's rmse: 6.44924\tvalid_1's rmse: 53.5071\n",
      "[870]\ttraining's rmse: 6.10578\tvalid_1's rmse: 53.4887\n",
      "[900]\ttraining's rmse: 5.78258\tvalid_1's rmse: 53.4706\n",
      "[930]\ttraining's rmse: 5.47764\tvalid_1's rmse: 53.4458\n",
      "[960]\ttraining's rmse: 5.19072\tvalid_1's rmse: 53.4336\n",
      "[990]\ttraining's rmse: 4.91904\tvalid_1's rmse: 53.4145\n",
      "[1020]\ttraining's rmse: 4.67157\tvalid_1's rmse: 53.3936\n",
      "[1050]\ttraining's rmse: 4.43987\tvalid_1's rmse: 53.3867\n",
      "[1080]\ttraining's rmse: 4.22343\tvalid_1's rmse: 53.3763\n",
      "[1110]\ttraining's rmse: 4.01621\tvalid_1's rmse: 53.3756\n",
      "[1140]\ttraining's rmse: 3.81824\tvalid_1's rmse: 53.37\n",
      "[1170]\ttraining's rmse: 3.63521\tvalid_1's rmse: 53.3574\n",
      "[1200]\ttraining's rmse: 3.46169\tvalid_1's rmse: 53.3512\n",
      "[1230]\ttraining's rmse: 3.29818\tvalid_1's rmse: 53.35\n",
      "[1260]\ttraining's rmse: 3.13802\tvalid_1's rmse: 53.3462\n",
      "[1290]\ttraining's rmse: 2.99343\tvalid_1's rmse: 53.3355\n",
      "[1320]\ttraining's rmse: 2.85984\tvalid_1's rmse: 53.3293\n",
      "[1350]\ttraining's rmse: 2.72648\tvalid_1's rmse: 53.3252\n",
      "[1380]\ttraining's rmse: 2.60087\tvalid_1's rmse: 53.3191\n",
      "[1410]\ttraining's rmse: 2.4836\tvalid_1's rmse: 53.3181\n",
      "[1440]\ttraining's rmse: 2.37531\tvalid_1's rmse: 53.3159\n",
      "[1470]\ttraining's rmse: 2.27076\tvalid_1's rmse: 53.3156\n",
      "[1500]\ttraining's rmse: 2.1715\tvalid_1's rmse: 53.312\n",
      "[1530]\ttraining's rmse: 2.07354\tvalid_1's rmse: 53.3056\n",
      "[1560]\ttraining's rmse: 1.98481\tvalid_1's rmse: 53.3068\n",
      "[1590]\ttraining's rmse: 1.90185\tvalid_1's rmse: 53.3061\n",
      "[1620]\ttraining's rmse: 1.82211\tvalid_1's rmse: 53.306\n",
      "[1650]\ttraining's rmse: 1.74646\tvalid_1's rmse: 53.3011\n",
      "[1680]\ttraining's rmse: 1.67168\tvalid_1's rmse: 53.2967\n",
      "[1710]\ttraining's rmse: 1.60238\tvalid_1's rmse: 53.2952\n",
      "[1740]\ttraining's rmse: 1.53674\tvalid_1's rmse: 53.2914\n",
      "[1770]\ttraining's rmse: 1.47196\tvalid_1's rmse: 53.2928\n",
      "[1800]\ttraining's rmse: 1.41124\tvalid_1's rmse: 53.2917\n",
      "[1830]\ttraining's rmse: 1.35571\tvalid_1's rmse: 53.2937\n",
      "[1860]\ttraining's rmse: 1.30073\tvalid_1's rmse: 53.2927\n",
      "[1890]\ttraining's rmse: 1.24957\tvalid_1's rmse: 53.2902\n",
      "[1920]\ttraining's rmse: 1.20172\tvalid_1's rmse: 53.2879\n",
      "[1950]\ttraining's rmse: 1.15545\tvalid_1's rmse: 53.2875\n",
      "[1980]\ttraining's rmse: 1.1101\tvalid_1's rmse: 53.2874\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's rmse: 1.08218\tvalid_1's rmse: 53.2873\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003512 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 20024\n",
      "[LightGBM] [Info] Number of data points in the train set: 9219, number of used features: 79\n",
      "[LightGBM] [Info] Start training from score 374.696673\n",
      "Training until validation scores don't improve for 125 rounds\n",
      "[30]\ttraining's rmse: 176.03\tvalid_1's rmse: 180.77\n",
      "[60]\ttraining's rmse: 107.941\tvalid_1's rmse: 116.49\n",
      "[90]\ttraining's rmse: 71.3591\tvalid_1's rmse: 84.1858\n",
      "[120]\ttraining's rmse: 51.518\tvalid_1's rmse: 68.6165\n",
      "[150]\ttraining's rmse: 40.5829\tvalid_1's rmse: 61.465\n",
      "[180]\ttraining's rmse: 34.0328\tvalid_1's rmse: 57.9338\n",
      "[210]\ttraining's rmse: 29.6053\tvalid_1's rmse: 56.0898\n",
      "[240]\ttraining's rmse: 26.4302\tvalid_1's rmse: 55.0786\n",
      "[270]\ttraining's rmse: 23.8115\tvalid_1's rmse: 54.3913\n",
      "[300]\ttraining's rmse: 21.6566\tvalid_1's rmse: 53.9231\n",
      "[330]\ttraining's rmse: 19.8436\tvalid_1's rmse: 53.5908\n",
      "[360]\ttraining's rmse: 18.2594\tvalid_1's rmse: 53.378\n",
      "[390]\ttraining's rmse: 16.89\tvalid_1's rmse: 53.203\n",
      "[420]\ttraining's rmse: 15.682\tvalid_1's rmse: 53.018\n",
      "[450]\ttraining's rmse: 14.586\tvalid_1's rmse: 52.9309\n",
      "[480]\ttraining's rmse: 13.5728\tvalid_1's rmse: 52.8225\n",
      "[510]\ttraining's rmse: 12.6676\tvalid_1's rmse: 52.7093\n",
      "[540]\ttraining's rmse: 11.8427\tvalid_1's rmse: 52.6655\n",
      "[570]\ttraining's rmse: 11.0897\tvalid_1's rmse: 52.5945\n",
      "[600]\ttraining's rmse: 10.406\tvalid_1's rmse: 52.5281\n",
      "[630]\ttraining's rmse: 9.77796\tvalid_1's rmse: 52.4787\n",
      "[660]\ttraining's rmse: 9.18449\tvalid_1's rmse: 52.4723\n",
      "[690]\ttraining's rmse: 8.6371\tvalid_1's rmse: 52.4351\n",
      "[720]\ttraining's rmse: 8.13481\tvalid_1's rmse: 52.4006\n",
      "[750]\ttraining's rmse: 7.65945\tvalid_1's rmse: 52.3716\n",
      "[780]\ttraining's rmse: 7.22869\tvalid_1's rmse: 52.3326\n",
      "[810]\ttraining's rmse: 6.8272\tvalid_1's rmse: 52.2969\n",
      "[840]\ttraining's rmse: 6.45508\tvalid_1's rmse: 52.2717\n",
      "[870]\ttraining's rmse: 6.09598\tvalid_1's rmse: 52.2662\n",
      "[900]\ttraining's rmse: 5.75878\tvalid_1's rmse: 52.255\n",
      "[930]\ttraining's rmse: 5.44774\tvalid_1's rmse: 52.224\n",
      "[960]\ttraining's rmse: 5.15527\tvalid_1's rmse: 52.2148\n",
      "[990]\ttraining's rmse: 4.88212\tvalid_1's rmse: 52.2155\n",
      "[1020]\ttraining's rmse: 4.62676\tvalid_1's rmse: 52.2077\n",
      "[1050]\ttraining's rmse: 4.38771\tvalid_1's rmse: 52.196\n",
      "[1080]\ttraining's rmse: 4.16362\tvalid_1's rmse: 52.1887\n",
      "[1110]\ttraining's rmse: 3.95348\tvalid_1's rmse: 52.1772\n",
      "[1140]\ttraining's rmse: 3.75516\tvalid_1's rmse: 52.178\n",
      "[1170]\ttraining's rmse: 3.56755\tvalid_1's rmse: 52.1674\n",
      "[1200]\ttraining's rmse: 3.38941\tvalid_1's rmse: 52.1638\n",
      "[1230]\ttraining's rmse: 3.22336\tvalid_1's rmse: 52.1567\n",
      "[1260]\ttraining's rmse: 3.05777\tvalid_1's rmse: 52.1488\n",
      "[1290]\ttraining's rmse: 2.91108\tvalid_1's rmse: 52.1452\n",
      "[1320]\ttraining's rmse: 2.77029\tvalid_1's rmse: 52.1433\n",
      "[1350]\ttraining's rmse: 2.63459\tvalid_1's rmse: 52.1439\n",
      "[1380]\ttraining's rmse: 2.50989\tvalid_1's rmse: 52.1393\n",
      "[1410]\ttraining's rmse: 2.38918\tvalid_1's rmse: 52.1413\n",
      "[1440]\ttraining's rmse: 2.27546\tvalid_1's rmse: 52.1409\n",
      "[1470]\ttraining's rmse: 2.16834\tvalid_1's rmse: 52.1424\n",
      "Early stopping, best iteration is:\n",
      "[1368]\ttraining's rmse: 2.55811\tvalid_1's rmse: 52.1375\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003812 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 20024\n",
      "[LightGBM] [Info] Number of data points in the train set: 9219, number of used features: 79\n",
      "[LightGBM] [Info] Start training from score 372.605724\n",
      "Training until validation scores don't improve for 125 rounds\n",
      "[30]\ttraining's rmse: 176.44\tvalid_1's rmse: 183.498\n",
      "[60]\ttraining's rmse: 108.432\tvalid_1's rmse: 118.998\n",
      "[90]\ttraining's rmse: 71.7351\tvalid_1's rmse: 86.9882\n",
      "[120]\ttraining's rmse: 51.7507\tvalid_1's rmse: 71.6138\n",
      "[150]\ttraining's rmse: 40.5952\tvalid_1's rmse: 64.5065\n",
      "[180]\ttraining's rmse: 34.0683\tvalid_1's rmse: 60.9616\n",
      "[210]\ttraining's rmse: 29.6545\tvalid_1's rmse: 58.9578\n",
      "[240]\ttraining's rmse: 26.3072\tvalid_1's rmse: 57.6391\n",
      "[270]\ttraining's rmse: 23.6448\tvalid_1's rmse: 56.7326\n",
      "[300]\ttraining's rmse: 21.5129\tvalid_1's rmse: 56.0579\n",
      "[330]\ttraining's rmse: 19.7332\tvalid_1's rmse: 55.63\n",
      "[360]\ttraining's rmse: 18.1942\tvalid_1's rmse: 55.3009\n",
      "[390]\ttraining's rmse: 16.8059\tvalid_1's rmse: 55.0352\n",
      "[420]\ttraining's rmse: 15.5884\tvalid_1's rmse: 54.8289\n",
      "[450]\ttraining's rmse: 14.5098\tvalid_1's rmse: 54.6454\n",
      "[480]\ttraining's rmse: 13.5184\tvalid_1's rmse: 54.5295\n",
      "[510]\ttraining's rmse: 12.6208\tvalid_1's rmse: 54.4337\n",
      "[540]\ttraining's rmse: 11.7764\tvalid_1's rmse: 54.3233\n",
      "[570]\ttraining's rmse: 11.0323\tvalid_1's rmse: 54.2445\n",
      "[600]\ttraining's rmse: 10.3608\tvalid_1's rmse: 54.1729\n",
      "[630]\ttraining's rmse: 9.7205\tvalid_1's rmse: 54.1031\n",
      "[660]\ttraining's rmse: 9.14132\tvalid_1's rmse: 54.0343\n",
      "[690]\ttraining's rmse: 8.60999\tvalid_1's rmse: 53.9959\n",
      "[720]\ttraining's rmse: 8.10654\tvalid_1's rmse: 53.9529\n",
      "[750]\ttraining's rmse: 7.64689\tvalid_1's rmse: 53.9162\n",
      "[780]\ttraining's rmse: 7.21318\tvalid_1's rmse: 53.867\n",
      "[810]\ttraining's rmse: 6.80759\tvalid_1's rmse: 53.8403\n",
      "[840]\ttraining's rmse: 6.42876\tvalid_1's rmse: 53.8065\n",
      "[870]\ttraining's rmse: 6.08337\tvalid_1's rmse: 53.79\n",
      "[900]\ttraining's rmse: 5.7605\tvalid_1's rmse: 53.7648\n",
      "[930]\ttraining's rmse: 5.44867\tvalid_1's rmse: 53.7431\n",
      "[960]\ttraining's rmse: 5.16213\tvalid_1's rmse: 53.7125\n",
      "[990]\ttraining's rmse: 4.89386\tvalid_1's rmse: 53.6911\n",
      "[1020]\ttraining's rmse: 4.63799\tvalid_1's rmse: 53.6781\n",
      "[1050]\ttraining's rmse: 4.40032\tvalid_1's rmse: 53.6671\n",
      "[1080]\ttraining's rmse: 4.17554\tvalid_1's rmse: 53.6463\n",
      "[1110]\ttraining's rmse: 3.96965\tvalid_1's rmse: 53.6336\n",
      "[1140]\ttraining's rmse: 3.77441\tvalid_1's rmse: 53.6172\n",
      "[1170]\ttraining's rmse: 3.58527\tvalid_1's rmse: 53.6045\n",
      "[1200]\ttraining's rmse: 3.41299\tvalid_1's rmse: 53.6019\n",
      "[1230]\ttraining's rmse: 3.25018\tvalid_1's rmse: 53.5974\n",
      "[1260]\ttraining's rmse: 3.09366\tvalid_1's rmse: 53.5945\n",
      "[1290]\ttraining's rmse: 2.94578\tvalid_1's rmse: 53.5882\n",
      "[1320]\ttraining's rmse: 2.80391\tvalid_1's rmse: 53.5809\n",
      "[1350]\ttraining's rmse: 2.67215\tvalid_1's rmse: 53.5742\n",
      "[1380]\ttraining's rmse: 2.5512\tvalid_1's rmse: 53.5707\n",
      "[1410]\ttraining's rmse: 2.43296\tvalid_1's rmse: 53.5668\n",
      "[1440]\ttraining's rmse: 2.32021\tvalid_1's rmse: 53.5627\n",
      "[1470]\ttraining's rmse: 2.21513\tvalid_1's rmse: 53.5576\n",
      "[1500]\ttraining's rmse: 2.11224\tvalid_1's rmse: 53.5533\n",
      "[1530]\ttraining's rmse: 2.01698\tvalid_1's rmse: 53.5481\n",
      "[1560]\ttraining's rmse: 1.92572\tvalid_1's rmse: 53.5462\n",
      "[1590]\ttraining's rmse: 1.83967\tvalid_1's rmse: 53.5437\n",
      "[1620]\ttraining's rmse: 1.7599\tvalid_1's rmse: 53.546\n",
      "[1650]\ttraining's rmse: 1.6825\tvalid_1's rmse: 53.5411\n",
      "[1680]\ttraining's rmse: 1.60726\tvalid_1's rmse: 53.5358\n",
      "[1710]\ttraining's rmse: 1.53477\tvalid_1's rmse: 53.533\n",
      "[1740]\ttraining's rmse: 1.46967\tvalid_1's rmse: 53.529\n",
      "[1770]\ttraining's rmse: 1.40596\tvalid_1's rmse: 53.5268\n",
      "[1800]\ttraining's rmse: 1.34461\tvalid_1's rmse: 53.5271\n",
      "[1830]\ttraining's rmse: 1.28646\tvalid_1's rmse: 53.5252\n",
      "[1860]\ttraining's rmse: 1.23071\tvalid_1's rmse: 53.5233\n",
      "[1890]\ttraining's rmse: 1.17691\tvalid_1's rmse: 53.521\n",
      "[1920]\ttraining's rmse: 1.12714\tvalid_1's rmse: 53.5201\n",
      "[1950]\ttraining's rmse: 1.07745\tvalid_1's rmse: 53.5172\n",
      "[1980]\ttraining's rmse: 1.03339\tvalid_1's rmse: 53.5151\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's rmse: 1.00384\tvalid_1's rmse: 53.5139\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003528 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 20024\n",
      "[LightGBM] [Info] Number of data points in the train set: 9219, number of used features: 79\n",
      "[LightGBM] [Info] Start training from score 375.725620\n",
      "Training until validation scores don't improve for 125 rounds\n",
      "[30]\ttraining's rmse: 175.792\tvalid_1's rmse: 182.543\n",
      "[60]\ttraining's rmse: 107.799\tvalid_1's rmse: 119.396\n",
      "[90]\ttraining's rmse: 71.068\tvalid_1's rmse: 88.4861\n",
      "[120]\ttraining's rmse: 51.2888\tvalid_1's rmse: 74.164\n",
      "[150]\ttraining's rmse: 40.3041\tvalid_1's rmse: 67.3615\n",
      "[180]\ttraining's rmse: 33.7748\tvalid_1's rmse: 63.8775\n",
      "[210]\ttraining's rmse: 29.4815\tvalid_1's rmse: 61.7879\n",
      "[240]\ttraining's rmse: 26.2606\tvalid_1's rmse: 60.3974\n",
      "[270]\ttraining's rmse: 23.6811\tvalid_1's rmse: 59.3495\n",
      "[300]\ttraining's rmse: 21.5549\tvalid_1's rmse: 58.7045\n",
      "[330]\ttraining's rmse: 19.7503\tvalid_1's rmse: 58.1971\n",
      "[360]\ttraining's rmse: 18.2138\tvalid_1's rmse: 57.7828\n",
      "[390]\ttraining's rmse: 16.8252\tvalid_1's rmse: 57.4865\n",
      "[420]\ttraining's rmse: 15.6023\tvalid_1's rmse: 57.1984\n",
      "[450]\ttraining's rmse: 14.5041\tvalid_1's rmse: 56.9628\n",
      "[480]\ttraining's rmse: 13.5213\tvalid_1's rmse: 56.8186\n",
      "[510]\ttraining's rmse: 12.6013\tvalid_1's rmse: 56.6293\n",
      "[540]\ttraining's rmse: 11.7747\tvalid_1's rmse: 56.5269\n",
      "[570]\ttraining's rmse: 11.0537\tvalid_1's rmse: 56.4209\n",
      "[600]\ttraining's rmse: 10.3559\tvalid_1's rmse: 56.3318\n",
      "[630]\ttraining's rmse: 9.7226\tvalid_1's rmse: 56.2507\n",
      "[660]\ttraining's rmse: 9.13857\tvalid_1's rmse: 56.164\n",
      "[690]\ttraining's rmse: 8.6059\tvalid_1's rmse: 56.1165\n",
      "[720]\ttraining's rmse: 8.10466\tvalid_1's rmse: 56.0759\n",
      "[750]\ttraining's rmse: 7.64352\tvalid_1's rmse: 56.0154\n",
      "[780]\ttraining's rmse: 7.21554\tvalid_1's rmse: 55.9736\n",
      "[810]\ttraining's rmse: 6.80905\tvalid_1's rmse: 55.9181\n",
      "[840]\ttraining's rmse: 6.43248\tvalid_1's rmse: 55.887\n",
      "[870]\ttraining's rmse: 6.07705\tvalid_1's rmse: 55.8529\n",
      "[900]\ttraining's rmse: 5.74414\tvalid_1's rmse: 55.8253\n",
      "[930]\ttraining's rmse: 5.43705\tvalid_1's rmse: 55.8045\n",
      "[960]\ttraining's rmse: 5.13767\tvalid_1's rmse: 55.7879\n",
      "[990]\ttraining's rmse: 4.86134\tvalid_1's rmse: 55.7632\n",
      "[1020]\ttraining's rmse: 4.60703\tvalid_1's rmse: 55.7458\n",
      "[1050]\ttraining's rmse: 4.36546\tvalid_1's rmse: 55.7285\n",
      "[1080]\ttraining's rmse: 4.14192\tvalid_1's rmse: 55.7096\n",
      "[1110]\ttraining's rmse: 3.93351\tvalid_1's rmse: 55.6942\n",
      "[1140]\ttraining's rmse: 3.7323\tvalid_1's rmse: 55.6837\n",
      "[1170]\ttraining's rmse: 3.54485\tvalid_1's rmse: 55.6643\n",
      "[1200]\ttraining's rmse: 3.36962\tvalid_1's rmse: 55.6522\n",
      "[1230]\ttraining's rmse: 3.2059\tvalid_1's rmse: 55.6464\n",
      "[1260]\ttraining's rmse: 3.04678\tvalid_1's rmse: 55.6389\n",
      "[1290]\ttraining's rmse: 2.90234\tvalid_1's rmse: 55.6358\n",
      "[1320]\ttraining's rmse: 2.76066\tvalid_1's rmse: 55.6303\n",
      "[1350]\ttraining's rmse: 2.62819\tvalid_1's rmse: 55.6276\n",
      "[1380]\ttraining's rmse: 2.50243\tvalid_1's rmse: 55.6257\n",
      "[1410]\ttraining's rmse: 2.38245\tvalid_1's rmse: 55.6232\n",
      "[1440]\ttraining's rmse: 2.26947\tvalid_1's rmse: 55.6151\n",
      "[1470]\ttraining's rmse: 2.16408\tvalid_1's rmse: 55.608\n",
      "[1500]\ttraining's rmse: 2.06387\tvalid_1's rmse: 55.6023\n",
      "[1530]\ttraining's rmse: 1.96593\tvalid_1's rmse: 55.6028\n",
      "[1560]\ttraining's rmse: 1.8749\tvalid_1's rmse: 55.5982\n",
      "[1590]\ttraining's rmse: 1.78812\tvalid_1's rmse: 55.5948\n",
      "[1620]\ttraining's rmse: 1.70682\tvalid_1's rmse: 55.5921\n",
      "[1650]\ttraining's rmse: 1.63127\tvalid_1's rmse: 55.5862\n",
      "[1680]\ttraining's rmse: 1.55657\tvalid_1's rmse: 55.5815\n",
      "[1710]\ttraining's rmse: 1.48508\tvalid_1's rmse: 55.5798\n",
      "[1740]\ttraining's rmse: 1.418\tvalid_1's rmse: 55.5748\n",
      "[1770]\ttraining's rmse: 1.35306\tvalid_1's rmse: 55.574\n",
      "[1800]\ttraining's rmse: 1.29234\tvalid_1's rmse: 55.5722\n",
      "[1830]\ttraining's rmse: 1.23474\tvalid_1's rmse: 55.57\n",
      "[1860]\ttraining's rmse: 1.18008\tvalid_1's rmse: 55.57\n",
      "[1890]\ttraining's rmse: 1.12912\tvalid_1's rmse: 55.5672\n",
      "[1920]\ttraining's rmse: 1.08029\tvalid_1's rmse: 55.5665\n",
      "[1950]\ttraining's rmse: 1.03275\tvalid_1's rmse: 55.5658\n",
      "[1980]\ttraining's rmse: 0.987536\tvalid_1's rmse: 55.5662\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's rmse: 0.958092\tvalid_1's rmse: 55.5645\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002520 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 20024\n",
      "[LightGBM] [Info] Number of data points in the train set: 9219, number of used features: 79\n",
      "[LightGBM] [Info] Start training from score 374.635276\n",
      "Training until validation scores don't improve for 125 rounds\n",
      "[30]\ttraining's rmse: 177.374\tvalid_1's rmse: 181.778\n",
      "[60]\ttraining's rmse: 108.856\tvalid_1's rmse: 118.661\n",
      "[90]\ttraining's rmse: 71.7698\tvalid_1's rmse: 87.5312\n",
      "[120]\ttraining's rmse: 51.5709\tvalid_1's rmse: 72.4603\n",
      "[150]\ttraining's rmse: 40.5005\tvalid_1's rmse: 65.6107\n",
      "[180]\ttraining's rmse: 34.0565\tvalid_1's rmse: 62.4835\n",
      "[210]\ttraining's rmse: 29.6964\tvalid_1's rmse: 60.7225\n",
      "[240]\ttraining's rmse: 26.4429\tvalid_1's rmse: 59.3774\n",
      "[270]\ttraining's rmse: 23.8255\tvalid_1's rmse: 58.4153\n",
      "[300]\ttraining's rmse: 21.6943\tvalid_1's rmse: 57.837\n",
      "[330]\ttraining's rmse: 19.875\tvalid_1's rmse: 57.3351\n",
      "[360]\ttraining's rmse: 18.3285\tvalid_1's rmse: 57.0005\n",
      "[390]\ttraining's rmse: 16.9614\tvalid_1's rmse: 56.8006\n",
      "[420]\ttraining's rmse: 15.7069\tvalid_1's rmse: 56.5655\n",
      "[450]\ttraining's rmse: 14.6007\tvalid_1's rmse: 56.4196\n",
      "[480]\ttraining's rmse: 13.5898\tvalid_1's rmse: 56.3252\n",
      "[510]\ttraining's rmse: 12.6875\tvalid_1's rmse: 56.22\n",
      "[540]\ttraining's rmse: 11.865\tvalid_1's rmse: 56.1456\n",
      "[570]\ttraining's rmse: 11.0909\tvalid_1's rmse: 56.0935\n",
      "[600]\ttraining's rmse: 10.4067\tvalid_1's rmse: 56.0096\n",
      "[630]\ttraining's rmse: 9.75684\tvalid_1's rmse: 55.9733\n",
      "[660]\ttraining's rmse: 9.15899\tvalid_1's rmse: 55.9291\n",
      "[690]\ttraining's rmse: 8.60562\tvalid_1's rmse: 55.8925\n",
      "[720]\ttraining's rmse: 8.10817\tvalid_1's rmse: 55.8553\n",
      "[750]\ttraining's rmse: 7.63032\tvalid_1's rmse: 55.831\n",
      "[780]\ttraining's rmse: 7.19412\tvalid_1's rmse: 55.8142\n",
      "[810]\ttraining's rmse: 6.78306\tvalid_1's rmse: 55.7669\n",
      "[840]\ttraining's rmse: 6.4066\tvalid_1's rmse: 55.7325\n",
      "[870]\ttraining's rmse: 6.04974\tvalid_1's rmse: 55.7201\n",
      "[900]\ttraining's rmse: 5.71238\tvalid_1's rmse: 55.6933\n",
      "[930]\ttraining's rmse: 5.39929\tvalid_1's rmse: 55.672\n",
      "[960]\ttraining's rmse: 5.10205\tvalid_1's rmse: 55.6584\n",
      "[990]\ttraining's rmse: 4.82067\tvalid_1's rmse: 55.6475\n",
      "[1020]\ttraining's rmse: 4.56781\tvalid_1's rmse: 55.6443\n",
      "[1050]\ttraining's rmse: 4.32222\tvalid_1's rmse: 55.6081\n",
      "[1080]\ttraining's rmse: 4.09184\tvalid_1's rmse: 55.6071\n",
      "[1110]\ttraining's rmse: 3.87431\tvalid_1's rmse: 55.6054\n",
      "[1140]\ttraining's rmse: 3.67615\tvalid_1's rmse: 55.587\n",
      "[1170]\ttraining's rmse: 3.48507\tvalid_1's rmse: 55.582\n",
      "[1200]\ttraining's rmse: 3.309\tvalid_1's rmse: 55.5754\n",
      "[1230]\ttraining's rmse: 3.1417\tvalid_1's rmse: 55.5613\n",
      "[1260]\ttraining's rmse: 2.98303\tvalid_1's rmse: 55.5559\n",
      "[1290]\ttraining's rmse: 2.83492\tvalid_1's rmse: 55.5439\n",
      "[1320]\ttraining's rmse: 2.69167\tvalid_1's rmse: 55.5374\n",
      "[1350]\ttraining's rmse: 2.55931\tvalid_1's rmse: 55.538\n",
      "[1380]\ttraining's rmse: 2.43272\tvalid_1's rmse: 55.5392\n",
      "[1410]\ttraining's rmse: 2.31315\tvalid_1's rmse: 55.5376\n",
      "[1440]\ttraining's rmse: 2.19967\tvalid_1's rmse: 55.5323\n",
      "[1470]\ttraining's rmse: 2.0923\tvalid_1's rmse: 55.526\n",
      "[1500]\ttraining's rmse: 1.99168\tvalid_1's rmse: 55.5228\n",
      "[1530]\ttraining's rmse: 1.89244\tvalid_1's rmse: 55.52\n",
      "[1560]\ttraining's rmse: 1.80165\tvalid_1's rmse: 55.517\n",
      "[1590]\ttraining's rmse: 1.71482\tvalid_1's rmse: 55.5164\n",
      "[1620]\ttraining's rmse: 1.63253\tvalid_1's rmse: 55.5126\n",
      "[1650]\ttraining's rmse: 1.55531\tvalid_1's rmse: 55.5095\n",
      "[1680]\ttraining's rmse: 1.47998\tvalid_1's rmse: 55.5045\n",
      "[1710]\ttraining's rmse: 1.40913\tvalid_1's rmse: 55.5021\n",
      "[1740]\ttraining's rmse: 1.34261\tvalid_1's rmse: 55.5003\n",
      "[1770]\ttraining's rmse: 1.27955\tvalid_1's rmse: 55.4975\n",
      "[1800]\ttraining's rmse: 1.22126\tvalid_1's rmse: 55.4918\n",
      "[1830]\ttraining's rmse: 1.16471\tvalid_1's rmse: 55.49\n",
      "[1860]\ttraining's rmse: 1.11075\tvalid_1's rmse: 55.4876\n",
      "[1890]\ttraining's rmse: 1.06079\tvalid_1's rmse: 55.4848\n",
      "[1920]\ttraining's rmse: 1.01272\tvalid_1's rmse: 55.483\n",
      "[1950]\ttraining's rmse: 0.966129\tvalid_1's rmse: 55.4795\n",
      "[1980]\ttraining's rmse: 0.922044\tvalid_1's rmse: 55.4792\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's rmse: 0.893762\tvalid_1's rmse: 55.478\n",
      "6\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002918 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 20023\n",
      "[LightGBM] [Info] Number of data points in the train set: 9219, number of used features: 79\n",
      "[LightGBM] [Info] Start training from score 382.928992\n",
      "Training until validation scores don't improve for 125 rounds\n",
      "[30]\ttraining's rmse: 173.259\tvalid_1's rmse: 183.354\n",
      "[60]\ttraining's rmse: 104.699\tvalid_1's rmse: 118.587\n",
      "[90]\ttraining's rmse: 67.554\tvalid_1's rmse: 86.7562\n",
      "[120]\ttraining's rmse: 47.7819\tvalid_1's rmse: 71.832\n",
      "[150]\ttraining's rmse: 37.1072\tvalid_1's rmse: 65.0408\n",
      "[180]\ttraining's rmse: 30.9843\tvalid_1's rmse: 61.6694\n",
      "[210]\ttraining's rmse: 26.929\tvalid_1's rmse: 59.6079\n",
      "[240]\ttraining's rmse: 23.9363\tvalid_1's rmse: 58.2361\n",
      "[270]\ttraining's rmse: 21.5618\tvalid_1's rmse: 57.2494\n",
      "[300]\ttraining's rmse: 19.6109\tvalid_1's rmse: 56.6802\n",
      "[330]\ttraining's rmse: 18.0093\tvalid_1's rmse: 56.2795\n",
      "[360]\ttraining's rmse: 16.6028\tvalid_1's rmse: 55.9531\n",
      "[390]\ttraining's rmse: 15.3321\tvalid_1's rmse: 55.6428\n",
      "[420]\ttraining's rmse: 14.2132\tvalid_1's rmse: 55.427\n",
      "[450]\ttraining's rmse: 13.2012\tvalid_1's rmse: 55.2428\n",
      "[480]\ttraining's rmse: 12.2906\tvalid_1's rmse: 55.0931\n",
      "[510]\ttraining's rmse: 11.453\tvalid_1's rmse: 54.9693\n",
      "[540]\ttraining's rmse: 10.6967\tvalid_1's rmse: 54.881\n",
      "[570]\ttraining's rmse: 10.0086\tvalid_1's rmse: 54.8197\n",
      "[600]\ttraining's rmse: 9.38211\tvalid_1's rmse: 54.7553\n",
      "[630]\ttraining's rmse: 8.7957\tvalid_1's rmse: 54.6897\n",
      "[660]\ttraining's rmse: 8.26433\tvalid_1's rmse: 54.627\n",
      "[690]\ttraining's rmse: 7.76431\tvalid_1's rmse: 54.5782\n",
      "[720]\ttraining's rmse: 7.31419\tvalid_1's rmse: 54.5237\n",
      "[750]\ttraining's rmse: 6.8874\tvalid_1's rmse: 54.4861\n",
      "[780]\ttraining's rmse: 6.49064\tvalid_1's rmse: 54.4752\n",
      "[810]\ttraining's rmse: 6.11747\tvalid_1's rmse: 54.4573\n",
      "[840]\ttraining's rmse: 5.77358\tvalid_1's rmse: 54.4252\n",
      "[870]\ttraining's rmse: 5.45713\tvalid_1's rmse: 54.398\n",
      "[900]\ttraining's rmse: 5.15317\tvalid_1's rmse: 54.379\n",
      "[930]\ttraining's rmse: 4.87107\tvalid_1's rmse: 54.3635\n",
      "[960]\ttraining's rmse: 4.59588\tvalid_1's rmse: 54.345\n",
      "[990]\ttraining's rmse: 4.35288\tvalid_1's rmse: 54.3356\n",
      "[1020]\ttraining's rmse: 4.11631\tvalid_1's rmse: 54.3338\n",
      "[1050]\ttraining's rmse: 3.89428\tvalid_1's rmse: 54.3214\n",
      "[1080]\ttraining's rmse: 3.6881\tvalid_1's rmse: 54.3126\n",
      "[1110]\ttraining's rmse: 3.49073\tvalid_1's rmse: 54.3025\n",
      "[1140]\ttraining's rmse: 3.30971\tvalid_1's rmse: 54.2899\n",
      "[1170]\ttraining's rmse: 3.14306\tvalid_1's rmse: 54.2797\n",
      "[1200]\ttraining's rmse: 2.98175\tvalid_1's rmse: 54.2742\n",
      "[1230]\ttraining's rmse: 2.82884\tvalid_1's rmse: 54.2698\n",
      "[1260]\ttraining's rmse: 2.68712\tvalid_1's rmse: 54.2622\n",
      "[1290]\ttraining's rmse: 2.55237\tvalid_1's rmse: 54.2535\n",
      "[1320]\ttraining's rmse: 2.42367\tvalid_1's rmse: 54.2469\n",
      "[1350]\ttraining's rmse: 2.30461\tvalid_1's rmse: 54.2425\n",
      "[1380]\ttraining's rmse: 2.1882\tvalid_1's rmse: 54.2382\n",
      "[1410]\ttraining's rmse: 2.08061\tvalid_1's rmse: 54.2374\n",
      "[1440]\ttraining's rmse: 1.98159\tvalid_1's rmse: 54.2355\n",
      "[1470]\ttraining's rmse: 1.88594\tvalid_1's rmse: 54.2359\n",
      "[1500]\ttraining's rmse: 1.79549\tvalid_1's rmse: 54.2356\n",
      "[1530]\ttraining's rmse: 1.70745\tvalid_1's rmse: 54.2307\n",
      "[1560]\ttraining's rmse: 1.62595\tvalid_1's rmse: 54.2271\n",
      "[1590]\ttraining's rmse: 1.54915\tvalid_1's rmse: 54.2244\n",
      "[1620]\ttraining's rmse: 1.47518\tvalid_1's rmse: 54.2203\n",
      "[1650]\ttraining's rmse: 1.40537\tvalid_1's rmse: 54.2197\n",
      "[1680]\ttraining's rmse: 1.3377\tvalid_1's rmse: 54.2195\n",
      "[1710]\ttraining's rmse: 1.27528\tvalid_1's rmse: 54.2206\n",
      "[1740]\ttraining's rmse: 1.21509\tvalid_1's rmse: 54.2201\n",
      "[1770]\ttraining's rmse: 1.15843\tvalid_1's rmse: 54.2165\n",
      "[1800]\ttraining's rmse: 1.10508\tvalid_1's rmse: 54.2139\n",
      "[1830]\ttraining's rmse: 1.05341\tvalid_1's rmse: 54.2115\n",
      "[1860]\ttraining's rmse: 1.00397\tvalid_1's rmse: 54.2116\n",
      "[1890]\ttraining's rmse: 0.957545\tvalid_1's rmse: 54.2113\n",
      "[1920]\ttraining's rmse: 0.912858\tvalid_1's rmse: 54.2103\n",
      "[1950]\ttraining's rmse: 0.872119\tvalid_1's rmse: 54.2091\n",
      "[1980]\ttraining's rmse: 0.830623\tvalid_1's rmse: 54.2083\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's rmse: 0.804567\tvalid_1's rmse: 54.2066\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002956 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 20023\n",
      "[LightGBM] [Info] Number of data points in the train set: 9219, number of used features: 79\n",
      "[LightGBM] [Info] Start training from score 378.645307\n",
      "Training until validation scores don't improve for 125 rounds\n",
      "[30]\ttraining's rmse: 174.459\tvalid_1's rmse: 188.068\n",
      "[60]\ttraining's rmse: 107.269\tvalid_1's rmse: 126.689\n",
      "[90]\ttraining's rmse: 70.98\tvalid_1's rmse: 96.3898\n",
      "[120]\ttraining's rmse: 51.4429\tvalid_1's rmse: 81.7897\n",
      "[150]\ttraining's rmse: 40.7533\tvalid_1's rmse: 74.4014\n",
      "[180]\ttraining's rmse: 34.2476\tvalid_1's rmse: 70.068\n",
      "[210]\ttraining's rmse: 29.9825\tvalid_1's rmse: 67.5203\n",
      "[240]\ttraining's rmse: 26.766\tvalid_1's rmse: 65.7013\n",
      "[270]\ttraining's rmse: 24.1679\tvalid_1's rmse: 64.3435\n",
      "[300]\ttraining's rmse: 22.0434\tvalid_1's rmse: 63.5946\n",
      "[330]\ttraining's rmse: 20.2075\tvalid_1's rmse: 62.951\n",
      "[360]\ttraining's rmse: 18.6403\tvalid_1's rmse: 62.4228\n",
      "[390]\ttraining's rmse: 17.237\tvalid_1's rmse: 61.9425\n",
      "[420]\ttraining's rmse: 15.9762\tvalid_1's rmse: 61.5951\n",
      "[450]\ttraining's rmse: 14.8263\tvalid_1's rmse: 61.3412\n",
      "[480]\ttraining's rmse: 13.8166\tvalid_1's rmse: 61.1651\n",
      "[510]\ttraining's rmse: 12.8936\tvalid_1's rmse: 61.0001\n",
      "[540]\ttraining's rmse: 12.0575\tvalid_1's rmse: 60.89\n",
      "[570]\ttraining's rmse: 11.2927\tvalid_1's rmse: 60.7547\n",
      "[600]\ttraining's rmse: 10.6008\tvalid_1's rmse: 60.6057\n",
      "[630]\ttraining's rmse: 9.96713\tvalid_1's rmse: 60.4827\n",
      "[660]\ttraining's rmse: 9.36108\tvalid_1's rmse: 60.3758\n",
      "[690]\ttraining's rmse: 8.81467\tvalid_1's rmse: 60.307\n",
      "[720]\ttraining's rmse: 8.30106\tvalid_1's rmse: 60.2287\n",
      "[750]\ttraining's rmse: 7.82114\tvalid_1's rmse: 60.1599\n",
      "[780]\ttraining's rmse: 7.38799\tvalid_1's rmse: 60.0937\n",
      "[810]\ttraining's rmse: 6.95974\tvalid_1's rmse: 60.0445\n",
      "[840]\ttraining's rmse: 6.56778\tvalid_1's rmse: 59.9771\n",
      "[870]\ttraining's rmse: 6.20207\tvalid_1's rmse: 59.9642\n",
      "[900]\ttraining's rmse: 5.86165\tvalid_1's rmse: 59.9261\n",
      "[930]\ttraining's rmse: 5.55172\tvalid_1's rmse: 59.8984\n",
      "[960]\ttraining's rmse: 5.25571\tvalid_1's rmse: 59.8506\n",
      "[990]\ttraining's rmse: 4.97249\tvalid_1's rmse: 59.8122\n",
      "[1020]\ttraining's rmse: 4.71479\tvalid_1's rmse: 59.7981\n",
      "[1050]\ttraining's rmse: 4.46717\tvalid_1's rmse: 59.774\n",
      "[1080]\ttraining's rmse: 4.23343\tvalid_1's rmse: 59.757\n",
      "[1110]\ttraining's rmse: 4.01834\tvalid_1's rmse: 59.7302\n",
      "[1140]\ttraining's rmse: 3.81326\tvalid_1's rmse: 59.7135\n",
      "[1170]\ttraining's rmse: 3.62222\tvalid_1's rmse: 59.6982\n",
      "[1200]\ttraining's rmse: 3.43959\tvalid_1's rmse: 59.6792\n",
      "[1230]\ttraining's rmse: 3.27313\tvalid_1's rmse: 59.656\n",
      "[1260]\ttraining's rmse: 3.10578\tvalid_1's rmse: 59.6413\n",
      "[1290]\ttraining's rmse: 2.95044\tvalid_1's rmse: 59.6286\n",
      "[1320]\ttraining's rmse: 2.80735\tvalid_1's rmse: 59.6081\n",
      "[1350]\ttraining's rmse: 2.67022\tvalid_1's rmse: 59.5995\n",
      "[1380]\ttraining's rmse: 2.54052\tvalid_1's rmse: 59.5956\n",
      "[1410]\ttraining's rmse: 2.41664\tvalid_1's rmse: 59.5888\n",
      "[1440]\ttraining's rmse: 2.30436\tvalid_1's rmse: 59.5803\n",
      "[1470]\ttraining's rmse: 2.19387\tvalid_1's rmse: 59.578\n",
      "[1500]\ttraining's rmse: 2.0899\tvalid_1's rmse: 59.5691\n",
      "[1530]\ttraining's rmse: 1.9936\tvalid_1's rmse: 59.5615\n",
      "[1560]\ttraining's rmse: 1.8989\tvalid_1's rmse: 59.5554\n",
      "[1590]\ttraining's rmse: 1.80922\tvalid_1's rmse: 59.547\n",
      "[1620]\ttraining's rmse: 1.72582\tvalid_1's rmse: 59.5382\n",
      "[1650]\ttraining's rmse: 1.64734\tvalid_1's rmse: 59.5358\n",
      "[1680]\ttraining's rmse: 1.57159\tvalid_1's rmse: 59.5314\n",
      "[1710]\ttraining's rmse: 1.49973\tvalid_1's rmse: 59.5222\n",
      "[1740]\ttraining's rmse: 1.4327\tvalid_1's rmse: 59.5196\n",
      "[1770]\ttraining's rmse: 1.36811\tvalid_1's rmse: 59.5136\n",
      "[1800]\ttraining's rmse: 1.30648\tvalid_1's rmse: 59.5081\n",
      "[1830]\ttraining's rmse: 1.24844\tvalid_1's rmse: 59.4991\n",
      "[1860]\ttraining's rmse: 1.19167\tvalid_1's rmse: 59.4947\n",
      "[1890]\ttraining's rmse: 1.13747\tvalid_1's rmse: 59.4912\n",
      "[1920]\ttraining's rmse: 1.08826\tvalid_1's rmse: 59.4894\n",
      "[1950]\ttraining's rmse: 1.04112\tvalid_1's rmse: 59.489\n",
      "[1980]\ttraining's rmse: 0.994578\tvalid_1's rmse: 59.4861\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's rmse: 0.965754\tvalid_1's rmse: 59.4851\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003787 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 20023\n",
      "[LightGBM] [Info] Number of data points in the train set: 9219, number of used features: 79\n",
      "[LightGBM] [Info] Start training from score 378.655421\n",
      "Training until validation scores don't improve for 125 rounds\n",
      "[30]\ttraining's rmse: 174.999\tvalid_1's rmse: 182.755\n",
      "[60]\ttraining's rmse: 107.422\tvalid_1's rmse: 120.1\n",
      "[90]\ttraining's rmse: 70.9445\tvalid_1's rmse: 89.0449\n",
      "[120]\ttraining's rmse: 51.3573\tvalid_1's rmse: 74.3436\n",
      "[150]\ttraining's rmse: 40.5184\tvalid_1's rmse: 67.0238\n",
      "[180]\ttraining's rmse: 34.0974\tvalid_1's rmse: 63.2958\n",
      "[210]\ttraining's rmse: 29.7608\tvalid_1's rmse: 61.2234\n",
      "[240]\ttraining's rmse: 26.5037\tvalid_1's rmse: 59.7711\n",
      "[270]\ttraining's rmse: 23.9344\tvalid_1's rmse: 58.8263\n",
      "[300]\ttraining's rmse: 21.7902\tvalid_1's rmse: 58.0846\n",
      "[330]\ttraining's rmse: 20.0088\tvalid_1's rmse: 57.6095\n",
      "[360]\ttraining's rmse: 18.4884\tvalid_1's rmse: 57.2461\n",
      "[390]\ttraining's rmse: 17.0853\tvalid_1's rmse: 56.949\n",
      "[420]\ttraining's rmse: 15.8645\tvalid_1's rmse: 56.773\n",
      "[450]\ttraining's rmse: 14.7496\tvalid_1's rmse: 56.6134\n",
      "[480]\ttraining's rmse: 13.7517\tvalid_1's rmse: 56.4652\n",
      "[510]\ttraining's rmse: 12.8446\tvalid_1's rmse: 56.3316\n",
      "[540]\ttraining's rmse: 12.0234\tvalid_1's rmse: 56.1877\n",
      "[570]\ttraining's rmse: 11.2628\tvalid_1's rmse: 56.0992\n",
      "[600]\ttraining's rmse: 10.5822\tvalid_1's rmse: 55.9842\n",
      "[630]\ttraining's rmse: 9.93115\tvalid_1's rmse: 55.9096\n",
      "[660]\ttraining's rmse: 9.3239\tvalid_1's rmse: 55.8493\n",
      "[690]\ttraining's rmse: 8.79013\tvalid_1's rmse: 55.8081\n",
      "[720]\ttraining's rmse: 8.2827\tvalid_1's rmse: 55.7799\n",
      "[750]\ttraining's rmse: 7.81854\tvalid_1's rmse: 55.7526\n",
      "[780]\ttraining's rmse: 7.3823\tvalid_1's rmse: 55.7019\n",
      "[810]\ttraining's rmse: 6.96893\tvalid_1's rmse: 55.6749\n",
      "[840]\ttraining's rmse: 6.58725\tvalid_1's rmse: 55.6272\n",
      "[870]\ttraining's rmse: 6.22872\tvalid_1's rmse: 55.597\n",
      "[900]\ttraining's rmse: 5.88808\tvalid_1's rmse: 55.578\n",
      "[930]\ttraining's rmse: 5.57452\tvalid_1's rmse: 55.5586\n",
      "[960]\ttraining's rmse: 5.2798\tvalid_1's rmse: 55.5276\n",
      "[990]\ttraining's rmse: 5.01057\tvalid_1's rmse: 55.5234\n",
      "[1020]\ttraining's rmse: 4.75542\tvalid_1's rmse: 55.5051\n",
      "[1050]\ttraining's rmse: 4.51996\tvalid_1's rmse: 55.4781\n",
      "[1080]\ttraining's rmse: 4.29249\tvalid_1's rmse: 55.4625\n",
      "[1110]\ttraining's rmse: 4.07541\tvalid_1's rmse: 55.4496\n",
      "[1140]\ttraining's rmse: 3.8769\tvalid_1's rmse: 55.4379\n",
      "[1170]\ttraining's rmse: 3.68758\tvalid_1's rmse: 55.4347\n",
      "[1200]\ttraining's rmse: 3.50705\tvalid_1's rmse: 55.425\n",
      "[1230]\ttraining's rmse: 3.34153\tvalid_1's rmse: 55.4138\n",
      "[1260]\ttraining's rmse: 3.18399\tvalid_1's rmse: 55.401\n",
      "[1290]\ttraining's rmse: 3.02964\tvalid_1's rmse: 55.3927\n",
      "[1320]\ttraining's rmse: 2.88762\tvalid_1's rmse: 55.3862\n",
      "[1350]\ttraining's rmse: 2.75502\tvalid_1's rmse: 55.3787\n",
      "[1380]\ttraining's rmse: 2.62628\tvalid_1's rmse: 55.374\n",
      "[1410]\ttraining's rmse: 2.50444\tvalid_1's rmse: 55.3647\n",
      "[1440]\ttraining's rmse: 2.39377\tvalid_1's rmse: 55.3594\n",
      "[1470]\ttraining's rmse: 2.2871\tvalid_1's rmse: 55.3506\n",
      "[1500]\ttraining's rmse: 2.18517\tvalid_1's rmse: 55.346\n",
      "[1530]\ttraining's rmse: 2.08703\tvalid_1's rmse: 55.3451\n",
      "[1560]\ttraining's rmse: 1.99463\tvalid_1's rmse: 55.3372\n",
      "[1590]\ttraining's rmse: 1.90734\tvalid_1's rmse: 55.3315\n",
      "[1620]\ttraining's rmse: 1.82729\tvalid_1's rmse: 55.3277\n",
      "[1650]\ttraining's rmse: 1.74889\tvalid_1's rmse: 55.3251\n",
      "[1680]\ttraining's rmse: 1.67333\tvalid_1's rmse: 55.3203\n",
      "[1710]\ttraining's rmse: 1.60046\tvalid_1's rmse: 55.3184\n",
      "[1740]\ttraining's rmse: 1.52995\tvalid_1's rmse: 55.3161\n",
      "[1770]\ttraining's rmse: 1.466\tvalid_1's rmse: 55.3143\n",
      "[1800]\ttraining's rmse: 1.4033\tvalid_1's rmse: 55.3106\n",
      "[1830]\ttraining's rmse: 1.34474\tvalid_1's rmse: 55.3052\n",
      "[1860]\ttraining's rmse: 1.28826\tvalid_1's rmse: 55.3042\n",
      "[1890]\ttraining's rmse: 1.23383\tvalid_1's rmse: 55.3017\n",
      "[1920]\ttraining's rmse: 1.18327\tvalid_1's rmse: 55.2991\n",
      "[1950]\ttraining's rmse: 1.13505\tvalid_1's rmse: 55.2961\n",
      "[1980]\ttraining's rmse: 1.08871\tvalid_1's rmse: 55.2943\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's rmse: 1.05967\tvalid_1's rmse: 55.2936\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003699 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 20023\n",
      "[LightGBM] [Info] Number of data points in the train set: 9219, number of used features: 79\n",
      "[LightGBM] [Info] Start training from score 376.520758\n",
      "Training until validation scores don't improve for 125 rounds\n",
      "[30]\ttraining's rmse: 175.171\tvalid_1's rmse: 182.346\n",
      "[60]\ttraining's rmse: 107.575\tvalid_1's rmse: 118.77\n",
      "[90]\ttraining's rmse: 71.0426\tvalid_1's rmse: 87.1176\n",
      "[120]\ttraining's rmse: 51.3277\tvalid_1's rmse: 71.9573\n",
      "[150]\ttraining's rmse: 40.4379\tvalid_1's rmse: 64.8513\n",
      "[180]\ttraining's rmse: 33.9001\tvalid_1's rmse: 61.3603\n",
      "[210]\ttraining's rmse: 29.3918\tvalid_1's rmse: 59.3049\n",
      "[240]\ttraining's rmse: 26.1326\tvalid_1's rmse: 58.0262\n",
      "[270]\ttraining's rmse: 23.538\tvalid_1's rmse: 57.0427\n",
      "[300]\ttraining's rmse: 21.3852\tvalid_1's rmse: 56.3837\n",
      "[330]\ttraining's rmse: 19.5966\tvalid_1's rmse: 55.9504\n",
      "[360]\ttraining's rmse: 18.0697\tvalid_1's rmse: 55.6246\n",
      "[390]\ttraining's rmse: 16.6842\tvalid_1's rmse: 55.371\n",
      "[420]\ttraining's rmse: 15.4541\tvalid_1's rmse: 55.1407\n",
      "[450]\ttraining's rmse: 14.3757\tvalid_1's rmse: 54.9218\n",
      "[480]\ttraining's rmse: 13.3864\tvalid_1's rmse: 54.7904\n",
      "[510]\ttraining's rmse: 12.481\tvalid_1's rmse: 54.6784\n",
      "[540]\ttraining's rmse: 11.6733\tvalid_1's rmse: 54.5488\n",
      "[570]\ttraining's rmse: 10.9252\tvalid_1's rmse: 54.4184\n",
      "[600]\ttraining's rmse: 10.248\tvalid_1's rmse: 54.3282\n",
      "[630]\ttraining's rmse: 9.61275\tvalid_1's rmse: 54.2513\n",
      "[660]\ttraining's rmse: 9.02324\tvalid_1's rmse: 54.2016\n",
      "[690]\ttraining's rmse: 8.47657\tvalid_1's rmse: 54.132\n",
      "[720]\ttraining's rmse: 7.97277\tvalid_1's rmse: 54.1126\n",
      "[750]\ttraining's rmse: 7.51359\tvalid_1's rmse: 54.0762\n",
      "[780]\ttraining's rmse: 7.08659\tvalid_1's rmse: 54.0488\n",
      "[810]\ttraining's rmse: 6.69245\tvalid_1's rmse: 54.0332\n",
      "[840]\ttraining's rmse: 6.32304\tvalid_1's rmse: 54.0002\n",
      "[870]\ttraining's rmse: 5.9756\tvalid_1's rmse: 53.9716\n",
      "[900]\ttraining's rmse: 5.65147\tvalid_1's rmse: 53.9584\n",
      "[930]\ttraining's rmse: 5.34851\tvalid_1's rmse: 53.9367\n",
      "[960]\ttraining's rmse: 5.06162\tvalid_1's rmse: 53.9008\n",
      "[990]\ttraining's rmse: 4.79486\tvalid_1's rmse: 53.8742\n",
      "[1020]\ttraining's rmse: 4.53598\tvalid_1's rmse: 53.859\n",
      "[1050]\ttraining's rmse: 4.29359\tvalid_1's rmse: 53.8432\n",
      "[1080]\ttraining's rmse: 4.07231\tvalid_1's rmse: 53.8274\n",
      "[1110]\ttraining's rmse: 3.86017\tvalid_1's rmse: 53.8213\n",
      "[1140]\ttraining's rmse: 3.66308\tvalid_1's rmse: 53.8107\n",
      "[1170]\ttraining's rmse: 3.48194\tvalid_1's rmse: 53.7986\n",
      "[1200]\ttraining's rmse: 3.30829\tvalid_1's rmse: 53.7927\n",
      "[1230]\ttraining's rmse: 3.14397\tvalid_1's rmse: 53.7841\n",
      "[1260]\ttraining's rmse: 2.98713\tvalid_1's rmse: 53.7726\n",
      "[1290]\ttraining's rmse: 2.83752\tvalid_1's rmse: 53.7708\n",
      "[1320]\ttraining's rmse: 2.6956\tvalid_1's rmse: 53.7622\n",
      "[1350]\ttraining's rmse: 2.56169\tvalid_1's rmse: 53.7572\n",
      "[1380]\ttraining's rmse: 2.43561\tvalid_1's rmse: 53.7504\n",
      "[1410]\ttraining's rmse: 2.31828\tvalid_1's rmse: 53.7478\n",
      "[1440]\ttraining's rmse: 2.20613\tvalid_1's rmse: 53.7413\n",
      "[1470]\ttraining's rmse: 2.10134\tvalid_1's rmse: 53.7386\n",
      "[1500]\ttraining's rmse: 2.00086\tvalid_1's rmse: 53.7321\n",
      "[1530]\ttraining's rmse: 1.9079\tvalid_1's rmse: 53.7297\n",
      "[1560]\ttraining's rmse: 1.81827\tvalid_1's rmse: 53.729\n",
      "[1590]\ttraining's rmse: 1.73257\tvalid_1's rmse: 53.7308\n",
      "[1620]\ttraining's rmse: 1.64871\tvalid_1's rmse: 53.7248\n",
      "[1650]\ttraining's rmse: 1.57231\tvalid_1's rmse: 53.7206\n",
      "[1680]\ttraining's rmse: 1.50067\tvalid_1's rmse: 53.7165\n",
      "[1710]\ttraining's rmse: 1.43114\tvalid_1's rmse: 53.7148\n",
      "[1740]\ttraining's rmse: 1.36387\tvalid_1's rmse: 53.7106\n",
      "[1770]\ttraining's rmse: 1.30119\tvalid_1's rmse: 53.7068\n",
      "[1800]\ttraining's rmse: 1.24164\tvalid_1's rmse: 53.7046\n",
      "[1830]\ttraining's rmse: 1.18519\tvalid_1's rmse: 53.7027\n",
      "[1860]\ttraining's rmse: 1.13223\tvalid_1's rmse: 53.6992\n",
      "[1890]\ttraining's rmse: 1.08039\tvalid_1's rmse: 53.6982\n",
      "[1920]\ttraining's rmse: 1.03248\tvalid_1's rmse: 53.6981\n",
      "[1950]\ttraining's rmse: 0.986201\tvalid_1's rmse: 53.6966\n",
      "[1980]\ttraining's rmse: 0.942065\tvalid_1's rmse: 53.6948\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's rmse: 0.914243\tvalid_1's rmse: 53.694\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002567 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 20023\n",
      "[LightGBM] [Info] Number of data points in the train set: 9219, number of used features: 79\n",
      "[LightGBM] [Info] Start training from score 378.889588\n",
      "Training until validation scores don't improve for 125 rounds\n",
      "[30]\ttraining's rmse: 175.724\tvalid_1's rmse: 180.946\n",
      "[60]\ttraining's rmse: 108.645\tvalid_1's rmse: 118.462\n",
      "[90]\ttraining's rmse: 72.0465\tvalid_1's rmse: 86.9662\n",
      "[120]\ttraining's rmse: 52.3594\tvalid_1's rmse: 72.1115\n",
      "[150]\ttraining's rmse: 41.2842\tvalid_1's rmse: 65.2158\n",
      "[180]\ttraining's rmse: 34.7203\tvalid_1's rmse: 61.6898\n",
      "[210]\ttraining's rmse: 30.3043\tvalid_1's rmse: 59.723\n",
      "[240]\ttraining's rmse: 27.0366\tvalid_1's rmse: 58.4464\n",
      "[270]\ttraining's rmse: 24.346\tvalid_1's rmse: 57.6194\n",
      "[300]\ttraining's rmse: 22.1346\tvalid_1's rmse: 56.9835\n",
      "[330]\ttraining's rmse: 20.309\tvalid_1's rmse: 56.5729\n",
      "[360]\ttraining's rmse: 18.6994\tvalid_1's rmse: 56.3089\n",
      "[390]\ttraining's rmse: 17.2741\tvalid_1's rmse: 56.0903\n",
      "[420]\ttraining's rmse: 15.999\tvalid_1's rmse: 55.9128\n",
      "[450]\ttraining's rmse: 14.8501\tvalid_1's rmse: 55.7511\n",
      "[480]\ttraining's rmse: 13.82\tvalid_1's rmse: 55.6032\n",
      "[510]\ttraining's rmse: 12.8939\tvalid_1's rmse: 55.4754\n",
      "[540]\ttraining's rmse: 12.0483\tvalid_1's rmse: 55.3823\n",
      "[570]\ttraining's rmse: 11.2846\tvalid_1's rmse: 55.3052\n",
      "[600]\ttraining's rmse: 10.578\tvalid_1's rmse: 55.2478\n",
      "[630]\ttraining's rmse: 9.94236\tvalid_1's rmse: 55.2221\n",
      "[660]\ttraining's rmse: 9.34692\tvalid_1's rmse: 55.1893\n",
      "[690]\ttraining's rmse: 8.79536\tvalid_1's rmse: 55.1314\n",
      "[720]\ttraining's rmse: 8.28689\tvalid_1's rmse: 55.1146\n",
      "[750]\ttraining's rmse: 7.81382\tvalid_1's rmse: 55.1032\n",
      "[780]\ttraining's rmse: 7.36244\tvalid_1's rmse: 55.0647\n",
      "[810]\ttraining's rmse: 6.94836\tvalid_1's rmse: 55.0328\n",
      "[840]\ttraining's rmse: 6.5591\tvalid_1's rmse: 55.019\n",
      "[870]\ttraining's rmse: 6.1975\tvalid_1's rmse: 55.01\n",
      "[900]\ttraining's rmse: 5.85926\tvalid_1's rmse: 54.9848\n",
      "[930]\ttraining's rmse: 5.54065\tvalid_1's rmse: 54.9592\n",
      "[960]\ttraining's rmse: 5.25459\tvalid_1's rmse: 54.9418\n",
      "[990]\ttraining's rmse: 4.98241\tvalid_1's rmse: 54.9322\n",
      "[1020]\ttraining's rmse: 4.7268\tvalid_1's rmse: 54.9034\n",
      "[1050]\ttraining's rmse: 4.48348\tvalid_1's rmse: 54.898\n",
      "[1080]\ttraining's rmse: 4.26312\tvalid_1's rmse: 54.8878\n",
      "[1110]\ttraining's rmse: 4.04984\tvalid_1's rmse: 54.884\n",
      "[1140]\ttraining's rmse: 3.84959\tvalid_1's rmse: 54.8733\n",
      "[1170]\ttraining's rmse: 3.65864\tvalid_1's rmse: 54.8682\n",
      "[1200]\ttraining's rmse: 3.47503\tvalid_1's rmse: 54.86\n",
      "[1230]\ttraining's rmse: 3.3028\tvalid_1's rmse: 54.8463\n",
      "[1260]\ttraining's rmse: 3.14085\tvalid_1's rmse: 54.8381\n",
      "[1290]\ttraining's rmse: 2.9945\tvalid_1's rmse: 54.8307\n",
      "[1320]\ttraining's rmse: 2.85579\tvalid_1's rmse: 54.8284\n",
      "[1350]\ttraining's rmse: 2.71972\tvalid_1's rmse: 54.8239\n",
      "[1380]\ttraining's rmse: 2.58957\tvalid_1's rmse: 54.8165\n",
      "[1410]\ttraining's rmse: 2.47107\tvalid_1's rmse: 54.8164\n",
      "[1440]\ttraining's rmse: 2.36115\tvalid_1's rmse: 54.811\n",
      "[1470]\ttraining's rmse: 2.2543\tvalid_1's rmse: 54.8037\n",
      "[1500]\ttraining's rmse: 2.15219\tvalid_1's rmse: 54.7999\n",
      "[1530]\ttraining's rmse: 2.0547\tvalid_1's rmse: 54.797\n",
      "[1560]\ttraining's rmse: 1.96193\tvalid_1's rmse: 54.7981\n",
      "[1590]\ttraining's rmse: 1.87571\tvalid_1's rmse: 54.7956\n",
      "[1620]\ttraining's rmse: 1.79354\tvalid_1's rmse: 54.7952\n",
      "[1650]\ttraining's rmse: 1.71489\tvalid_1's rmse: 54.795\n",
      "[1680]\ttraining's rmse: 1.64003\tvalid_1's rmse: 54.794\n",
      "[1710]\ttraining's rmse: 1.56994\tvalid_1's rmse: 54.7894\n",
      "[1740]\ttraining's rmse: 1.50376\tvalid_1's rmse: 54.7884\n",
      "[1770]\ttraining's rmse: 1.44111\tvalid_1's rmse: 54.7873\n",
      "[1800]\ttraining's rmse: 1.38022\tvalid_1's rmse: 54.7865\n",
      "[1830]\ttraining's rmse: 1.32238\tvalid_1's rmse: 54.7837\n",
      "[1860]\ttraining's rmse: 1.26688\tvalid_1's rmse: 54.7834\n",
      "[1890]\ttraining's rmse: 1.21607\tvalid_1's rmse: 54.7833\n",
      "[1920]\ttraining's rmse: 1.16638\tvalid_1's rmse: 54.7822\n",
      "[1950]\ttraining's rmse: 1.11919\tvalid_1's rmse: 54.7811\n",
      "[1980]\ttraining's rmse: 1.0723\tvalid_1's rmse: 54.7807\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's rmse: 1.04381\tvalid_1's rmse: 54.7799\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003554 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 20023\n",
      "[LightGBM] [Info] Number of data points in the train set: 9219, number of used features: 79\n",
      "[LightGBM] [Info] Start training from score 374.696673\n",
      "Training until validation scores don't improve for 125 rounds\n",
      "[30]\ttraining's rmse: 176.184\tvalid_1's rmse: 181.731\n",
      "[60]\ttraining's rmse: 108.258\tvalid_1's rmse: 118.262\n",
      "[90]\ttraining's rmse: 71.6756\tvalid_1's rmse: 86.5869\n",
      "[120]\ttraining's rmse: 51.8851\tvalid_1's rmse: 71.2394\n",
      "[150]\ttraining's rmse: 40.8662\tvalid_1's rmse: 63.9826\n",
      "[180]\ttraining's rmse: 34.294\tvalid_1's rmse: 60.2888\n",
      "[210]\ttraining's rmse: 29.8968\tvalid_1's rmse: 58.3764\n",
      "[240]\ttraining's rmse: 26.6766\tvalid_1's rmse: 57.2861\n",
      "[270]\ttraining's rmse: 24.0865\tvalid_1's rmse: 56.5074\n",
      "[300]\ttraining's rmse: 21.8931\tvalid_1's rmse: 55.9417\n",
      "[330]\ttraining's rmse: 20.0778\tvalid_1's rmse: 55.7014\n",
      "[360]\ttraining's rmse: 18.4891\tvalid_1's rmse: 55.4949\n",
      "[390]\ttraining's rmse: 17.1225\tvalid_1's rmse: 55.3858\n",
      "[420]\ttraining's rmse: 15.8902\tvalid_1's rmse: 55.2429\n",
      "[450]\ttraining's rmse: 14.7895\tvalid_1's rmse: 55.157\n",
      "[480]\ttraining's rmse: 13.7714\tvalid_1's rmse: 55.0601\n",
      "[510]\ttraining's rmse: 12.8301\tvalid_1's rmse: 54.97\n",
      "[540]\ttraining's rmse: 11.9998\tvalid_1's rmse: 54.8721\n",
      "[570]\ttraining's rmse: 11.2378\tvalid_1's rmse: 54.7978\n",
      "[600]\ttraining's rmse: 10.5439\tvalid_1's rmse: 54.7691\n",
      "[630]\ttraining's rmse: 9.90777\tvalid_1's rmse: 54.7405\n",
      "[660]\ttraining's rmse: 9.31636\tvalid_1's rmse: 54.7101\n",
      "[690]\ttraining's rmse: 8.77263\tvalid_1's rmse: 54.6821\n",
      "[720]\ttraining's rmse: 8.26205\tvalid_1's rmse: 54.6608\n",
      "[750]\ttraining's rmse: 7.78392\tvalid_1's rmse: 54.626\n",
      "[780]\ttraining's rmse: 7.34533\tvalid_1's rmse: 54.591\n",
      "[810]\ttraining's rmse: 6.93872\tvalid_1's rmse: 54.567\n",
      "[840]\ttraining's rmse: 6.56854\tvalid_1's rmse: 54.5408\n",
      "[870]\ttraining's rmse: 6.20845\tvalid_1's rmse: 54.5151\n",
      "[900]\ttraining's rmse: 5.87278\tvalid_1's rmse: 54.4993\n",
      "[930]\ttraining's rmse: 5.56287\tvalid_1's rmse: 54.4777\n",
      "[960]\ttraining's rmse: 5.272\tvalid_1's rmse: 54.4643\n",
      "[990]\ttraining's rmse: 5.00056\tvalid_1's rmse: 54.4625\n",
      "[1020]\ttraining's rmse: 4.74428\tvalid_1's rmse: 54.4562\n",
      "[1050]\ttraining's rmse: 4.50512\tvalid_1's rmse: 54.4548\n",
      "[1080]\ttraining's rmse: 4.27627\tvalid_1's rmse: 54.4478\n",
      "[1110]\ttraining's rmse: 4.06071\tvalid_1's rmse: 54.4402\n",
      "[1140]\ttraining's rmse: 3.86076\tvalid_1's rmse: 54.4347\n",
      "[1170]\ttraining's rmse: 3.666\tvalid_1's rmse: 54.4326\n",
      "[1200]\ttraining's rmse: 3.48346\tvalid_1's rmse: 54.4255\n",
      "[1230]\ttraining's rmse: 3.31647\tvalid_1's rmse: 54.4235\n",
      "[1260]\ttraining's rmse: 3.15462\tvalid_1's rmse: 54.4272\n",
      "[1290]\ttraining's rmse: 3.00059\tvalid_1's rmse: 54.4226\n",
      "[1320]\ttraining's rmse: 2.85822\tvalid_1's rmse: 54.4125\n",
      "[1350]\ttraining's rmse: 2.72289\tvalid_1's rmse: 54.4036\n",
      "[1380]\ttraining's rmse: 2.59178\tvalid_1's rmse: 54.4029\n",
      "[1410]\ttraining's rmse: 2.46645\tvalid_1's rmse: 54.4002\n",
      "[1440]\ttraining's rmse: 2.35112\tvalid_1's rmse: 54.4013\n",
      "[1470]\ttraining's rmse: 2.24288\tvalid_1's rmse: 54.3975\n",
      "[1500]\ttraining's rmse: 2.13597\tvalid_1's rmse: 54.3966\n",
      "[1530]\ttraining's rmse: 2.03437\tvalid_1's rmse: 54.3929\n",
      "[1560]\ttraining's rmse: 1.94061\tvalid_1's rmse: 54.3919\n",
      "[1590]\ttraining's rmse: 1.8513\tvalid_1's rmse: 54.3905\n",
      "[1620]\ttraining's rmse: 1.76764\tvalid_1's rmse: 54.3895\n",
      "[1650]\ttraining's rmse: 1.69114\tvalid_1's rmse: 54.3884\n",
      "[1680]\ttraining's rmse: 1.6118\tvalid_1's rmse: 54.3853\n",
      "[1710]\ttraining's rmse: 1.53705\tvalid_1's rmse: 54.3855\n",
      "[1740]\ttraining's rmse: 1.46904\tvalid_1's rmse: 54.3831\n",
      "[1770]\ttraining's rmse: 1.40262\tvalid_1's rmse: 54.3817\n",
      "[1800]\ttraining's rmse: 1.33894\tvalid_1's rmse: 54.3815\n",
      "[1830]\ttraining's rmse: 1.27997\tvalid_1's rmse: 54.3785\n",
      "[1860]\ttraining's rmse: 1.22369\tvalid_1's rmse: 54.379\n",
      "[1890]\ttraining's rmse: 1.17084\tvalid_1's rmse: 54.3775\n",
      "[1920]\ttraining's rmse: 1.12085\tvalid_1's rmse: 54.3777\n",
      "[1950]\ttraining's rmse: 1.07215\tvalid_1's rmse: 54.3772\n",
      "[1980]\ttraining's rmse: 1.02507\tvalid_1's rmse: 54.3785\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's rmse: 0.995951\tvalid_1's rmse: 54.3783\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002226 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 20023\n",
      "[LightGBM] [Info] Number of data points in the train set: 9219, number of used features: 79\n",
      "[LightGBM] [Info] Start training from score 372.605724\n",
      "Training until validation scores don't improve for 125 rounds\n",
      "[30]\ttraining's rmse: 177.053\tvalid_1's rmse: 184.754\n",
      "[60]\ttraining's rmse: 108.847\tvalid_1's rmse: 120.448\n",
      "[90]\ttraining's rmse: 71.7849\tvalid_1's rmse: 88.8047\n",
      "[120]\ttraining's rmse: 51.7274\tvalid_1's rmse: 73.9484\n",
      "[150]\ttraining's rmse: 40.5352\tvalid_1's rmse: 67.0686\n",
      "[180]\ttraining's rmse: 33.8858\tvalid_1's rmse: 63.5209\n",
      "[210]\ttraining's rmse: 29.5428\tvalid_1's rmse: 61.6278\n",
      "[240]\ttraining's rmse: 26.3021\tvalid_1's rmse: 60.3653\n",
      "[270]\ttraining's rmse: 23.705\tvalid_1's rmse: 59.4599\n",
      "[300]\ttraining's rmse: 21.5983\tvalid_1's rmse: 58.9154\n",
      "[330]\ttraining's rmse: 19.7949\tvalid_1's rmse: 58.4813\n",
      "[360]\ttraining's rmse: 18.244\tvalid_1's rmse: 58.1961\n",
      "[390]\ttraining's rmse: 16.8598\tvalid_1's rmse: 57.9439\n",
      "[420]\ttraining's rmse: 15.6319\tvalid_1's rmse: 57.7852\n",
      "[450]\ttraining's rmse: 14.5269\tvalid_1's rmse: 57.617\n",
      "[480]\ttraining's rmse: 13.5309\tvalid_1's rmse: 57.4557\n",
      "[510]\ttraining's rmse: 12.6117\tvalid_1's rmse: 57.3548\n",
      "[540]\ttraining's rmse: 11.7855\tvalid_1's rmse: 57.2593\n",
      "[570]\ttraining's rmse: 11.0206\tvalid_1's rmse: 57.1761\n",
      "[600]\ttraining's rmse: 10.3299\tvalid_1's rmse: 57.074\n",
      "[630]\ttraining's rmse: 9.69591\tvalid_1's rmse: 57.0125\n",
      "[660]\ttraining's rmse: 9.11241\tvalid_1's rmse: 56.9643\n",
      "[690]\ttraining's rmse: 8.56101\tvalid_1's rmse: 56.912\n",
      "[720]\ttraining's rmse: 8.05576\tvalid_1's rmse: 56.8531\n",
      "[750]\ttraining's rmse: 7.57863\tvalid_1's rmse: 56.8098\n",
      "[780]\ttraining's rmse: 7.13778\tvalid_1's rmse: 56.7673\n",
      "[810]\ttraining's rmse: 6.72455\tvalid_1's rmse: 56.7222\n",
      "[840]\ttraining's rmse: 6.34839\tvalid_1's rmse: 56.6889\n",
      "[870]\ttraining's rmse: 5.99798\tvalid_1's rmse: 56.6616\n",
      "[900]\ttraining's rmse: 5.67155\tvalid_1's rmse: 56.6328\n",
      "[930]\ttraining's rmse: 5.36556\tvalid_1's rmse: 56.6089\n",
      "[960]\ttraining's rmse: 5.07377\tvalid_1's rmse: 56.5897\n",
      "[990]\ttraining's rmse: 4.80068\tvalid_1's rmse: 56.5828\n",
      "[1020]\ttraining's rmse: 4.54874\tvalid_1's rmse: 56.5636\n",
      "[1050]\ttraining's rmse: 4.30706\tvalid_1's rmse: 56.5504\n",
      "[1080]\ttraining's rmse: 4.08182\tvalid_1's rmse: 56.536\n",
      "[1110]\ttraining's rmse: 3.87104\tvalid_1's rmse: 56.5252\n",
      "[1140]\ttraining's rmse: 3.67889\tvalid_1's rmse: 56.5113\n",
      "[1170]\ttraining's rmse: 3.49049\tvalid_1's rmse: 56.5007\n",
      "[1200]\ttraining's rmse: 3.31455\tvalid_1's rmse: 56.4977\n",
      "[1230]\ttraining's rmse: 3.15127\tvalid_1's rmse: 56.497\n",
      "[1260]\ttraining's rmse: 2.99588\tvalid_1's rmse: 56.4896\n",
      "[1290]\ttraining's rmse: 2.84799\tvalid_1's rmse: 56.4842\n",
      "[1320]\ttraining's rmse: 2.70976\tvalid_1's rmse: 56.4798\n",
      "[1350]\ttraining's rmse: 2.5776\tvalid_1's rmse: 56.4744\n",
      "[1380]\ttraining's rmse: 2.45312\tvalid_1's rmse: 56.4709\n",
      "[1410]\ttraining's rmse: 2.33173\tvalid_1's rmse: 56.4662\n",
      "[1440]\ttraining's rmse: 2.21727\tvalid_1's rmse: 56.46\n",
      "[1470]\ttraining's rmse: 2.11287\tvalid_1's rmse: 56.4553\n",
      "[1500]\ttraining's rmse: 2.01284\tvalid_1's rmse: 56.4524\n",
      "[1530]\ttraining's rmse: 1.91972\tvalid_1's rmse: 56.4458\n",
      "[1560]\ttraining's rmse: 1.83158\tvalid_1's rmse: 56.4456\n",
      "[1590]\ttraining's rmse: 1.74541\tvalid_1's rmse: 56.442\n",
      "[1620]\ttraining's rmse: 1.66791\tvalid_1's rmse: 56.4405\n",
      "[1650]\ttraining's rmse: 1.59298\tvalid_1's rmse: 56.4348\n",
      "[1680]\ttraining's rmse: 1.51988\tvalid_1's rmse: 56.4308\n",
      "[1710]\ttraining's rmse: 1.44914\tvalid_1's rmse: 56.4302\n",
      "[1740]\ttraining's rmse: 1.38316\tvalid_1's rmse: 56.429\n",
      "[1770]\ttraining's rmse: 1.32339\tvalid_1's rmse: 56.4273\n",
      "[1800]\ttraining's rmse: 1.26483\tvalid_1's rmse: 56.4281\n",
      "[1830]\ttraining's rmse: 1.20685\tvalid_1's rmse: 56.427\n",
      "[1860]\ttraining's rmse: 1.15325\tvalid_1's rmse: 56.4246\n",
      "[1890]\ttraining's rmse: 1.10222\tvalid_1's rmse: 56.4248\n",
      "[1920]\ttraining's rmse: 1.05434\tvalid_1's rmse: 56.424\n",
      "[1950]\ttraining's rmse: 1.00789\tvalid_1's rmse: 56.4243\n",
      "[1980]\ttraining's rmse: 0.963958\tvalid_1's rmse: 56.4219\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's rmse: 0.935963\tvalid_1's rmse: 56.4225\n",
      "7\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002278 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 20021\n",
      "[LightGBM] [Info] Number of data points in the train set: 9219, number of used features: 79\n",
      "[LightGBM] [Info] Start training from score 389.883047\n",
      "Training until validation scores don't improve for 125 rounds\n",
      "[30]\ttraining's rmse: 173.652\tvalid_1's rmse: 179.577\n",
      "[60]\ttraining's rmse: 105.11\tvalid_1's rmse: 115.867\n",
      "[90]\ttraining's rmse: 68.0386\tvalid_1's rmse: 83.4182\n",
      "[120]\ttraining's rmse: 48.1683\tvalid_1's rmse: 67.706\n",
      "[150]\ttraining's rmse: 37.4231\tvalid_1's rmse: 60.2459\n",
      "[180]\ttraining's rmse: 31.2142\tvalid_1's rmse: 56.6303\n",
      "[210]\ttraining's rmse: 27.2142\tvalid_1's rmse: 54.5801\n",
      "[240]\ttraining's rmse: 24.1859\tvalid_1's rmse: 53.2149\n",
      "[270]\ttraining's rmse: 21.74\tvalid_1's rmse: 52.2318\n",
      "[300]\ttraining's rmse: 19.7715\tvalid_1's rmse: 51.5787\n",
      "[330]\ttraining's rmse: 18.1361\tvalid_1's rmse: 51.1322\n",
      "[360]\ttraining's rmse: 16.7142\tvalid_1's rmse: 50.7792\n",
      "[390]\ttraining's rmse: 15.4393\tvalid_1's rmse: 50.5151\n",
      "[420]\ttraining's rmse: 14.3269\tvalid_1's rmse: 50.3533\n",
      "[450]\ttraining's rmse: 13.3073\tvalid_1's rmse: 50.1899\n",
      "[480]\ttraining's rmse: 12.3808\tvalid_1's rmse: 50.051\n",
      "[510]\ttraining's rmse: 11.5514\tvalid_1's rmse: 49.9015\n",
      "[540]\ttraining's rmse: 10.8091\tvalid_1's rmse: 49.8308\n",
      "[570]\ttraining's rmse: 10.1289\tvalid_1's rmse: 49.7156\n",
      "[600]\ttraining's rmse: 9.48936\tvalid_1's rmse: 49.6451\n",
      "[630]\ttraining's rmse: 8.89197\tvalid_1's rmse: 49.5744\n",
      "[660]\ttraining's rmse: 8.35376\tvalid_1's rmse: 49.5338\n",
      "[690]\ttraining's rmse: 7.85026\tvalid_1's rmse: 49.4776\n",
      "[720]\ttraining's rmse: 7.39395\tvalid_1's rmse: 49.427\n",
      "[750]\ttraining's rmse: 6.97211\tvalid_1's rmse: 49.3871\n",
      "[780]\ttraining's rmse: 6.56382\tvalid_1's rmse: 49.3671\n",
      "[810]\ttraining's rmse: 6.19454\tvalid_1's rmse: 49.338\n",
      "[840]\ttraining's rmse: 5.84589\tvalid_1's rmse: 49.3101\n",
      "[870]\ttraining's rmse: 5.5123\tvalid_1's rmse: 49.2742\n",
      "[900]\ttraining's rmse: 5.20967\tvalid_1's rmse: 49.2563\n",
      "[930]\ttraining's rmse: 4.92097\tvalid_1's rmse: 49.2492\n",
      "[960]\ttraining's rmse: 4.6507\tvalid_1's rmse: 49.2268\n",
      "[990]\ttraining's rmse: 4.4057\tvalid_1's rmse: 49.217\n",
      "[1020]\ttraining's rmse: 4.1767\tvalid_1's rmse: 49.2023\n",
      "[1050]\ttraining's rmse: 3.95646\tvalid_1's rmse: 49.1964\n",
      "[1080]\ttraining's rmse: 3.75136\tvalid_1's rmse: 49.1807\n",
      "[1110]\ttraining's rmse: 3.55546\tvalid_1's rmse: 49.1605\n",
      "[1140]\ttraining's rmse: 3.36914\tvalid_1's rmse: 49.142\n",
      "[1170]\ttraining's rmse: 3.19714\tvalid_1's rmse: 49.1348\n",
      "[1200]\ttraining's rmse: 3.03396\tvalid_1's rmse: 49.1237\n",
      "[1230]\ttraining's rmse: 2.87578\tvalid_1's rmse: 49.1175\n",
      "[1260]\ttraining's rmse: 2.73299\tvalid_1's rmse: 49.1066\n",
      "[1290]\ttraining's rmse: 2.59386\tvalid_1's rmse: 49.0978\n",
      "[1320]\ttraining's rmse: 2.46541\tvalid_1's rmse: 49.0934\n",
      "[1350]\ttraining's rmse: 2.34235\tvalid_1's rmse: 49.0885\n",
      "[1380]\ttraining's rmse: 2.22607\tvalid_1's rmse: 49.0802\n",
      "[1410]\ttraining's rmse: 2.11632\tvalid_1's rmse: 49.0778\n",
      "[1440]\ttraining's rmse: 2.01429\tvalid_1's rmse: 49.0745\n",
      "[1470]\ttraining's rmse: 1.91875\tvalid_1's rmse: 49.0712\n",
      "[1500]\ttraining's rmse: 1.82565\tvalid_1's rmse: 49.072\n",
      "[1530]\ttraining's rmse: 1.7381\tvalid_1's rmse: 49.0673\n",
      "[1560]\ttraining's rmse: 1.6558\tvalid_1's rmse: 49.0657\n",
      "[1590]\ttraining's rmse: 1.57777\tvalid_1's rmse: 49.0604\n",
      "[1620]\ttraining's rmse: 1.5021\tvalid_1's rmse: 49.054\n",
      "[1650]\ttraining's rmse: 1.43079\tvalid_1's rmse: 49.0494\n",
      "[1680]\ttraining's rmse: 1.36238\tvalid_1's rmse: 49.0474\n",
      "[1710]\ttraining's rmse: 1.29801\tvalid_1's rmse: 49.0455\n",
      "[1740]\ttraining's rmse: 1.2364\tvalid_1's rmse: 49.043\n",
      "[1770]\ttraining's rmse: 1.17775\tvalid_1's rmse: 49.0387\n",
      "[1800]\ttraining's rmse: 1.12275\tvalid_1's rmse: 49.0363\n",
      "[1830]\ttraining's rmse: 1.07052\tvalid_1's rmse: 49.0333\n",
      "[1860]\ttraining's rmse: 1.02083\tvalid_1's rmse: 49.0321\n",
      "[1890]\ttraining's rmse: 0.973382\tvalid_1's rmse: 49.0316\n",
      "[1920]\ttraining's rmse: 0.928873\tvalid_1's rmse: 49.0312\n",
      "[1950]\ttraining's rmse: 0.885898\tvalid_1's rmse: 49.0306\n",
      "[1980]\ttraining's rmse: 0.845425\tvalid_1's rmse: 49.0276\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's rmse: 0.819548\tvalid_1's rmse: 49.0274\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003621 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 20021\n",
      "[LightGBM] [Info] Number of data points in the train set: 9219, number of used features: 79\n",
      "[LightGBM] [Info] Start training from score 387.612263\n",
      "Training until validation scores don't improve for 125 rounds\n",
      "[30]\ttraining's rmse: 176.225\tvalid_1's rmse: 183.912\n",
      "[60]\ttraining's rmse: 109.198\tvalid_1's rmse: 120.202\n",
      "[90]\ttraining's rmse: 72.702\tvalid_1's rmse: 88.4262\n",
      "[120]\ttraining's rmse: 52.7598\tvalid_1's rmse: 73.335\n",
      "[150]\ttraining's rmse: 41.7982\tvalid_1's rmse: 66.4471\n",
      "[180]\ttraining's rmse: 35.0485\tvalid_1's rmse: 62.9191\n",
      "[210]\ttraining's rmse: 30.4971\tvalid_1's rmse: 61.0664\n",
      "[240]\ttraining's rmse: 27.0919\tvalid_1's rmse: 59.9663\n",
      "[270]\ttraining's rmse: 24.3664\tvalid_1's rmse: 59.1109\n",
      "[300]\ttraining's rmse: 22.1697\tvalid_1's rmse: 58.6143\n",
      "[330]\ttraining's rmse: 20.2914\tvalid_1's rmse: 58.2796\n",
      "[360]\ttraining's rmse: 18.663\tvalid_1's rmse: 58.0507\n",
      "[390]\ttraining's rmse: 17.2183\tvalid_1's rmse: 57.8452\n",
      "[420]\ttraining's rmse: 15.9212\tvalid_1's rmse: 57.6826\n",
      "[450]\ttraining's rmse: 14.755\tvalid_1's rmse: 57.5265\n",
      "[480]\ttraining's rmse: 13.7171\tvalid_1's rmse: 57.4279\n",
      "[510]\ttraining's rmse: 12.7704\tvalid_1's rmse: 57.3404\n",
      "[540]\ttraining's rmse: 11.9078\tvalid_1's rmse: 57.2761\n",
      "[570]\ttraining's rmse: 11.1173\tvalid_1's rmse: 57.2037\n",
      "[600]\ttraining's rmse: 10.4181\tvalid_1's rmse: 57.1356\n",
      "[630]\ttraining's rmse: 9.74698\tvalid_1's rmse: 57.0653\n",
      "[660]\ttraining's rmse: 9.14818\tvalid_1's rmse: 57.0271\n",
      "[690]\ttraining's rmse: 8.57925\tvalid_1's rmse: 56.996\n",
      "[720]\ttraining's rmse: 8.04992\tvalid_1's rmse: 56.963\n",
      "[750]\ttraining's rmse: 7.57879\tvalid_1's rmse: 56.9175\n",
      "[780]\ttraining's rmse: 7.1245\tvalid_1's rmse: 56.8963\n",
      "[810]\ttraining's rmse: 6.70437\tvalid_1's rmse: 56.8834\n",
      "[840]\ttraining's rmse: 6.3177\tvalid_1's rmse: 56.8524\n",
      "[870]\ttraining's rmse: 5.96016\tvalid_1's rmse: 56.8328\n",
      "[900]\ttraining's rmse: 5.62282\tvalid_1's rmse: 56.8117\n",
      "[930]\ttraining's rmse: 5.30653\tvalid_1's rmse: 56.7892\n",
      "[960]\ttraining's rmse: 5.01305\tvalid_1's rmse: 56.7737\n",
      "[990]\ttraining's rmse: 4.73875\tvalid_1's rmse: 56.7606\n",
      "[1020]\ttraining's rmse: 4.48019\tvalid_1's rmse: 56.7559\n",
      "[1050]\ttraining's rmse: 4.24562\tvalid_1's rmse: 56.7477\n",
      "[1080]\ttraining's rmse: 4.02165\tvalid_1's rmse: 56.7371\n",
      "[1110]\ttraining's rmse: 3.8047\tvalid_1's rmse: 56.7254\n",
      "[1140]\ttraining's rmse: 3.60463\tvalid_1's rmse: 56.7175\n",
      "[1170]\ttraining's rmse: 3.41865\tvalid_1's rmse: 56.7124\n",
      "[1200]\ttraining's rmse: 3.23962\tvalid_1's rmse: 56.7013\n",
      "[1230]\ttraining's rmse: 3.07193\tvalid_1's rmse: 56.6966\n",
      "[1260]\ttraining's rmse: 2.91318\tvalid_1's rmse: 56.69\n",
      "[1290]\ttraining's rmse: 2.76409\tvalid_1's rmse: 56.6849\n",
      "[1320]\ttraining's rmse: 2.62181\tvalid_1's rmse: 56.6842\n",
      "[1350]\ttraining's rmse: 2.48711\tvalid_1's rmse: 56.678\n",
      "[1380]\ttraining's rmse: 2.36295\tvalid_1's rmse: 56.6731\n",
      "[1410]\ttraining's rmse: 2.24598\tvalid_1's rmse: 56.6674\n",
      "[1440]\ttraining's rmse: 2.13527\tvalid_1's rmse: 56.6633\n",
      "[1470]\ttraining's rmse: 2.02934\tvalid_1's rmse: 56.6615\n",
      "[1500]\ttraining's rmse: 1.92777\tvalid_1's rmse: 56.6602\n",
      "[1530]\ttraining's rmse: 1.83203\tvalid_1's rmse: 56.6591\n",
      "[1560]\ttraining's rmse: 1.74455\tvalid_1's rmse: 56.6547\n",
      "[1590]\ttraining's rmse: 1.66016\tvalid_1's rmse: 56.6543\n",
      "[1620]\ttraining's rmse: 1.57881\tvalid_1's rmse: 56.6519\n",
      "[1650]\ttraining's rmse: 1.50304\tvalid_1's rmse: 56.6503\n",
      "[1680]\ttraining's rmse: 1.42973\tvalid_1's rmse: 56.6496\n",
      "[1710]\ttraining's rmse: 1.36\tvalid_1's rmse: 56.6486\n",
      "[1740]\ttraining's rmse: 1.29489\tvalid_1's rmse: 56.6473\n",
      "[1770]\ttraining's rmse: 1.23215\tvalid_1's rmse: 56.6442\n",
      "[1800]\ttraining's rmse: 1.17322\tvalid_1's rmse: 56.6403\n",
      "[1830]\ttraining's rmse: 1.11835\tvalid_1's rmse: 56.6381\n",
      "[1860]\ttraining's rmse: 1.06556\tvalid_1's rmse: 56.6353\n",
      "[1890]\ttraining's rmse: 1.01502\tvalid_1's rmse: 56.6325\n",
      "[1920]\ttraining's rmse: 0.966105\tvalid_1's rmse: 56.6313\n",
      "[1950]\ttraining's rmse: 0.922474\tvalid_1's rmse: 56.6318\n",
      "[1980]\ttraining's rmse: 0.879357\tvalid_1's rmse: 56.6303\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's rmse: 0.851946\tvalid_1's rmse: 56.6286\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003939 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 20021\n",
      "[LightGBM] [Info] Number of data points in the train set: 9219, number of used features: 79\n",
      "[LightGBM] [Info] Start training from score 382.928992\n",
      "Training until validation scores don't improve for 125 rounds\n",
      "[30]\ttraining's rmse: 174.867\tvalid_1's rmse: 186.587\n",
      "[60]\ttraining's rmse: 107.585\tvalid_1's rmse: 124.47\n",
      "[90]\ttraining's rmse: 70.873\tvalid_1's rmse: 92.9547\n",
      "[120]\ttraining's rmse: 51.1905\tvalid_1's rmse: 78.2523\n",
      "[150]\ttraining's rmse: 40.3737\tvalid_1's rmse: 71.0277\n",
      "[180]\ttraining's rmse: 33.9827\tvalid_1's rmse: 67.2111\n",
      "[210]\ttraining's rmse: 29.7137\tvalid_1's rmse: 65.0209\n",
      "[240]\ttraining's rmse: 26.5447\tvalid_1's rmse: 63.575\n",
      "[270]\ttraining's rmse: 23.9331\tvalid_1's rmse: 62.4709\n",
      "[300]\ttraining's rmse: 21.8418\tvalid_1's rmse: 61.8382\n",
      "[330]\ttraining's rmse: 20.0293\tvalid_1's rmse: 61.3694\n",
      "[360]\ttraining's rmse: 18.4581\tvalid_1's rmse: 61.0254\n",
      "[390]\ttraining's rmse: 17.0605\tvalid_1's rmse: 60.7649\n",
      "[420]\ttraining's rmse: 15.8174\tvalid_1's rmse: 60.6109\n",
      "[450]\ttraining's rmse: 14.6988\tvalid_1's rmse: 60.4958\n",
      "[480]\ttraining's rmse: 13.6769\tvalid_1's rmse: 60.3432\n",
      "[510]\ttraining's rmse: 12.7579\tvalid_1's rmse: 60.248\n",
      "[540]\ttraining's rmse: 11.9372\tvalid_1's rmse: 60.146\n",
      "[570]\ttraining's rmse: 11.1599\tvalid_1's rmse: 60.065\n",
      "[600]\ttraining's rmse: 10.4589\tvalid_1's rmse: 60.0033\n",
      "[630]\ttraining's rmse: 9.81566\tvalid_1's rmse: 59.9448\n",
      "[660]\ttraining's rmse: 9.22281\tvalid_1's rmse: 59.8717\n",
      "[690]\ttraining's rmse: 8.66465\tvalid_1's rmse: 59.8084\n",
      "[720]\ttraining's rmse: 8.16134\tvalid_1's rmse: 59.7474\n",
      "[750]\ttraining's rmse: 7.69152\tvalid_1's rmse: 59.7233\n",
      "[780]\ttraining's rmse: 7.24966\tvalid_1's rmse: 59.6999\n",
      "[810]\ttraining's rmse: 6.84249\tvalid_1's rmse: 59.6802\n",
      "[840]\ttraining's rmse: 6.46305\tvalid_1's rmse: 59.6503\n",
      "[870]\ttraining's rmse: 6.10376\tvalid_1's rmse: 59.6245\n",
      "[900]\ttraining's rmse: 5.77169\tvalid_1's rmse: 59.6145\n",
      "[930]\ttraining's rmse: 5.45795\tvalid_1's rmse: 59.5907\n",
      "[960]\ttraining's rmse: 5.17117\tvalid_1's rmse: 59.5672\n",
      "[990]\ttraining's rmse: 4.88821\tvalid_1's rmse: 59.5464\n",
      "[1020]\ttraining's rmse: 4.62878\tvalid_1's rmse: 59.5411\n",
      "[1050]\ttraining's rmse: 4.38589\tvalid_1's rmse: 59.5359\n",
      "[1080]\ttraining's rmse: 4.16281\tvalid_1's rmse: 59.5287\n",
      "[1110]\ttraining's rmse: 3.95232\tvalid_1's rmse: 59.5168\n",
      "[1140]\ttraining's rmse: 3.75196\tvalid_1's rmse: 59.4945\n",
      "[1170]\ttraining's rmse: 3.56189\tvalid_1's rmse: 59.483\n",
      "[1200]\ttraining's rmse: 3.38297\tvalid_1's rmse: 59.4716\n",
      "[1230]\ttraining's rmse: 3.21194\tvalid_1's rmse: 59.4699\n",
      "[1260]\ttraining's rmse: 3.05067\tvalid_1's rmse: 59.4564\n",
      "[1290]\ttraining's rmse: 2.90317\tvalid_1's rmse: 59.453\n",
      "[1320]\ttraining's rmse: 2.75977\tvalid_1's rmse: 59.44\n",
      "[1350]\ttraining's rmse: 2.62516\tvalid_1's rmse: 59.4357\n",
      "[1380]\ttraining's rmse: 2.49892\tvalid_1's rmse: 59.4362\n",
      "[1410]\ttraining's rmse: 2.37832\tvalid_1's rmse: 59.4313\n",
      "[1440]\ttraining's rmse: 2.26323\tvalid_1's rmse: 59.4285\n",
      "[1470]\ttraining's rmse: 2.15578\tvalid_1's rmse: 59.4256\n",
      "[1500]\ttraining's rmse: 2.05549\tvalid_1's rmse: 59.4245\n",
      "[1530]\ttraining's rmse: 1.95847\tvalid_1's rmse: 59.4206\n",
      "[1560]\ttraining's rmse: 1.8667\tvalid_1's rmse: 59.4223\n",
      "[1590]\ttraining's rmse: 1.77896\tvalid_1's rmse: 59.4227\n",
      "[1620]\ttraining's rmse: 1.69632\tvalid_1's rmse: 59.4157\n",
      "[1650]\ttraining's rmse: 1.62127\tvalid_1's rmse: 59.4117\n",
      "[1680]\ttraining's rmse: 1.54709\tvalid_1's rmse: 59.4095\n",
      "[1710]\ttraining's rmse: 1.47701\tvalid_1's rmse: 59.4086\n",
      "[1740]\ttraining's rmse: 1.40958\tvalid_1's rmse: 59.4057\n",
      "[1770]\ttraining's rmse: 1.3464\tvalid_1's rmse: 59.4058\n",
      "[1800]\ttraining's rmse: 1.28673\tvalid_1's rmse: 59.4039\n",
      "[1830]\ttraining's rmse: 1.22921\tvalid_1's rmse: 59.4001\n",
      "[1860]\ttraining's rmse: 1.17484\tvalid_1's rmse: 59.3997\n",
      "[1890]\ttraining's rmse: 1.12245\tvalid_1's rmse: 59.3988\n",
      "[1920]\ttraining's rmse: 1.0741\tvalid_1's rmse: 59.399\n",
      "[1950]\ttraining's rmse: 1.02646\tvalid_1's rmse: 59.3981\n",
      "[1980]\ttraining's rmse: 0.981747\tvalid_1's rmse: 59.3968\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's rmse: 0.954587\tvalid_1's rmse: 59.3964\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003423 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 20021\n",
      "[LightGBM] [Info] Number of data points in the train set: 9219, number of used features: 79\n",
      "[LightGBM] [Info] Start training from score 378.645307\n",
      "Training until validation scores don't improve for 125 rounds\n",
      "[30]\ttraining's rmse: 173.998\tvalid_1's rmse: 187.828\n",
      "[60]\ttraining's rmse: 106.412\tvalid_1's rmse: 125.287\n",
      "[90]\ttraining's rmse: 69.9896\tvalid_1's rmse: 94.8792\n",
      "[120]\ttraining's rmse: 50.4002\tvalid_1's rmse: 80.6783\n",
      "[150]\ttraining's rmse: 39.8138\tvalid_1's rmse: 73.8687\n",
      "[180]\ttraining's rmse: 33.4007\tvalid_1's rmse: 69.924\n",
      "[210]\ttraining's rmse: 29.1622\tvalid_1's rmse: 67.6347\n",
      "[240]\ttraining's rmse: 26.0707\tvalid_1's rmse: 66.2327\n",
      "[270]\ttraining's rmse: 23.5528\tvalid_1's rmse: 65.0894\n",
      "[300]\ttraining's rmse: 21.4591\tvalid_1's rmse: 64.307\n",
      "[330]\ttraining's rmse: 19.6732\tvalid_1's rmse: 63.6596\n",
      "[360]\ttraining's rmse: 18.1524\tvalid_1's rmse: 63.2262\n",
      "[390]\ttraining's rmse: 16.7806\tvalid_1's rmse: 62.8717\n",
      "[420]\ttraining's rmse: 15.5763\tvalid_1's rmse: 62.6866\n",
      "[450]\ttraining's rmse: 14.4795\tvalid_1's rmse: 62.485\n",
      "[480]\ttraining's rmse: 13.4863\tvalid_1's rmse: 62.3303\n",
      "[510]\ttraining's rmse: 12.5996\tvalid_1's rmse: 62.227\n",
      "[540]\ttraining's rmse: 11.7888\tvalid_1's rmse: 62.0931\n",
      "[570]\ttraining's rmse: 11.0305\tvalid_1's rmse: 61.9802\n",
      "[600]\ttraining's rmse: 10.3473\tvalid_1's rmse: 61.8953\n",
      "[630]\ttraining's rmse: 9.73288\tvalid_1's rmse: 61.8251\n",
      "[660]\ttraining's rmse: 9.15345\tvalid_1's rmse: 61.7758\n",
      "[690]\ttraining's rmse: 8.62408\tvalid_1's rmse: 61.723\n",
      "[720]\ttraining's rmse: 8.13112\tvalid_1's rmse: 61.6915\n",
      "[750]\ttraining's rmse: 7.66572\tvalid_1's rmse: 61.6369\n",
      "[780]\ttraining's rmse: 7.24512\tvalid_1's rmse: 61.6199\n",
      "[810]\ttraining's rmse: 6.83095\tvalid_1's rmse: 61.6036\n",
      "[840]\ttraining's rmse: 6.45417\tvalid_1's rmse: 61.5922\n",
      "[870]\ttraining's rmse: 6.10838\tvalid_1's rmse: 61.5868\n",
      "[900]\ttraining's rmse: 5.77164\tvalid_1's rmse: 61.5673\n",
      "[930]\ttraining's rmse: 5.46473\tvalid_1's rmse: 61.5375\n",
      "[960]\ttraining's rmse: 5.17608\tvalid_1's rmse: 61.5047\n",
      "[990]\ttraining's rmse: 4.89581\tvalid_1's rmse: 61.4877\n",
      "[1020]\ttraining's rmse: 4.64644\tvalid_1's rmse: 61.4818\n",
      "[1050]\ttraining's rmse: 4.40752\tvalid_1's rmse: 61.4572\n",
      "[1080]\ttraining's rmse: 4.18084\tvalid_1's rmse: 61.4316\n",
      "[1110]\ttraining's rmse: 3.97242\tvalid_1's rmse: 61.4231\n",
      "[1140]\ttraining's rmse: 3.77486\tvalid_1's rmse: 61.4049\n",
      "[1170]\ttraining's rmse: 3.58741\tvalid_1's rmse: 61.3891\n",
      "[1200]\ttraining's rmse: 3.41176\tvalid_1's rmse: 61.3757\n",
      "[1230]\ttraining's rmse: 3.24543\tvalid_1's rmse: 61.3848\n",
      "[1260]\ttraining's rmse: 3.08561\tvalid_1's rmse: 61.3674\n",
      "[1290]\ttraining's rmse: 2.93822\tvalid_1's rmse: 61.3552\n",
      "[1320]\ttraining's rmse: 2.79557\tvalid_1's rmse: 61.3461\n",
      "[1350]\ttraining's rmse: 2.66117\tvalid_1's rmse: 61.3426\n",
      "[1380]\ttraining's rmse: 2.53835\tvalid_1's rmse: 61.3414\n",
      "[1410]\ttraining's rmse: 2.41984\tvalid_1's rmse: 61.338\n",
      "[1440]\ttraining's rmse: 2.30704\tvalid_1's rmse: 61.3376\n",
      "[1470]\ttraining's rmse: 2.19915\tvalid_1's rmse: 61.3229\n",
      "[1500]\ttraining's rmse: 2.09818\tvalid_1's rmse: 61.3087\n",
      "[1530]\ttraining's rmse: 2.00136\tvalid_1's rmse: 61.2966\n",
      "[1560]\ttraining's rmse: 1.91236\tvalid_1's rmse: 61.2963\n",
      "[1590]\ttraining's rmse: 1.82129\tvalid_1's rmse: 61.2866\n",
      "[1620]\ttraining's rmse: 1.74108\tvalid_1's rmse: 61.2811\n",
      "[1650]\ttraining's rmse: 1.66583\tvalid_1's rmse: 61.2751\n",
      "[1680]\ttraining's rmse: 1.59152\tvalid_1's rmse: 61.2719\n",
      "[1710]\ttraining's rmse: 1.52011\tvalid_1's rmse: 61.2688\n",
      "[1740]\ttraining's rmse: 1.45407\tvalid_1's rmse: 61.2675\n",
      "[1770]\ttraining's rmse: 1.38945\tvalid_1's rmse: 61.2641\n",
      "[1800]\ttraining's rmse: 1.32863\tvalid_1's rmse: 61.2613\n",
      "[1830]\ttraining's rmse: 1.2694\tvalid_1's rmse: 61.2608\n",
      "[1860]\ttraining's rmse: 1.21308\tvalid_1's rmse: 61.2597\n",
      "[1890]\ttraining's rmse: 1.16035\tvalid_1's rmse: 61.2533\n",
      "[1920]\ttraining's rmse: 1.11061\tvalid_1's rmse: 61.252\n",
      "[1950]\ttraining's rmse: 1.06369\tvalid_1's rmse: 61.2513\n",
      "[1980]\ttraining's rmse: 1.0175\tvalid_1's rmse: 61.2486\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's rmse: 0.98954\tvalid_1's rmse: 61.2476\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002531 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 20021\n",
      "[LightGBM] [Info] Number of data points in the train set: 9219, number of used features: 79\n",
      "[LightGBM] [Info] Start training from score 378.655421\n",
      "Training until validation scores don't improve for 125 rounds\n",
      "[30]\ttraining's rmse: 175.969\tvalid_1's rmse: 182.942\n",
      "[60]\ttraining's rmse: 108.637\tvalid_1's rmse: 120.08\n",
      "[90]\ttraining's rmse: 72.3824\tvalid_1's rmse: 89.2412\n",
      "[120]\ttraining's rmse: 52.6874\tvalid_1's rmse: 74.3153\n",
      "[150]\ttraining's rmse: 41.703\tvalid_1's rmse: 67.0679\n",
      "[180]\ttraining's rmse: 35.153\tvalid_1's rmse: 63.6216\n",
      "[210]\ttraining's rmse: 30.6875\tvalid_1's rmse: 61.4766\n",
      "[240]\ttraining's rmse: 27.2492\tvalid_1's rmse: 59.9992\n",
      "[270]\ttraining's rmse: 24.5629\tvalid_1's rmse: 59.0888\n",
      "[300]\ttraining's rmse: 22.418\tvalid_1's rmse: 58.4611\n",
      "[330]\ttraining's rmse: 20.5738\tvalid_1's rmse: 58.0179\n",
      "[360]\ttraining's rmse: 18.975\tvalid_1's rmse: 57.6862\n",
      "[390]\ttraining's rmse: 17.519\tvalid_1's rmse: 57.4078\n",
      "[420]\ttraining's rmse: 16.2533\tvalid_1's rmse: 57.2163\n",
      "[450]\ttraining's rmse: 15.0935\tvalid_1's rmse: 57.0601\n",
      "[480]\ttraining's rmse: 14.0455\tvalid_1's rmse: 56.8859\n",
      "[510]\ttraining's rmse: 13.09\tvalid_1's rmse: 56.7638\n",
      "[540]\ttraining's rmse: 12.2283\tvalid_1's rmse: 56.6631\n",
      "[570]\ttraining's rmse: 11.4405\tvalid_1's rmse: 56.5782\n",
      "[600]\ttraining's rmse: 10.723\tvalid_1's rmse: 56.5103\n",
      "[630]\ttraining's rmse: 10.0626\tvalid_1's rmse: 56.4475\n",
      "[660]\ttraining's rmse: 9.45042\tvalid_1's rmse: 56.3738\n",
      "[690]\ttraining's rmse: 8.88698\tvalid_1's rmse: 56.3287\n",
      "[720]\ttraining's rmse: 8.36419\tvalid_1's rmse: 56.2957\n",
      "[750]\ttraining's rmse: 7.87541\tvalid_1's rmse: 56.2456\n",
      "[780]\ttraining's rmse: 7.4194\tvalid_1's rmse: 56.2216\n",
      "[810]\ttraining's rmse: 6.99961\tvalid_1's rmse: 56.2014\n",
      "[840]\ttraining's rmse: 6.60568\tvalid_1's rmse: 56.1896\n",
      "[870]\ttraining's rmse: 6.23223\tvalid_1's rmse: 56.1656\n",
      "[900]\ttraining's rmse: 5.88197\tvalid_1's rmse: 56.1526\n",
      "[930]\ttraining's rmse: 5.56416\tvalid_1's rmse: 56.1309\n",
      "[960]\ttraining's rmse: 5.26693\tvalid_1's rmse: 56.1114\n",
      "[990]\ttraining's rmse: 4.9861\tvalid_1's rmse: 56.0926\n",
      "[1020]\ttraining's rmse: 4.71981\tvalid_1's rmse: 56.0745\n",
      "[1050]\ttraining's rmse: 4.4727\tvalid_1's rmse: 56.0508\n",
      "[1080]\ttraining's rmse: 4.23773\tvalid_1's rmse: 56.046\n",
      "[1110]\ttraining's rmse: 4.02206\tvalid_1's rmse: 56.046\n",
      "[1140]\ttraining's rmse: 3.81815\tvalid_1's rmse: 56.0423\n",
      "[1170]\ttraining's rmse: 3.62246\tvalid_1's rmse: 56.0355\n",
      "[1200]\ttraining's rmse: 3.43909\tvalid_1's rmse: 56.0306\n",
      "[1230]\ttraining's rmse: 3.26859\tvalid_1's rmse: 56.0224\n",
      "[1260]\ttraining's rmse: 3.10904\tvalid_1's rmse: 56.0079\n",
      "[1290]\ttraining's rmse: 2.95765\tvalid_1's rmse: 56.0073\n",
      "[1320]\ttraining's rmse: 2.81003\tvalid_1's rmse: 56.006\n",
      "[1350]\ttraining's rmse: 2.67248\tvalid_1's rmse: 56.0028\n",
      "[1380]\ttraining's rmse: 2.5428\tvalid_1's rmse: 55.9997\n",
      "[1410]\ttraining's rmse: 2.41668\tvalid_1's rmse: 55.9959\n",
      "[1440]\ttraining's rmse: 2.29947\tvalid_1's rmse: 55.9951\n",
      "[1470]\ttraining's rmse: 2.1918\tvalid_1's rmse: 55.9931\n",
      "[1500]\ttraining's rmse: 2.08686\tvalid_1's rmse: 55.99\n",
      "[1530]\ttraining's rmse: 1.98996\tvalid_1's rmse: 55.9847\n",
      "[1560]\ttraining's rmse: 1.89296\tvalid_1's rmse: 55.9828\n",
      "[1590]\ttraining's rmse: 1.80605\tvalid_1's rmse: 55.981\n",
      "[1620]\ttraining's rmse: 1.72271\tvalid_1's rmse: 55.978\n",
      "[1650]\ttraining's rmse: 1.64484\tvalid_1's rmse: 55.9734\n",
      "[1680]\ttraining's rmse: 1.56994\tvalid_1's rmse: 55.9716\n",
      "[1710]\ttraining's rmse: 1.498\tvalid_1's rmse: 55.9678\n",
      "[1740]\ttraining's rmse: 1.42907\tvalid_1's rmse: 55.9667\n",
      "[1770]\ttraining's rmse: 1.36167\tvalid_1's rmse: 55.9673\n",
      "[1800]\ttraining's rmse: 1.29942\tvalid_1's rmse: 55.9643\n",
      "[1830]\ttraining's rmse: 1.24243\tvalid_1's rmse: 55.9619\n",
      "[1860]\ttraining's rmse: 1.18676\tvalid_1's rmse: 55.9612\n",
      "[1890]\ttraining's rmse: 1.13512\tvalid_1's rmse: 55.9616\n",
      "[1920]\ttraining's rmse: 1.08497\tvalid_1's rmse: 55.9603\n",
      "[1950]\ttraining's rmse: 1.03753\tvalid_1's rmse: 55.9601\n",
      "[1980]\ttraining's rmse: 0.992254\tvalid_1's rmse: 55.9583\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's rmse: 0.962922\tvalid_1's rmse: 55.9571\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003641 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 20021\n",
      "[LightGBM] [Info] Number of data points in the train set: 9219, number of used features: 79\n",
      "[LightGBM] [Info] Start training from score 376.520758\n",
      "Training until validation scores don't improve for 125 rounds\n",
      "[30]\ttraining's rmse: 175.723\tvalid_1's rmse: 182.61\n",
      "[60]\ttraining's rmse: 108.082\tvalid_1's rmse: 118.646\n",
      "[90]\ttraining's rmse: 71.4366\tvalid_1's rmse: 86.0407\n",
      "[120]\ttraining's rmse: 51.7174\tvalid_1's rmse: 70.2385\n",
      "[150]\ttraining's rmse: 40.7501\tvalid_1's rmse: 62.8914\n",
      "[180]\ttraining's rmse: 34.171\tvalid_1's rmse: 59.1469\n",
      "[210]\ttraining's rmse: 29.7428\tvalid_1's rmse: 57.0549\n",
      "[240]\ttraining's rmse: 26.4212\tvalid_1's rmse: 55.7289\n",
      "[270]\ttraining's rmse: 23.7516\tvalid_1's rmse: 54.8953\n",
      "[300]\ttraining's rmse: 21.599\tvalid_1's rmse: 54.2615\n",
      "[330]\ttraining's rmse: 19.7494\tvalid_1's rmse: 53.836\n",
      "[360]\ttraining's rmse: 18.1646\tvalid_1's rmse: 53.4559\n",
      "[390]\ttraining's rmse: 16.8002\tvalid_1's rmse: 53.1695\n",
      "[420]\ttraining's rmse: 15.5577\tvalid_1's rmse: 52.9363\n",
      "[450]\ttraining's rmse: 14.4535\tvalid_1's rmse: 52.7554\n",
      "[480]\ttraining's rmse: 13.4472\tvalid_1's rmse: 52.6209\n",
      "[510]\ttraining's rmse: 12.5534\tvalid_1's rmse: 52.5277\n",
      "[540]\ttraining's rmse: 11.7167\tvalid_1's rmse: 52.4353\n",
      "[570]\ttraining's rmse: 10.9719\tvalid_1's rmse: 52.3315\n",
      "[600]\ttraining's rmse: 10.2828\tvalid_1's rmse: 52.2208\n",
      "[630]\ttraining's rmse: 9.64161\tvalid_1's rmse: 52.1387\n",
      "[660]\ttraining's rmse: 9.05319\tvalid_1's rmse: 52.0847\n",
      "[690]\ttraining's rmse: 8.51019\tvalid_1's rmse: 52.0303\n",
      "[720]\ttraining's rmse: 7.99906\tvalid_1's rmse: 51.9901\n",
      "[750]\ttraining's rmse: 7.53522\tvalid_1's rmse: 51.9564\n",
      "[780]\ttraining's rmse: 7.10838\tvalid_1's rmse: 51.9187\n",
      "[810]\ttraining's rmse: 6.70724\tvalid_1's rmse: 51.8942\n",
      "[840]\ttraining's rmse: 6.32943\tvalid_1's rmse: 51.8676\n",
      "[870]\ttraining's rmse: 5.97013\tvalid_1's rmse: 51.8412\n",
      "[900]\ttraining's rmse: 5.63978\tvalid_1's rmse: 51.8204\n",
      "[930]\ttraining's rmse: 5.329\tvalid_1's rmse: 51.7967\n",
      "[960]\ttraining's rmse: 5.04337\tvalid_1's rmse: 51.7751\n",
      "[990]\ttraining's rmse: 4.77243\tvalid_1's rmse: 51.7573\n",
      "[1020]\ttraining's rmse: 4.52006\tvalid_1's rmse: 51.7414\n",
      "[1050]\ttraining's rmse: 4.28707\tvalid_1's rmse: 51.7361\n",
      "[1080]\ttraining's rmse: 4.06594\tvalid_1's rmse: 51.7306\n",
      "[1110]\ttraining's rmse: 3.85287\tvalid_1's rmse: 51.7157\n",
      "[1140]\ttraining's rmse: 3.65696\tvalid_1's rmse: 51.7152\n",
      "[1170]\ttraining's rmse: 3.47521\tvalid_1's rmse: 51.7038\n",
      "[1200]\ttraining's rmse: 3.30189\tvalid_1's rmse: 51.6986\n",
      "[1230]\ttraining's rmse: 3.13986\tvalid_1's rmse: 51.6936\n",
      "[1260]\ttraining's rmse: 2.98342\tvalid_1's rmse: 51.6918\n",
      "[1290]\ttraining's rmse: 2.83396\tvalid_1's rmse: 51.6909\n",
      "[1320]\ttraining's rmse: 2.68925\tvalid_1's rmse: 51.6862\n",
      "[1350]\ttraining's rmse: 2.55656\tvalid_1's rmse: 51.6802\n",
      "[1380]\ttraining's rmse: 2.43037\tvalid_1's rmse: 51.6779\n",
      "[1410]\ttraining's rmse: 2.30952\tvalid_1's rmse: 51.675\n",
      "[1440]\ttraining's rmse: 2.19774\tvalid_1's rmse: 51.6687\n",
      "[1470]\ttraining's rmse: 2.09033\tvalid_1's rmse: 51.6629\n",
      "[1500]\ttraining's rmse: 1.99011\tvalid_1's rmse: 51.6567\n",
      "[1530]\ttraining's rmse: 1.89486\tvalid_1's rmse: 51.6543\n",
      "[1560]\ttraining's rmse: 1.80825\tvalid_1's rmse: 51.6518\n",
      "[1590]\ttraining's rmse: 1.72354\tvalid_1's rmse: 51.6503\n",
      "[1620]\ttraining's rmse: 1.64058\tvalid_1's rmse: 51.6495\n",
      "[1650]\ttraining's rmse: 1.56575\tvalid_1's rmse: 51.6433\n",
      "[1680]\ttraining's rmse: 1.49265\tvalid_1's rmse: 51.6436\n",
      "[1710]\ttraining's rmse: 1.42299\tvalid_1's rmse: 51.6419\n",
      "[1740]\ttraining's rmse: 1.35841\tvalid_1's rmse: 51.6404\n",
      "[1770]\ttraining's rmse: 1.29541\tvalid_1's rmse: 51.6392\n",
      "[1800]\ttraining's rmse: 1.23643\tvalid_1's rmse: 51.6381\n",
      "[1830]\ttraining's rmse: 1.1793\tvalid_1's rmse: 51.637\n",
      "[1860]\ttraining's rmse: 1.12511\tvalid_1's rmse: 51.6355\n",
      "[1890]\ttraining's rmse: 1.07495\tvalid_1's rmse: 51.6343\n",
      "[1920]\ttraining's rmse: 1.0263\tvalid_1's rmse: 51.6318\n",
      "[1950]\ttraining's rmse: 0.979629\tvalid_1's rmse: 51.6312\n",
      "[1980]\ttraining's rmse: 0.935178\tvalid_1's rmse: 51.631\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's rmse: 0.907098\tvalid_1's rmse: 51.6287\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003478 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 20021\n",
      "[LightGBM] [Info] Number of data points in the train set: 9219, number of used features: 79\n",
      "[LightGBM] [Info] Start training from score 378.889588\n",
      "Training until validation scores don't improve for 125 rounds\n",
      "[30]\ttraining's rmse: 175.93\tvalid_1's rmse: 182.852\n",
      "[60]\ttraining's rmse: 108.518\tvalid_1's rmse: 120.17\n",
      "[90]\ttraining's rmse: 71.6219\tvalid_1's rmse: 88.5401\n",
      "[120]\ttraining's rmse: 51.594\tvalid_1's rmse: 73.2906\n",
      "[150]\ttraining's rmse: 40.5232\tvalid_1's rmse: 66.1611\n",
      "[180]\ttraining's rmse: 33.9769\tvalid_1's rmse: 62.6117\n",
      "[210]\ttraining's rmse: 29.6081\tvalid_1's rmse: 60.6017\n",
      "[240]\ttraining's rmse: 26.3415\tvalid_1's rmse: 59.2714\n",
      "[270]\ttraining's rmse: 23.708\tvalid_1's rmse: 58.3478\n",
      "[300]\ttraining's rmse: 21.5591\tvalid_1's rmse: 57.7611\n",
      "[330]\ttraining's rmse: 19.7588\tvalid_1's rmse: 57.3059\n",
      "[360]\ttraining's rmse: 18.1709\tvalid_1's rmse: 57.0269\n",
      "[390]\ttraining's rmse: 16.772\tvalid_1's rmse: 56.8138\n",
      "[420]\ttraining's rmse: 15.5423\tvalid_1's rmse: 56.6314\n",
      "[450]\ttraining's rmse: 14.4232\tvalid_1's rmse: 56.4817\n",
      "[480]\ttraining's rmse: 13.4234\tvalid_1's rmse: 56.403\n",
      "[510]\ttraining's rmse: 12.4904\tvalid_1's rmse: 56.326\n",
      "[540]\ttraining's rmse: 11.6638\tvalid_1's rmse: 56.2682\n",
      "[570]\ttraining's rmse: 10.8927\tvalid_1's rmse: 56.2054\n",
      "[600]\ttraining's rmse: 10.1977\tvalid_1's rmse: 56.1849\n",
      "[630]\ttraining's rmse: 9.56454\tvalid_1's rmse: 56.1518\n",
      "[660]\ttraining's rmse: 8.98372\tvalid_1's rmse: 56.1399\n",
      "[690]\ttraining's rmse: 8.43908\tvalid_1's rmse: 56.1193\n",
      "[720]\ttraining's rmse: 7.93806\tvalid_1's rmse: 56.0952\n",
      "[750]\ttraining's rmse: 7.46862\tvalid_1's rmse: 56.0586\n",
      "[780]\ttraining's rmse: 7.02847\tvalid_1's rmse: 56.0204\n",
      "[810]\ttraining's rmse: 6.6288\tvalid_1's rmse: 55.9961\n",
      "[840]\ttraining's rmse: 6.24848\tvalid_1's rmse: 55.9747\n",
      "[870]\ttraining's rmse: 5.89946\tvalid_1's rmse: 55.9342\n",
      "[900]\ttraining's rmse: 5.57096\tvalid_1's rmse: 55.9148\n",
      "[930]\ttraining's rmse: 5.26568\tvalid_1's rmse: 55.8972\n",
      "[960]\ttraining's rmse: 4.97931\tvalid_1's rmse: 55.8774\n",
      "[990]\ttraining's rmse: 4.71143\tvalid_1's rmse: 55.8682\n",
      "[1020]\ttraining's rmse: 4.4633\tvalid_1's rmse: 55.8578\n",
      "[1050]\ttraining's rmse: 4.22575\tvalid_1's rmse: 55.8512\n",
      "[1080]\ttraining's rmse: 4.00357\tvalid_1's rmse: 55.84\n",
      "[1110]\ttraining's rmse: 3.79539\tvalid_1's rmse: 55.8374\n",
      "[1140]\ttraining's rmse: 3.59855\tvalid_1's rmse: 55.8329\n",
      "[1170]\ttraining's rmse: 3.41309\tvalid_1's rmse: 55.8244\n",
      "[1200]\ttraining's rmse: 3.23816\tvalid_1's rmse: 55.8241\n",
      "[1230]\ttraining's rmse: 3.07591\tvalid_1's rmse: 55.8154\n",
      "[1260]\ttraining's rmse: 2.92157\tvalid_1's rmse: 55.8093\n",
      "[1290]\ttraining's rmse: 2.77712\tvalid_1's rmse: 55.8014\n",
      "[1320]\ttraining's rmse: 2.63894\tvalid_1's rmse: 55.8011\n",
      "[1350]\ttraining's rmse: 2.50562\tvalid_1's rmse: 55.7933\n",
      "[1380]\ttraining's rmse: 2.38311\tvalid_1's rmse: 55.7909\n",
      "[1410]\ttraining's rmse: 2.26591\tvalid_1's rmse: 55.7914\n",
      "[1440]\ttraining's rmse: 2.15187\tvalid_1's rmse: 55.791\n",
      "[1470]\ttraining's rmse: 2.04745\tvalid_1's rmse: 55.7908\n",
      "[1500]\ttraining's rmse: 1.94833\tvalid_1's rmse: 55.786\n",
      "[1530]\ttraining's rmse: 1.8532\tvalid_1's rmse: 55.7834\n",
      "[1560]\ttraining's rmse: 1.76343\tvalid_1's rmse: 55.7823\n",
      "[1590]\ttraining's rmse: 1.67946\tvalid_1's rmse: 55.779\n",
      "[1620]\ttraining's rmse: 1.60314\tvalid_1's rmse: 55.7788\n",
      "[1650]\ttraining's rmse: 1.52685\tvalid_1's rmse: 55.7757\n",
      "[1680]\ttraining's rmse: 1.45425\tvalid_1's rmse: 55.7739\n",
      "[1710]\ttraining's rmse: 1.38597\tvalid_1's rmse: 55.7727\n",
      "[1740]\ttraining's rmse: 1.32127\tvalid_1's rmse: 55.7708\n",
      "[1770]\ttraining's rmse: 1.26154\tvalid_1's rmse: 55.7692\n",
      "[1800]\ttraining's rmse: 1.20317\tvalid_1's rmse: 55.7668\n",
      "[1830]\ttraining's rmse: 1.14844\tvalid_1's rmse: 55.7676\n",
      "[1860]\ttraining's rmse: 1.09377\tvalid_1's rmse: 55.7667\n",
      "[1890]\ttraining's rmse: 1.044\tvalid_1's rmse: 55.7648\n",
      "[1920]\ttraining's rmse: 0.996954\tvalid_1's rmse: 55.7642\n",
      "[1950]\ttraining's rmse: 0.952816\tvalid_1's rmse: 55.7642\n",
      "[1980]\ttraining's rmse: 0.909073\tvalid_1's rmse: 55.7633\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's rmse: 0.882398\tvalid_1's rmse: 55.7629\n",
      "8\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002380 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 20020\n",
      "[LightGBM] [Info] Number of data points in the train set: 9219, number of used features: 79\n",
      "[LightGBM] [Info] Start training from score 379.856393\n",
      "Training until validation scores don't improve for 125 rounds\n",
      "[30]\ttraining's rmse: 171.816\tvalid_1's rmse: 168.604\n",
      "[60]\ttraining's rmse: 104.082\tvalid_1's rmse: 107.697\n",
      "[90]\ttraining's rmse: 67.5156\tvalid_1's rmse: 76.9429\n",
      "[120]\ttraining's rmse: 47.9594\tvalid_1's rmse: 62.1263\n",
      "[150]\ttraining's rmse: 37.473\tvalid_1's rmse: 55.2388\n",
      "[180]\ttraining's rmse: 31.3801\tvalid_1's rmse: 51.7387\n",
      "[210]\ttraining's rmse: 27.2929\tvalid_1's rmse: 49.809\n",
      "[240]\ttraining's rmse: 24.3142\tvalid_1's rmse: 48.7501\n",
      "[270]\ttraining's rmse: 21.8816\tvalid_1's rmse: 48.0342\n",
      "[300]\ttraining's rmse: 19.9492\tvalid_1's rmse: 47.5434\n",
      "[330]\ttraining's rmse: 18.2848\tvalid_1's rmse: 47.2177\n",
      "[360]\ttraining's rmse: 16.8159\tvalid_1's rmse: 46.9396\n",
      "[390]\ttraining's rmse: 15.5592\tvalid_1's rmse: 46.6803\n",
      "[420]\ttraining's rmse: 14.4244\tvalid_1's rmse: 46.4849\n",
      "[450]\ttraining's rmse: 13.4163\tvalid_1's rmse: 46.3131\n",
      "[480]\ttraining's rmse: 12.4768\tvalid_1's rmse: 46.1903\n",
      "[510]\ttraining's rmse: 11.6415\tvalid_1's rmse: 46.09\n",
      "[540]\ttraining's rmse: 10.8677\tvalid_1's rmse: 45.9961\n",
      "[570]\ttraining's rmse: 10.1579\tvalid_1's rmse: 45.9268\n",
      "[600]\ttraining's rmse: 9.53233\tvalid_1's rmse: 45.8767\n",
      "[630]\ttraining's rmse: 8.9317\tvalid_1's rmse: 45.8432\n",
      "[660]\ttraining's rmse: 8.374\tvalid_1's rmse: 45.7976\n",
      "[690]\ttraining's rmse: 7.8545\tvalid_1's rmse: 45.7322\n",
      "[720]\ttraining's rmse: 7.38698\tvalid_1's rmse: 45.6864\n",
      "[750]\ttraining's rmse: 6.95447\tvalid_1's rmse: 45.6453\n",
      "[780]\ttraining's rmse: 6.54493\tvalid_1's rmse: 45.6214\n",
      "[810]\ttraining's rmse: 6.16911\tvalid_1's rmse: 45.6015\n",
      "[840]\ttraining's rmse: 5.82052\tvalid_1's rmse: 45.5699\n",
      "[870]\ttraining's rmse: 5.49603\tvalid_1's rmse: 45.5416\n",
      "[900]\ttraining's rmse: 5.18788\tvalid_1's rmse: 45.5201\n",
      "[930]\ttraining's rmse: 4.89644\tvalid_1's rmse: 45.4999\n",
      "[960]\ttraining's rmse: 4.62841\tvalid_1's rmse: 45.4882\n",
      "[990]\ttraining's rmse: 4.37879\tvalid_1's rmse: 45.4705\n",
      "[1020]\ttraining's rmse: 4.14087\tvalid_1's rmse: 45.4534\n",
      "[1050]\ttraining's rmse: 3.92048\tvalid_1's rmse: 45.442\n",
      "[1080]\ttraining's rmse: 3.71182\tvalid_1's rmse: 45.4343\n",
      "[1110]\ttraining's rmse: 3.51387\tvalid_1's rmse: 45.4297\n",
      "[1140]\ttraining's rmse: 3.33275\tvalid_1's rmse: 45.4196\n",
      "[1170]\ttraining's rmse: 3.15883\tvalid_1's rmse: 45.4161\n",
      "[1200]\ttraining's rmse: 2.99301\tvalid_1's rmse: 45.4106\n",
      "[1230]\ttraining's rmse: 2.83674\tvalid_1's rmse: 45.403\n",
      "[1260]\ttraining's rmse: 2.692\tvalid_1's rmse: 45.3987\n",
      "[1290]\ttraining's rmse: 2.5543\tvalid_1's rmse: 45.3936\n",
      "[1320]\ttraining's rmse: 2.42344\tvalid_1's rmse: 45.3854\n",
      "[1350]\ttraining's rmse: 2.29999\tvalid_1's rmse: 45.3761\n",
      "[1380]\ttraining's rmse: 2.18437\tvalid_1's rmse: 45.372\n",
      "[1410]\ttraining's rmse: 2.07239\tvalid_1's rmse: 45.3691\n",
      "[1440]\ttraining's rmse: 1.9677\tvalid_1's rmse: 45.3674\n",
      "[1470]\ttraining's rmse: 1.86877\tvalid_1's rmse: 45.3693\n",
      "[1500]\ttraining's rmse: 1.77687\tvalid_1's rmse: 45.3658\n",
      "[1530]\ttraining's rmse: 1.68759\tvalid_1's rmse: 45.3617\n",
      "[1560]\ttraining's rmse: 1.60369\tvalid_1's rmse: 45.3581\n",
      "[1590]\ttraining's rmse: 1.52556\tvalid_1's rmse: 45.3544\n",
      "[1620]\ttraining's rmse: 1.45258\tvalid_1's rmse: 45.3507\n",
      "[1650]\ttraining's rmse: 1.38276\tvalid_1's rmse: 45.3486\n",
      "[1680]\ttraining's rmse: 1.31618\tvalid_1's rmse: 45.346\n",
      "[1710]\ttraining's rmse: 1.25345\tvalid_1's rmse: 45.3465\n",
      "[1740]\ttraining's rmse: 1.19246\tvalid_1's rmse: 45.3441\n",
      "[1770]\ttraining's rmse: 1.13585\tvalid_1's rmse: 45.3435\n",
      "[1800]\ttraining's rmse: 1.08119\tvalid_1's rmse: 45.3428\n",
      "[1830]\ttraining's rmse: 1.02874\tvalid_1's rmse: 45.3416\n",
      "[1860]\ttraining's rmse: 0.979591\tvalid_1's rmse: 45.3385\n",
      "[1890]\ttraining's rmse: 0.933255\tvalid_1's rmse: 45.3374\n",
      "[1920]\ttraining's rmse: 0.889732\tvalid_1's rmse: 45.336\n",
      "[1950]\ttraining's rmse: 0.846614\tvalid_1's rmse: 45.3333\n",
      "[1980]\ttraining's rmse: 0.808355\tvalid_1's rmse: 45.3315\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's rmse: 0.782798\tvalid_1's rmse: 45.3303\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003651 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 20020\n",
      "[LightGBM] [Info] Number of data points in the train set: 9219, number of used features: 79\n",
      "[LightGBM] [Info] Start training from score 387.720243\n",
      "Training until validation scores don't improve for 125 rounds\n",
      "[30]\ttraining's rmse: 176.912\tvalid_1's rmse: 174.895\n",
      "[60]\ttraining's rmse: 108.948\tvalid_1's rmse: 115.396\n",
      "[90]\ttraining's rmse: 72.1705\tvalid_1's rmse: 85.375\n",
      "[120]\ttraining's rmse: 52.2474\tvalid_1's rmse: 70.9734\n",
      "[150]\ttraining's rmse: 41.3046\tvalid_1's rmse: 64.0464\n",
      "[180]\ttraining's rmse: 34.6773\tvalid_1's rmse: 60.4922\n",
      "[210]\ttraining's rmse: 30.2313\tvalid_1's rmse: 58.5837\n",
      "[240]\ttraining's rmse: 26.8752\tvalid_1's rmse: 57.3889\n",
      "[270]\ttraining's rmse: 24.222\tvalid_1's rmse: 56.4925\n",
      "[300]\ttraining's rmse: 21.9916\tvalid_1's rmse: 56.0558\n",
      "[330]\ttraining's rmse: 20.1047\tvalid_1's rmse: 55.616\n",
      "[360]\ttraining's rmse: 18.4754\tvalid_1's rmse: 55.3508\n",
      "[390]\ttraining's rmse: 17.0379\tvalid_1's rmse: 55.0852\n",
      "[420]\ttraining's rmse: 15.7777\tvalid_1's rmse: 54.8748\n",
      "[450]\ttraining's rmse: 14.6585\tvalid_1's rmse: 54.6667\n",
      "[480]\ttraining's rmse: 13.6206\tvalid_1's rmse: 54.5527\n",
      "[510]\ttraining's rmse: 12.6821\tvalid_1's rmse: 54.4076\n",
      "[540]\ttraining's rmse: 11.835\tvalid_1's rmse: 54.3144\n",
      "[570]\ttraining's rmse: 11.0583\tvalid_1's rmse: 54.2115\n",
      "[600]\ttraining's rmse: 10.3397\tvalid_1's rmse: 54.1371\n",
      "[630]\ttraining's rmse: 9.69922\tvalid_1's rmse: 54.0415\n",
      "[660]\ttraining's rmse: 9.09176\tvalid_1's rmse: 53.993\n",
      "[690]\ttraining's rmse: 8.52887\tvalid_1's rmse: 53.9365\n",
      "[720]\ttraining's rmse: 8.02241\tvalid_1's rmse: 53.8798\n",
      "[750]\ttraining's rmse: 7.56036\tvalid_1's rmse: 53.8226\n",
      "[780]\ttraining's rmse: 7.1184\tvalid_1's rmse: 53.792\n",
      "[810]\ttraining's rmse: 6.70476\tvalid_1's rmse: 53.754\n",
      "[840]\ttraining's rmse: 6.31759\tvalid_1's rmse: 53.7029\n",
      "[870]\ttraining's rmse: 5.97214\tvalid_1's rmse: 53.6952\n",
      "[900]\ttraining's rmse: 5.64488\tvalid_1's rmse: 53.6609\n",
      "[930]\ttraining's rmse: 5.33724\tvalid_1's rmse: 53.6452\n",
      "[960]\ttraining's rmse: 5.04536\tvalid_1's rmse: 53.6234\n",
      "[990]\ttraining's rmse: 4.76918\tvalid_1's rmse: 53.6082\n",
      "[1020]\ttraining's rmse: 4.51766\tvalid_1's rmse: 53.5966\n",
      "[1050]\ttraining's rmse: 4.2775\tvalid_1's rmse: 53.5815\n",
      "[1080]\ttraining's rmse: 4.05487\tvalid_1's rmse: 53.5693\n",
      "[1110]\ttraining's rmse: 3.84415\tvalid_1's rmse: 53.5625\n",
      "[1140]\ttraining's rmse: 3.64332\tvalid_1's rmse: 53.5537\n",
      "[1170]\ttraining's rmse: 3.45292\tvalid_1's rmse: 53.5391\n",
      "[1200]\ttraining's rmse: 3.27685\tvalid_1's rmse: 53.5322\n",
      "[1230]\ttraining's rmse: 3.11275\tvalid_1's rmse: 53.5299\n",
      "[1260]\ttraining's rmse: 2.9566\tvalid_1's rmse: 53.525\n",
      "[1290]\ttraining's rmse: 2.80818\tvalid_1's rmse: 53.5142\n",
      "[1320]\ttraining's rmse: 2.66861\tvalid_1's rmse: 53.51\n",
      "[1350]\ttraining's rmse: 2.53461\tvalid_1's rmse: 53.5059\n",
      "[1380]\ttraining's rmse: 2.41366\tvalid_1's rmse: 53.5002\n",
      "[1410]\ttraining's rmse: 2.29359\tvalid_1's rmse: 53.4966\n",
      "[1440]\ttraining's rmse: 2.18328\tvalid_1's rmse: 53.4927\n",
      "[1470]\ttraining's rmse: 2.081\tvalid_1's rmse: 53.4893\n",
      "[1500]\ttraining's rmse: 1.98307\tvalid_1's rmse: 53.4836\n",
      "[1530]\ttraining's rmse: 1.88738\tvalid_1's rmse: 53.4764\n",
      "[1560]\ttraining's rmse: 1.79977\tvalid_1's rmse: 53.4735\n",
      "[1590]\ttraining's rmse: 1.71561\tvalid_1's rmse: 53.4729\n",
      "[1620]\ttraining's rmse: 1.63637\tvalid_1's rmse: 53.4734\n",
      "[1650]\ttraining's rmse: 1.56085\tvalid_1's rmse: 53.4712\n",
      "[1680]\ttraining's rmse: 1.48988\tvalid_1's rmse: 53.4674\n",
      "[1710]\ttraining's rmse: 1.42236\tvalid_1's rmse: 53.4646\n",
      "[1740]\ttraining's rmse: 1.35648\tvalid_1's rmse: 53.4604\n",
      "[1770]\ttraining's rmse: 1.29565\tvalid_1's rmse: 53.4593\n",
      "[1800]\ttraining's rmse: 1.23802\tvalid_1's rmse: 53.4597\n",
      "[1830]\ttraining's rmse: 1.18235\tvalid_1's rmse: 53.4563\n",
      "[1860]\ttraining's rmse: 1.12801\tvalid_1's rmse: 53.4557\n",
      "[1890]\ttraining's rmse: 1.07606\tvalid_1's rmse: 53.4552\n",
      "[1920]\ttraining's rmse: 1.02938\tvalid_1's rmse: 53.4528\n",
      "[1950]\ttraining's rmse: 0.982346\tvalid_1's rmse: 53.4534\n",
      "[1980]\ttraining's rmse: 0.937175\tvalid_1's rmse: 53.4539\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's rmse: 0.909335\tvalid_1's rmse: 53.4534\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002542 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 20020\n",
      "[LightGBM] [Info] Number of data points in the train set: 9219, number of used features: 79\n",
      "[LightGBM] [Info] Start training from score 389.883047\n",
      "Training until validation scores don't improve for 125 rounds\n",
      "[30]\ttraining's rmse: 175.756\tvalid_1's rmse: 182.755\n",
      "[60]\ttraining's rmse: 107.594\tvalid_1's rmse: 120.368\n",
      "[90]\ttraining's rmse: 70.6839\tvalid_1's rmse: 88.6474\n",
      "[120]\ttraining's rmse: 50.7842\tvalid_1's rmse: 73.3287\n",
      "[150]\ttraining's rmse: 39.8334\tvalid_1's rmse: 65.8494\n",
      "[180]\ttraining's rmse: 33.3716\tvalid_1's rmse: 62.051\n",
      "[210]\ttraining's rmse: 29.0503\tvalid_1's rmse: 59.8361\n",
      "[240]\ttraining's rmse: 25.9125\tvalid_1's rmse: 58.5927\n",
      "[270]\ttraining's rmse: 23.3291\tvalid_1's rmse: 57.6932\n",
      "[300]\ttraining's rmse: 21.2412\tvalid_1's rmse: 57.1388\n",
      "[330]\ttraining's rmse: 19.4743\tvalid_1's rmse: 56.6924\n",
      "[360]\ttraining's rmse: 17.9483\tvalid_1's rmse: 56.3662\n",
      "[390]\ttraining's rmse: 16.5933\tvalid_1's rmse: 56.0817\n",
      "[420]\ttraining's rmse: 15.3817\tvalid_1's rmse: 55.8826\n",
      "[450]\ttraining's rmse: 14.2877\tvalid_1's rmse: 55.7338\n",
      "[480]\ttraining's rmse: 13.3081\tvalid_1's rmse: 55.6031\n",
      "[510]\ttraining's rmse: 12.4284\tvalid_1's rmse: 55.4631\n",
      "[540]\ttraining's rmse: 11.6007\tvalid_1's rmse: 55.3463\n",
      "[570]\ttraining's rmse: 10.8626\tvalid_1's rmse: 55.2209\n",
      "[600]\ttraining's rmse: 10.1691\tvalid_1's rmse: 55.1104\n",
      "[630]\ttraining's rmse: 9.53845\tvalid_1's rmse: 55.0156\n",
      "[660]\ttraining's rmse: 8.95138\tvalid_1's rmse: 54.9708\n",
      "[690]\ttraining's rmse: 8.42079\tvalid_1's rmse: 54.932\n",
      "[720]\ttraining's rmse: 7.91735\tvalid_1's rmse: 54.8871\n",
      "[750]\ttraining's rmse: 7.45773\tvalid_1's rmse: 54.849\n",
      "[780]\ttraining's rmse: 7.03368\tvalid_1's rmse: 54.817\n",
      "[810]\ttraining's rmse: 6.63457\tvalid_1's rmse: 54.782\n",
      "[840]\ttraining's rmse: 6.27047\tvalid_1's rmse: 54.7521\n",
      "[870]\ttraining's rmse: 5.93809\tvalid_1's rmse: 54.7215\n",
      "[900]\ttraining's rmse: 5.61473\tvalid_1's rmse: 54.677\n",
      "[930]\ttraining's rmse: 5.32512\tvalid_1's rmse: 54.656\n",
      "[960]\ttraining's rmse: 5.04699\tvalid_1's rmse: 54.6254\n",
      "[990]\ttraining's rmse: 4.77951\tvalid_1's rmse: 54.6047\n",
      "[1020]\ttraining's rmse: 4.53014\tvalid_1's rmse: 54.5905\n",
      "[1050]\ttraining's rmse: 4.2962\tvalid_1's rmse: 54.5776\n",
      "[1080]\ttraining's rmse: 4.08189\tvalid_1's rmse: 54.5566\n",
      "[1110]\ttraining's rmse: 3.87569\tvalid_1's rmse: 54.5435\n",
      "[1140]\ttraining's rmse: 3.68407\tvalid_1's rmse: 54.5296\n",
      "[1170]\ttraining's rmse: 3.50066\tvalid_1's rmse: 54.5235\n",
      "[1200]\ttraining's rmse: 3.32617\tvalid_1's rmse: 54.5099\n",
      "[1230]\ttraining's rmse: 3.16082\tvalid_1's rmse: 54.5018\n",
      "[1260]\ttraining's rmse: 3.0112\tvalid_1's rmse: 54.4888\n",
      "[1290]\ttraining's rmse: 2.86645\tvalid_1's rmse: 54.4847\n",
      "[1320]\ttraining's rmse: 2.72781\tvalid_1's rmse: 54.4782\n",
      "[1350]\ttraining's rmse: 2.59851\tvalid_1's rmse: 54.4726\n",
      "[1380]\ttraining's rmse: 2.47961\tvalid_1's rmse: 54.4651\n",
      "[1410]\ttraining's rmse: 2.36358\tvalid_1's rmse: 54.4543\n",
      "[1440]\ttraining's rmse: 2.25398\tvalid_1's rmse: 54.4516\n",
      "[1470]\ttraining's rmse: 2.15047\tvalid_1's rmse: 54.4486\n",
      "[1500]\ttraining's rmse: 2.04994\tvalid_1's rmse: 54.4453\n",
      "[1530]\ttraining's rmse: 1.95558\tvalid_1's rmse: 54.4398\n",
      "[1560]\ttraining's rmse: 1.868\tvalid_1's rmse: 54.4362\n",
      "[1590]\ttraining's rmse: 1.78608\tvalid_1's rmse: 54.4329\n",
      "[1620]\ttraining's rmse: 1.70745\tvalid_1's rmse: 54.431\n",
      "[1650]\ttraining's rmse: 1.63227\tvalid_1's rmse: 54.4298\n",
      "[1680]\ttraining's rmse: 1.55915\tvalid_1's rmse: 54.4259\n",
      "[1710]\ttraining's rmse: 1.49275\tvalid_1's rmse: 54.4252\n",
      "[1740]\ttraining's rmse: 1.42792\tvalid_1's rmse: 54.422\n",
      "[1770]\ttraining's rmse: 1.36591\tvalid_1's rmse: 54.4203\n",
      "[1800]\ttraining's rmse: 1.30767\tvalid_1's rmse: 54.4183\n",
      "[1830]\ttraining's rmse: 1.25274\tvalid_1's rmse: 54.4154\n",
      "[1860]\ttraining's rmse: 1.1987\tvalid_1's rmse: 54.4171\n",
      "[1890]\ttraining's rmse: 1.14869\tvalid_1's rmse: 54.4156\n",
      "[1920]\ttraining's rmse: 1.10026\tvalid_1's rmse: 54.4152\n",
      "[1950]\ttraining's rmse: 1.05546\tvalid_1's rmse: 54.4134\n",
      "[1980]\ttraining's rmse: 1.01173\tvalid_1's rmse: 54.4121\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's rmse: 0.983905\tvalid_1's rmse: 54.4122\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002708 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 20020\n",
      "[LightGBM] [Info] Number of data points in the train set: 9219, number of used features: 79\n",
      "[LightGBM] [Info] Start training from score 387.612263\n",
      "Training until validation scores don't improve for 125 rounds\n",
      "[30]\ttraining's rmse: 175.692\tvalid_1's rmse: 183.899\n",
      "[60]\ttraining's rmse: 108.423\tvalid_1's rmse: 119.832\n",
      "[90]\ttraining's rmse: 71.8789\tvalid_1's rmse: 88.2806\n",
      "[120]\ttraining's rmse: 52.0788\tvalid_1's rmse: 73.6648\n",
      "[150]\ttraining's rmse: 41.1065\tvalid_1's rmse: 66.9805\n",
      "[180]\ttraining's rmse: 34.4778\tvalid_1's rmse: 63.453\n",
      "[210]\ttraining's rmse: 29.9793\tvalid_1's rmse: 61.4941\n",
      "[240]\ttraining's rmse: 26.6334\tvalid_1's rmse: 60.1375\n",
      "[270]\ttraining's rmse: 23.9458\tvalid_1's rmse: 59.1369\n",
      "[300]\ttraining's rmse: 21.7848\tvalid_1's rmse: 58.684\n",
      "[330]\ttraining's rmse: 19.9852\tvalid_1's rmse: 58.3229\n",
      "[360]\ttraining's rmse: 18.4036\tvalid_1's rmse: 58.0282\n",
      "[390]\ttraining's rmse: 16.9761\tvalid_1's rmse: 57.8686\n",
      "[420]\ttraining's rmse: 15.7427\tvalid_1's rmse: 57.6962\n",
      "[450]\ttraining's rmse: 14.6208\tvalid_1's rmse: 57.5725\n",
      "[480]\ttraining's rmse: 13.6042\tvalid_1's rmse: 57.4338\n",
      "[510]\ttraining's rmse: 12.6909\tvalid_1's rmse: 57.3553\n",
      "[540]\ttraining's rmse: 11.853\tvalid_1's rmse: 57.2465\n",
      "[570]\ttraining's rmse: 11.0875\tvalid_1's rmse: 57.1654\n",
      "[600]\ttraining's rmse: 10.3897\tvalid_1's rmse: 57.0935\n",
      "[630]\ttraining's rmse: 9.7459\tvalid_1's rmse: 57.015\n",
      "[660]\ttraining's rmse: 9.14019\tvalid_1's rmse: 56.9679\n",
      "[690]\ttraining's rmse: 8.58629\tvalid_1's rmse: 56.9168\n",
      "[720]\ttraining's rmse: 8.0715\tvalid_1's rmse: 56.9071\n",
      "[750]\ttraining's rmse: 7.60097\tvalid_1's rmse: 56.8936\n",
      "[780]\ttraining's rmse: 7.16166\tvalid_1's rmse: 56.8556\n",
      "[810]\ttraining's rmse: 6.76062\tvalid_1's rmse: 56.8288\n",
      "[840]\ttraining's rmse: 6.37382\tvalid_1's rmse: 56.8127\n",
      "[870]\ttraining's rmse: 6.02425\tvalid_1's rmse: 56.7951\n",
      "[900]\ttraining's rmse: 5.69394\tvalid_1's rmse: 56.784\n",
      "[930]\ttraining's rmse: 5.38224\tvalid_1's rmse: 56.7568\n",
      "[960]\ttraining's rmse: 5.09054\tvalid_1's rmse: 56.7463\n",
      "[990]\ttraining's rmse: 4.8207\tvalid_1's rmse: 56.7229\n",
      "[1020]\ttraining's rmse: 4.56201\tvalid_1's rmse: 56.7158\n",
      "[1050]\ttraining's rmse: 4.31941\tvalid_1's rmse: 56.708\n",
      "[1080]\ttraining's rmse: 4.09057\tvalid_1's rmse: 56.7004\n",
      "[1110]\ttraining's rmse: 3.87525\tvalid_1's rmse: 56.6835\n",
      "[1140]\ttraining's rmse: 3.67282\tvalid_1's rmse: 56.6784\n",
      "[1170]\ttraining's rmse: 3.47856\tvalid_1's rmse: 56.6702\n",
      "[1200]\ttraining's rmse: 3.2986\tvalid_1's rmse: 56.663\n",
      "[1230]\ttraining's rmse: 3.12548\tvalid_1's rmse: 56.6575\n",
      "[1260]\ttraining's rmse: 2.96734\tvalid_1's rmse: 56.6482\n",
      "[1290]\ttraining's rmse: 2.81693\tvalid_1's rmse: 56.641\n",
      "[1320]\ttraining's rmse: 2.67772\tvalid_1's rmse: 56.6446\n",
      "[1350]\ttraining's rmse: 2.54568\tvalid_1's rmse: 56.645\n",
      "[1380]\ttraining's rmse: 2.41972\tvalid_1's rmse: 56.64\n",
      "[1410]\ttraining's rmse: 2.30328\tvalid_1's rmse: 56.6386\n",
      "[1440]\ttraining's rmse: 2.18826\tvalid_1's rmse: 56.6364\n",
      "[1470]\ttraining's rmse: 2.08237\tvalid_1's rmse: 56.6351\n",
      "[1500]\ttraining's rmse: 1.98313\tvalid_1's rmse: 56.6319\n",
      "[1530]\ttraining's rmse: 1.88475\tvalid_1's rmse: 56.6321\n",
      "[1560]\ttraining's rmse: 1.79395\tvalid_1's rmse: 56.6266\n",
      "[1590]\ttraining's rmse: 1.70815\tvalid_1's rmse: 56.6222\n",
      "[1620]\ttraining's rmse: 1.62593\tvalid_1's rmse: 56.6208\n",
      "[1650]\ttraining's rmse: 1.54992\tvalid_1's rmse: 56.6188\n",
      "[1680]\ttraining's rmse: 1.47496\tvalid_1's rmse: 56.6174\n",
      "[1710]\ttraining's rmse: 1.40543\tvalid_1's rmse: 56.6158\n",
      "[1740]\ttraining's rmse: 1.33931\tvalid_1's rmse: 56.6141\n",
      "[1770]\ttraining's rmse: 1.27715\tvalid_1's rmse: 56.6129\n",
      "[1800]\ttraining's rmse: 1.21576\tvalid_1's rmse: 56.6117\n",
      "[1830]\ttraining's rmse: 1.16055\tvalid_1's rmse: 56.6098\n",
      "[1860]\ttraining's rmse: 1.10625\tvalid_1's rmse: 56.6098\n",
      "[1890]\ttraining's rmse: 1.05512\tvalid_1's rmse: 56.6079\n",
      "[1920]\ttraining's rmse: 1.00603\tvalid_1's rmse: 56.6057\n",
      "[1950]\ttraining's rmse: 0.958046\tvalid_1's rmse: 56.6049\n",
      "[1980]\ttraining's rmse: 0.913613\tvalid_1's rmse: 56.6051\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's rmse: 0.885073\tvalid_1's rmse: 56.6044\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003672 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 20020\n",
      "[LightGBM] [Info] Number of data points in the train set: 9219, number of used features: 79\n",
      "[LightGBM] [Info] Start training from score 382.928992\n",
      "Training until validation scores don't improve for 125 rounds\n",
      "[30]\ttraining's rmse: 175.828\tvalid_1's rmse: 187.512\n",
      "[60]\ttraining's rmse: 108.453\tvalid_1's rmse: 125.313\n",
      "[90]\ttraining's rmse: 71.5295\tvalid_1's rmse: 94.4948\n",
      "[120]\ttraining's rmse: 51.8226\tvalid_1's rmse: 80.168\n",
      "[150]\ttraining's rmse: 40.9513\tvalid_1's rmse: 73.0919\n",
      "[180]\ttraining's rmse: 34.3855\tvalid_1's rmse: 69.2723\n",
      "[210]\ttraining's rmse: 30.0669\tvalid_1's rmse: 67.0454\n",
      "[240]\ttraining's rmse: 26.7665\tvalid_1's rmse: 65.6076\n",
      "[270]\ttraining's rmse: 24.132\tvalid_1's rmse: 64.5218\n",
      "[300]\ttraining's rmse: 22.03\tvalid_1's rmse: 64.008\n",
      "[330]\ttraining's rmse: 20.1736\tvalid_1's rmse: 63.5937\n",
      "[360]\ttraining's rmse: 18.5929\tvalid_1's rmse: 63.2904\n",
      "[390]\ttraining's rmse: 17.1678\tvalid_1's rmse: 63.0352\n",
      "[420]\ttraining's rmse: 15.9216\tvalid_1's rmse: 62.8886\n",
      "[450]\ttraining's rmse: 14.809\tvalid_1's rmse: 62.7242\n",
      "[480]\ttraining's rmse: 13.7807\tvalid_1's rmse: 62.574\n",
      "[510]\ttraining's rmse: 12.8585\tvalid_1's rmse: 62.4471\n",
      "[540]\ttraining's rmse: 12.016\tvalid_1's rmse: 62.3582\n",
      "[570]\ttraining's rmse: 11.249\tvalid_1's rmse: 62.2811\n",
      "[600]\ttraining's rmse: 10.5381\tvalid_1's rmse: 62.2259\n",
      "[630]\ttraining's rmse: 9.90281\tvalid_1's rmse: 62.1622\n",
      "[660]\ttraining's rmse: 9.31046\tvalid_1's rmse: 62.121\n",
      "[690]\ttraining's rmse: 8.76571\tvalid_1's rmse: 62.086\n",
      "[720]\ttraining's rmse: 8.24706\tvalid_1's rmse: 62.03\n",
      "[750]\ttraining's rmse: 7.77939\tvalid_1's rmse: 61.9875\n",
      "[780]\ttraining's rmse: 7.33909\tvalid_1's rmse: 61.9681\n",
      "[810]\ttraining's rmse: 6.93487\tvalid_1's rmse: 61.9471\n",
      "[840]\ttraining's rmse: 6.55262\tvalid_1's rmse: 61.9246\n",
      "[870]\ttraining's rmse: 6.18868\tvalid_1's rmse: 61.9131\n",
      "[900]\ttraining's rmse: 5.86067\tvalid_1's rmse: 61.889\n",
      "[930]\ttraining's rmse: 5.54911\tvalid_1's rmse: 61.886\n",
      "[960]\ttraining's rmse: 5.24954\tvalid_1's rmse: 61.8688\n",
      "[990]\ttraining's rmse: 4.96868\tvalid_1's rmse: 61.8637\n",
      "[1020]\ttraining's rmse: 4.70602\tvalid_1's rmse: 61.8629\n",
      "[1050]\ttraining's rmse: 4.46626\tvalid_1's rmse: 61.8524\n",
      "[1080]\ttraining's rmse: 4.23612\tvalid_1's rmse: 61.8392\n",
      "[1110]\ttraining's rmse: 4.02084\tvalid_1's rmse: 61.8185\n",
      "[1140]\ttraining's rmse: 3.81792\tvalid_1's rmse: 61.8108\n",
      "[1170]\ttraining's rmse: 3.63495\tvalid_1's rmse: 61.8033\n",
      "[1200]\ttraining's rmse: 3.45761\tvalid_1's rmse: 61.7912\n",
      "[1230]\ttraining's rmse: 3.27939\tvalid_1's rmse: 61.7847\n",
      "[1260]\ttraining's rmse: 3.11646\tvalid_1's rmse: 61.7887\n",
      "[1290]\ttraining's rmse: 2.96536\tvalid_1's rmse: 61.7932\n",
      "[1320]\ttraining's rmse: 2.82357\tvalid_1's rmse: 61.7885\n",
      "[1350]\ttraining's rmse: 2.68655\tvalid_1's rmse: 61.7839\n",
      "[1380]\ttraining's rmse: 2.56031\tvalid_1's rmse: 61.7864\n",
      "[1410]\ttraining's rmse: 2.43642\tvalid_1's rmse: 61.7812\n",
      "[1440]\ttraining's rmse: 2.3193\tvalid_1's rmse: 61.7755\n",
      "[1470]\ttraining's rmse: 2.21081\tvalid_1's rmse: 61.7706\n",
      "[1500]\ttraining's rmse: 2.10749\tvalid_1's rmse: 61.7651\n",
      "[1530]\ttraining's rmse: 2.01161\tvalid_1's rmse: 61.7615\n",
      "[1560]\ttraining's rmse: 1.91667\tvalid_1's rmse: 61.7589\n",
      "[1590]\ttraining's rmse: 1.82842\tvalid_1's rmse: 61.7551\n",
      "[1620]\ttraining's rmse: 1.74586\tvalid_1's rmse: 61.7552\n",
      "[1650]\ttraining's rmse: 1.66775\tvalid_1's rmse: 61.7531\n",
      "[1680]\ttraining's rmse: 1.59277\tvalid_1's rmse: 61.7494\n",
      "[1710]\ttraining's rmse: 1.51971\tvalid_1's rmse: 61.7474\n",
      "[1740]\ttraining's rmse: 1.45385\tvalid_1's rmse: 61.7453\n",
      "[1770]\ttraining's rmse: 1.38787\tvalid_1's rmse: 61.7425\n",
      "[1800]\ttraining's rmse: 1.32828\tvalid_1's rmse: 61.7406\n",
      "[1830]\ttraining's rmse: 1.26996\tvalid_1's rmse: 61.7417\n",
      "[1860]\ttraining's rmse: 1.21519\tvalid_1's rmse: 61.7406\n",
      "[1890]\ttraining's rmse: 1.16229\tvalid_1's rmse: 61.7411\n",
      "[1920]\ttraining's rmse: 1.11384\tvalid_1's rmse: 61.7394\n",
      "[1950]\ttraining's rmse: 1.06619\tvalid_1's rmse: 61.74\n",
      "[1980]\ttraining's rmse: 1.02115\tvalid_1's rmse: 61.7388\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's rmse: 0.992645\tvalid_1's rmse: 61.7393\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003298 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 20020\n",
      "[LightGBM] [Info] Number of data points in the train set: 9219, number of used features: 79\n",
      "[LightGBM] [Info] Start training from score 378.645307\n",
      "Training until validation scores don't improve for 125 rounds\n",
      "[30]\ttraining's rmse: 174.674\tvalid_1's rmse: 188.11\n",
      "[60]\ttraining's rmse: 107.044\tvalid_1's rmse: 126.046\n",
      "[90]\ttraining's rmse: 70.3946\tvalid_1's rmse: 95.2947\n",
      "[120]\ttraining's rmse: 50.6235\tvalid_1's rmse: 80.8275\n",
      "[150]\ttraining's rmse: 39.864\tvalid_1's rmse: 73.9366\n",
      "[180]\ttraining's rmse: 33.4237\tvalid_1's rmse: 70.0537\n",
      "[210]\ttraining's rmse: 29.1206\tvalid_1's rmse: 67.9113\n",
      "[240]\ttraining's rmse: 25.971\tvalid_1's rmse: 66.4135\n",
      "[270]\ttraining's rmse: 23.4393\tvalid_1's rmse: 65.2413\n",
      "[300]\ttraining's rmse: 21.3605\tvalid_1's rmse: 64.4194\n",
      "[330]\ttraining's rmse: 19.5772\tvalid_1's rmse: 63.7582\n",
      "[360]\ttraining's rmse: 18.0397\tvalid_1's rmse: 63.4156\n",
      "[390]\ttraining's rmse: 16.6662\tvalid_1's rmse: 63.0655\n",
      "[420]\ttraining's rmse: 15.447\tvalid_1's rmse: 62.8715\n",
      "[450]\ttraining's rmse: 14.3544\tvalid_1's rmse: 62.7077\n",
      "[480]\ttraining's rmse: 13.3806\tvalid_1's rmse: 62.6139\n",
      "[510]\ttraining's rmse: 12.4915\tvalid_1's rmse: 62.4912\n",
      "[540]\ttraining's rmse: 11.6985\tvalid_1's rmse: 62.3774\n",
      "[570]\ttraining's rmse: 10.9672\tvalid_1's rmse: 62.2437\n",
      "[600]\ttraining's rmse: 10.2872\tvalid_1's rmse: 62.1909\n",
      "[630]\ttraining's rmse: 9.66221\tvalid_1's rmse: 62.0725\n",
      "[660]\ttraining's rmse: 9.07809\tvalid_1's rmse: 62.0153\n",
      "[690]\ttraining's rmse: 8.53303\tvalid_1's rmse: 61.9417\n",
      "[720]\ttraining's rmse: 8.03541\tvalid_1's rmse: 61.8645\n",
      "[750]\ttraining's rmse: 7.57732\tvalid_1's rmse: 61.834\n",
      "[780]\ttraining's rmse: 7.14504\tvalid_1's rmse: 61.7999\n",
      "[810]\ttraining's rmse: 6.74519\tvalid_1's rmse: 61.7493\n",
      "[840]\ttraining's rmse: 6.36461\tvalid_1's rmse: 61.7028\n",
      "[870]\ttraining's rmse: 6.01584\tvalid_1's rmse: 61.6883\n",
      "[900]\ttraining's rmse: 5.68397\tvalid_1's rmse: 61.6528\n",
      "[930]\ttraining's rmse: 5.3789\tvalid_1's rmse: 61.616\n",
      "[960]\ttraining's rmse: 5.0861\tvalid_1's rmse: 61.5955\n",
      "[990]\ttraining's rmse: 4.81718\tvalid_1's rmse: 61.562\n",
      "[1020]\ttraining's rmse: 4.56662\tvalid_1's rmse: 61.5266\n",
      "[1050]\ttraining's rmse: 4.32953\tvalid_1's rmse: 61.4997\n",
      "[1080]\ttraining's rmse: 4.10758\tvalid_1's rmse: 61.4897\n",
      "[1110]\ttraining's rmse: 3.89839\tvalid_1's rmse: 61.4646\n",
      "[1140]\ttraining's rmse: 3.70338\tvalid_1's rmse: 61.4708\n",
      "[1170]\ttraining's rmse: 3.51603\tvalid_1's rmse: 61.4568\n",
      "[1200]\ttraining's rmse: 3.34083\tvalid_1's rmse: 61.4329\n",
      "[1230]\ttraining's rmse: 3.1797\tvalid_1's rmse: 61.4179\n",
      "[1260]\ttraining's rmse: 3.02064\tvalid_1's rmse: 61.406\n",
      "[1290]\ttraining's rmse: 2.87252\tvalid_1's rmse: 61.3871\n",
      "[1320]\ttraining's rmse: 2.73243\tvalid_1's rmse: 61.3802\n",
      "[1350]\ttraining's rmse: 2.59808\tvalid_1's rmse: 61.3652\n",
      "[1380]\ttraining's rmse: 2.47428\tvalid_1's rmse: 61.3622\n",
      "[1410]\ttraining's rmse: 2.35588\tvalid_1's rmse: 61.3598\n",
      "[1440]\ttraining's rmse: 2.24656\tvalid_1's rmse: 61.3536\n",
      "[1470]\ttraining's rmse: 2.14124\tvalid_1's rmse: 61.3431\n",
      "[1500]\ttraining's rmse: 2.04155\tvalid_1's rmse: 61.337\n",
      "[1530]\ttraining's rmse: 1.94695\tvalid_1's rmse: 61.3237\n",
      "[1560]\ttraining's rmse: 1.85675\tvalid_1's rmse: 61.3185\n",
      "[1590]\ttraining's rmse: 1.76957\tvalid_1's rmse: 61.3116\n",
      "[1620]\ttraining's rmse: 1.68889\tvalid_1's rmse: 61.3103\n",
      "[1650]\ttraining's rmse: 1.6134\tvalid_1's rmse: 61.3067\n",
      "[1680]\ttraining's rmse: 1.54134\tvalid_1's rmse: 61.2994\n",
      "[1710]\ttraining's rmse: 1.47299\tvalid_1's rmse: 61.2966\n",
      "[1740]\ttraining's rmse: 1.40872\tvalid_1's rmse: 61.2934\n",
      "[1770]\ttraining's rmse: 1.34616\tvalid_1's rmse: 61.2912\n",
      "[1800]\ttraining's rmse: 1.28479\tvalid_1's rmse: 61.2866\n",
      "[1830]\ttraining's rmse: 1.22793\tvalid_1's rmse: 61.2814\n",
      "[1860]\ttraining's rmse: 1.1735\tvalid_1's rmse: 61.2799\n",
      "[1890]\ttraining's rmse: 1.1216\tvalid_1's rmse: 61.2741\n",
      "[1920]\ttraining's rmse: 1.0728\tvalid_1's rmse: 61.2713\n",
      "[1950]\ttraining's rmse: 1.02759\tvalid_1's rmse: 61.272\n",
      "[1980]\ttraining's rmse: 0.98243\tvalid_1's rmse: 61.2667\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's rmse: 0.955489\tvalid_1's rmse: 61.2647\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003251 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 20020\n",
      "[LightGBM] [Info] Number of data points in the train set: 9219, number of used features: 79\n",
      "[LightGBM] [Info] Start training from score 378.655421\n",
      "Training until validation scores don't improve for 125 rounds\n",
      "[30]\ttraining's rmse: 176.399\tvalid_1's rmse: 183.346\n",
      "[60]\ttraining's rmse: 108.43\tvalid_1's rmse: 119.369\n",
      "[90]\ttraining's rmse: 71.4052\tvalid_1's rmse: 87.1494\n",
      "[120]\ttraining's rmse: 51.7168\tvalid_1's rmse: 72.0653\n",
      "[150]\ttraining's rmse: 40.7445\tvalid_1's rmse: 64.7419\n",
      "[180]\ttraining's rmse: 34.4037\tvalid_1's rmse: 61.1607\n",
      "[210]\ttraining's rmse: 30.0378\tvalid_1's rmse: 59.1009\n",
      "[240]\ttraining's rmse: 26.7429\tvalid_1's rmse: 57.8679\n",
      "[270]\ttraining's rmse: 24.1361\tvalid_1's rmse: 56.85\n",
      "[300]\ttraining's rmse: 21.9874\tvalid_1's rmse: 56.2446\n",
      "[330]\ttraining's rmse: 20.1551\tvalid_1's rmse: 55.764\n",
      "[360]\ttraining's rmse: 18.5626\tvalid_1's rmse: 55.3783\n",
      "[390]\ttraining's rmse: 17.1818\tvalid_1's rmse: 55.1008\n",
      "[420]\ttraining's rmse: 15.9184\tvalid_1's rmse: 54.9007\n",
      "[450]\ttraining's rmse: 14.7772\tvalid_1's rmse: 54.6926\n",
      "[480]\ttraining's rmse: 13.7386\tvalid_1's rmse: 54.5165\n",
      "[510]\ttraining's rmse: 12.792\tvalid_1's rmse: 54.3907\n",
      "[540]\ttraining's rmse: 11.9418\tvalid_1's rmse: 54.277\n",
      "[570]\ttraining's rmse: 11.1583\tvalid_1's rmse: 54.2061\n",
      "[600]\ttraining's rmse: 10.4592\tvalid_1's rmse: 54.1489\n",
      "[630]\ttraining's rmse: 9.80989\tvalid_1's rmse: 54.0678\n",
      "[660]\ttraining's rmse: 9.20525\tvalid_1's rmse: 54.0172\n",
      "[690]\ttraining's rmse: 8.64618\tvalid_1's rmse: 53.967\n",
      "[720]\ttraining's rmse: 8.13735\tvalid_1's rmse: 53.9132\n",
      "[750]\ttraining's rmse: 7.65473\tvalid_1's rmse: 53.8433\n",
      "[780]\ttraining's rmse: 7.20513\tvalid_1's rmse: 53.8045\n",
      "[810]\ttraining's rmse: 6.78329\tvalid_1's rmse: 53.7642\n",
      "[840]\ttraining's rmse: 6.3986\tvalid_1's rmse: 53.7423\n",
      "[870]\ttraining's rmse: 6.04428\tvalid_1's rmse: 53.7337\n",
      "[900]\ttraining's rmse: 5.71157\tvalid_1's rmse: 53.7038\n",
      "[930]\ttraining's rmse: 5.40501\tvalid_1's rmse: 53.6715\n",
      "[960]\ttraining's rmse: 5.10759\tvalid_1's rmse: 53.6504\n",
      "[990]\ttraining's rmse: 4.82761\tvalid_1's rmse: 53.6389\n",
      "[1020]\ttraining's rmse: 4.57141\tvalid_1's rmse: 53.6269\n",
      "[1050]\ttraining's rmse: 4.32685\tvalid_1's rmse: 53.6161\n",
      "[1080]\ttraining's rmse: 4.09492\tvalid_1's rmse: 53.6007\n",
      "[1110]\ttraining's rmse: 3.87505\tvalid_1's rmse: 53.5924\n",
      "[1140]\ttraining's rmse: 3.67181\tvalid_1's rmse: 53.5785\n",
      "[1170]\ttraining's rmse: 3.48164\tvalid_1's rmse: 53.564\n",
      "[1200]\ttraining's rmse: 3.30759\tvalid_1's rmse: 53.5523\n",
      "[1230]\ttraining's rmse: 3.13816\tvalid_1's rmse: 53.5432\n",
      "[1260]\ttraining's rmse: 2.97518\tvalid_1's rmse: 53.5348\n",
      "[1290]\ttraining's rmse: 2.82388\tvalid_1's rmse: 53.528\n",
      "[1320]\ttraining's rmse: 2.68082\tvalid_1's rmse: 53.5286\n",
      "[1350]\ttraining's rmse: 2.54424\tvalid_1's rmse: 53.5233\n",
      "[1380]\ttraining's rmse: 2.41946\tvalid_1's rmse: 53.5194\n",
      "[1410]\ttraining's rmse: 2.29865\tvalid_1's rmse: 53.5093\n",
      "[1440]\ttraining's rmse: 2.18749\tvalid_1's rmse: 53.5013\n",
      "[1470]\ttraining's rmse: 2.08061\tvalid_1's rmse: 53.4979\n",
      "[1500]\ttraining's rmse: 1.97964\tvalid_1's rmse: 53.4907\n",
      "[1530]\ttraining's rmse: 1.88366\tvalid_1's rmse: 53.4833\n",
      "[1560]\ttraining's rmse: 1.79306\tvalid_1's rmse: 53.482\n",
      "[1590]\ttraining's rmse: 1.70634\tvalid_1's rmse: 53.4805\n",
      "[1620]\ttraining's rmse: 1.62663\tvalid_1's rmse: 53.4758\n",
      "[1650]\ttraining's rmse: 1.54895\tvalid_1's rmse: 53.4722\n",
      "[1680]\ttraining's rmse: 1.47624\tvalid_1's rmse: 53.4696\n",
      "[1710]\ttraining's rmse: 1.40515\tvalid_1's rmse: 53.4648\n",
      "[1740]\ttraining's rmse: 1.34039\tvalid_1's rmse: 53.4616\n",
      "[1770]\ttraining's rmse: 1.27869\tvalid_1's rmse: 53.4595\n",
      "[1800]\ttraining's rmse: 1.21843\tvalid_1's rmse: 53.4575\n",
      "[1830]\ttraining's rmse: 1.16145\tvalid_1's rmse: 53.4558\n",
      "[1860]\ttraining's rmse: 1.10728\tvalid_1's rmse: 53.454\n",
      "[1890]\ttraining's rmse: 1.05612\tvalid_1's rmse: 53.4529\n",
      "[1920]\ttraining's rmse: 1.00736\tvalid_1's rmse: 53.4499\n",
      "[1950]\ttraining's rmse: 0.961671\tvalid_1's rmse: 53.4486\n",
      "[1980]\ttraining's rmse: 0.918367\tvalid_1's rmse: 53.4457\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's rmse: 0.889533\tvalid_1's rmse: 53.4432\n",
      "9\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002462 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 20020\n",
      "[LightGBM] [Info] Number of data points in the train set: 9219, number of used features: 79\n",
      "[LightGBM] [Info] Start training from score 379.459898\n",
      "Training until validation scores don't improve for 125 rounds\n",
      "[30]\ttraining's rmse: 169.69\tvalid_1's rmse: 174.956\n",
      "[60]\ttraining's rmse: 102.804\tvalid_1's rmse: 113.133\n",
      "[90]\ttraining's rmse: 66.6033\tvalid_1's rmse: 82.5567\n",
      "[120]\ttraining's rmse: 47.2817\tvalid_1's rmse: 68.3722\n",
      "[150]\ttraining's rmse: 36.868\tvalid_1's rmse: 61.7505\n",
      "[180]\ttraining's rmse: 30.7677\tvalid_1's rmse: 58.5569\n",
      "[210]\ttraining's rmse: 26.7938\tvalid_1's rmse: 56.7301\n",
      "[240]\ttraining's rmse: 23.8333\tvalid_1's rmse: 55.5776\n",
      "[270]\ttraining's rmse: 21.4932\tvalid_1's rmse: 54.8255\n",
      "[300]\ttraining's rmse: 19.5537\tvalid_1's rmse: 54.2259\n",
      "[330]\ttraining's rmse: 17.9371\tvalid_1's rmse: 53.8306\n",
      "[360]\ttraining's rmse: 16.5262\tvalid_1's rmse: 53.4904\n",
      "[390]\ttraining's rmse: 15.2682\tvalid_1's rmse: 53.2327\n",
      "[420]\ttraining's rmse: 14.1489\tvalid_1's rmse: 53.0206\n",
      "[450]\ttraining's rmse: 13.1337\tvalid_1's rmse: 52.809\n",
      "[480]\ttraining's rmse: 12.2388\tvalid_1's rmse: 52.6742\n",
      "[510]\ttraining's rmse: 11.4263\tvalid_1's rmse: 52.5568\n",
      "[540]\ttraining's rmse: 10.6953\tvalid_1's rmse: 52.4388\n",
      "[570]\ttraining's rmse: 10.0058\tvalid_1's rmse: 52.3439\n",
      "[600]\ttraining's rmse: 9.38307\tvalid_1's rmse: 52.2928\n",
      "[630]\ttraining's rmse: 8.80586\tvalid_1's rmse: 52.2351\n",
      "[660]\ttraining's rmse: 8.27957\tvalid_1's rmse: 52.186\n",
      "[690]\ttraining's rmse: 7.79016\tvalid_1's rmse: 52.1354\n",
      "[720]\ttraining's rmse: 7.33847\tvalid_1's rmse: 52.0933\n",
      "[750]\ttraining's rmse: 6.90148\tvalid_1's rmse: 52.0407\n",
      "[780]\ttraining's rmse: 6.50802\tvalid_1's rmse: 52.0151\n",
      "[810]\ttraining's rmse: 6.13358\tvalid_1's rmse: 51.9839\n",
      "[840]\ttraining's rmse: 5.78713\tvalid_1's rmse: 51.9509\n",
      "[870]\ttraining's rmse: 5.46124\tvalid_1's rmse: 51.9297\n",
      "[900]\ttraining's rmse: 5.1608\tvalid_1's rmse: 51.9126\n",
      "[930]\ttraining's rmse: 4.88093\tvalid_1's rmse: 51.8777\n",
      "[960]\ttraining's rmse: 4.61968\tvalid_1's rmse: 51.8658\n",
      "[990]\ttraining's rmse: 4.37901\tvalid_1's rmse: 51.8364\n",
      "[1020]\ttraining's rmse: 4.14769\tvalid_1's rmse: 51.8163\n",
      "[1050]\ttraining's rmse: 3.93457\tvalid_1's rmse: 51.8047\n",
      "[1080]\ttraining's rmse: 3.73023\tvalid_1's rmse: 51.798\n",
      "[1110]\ttraining's rmse: 3.53884\tvalid_1's rmse: 51.7944\n",
      "[1140]\ttraining's rmse: 3.36009\tvalid_1's rmse: 51.7781\n",
      "[1170]\ttraining's rmse: 3.18879\tvalid_1's rmse: 51.7667\n",
      "[1200]\ttraining's rmse: 3.02705\tvalid_1's rmse: 51.7493\n",
      "[1230]\ttraining's rmse: 2.87669\tvalid_1's rmse: 51.7392\n",
      "[1260]\ttraining's rmse: 2.73336\tvalid_1's rmse: 51.7271\n",
      "[1290]\ttraining's rmse: 2.59712\tvalid_1's rmse: 51.7206\n",
      "[1320]\ttraining's rmse: 2.4687\tvalid_1's rmse: 51.709\n",
      "[1350]\ttraining's rmse: 2.35189\tvalid_1's rmse: 51.7006\n",
      "[1380]\ttraining's rmse: 2.23407\tvalid_1's rmse: 51.6918\n",
      "[1410]\ttraining's rmse: 2.12441\tvalid_1's rmse: 51.6834\n",
      "[1440]\ttraining's rmse: 2.02403\tvalid_1's rmse: 51.6792\n",
      "[1470]\ttraining's rmse: 1.92566\tvalid_1's rmse: 51.676\n",
      "[1500]\ttraining's rmse: 1.83288\tvalid_1's rmse: 51.6732\n",
      "[1530]\ttraining's rmse: 1.7456\tvalid_1's rmse: 51.6685\n",
      "[1560]\ttraining's rmse: 1.6633\tvalid_1's rmse: 51.6659\n",
      "[1590]\ttraining's rmse: 1.5835\tvalid_1's rmse: 51.661\n",
      "[1620]\ttraining's rmse: 1.51256\tvalid_1's rmse: 51.6578\n",
      "[1650]\ttraining's rmse: 1.4414\tvalid_1's rmse: 51.6536\n",
      "[1680]\ttraining's rmse: 1.37622\tvalid_1's rmse: 51.6495\n",
      "[1710]\ttraining's rmse: 1.31116\tvalid_1's rmse: 51.6456\n",
      "[1740]\ttraining's rmse: 1.25042\tvalid_1's rmse: 51.6419\n",
      "[1770]\ttraining's rmse: 1.19323\tvalid_1's rmse: 51.6385\n",
      "[1800]\ttraining's rmse: 1.13912\tvalid_1's rmse: 51.6322\n",
      "[1830]\ttraining's rmse: 1.08513\tvalid_1's rmse: 51.6296\n",
      "[1860]\ttraining's rmse: 1.03659\tvalid_1's rmse: 51.626\n",
      "[1890]\ttraining's rmse: 0.990257\tvalid_1's rmse: 51.6233\n",
      "[1920]\ttraining's rmse: 0.944986\tvalid_1's rmse: 51.6209\n",
      "[1950]\ttraining's rmse: 0.901874\tvalid_1's rmse: 51.6182\n",
      "[1980]\ttraining's rmse: 0.860704\tvalid_1's rmse: 51.6174\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's rmse: 0.834575\tvalid_1's rmse: 51.6155\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002522 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 20020\n",
      "[LightGBM] [Info] Number of data points in the train set: 9219, number of used features: 79\n",
      "[LightGBM] [Info] Start training from score 380.308244\n",
      "Training until validation scores don't improve for 125 rounds\n",
      "[30]\ttraining's rmse: 172.373\tvalid_1's rmse: 175.792\n",
      "[60]\ttraining's rmse: 106.451\tvalid_1's rmse: 114.224\n",
      "[90]\ttraining's rmse: 70.4843\tvalid_1's rmse: 83.2944\n",
      "[120]\ttraining's rmse: 51.2467\tvalid_1's rmse: 68.4057\n",
      "[150]\ttraining's rmse: 40.5155\tvalid_1's rmse: 61.7849\n",
      "[180]\ttraining's rmse: 34.1226\tvalid_1's rmse: 58.2472\n",
      "[210]\ttraining's rmse: 29.6556\tvalid_1's rmse: 56.2056\n",
      "[240]\ttraining's rmse: 26.376\tvalid_1's rmse: 54.951\n",
      "[270]\ttraining's rmse: 23.7425\tvalid_1's rmse: 54.0934\n",
      "[300]\ttraining's rmse: 21.5935\tvalid_1's rmse: 53.3704\n",
      "[330]\ttraining's rmse: 19.7418\tvalid_1's rmse: 52.9135\n",
      "[360]\ttraining's rmse: 18.142\tvalid_1's rmse: 52.5344\n",
      "[390]\ttraining's rmse: 16.7553\tvalid_1's rmse: 52.2236\n",
      "[420]\ttraining's rmse: 15.4891\tvalid_1's rmse: 51.966\n",
      "[450]\ttraining's rmse: 14.3607\tvalid_1's rmse: 51.7415\n",
      "[480]\ttraining's rmse: 13.3293\tvalid_1's rmse: 51.5997\n",
      "[510]\ttraining's rmse: 12.3899\tvalid_1's rmse: 51.3932\n",
      "[540]\ttraining's rmse: 11.5579\tvalid_1's rmse: 51.2644\n",
      "[570]\ttraining's rmse: 10.796\tvalid_1's rmse: 51.1996\n",
      "[600]\ttraining's rmse: 10.0952\tvalid_1's rmse: 51.1672\n",
      "[630]\ttraining's rmse: 9.42985\tvalid_1's rmse: 51.0864\n",
      "[660]\ttraining's rmse: 8.8374\tvalid_1's rmse: 51.0208\n",
      "[690]\ttraining's rmse: 8.28994\tvalid_1's rmse: 50.9693\n",
      "[720]\ttraining's rmse: 7.78111\tvalid_1's rmse: 50.9141\n",
      "[750]\ttraining's rmse: 7.30195\tvalid_1's rmse: 50.8447\n",
      "[780]\ttraining's rmse: 6.86568\tvalid_1's rmse: 50.798\n",
      "[810]\ttraining's rmse: 6.45059\tvalid_1's rmse: 50.7461\n",
      "[840]\ttraining's rmse: 6.07714\tvalid_1's rmse: 50.7152\n",
      "[870]\ttraining's rmse: 5.72098\tvalid_1's rmse: 50.6934\n",
      "[900]\ttraining's rmse: 5.39646\tvalid_1's rmse: 50.6771\n",
      "[930]\ttraining's rmse: 5.09826\tvalid_1's rmse: 50.6627\n",
      "[960]\ttraining's rmse: 4.81138\tvalid_1's rmse: 50.6519\n",
      "[990]\ttraining's rmse: 4.54366\tvalid_1's rmse: 50.6249\n",
      "[1020]\ttraining's rmse: 4.29139\tvalid_1's rmse: 50.6059\n",
      "[1050]\ttraining's rmse: 4.05495\tvalid_1's rmse: 50.5909\n",
      "[1080]\ttraining's rmse: 3.83327\tvalid_1's rmse: 50.5781\n",
      "[1110]\ttraining's rmse: 3.62753\tvalid_1's rmse: 50.5615\n",
      "[1140]\ttraining's rmse: 3.43212\tvalid_1's rmse: 50.5503\n",
      "[1170]\ttraining's rmse: 3.25149\tvalid_1's rmse: 50.541\n",
      "[1200]\ttraining's rmse: 3.07763\tvalid_1's rmse: 50.5327\n",
      "[1230]\ttraining's rmse: 2.91805\tvalid_1's rmse: 50.5268\n",
      "[1260]\ttraining's rmse: 2.76484\tvalid_1's rmse: 50.5105\n",
      "[1290]\ttraining's rmse: 2.61865\tvalid_1's rmse: 50.5003\n",
      "[1320]\ttraining's rmse: 2.48224\tvalid_1's rmse: 50.4958\n",
      "[1350]\ttraining's rmse: 2.35262\tvalid_1's rmse: 50.489\n",
      "[1380]\ttraining's rmse: 2.23013\tvalid_1's rmse: 50.4836\n",
      "[1410]\ttraining's rmse: 2.11744\tvalid_1's rmse: 50.4774\n",
      "[1440]\ttraining's rmse: 2.01016\tvalid_1's rmse: 50.47\n",
      "[1470]\ttraining's rmse: 1.90782\tvalid_1's rmse: 50.4673\n",
      "[1500]\ttraining's rmse: 1.81239\tvalid_1's rmse: 50.4644\n",
      "[1530]\ttraining's rmse: 1.72096\tvalid_1's rmse: 50.4638\n",
      "[1560]\ttraining's rmse: 1.63476\tvalid_1's rmse: 50.462\n",
      "[1590]\ttraining's rmse: 1.55417\tvalid_1's rmse: 50.4576\n",
      "[1620]\ttraining's rmse: 1.4762\tvalid_1's rmse: 50.4552\n",
      "[1650]\ttraining's rmse: 1.40309\tvalid_1's rmse: 50.4526\n",
      "[1680]\ttraining's rmse: 1.33362\tvalid_1's rmse: 50.4483\n",
      "[1710]\ttraining's rmse: 1.26786\tvalid_1's rmse: 50.4446\n",
      "[1740]\ttraining's rmse: 1.20443\tvalid_1's rmse: 50.4423\n",
      "[1770]\ttraining's rmse: 1.14572\tvalid_1's rmse: 50.4394\n",
      "[1800]\ttraining's rmse: 1.09059\tvalid_1's rmse: 50.4387\n",
      "[1830]\ttraining's rmse: 1.03797\tvalid_1's rmse: 50.4355\n",
      "[1860]\ttraining's rmse: 0.987759\tvalid_1's rmse: 50.4327\n",
      "[1890]\ttraining's rmse: 0.939314\tvalid_1's rmse: 50.4321\n",
      "[1920]\ttraining's rmse: 0.892587\tvalid_1's rmse: 50.43\n",
      "[1950]\ttraining's rmse: 0.849687\tvalid_1's rmse: 50.43\n",
      "[1980]\ttraining's rmse: 0.809094\tvalid_1's rmse: 50.4273\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's rmse: 0.782161\tvalid_1's rmse: 50.4265\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003421 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 20020\n",
      "[LightGBM] [Info] Number of data points in the train set: 9219, number of used features: 79\n",
      "[LightGBM] [Info] Start training from score 379.856393\n",
      "Training until validation scores don't improve for 125 rounds\n",
      "[30]\ttraining's rmse: 172.832\tvalid_1's rmse: 171.596\n",
      "[60]\ttraining's rmse: 105.613\tvalid_1's rmse: 112.606\n",
      "[90]\ttraining's rmse: 69.3413\tvalid_1's rmse: 82.5468\n",
      "[120]\ttraining's rmse: 50.1657\tvalid_1's rmse: 68.6729\n",
      "[150]\ttraining's rmse: 39.5224\tvalid_1's rmse: 61.912\n",
      "[180]\ttraining's rmse: 33.3208\tvalid_1's rmse: 58.4473\n",
      "[210]\ttraining's rmse: 29.0515\tvalid_1's rmse: 56.5085\n",
      "[240]\ttraining's rmse: 25.9406\tvalid_1's rmse: 55.3921\n",
      "[270]\ttraining's rmse: 23.3418\tvalid_1's rmse: 54.5058\n",
      "[300]\ttraining's rmse: 21.217\tvalid_1's rmse: 53.9185\n",
      "[330]\ttraining's rmse: 19.4446\tvalid_1's rmse: 53.5369\n",
      "[360]\ttraining's rmse: 17.9101\tvalid_1's rmse: 53.2353\n",
      "[390]\ttraining's rmse: 16.5542\tvalid_1's rmse: 52.9305\n",
      "[420]\ttraining's rmse: 15.3538\tvalid_1's rmse: 52.7521\n",
      "[450]\ttraining's rmse: 14.2694\tvalid_1's rmse: 52.6129\n",
      "[480]\ttraining's rmse: 13.2777\tvalid_1's rmse: 52.4668\n",
      "[510]\ttraining's rmse: 12.3916\tvalid_1's rmse: 52.4152\n",
      "[540]\ttraining's rmse: 11.5912\tvalid_1's rmse: 52.3518\n",
      "[570]\ttraining's rmse: 10.8521\tvalid_1's rmse: 52.2346\n",
      "[600]\ttraining's rmse: 10.1812\tvalid_1's rmse: 52.1971\n",
      "[630]\ttraining's rmse: 9.55438\tvalid_1's rmse: 52.143\n",
      "[660]\ttraining's rmse: 8.97655\tvalid_1's rmse: 52.0891\n",
      "[690]\ttraining's rmse: 8.44163\tvalid_1's rmse: 52.0339\n",
      "[720]\ttraining's rmse: 7.94979\tvalid_1's rmse: 51.9969\n",
      "[750]\ttraining's rmse: 7.5083\tvalid_1's rmse: 51.9507\n",
      "[780]\ttraining's rmse: 7.08318\tvalid_1's rmse: 51.919\n",
      "[810]\ttraining's rmse: 6.67741\tvalid_1's rmse: 51.8864\n",
      "[840]\ttraining's rmse: 6.3101\tvalid_1's rmse: 51.8717\n",
      "[870]\ttraining's rmse: 5.96846\tvalid_1's rmse: 51.8505\n",
      "[900]\ttraining's rmse: 5.65097\tvalid_1's rmse: 51.8104\n",
      "[930]\ttraining's rmse: 5.34815\tvalid_1's rmse: 51.8028\n",
      "[960]\ttraining's rmse: 5.06158\tvalid_1's rmse: 51.7972\n",
      "[990]\ttraining's rmse: 4.80321\tvalid_1's rmse: 51.7833\n",
      "[1020]\ttraining's rmse: 4.5497\tvalid_1's rmse: 51.7812\n",
      "[1050]\ttraining's rmse: 4.31506\tvalid_1's rmse: 51.7604\n",
      "[1080]\ttraining's rmse: 4.08892\tvalid_1's rmse: 51.7548\n",
      "[1110]\ttraining's rmse: 3.88889\tvalid_1's rmse: 51.743\n",
      "[1140]\ttraining's rmse: 3.69229\tvalid_1's rmse: 51.7309\n",
      "[1170]\ttraining's rmse: 3.50734\tvalid_1's rmse: 51.7236\n",
      "[1200]\ttraining's rmse: 3.33042\tvalid_1's rmse: 51.7171\n",
      "[1230]\ttraining's rmse: 3.16702\tvalid_1's rmse: 51.7122\n",
      "[1260]\ttraining's rmse: 3.00955\tvalid_1's rmse: 51.707\n",
      "[1290]\ttraining's rmse: 2.86077\tvalid_1's rmse: 51.7003\n",
      "[1320]\ttraining's rmse: 2.71926\tvalid_1's rmse: 51.6978\n",
      "[1350]\ttraining's rmse: 2.58846\tvalid_1's rmse: 51.6956\n",
      "[1380]\ttraining's rmse: 2.46251\tvalid_1's rmse: 51.6856\n",
      "[1410]\ttraining's rmse: 2.34515\tvalid_1's rmse: 51.6818\n",
      "[1440]\ttraining's rmse: 2.23322\tvalid_1's rmse: 51.6826\n",
      "[1470]\ttraining's rmse: 2.12966\tvalid_1's rmse: 51.6821\n",
      "[1500]\ttraining's rmse: 2.03034\tvalid_1's rmse: 51.6748\n",
      "[1530]\ttraining's rmse: 1.93598\tvalid_1's rmse: 51.6756\n",
      "[1560]\ttraining's rmse: 1.84211\tvalid_1's rmse: 51.6715\n",
      "[1590]\ttraining's rmse: 1.75576\tvalid_1's rmse: 51.6666\n",
      "[1620]\ttraining's rmse: 1.67643\tvalid_1's rmse: 51.6673\n",
      "[1650]\ttraining's rmse: 1.60144\tvalid_1's rmse: 51.6649\n",
      "[1680]\ttraining's rmse: 1.5284\tvalid_1's rmse: 51.664\n",
      "[1710]\ttraining's rmse: 1.46179\tvalid_1's rmse: 51.6647\n",
      "[1740]\ttraining's rmse: 1.39649\tvalid_1's rmse: 51.6641\n",
      "[1770]\ttraining's rmse: 1.33362\tvalid_1's rmse: 51.6634\n",
      "[1800]\ttraining's rmse: 1.272\tvalid_1's rmse: 51.6631\n",
      "[1830]\ttraining's rmse: 1.21549\tvalid_1's rmse: 51.6638\n",
      "[1860]\ttraining's rmse: 1.16048\tvalid_1's rmse: 51.6643\n",
      "[1890]\ttraining's rmse: 1.10758\tvalid_1's rmse: 51.6642\n",
      "[1920]\ttraining's rmse: 1.05768\tvalid_1's rmse: 51.6636\n",
      "Early stopping, best iteration is:\n",
      "[1814]\ttraining's rmse: 1.24644\tvalid_1's rmse: 51.6621\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002669 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 20020\n",
      "[LightGBM] [Info] Number of data points in the train set: 9219, number of used features: 79\n",
      "[LightGBM] [Info] Start training from score 387.720243\n",
      "Training until validation scores don't improve for 125 rounds\n",
      "[30]\ttraining's rmse: 176.821\tvalid_1's rmse: 175.148\n",
      "[60]\ttraining's rmse: 108.635\tvalid_1's rmse: 114.836\n",
      "[90]\ttraining's rmse: 71.6089\tvalid_1's rmse: 84.3881\n",
      "[120]\ttraining's rmse: 51.6978\tvalid_1's rmse: 69.4339\n",
      "[150]\ttraining's rmse: 40.7046\tvalid_1's rmse: 62.4774\n",
      "[180]\ttraining's rmse: 34.1888\tvalid_1's rmse: 59.1473\n",
      "[210]\ttraining's rmse: 29.7274\tvalid_1's rmse: 57.4132\n",
      "[240]\ttraining's rmse: 26.379\tvalid_1's rmse: 56.2736\n",
      "[270]\ttraining's rmse: 23.7073\tvalid_1's rmse: 55.5043\n",
      "[300]\ttraining's rmse: 21.5511\tvalid_1's rmse: 54.9696\n",
      "[330]\ttraining's rmse: 19.7473\tvalid_1's rmse: 54.6464\n",
      "[360]\ttraining's rmse: 18.129\tvalid_1's rmse: 54.424\n",
      "[390]\ttraining's rmse: 16.7585\tvalid_1's rmse: 54.2194\n",
      "[420]\ttraining's rmse: 15.5062\tvalid_1's rmse: 53.9565\n",
      "[450]\ttraining's rmse: 14.4015\tvalid_1's rmse: 53.7817\n",
      "[480]\ttraining's rmse: 13.3629\tvalid_1's rmse: 53.6546\n",
      "[510]\ttraining's rmse: 12.4453\tvalid_1's rmse: 53.524\n",
      "[540]\ttraining's rmse: 11.6218\tvalid_1's rmse: 53.4028\n",
      "[570]\ttraining's rmse: 10.8618\tvalid_1's rmse: 53.3155\n",
      "[600]\ttraining's rmse: 10.161\tvalid_1's rmse: 53.2496\n",
      "[630]\ttraining's rmse: 9.51699\tvalid_1's rmse: 53.2039\n",
      "[660]\ttraining's rmse: 8.93599\tvalid_1's rmse: 53.1358\n",
      "[690]\ttraining's rmse: 8.39386\tvalid_1's rmse: 53.0804\n",
      "[720]\ttraining's rmse: 7.87545\tvalid_1's rmse: 53.0194\n",
      "[750]\ttraining's rmse: 7.41253\tvalid_1's rmse: 52.9879\n",
      "[780]\ttraining's rmse: 6.97631\tvalid_1's rmse: 52.9486\n",
      "[810]\ttraining's rmse: 6.56615\tvalid_1's rmse: 52.9054\n",
      "[840]\ttraining's rmse: 6.19224\tvalid_1's rmse: 52.8782\n",
      "[870]\ttraining's rmse: 5.8478\tvalid_1's rmse: 52.8514\n",
      "[900]\ttraining's rmse: 5.51991\tvalid_1's rmse: 52.8261\n",
      "[930]\ttraining's rmse: 5.21567\tvalid_1's rmse: 52.795\n",
      "[960]\ttraining's rmse: 4.93185\tvalid_1's rmse: 52.767\n",
      "[990]\ttraining's rmse: 4.65888\tvalid_1's rmse: 52.7509\n",
      "[1020]\ttraining's rmse: 4.40507\tvalid_1's rmse: 52.7333\n",
      "[1050]\ttraining's rmse: 4.16643\tvalid_1's rmse: 52.7092\n",
      "[1080]\ttraining's rmse: 3.94206\tvalid_1's rmse: 52.7038\n",
      "[1110]\ttraining's rmse: 3.73374\tvalid_1's rmse: 52.6948\n",
      "[1140]\ttraining's rmse: 3.5397\tvalid_1's rmse: 52.684\n",
      "[1170]\ttraining's rmse: 3.35595\tvalid_1's rmse: 52.6711\n",
      "[1200]\ttraining's rmse: 3.18299\tvalid_1's rmse: 52.6588\n",
      "[1230]\ttraining's rmse: 3.01638\tvalid_1's rmse: 52.653\n",
      "[1260]\ttraining's rmse: 2.86286\tvalid_1's rmse: 52.6414\n",
      "[1290]\ttraining's rmse: 2.71233\tvalid_1's rmse: 52.6302\n",
      "[1320]\ttraining's rmse: 2.57362\tvalid_1's rmse: 52.6248\n",
      "[1350]\ttraining's rmse: 2.44113\tvalid_1's rmse: 52.6156\n",
      "[1380]\ttraining's rmse: 2.31536\tvalid_1's rmse: 52.61\n",
      "[1410]\ttraining's rmse: 2.19802\tvalid_1's rmse: 52.6056\n",
      "[1440]\ttraining's rmse: 2.08998\tvalid_1's rmse: 52.5981\n",
      "[1470]\ttraining's rmse: 1.98614\tvalid_1's rmse: 52.5979\n",
      "[1500]\ttraining's rmse: 1.89031\tvalid_1's rmse: 52.5971\n",
      "[1530]\ttraining's rmse: 1.79732\tvalid_1's rmse: 52.5941\n",
      "[1560]\ttraining's rmse: 1.70891\tvalid_1's rmse: 52.59\n",
      "[1590]\ttraining's rmse: 1.62769\tvalid_1's rmse: 52.5889\n",
      "[1620]\ttraining's rmse: 1.5481\tvalid_1's rmse: 52.5891\n",
      "[1650]\ttraining's rmse: 1.47346\tvalid_1's rmse: 52.587\n",
      "[1680]\ttraining's rmse: 1.40164\tvalid_1's rmse: 52.5827\n",
      "[1710]\ttraining's rmse: 1.33371\tvalid_1's rmse: 52.579\n",
      "[1740]\ttraining's rmse: 1.26863\tvalid_1's rmse: 52.5764\n",
      "[1770]\ttraining's rmse: 1.20845\tvalid_1's rmse: 52.5735\n",
      "[1800]\ttraining's rmse: 1.15166\tvalid_1's rmse: 52.5747\n",
      "[1830]\ttraining's rmse: 1.09727\tvalid_1's rmse: 52.5717\n",
      "[1860]\ttraining's rmse: 1.04499\tvalid_1's rmse: 52.5694\n",
      "[1890]\ttraining's rmse: 0.995145\tvalid_1's rmse: 52.5674\n",
      "[1920]\ttraining's rmse: 0.948078\tvalid_1's rmse: 52.5645\n",
      "[1950]\ttraining's rmse: 0.903285\tvalid_1's rmse: 52.5605\n",
      "[1980]\ttraining's rmse: 0.860827\tvalid_1's rmse: 52.5594\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's rmse: 0.834099\tvalid_1's rmse: 52.557\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002451 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 20020\n",
      "[LightGBM] [Info] Number of data points in the train set: 9219, number of used features: 79\n",
      "[LightGBM] [Info] Start training from score 389.883047\n",
      "Training until validation scores don't improve for 125 rounds\n",
      "[30]\ttraining's rmse: 176.694\tvalid_1's rmse: 183.435\n",
      "[60]\ttraining's rmse: 108.976\tvalid_1's rmse: 120.898\n",
      "[90]\ttraining's rmse: 72.1176\tvalid_1's rmse: 89.4308\n",
      "[120]\ttraining's rmse: 52.3226\tvalid_1's rmse: 74.3812\n",
      "[150]\ttraining's rmse: 41.3013\tvalid_1's rmse: 67.0906\n",
      "[180]\ttraining's rmse: 34.6777\tvalid_1's rmse: 63.3963\n",
      "[210]\ttraining's rmse: 30.2744\tvalid_1's rmse: 61.2756\n",
      "[240]\ttraining's rmse: 26.9356\tvalid_1's rmse: 59.8721\n",
      "[270]\ttraining's rmse: 24.223\tvalid_1's rmse: 58.8918\n",
      "[300]\ttraining's rmse: 22.0395\tvalid_1's rmse: 58.2709\n",
      "[330]\ttraining's rmse: 20.2211\tvalid_1's rmse: 57.7584\n",
      "[360]\ttraining's rmse: 18.6267\tvalid_1's rmse: 57.4317\n",
      "[390]\ttraining's rmse: 17.2055\tvalid_1's rmse: 57.1479\n",
      "[420]\ttraining's rmse: 15.9413\tvalid_1's rmse: 56.9234\n",
      "[450]\ttraining's rmse: 14.7923\tvalid_1's rmse: 56.6891\n",
      "[480]\ttraining's rmse: 13.7574\tvalid_1's rmse: 56.5583\n",
      "[510]\ttraining's rmse: 12.8257\tvalid_1's rmse: 56.3805\n",
      "[540]\ttraining's rmse: 11.9651\tvalid_1's rmse: 56.2587\n",
      "[570]\ttraining's rmse: 11.2013\tvalid_1's rmse: 56.1329\n",
      "[600]\ttraining's rmse: 10.4925\tvalid_1's rmse: 56.0436\n",
      "[630]\ttraining's rmse: 9.83736\tvalid_1's rmse: 55.9694\n",
      "[660]\ttraining's rmse: 9.24308\tvalid_1's rmse: 55.9045\n",
      "[690]\ttraining's rmse: 8.68051\tvalid_1's rmse: 55.8567\n",
      "[720]\ttraining's rmse: 8.1695\tvalid_1's rmse: 55.81\n",
      "[750]\ttraining's rmse: 7.68587\tvalid_1's rmse: 55.7486\n",
      "[780]\ttraining's rmse: 7.23859\tvalid_1's rmse: 55.709\n",
      "[810]\ttraining's rmse: 6.82277\tvalid_1's rmse: 55.671\n",
      "[840]\ttraining's rmse: 6.44082\tvalid_1's rmse: 55.6438\n",
      "[870]\ttraining's rmse: 6.08713\tvalid_1's rmse: 55.61\n",
      "[900]\ttraining's rmse: 5.75603\tvalid_1's rmse: 55.5994\n",
      "[930]\ttraining's rmse: 5.44356\tvalid_1's rmse: 55.57\n",
      "[960]\ttraining's rmse: 5.15588\tvalid_1's rmse: 55.551\n",
      "[990]\ttraining's rmse: 4.87887\tvalid_1's rmse: 55.5165\n",
      "[1020]\ttraining's rmse: 4.63048\tvalid_1's rmse: 55.5032\n",
      "[1050]\ttraining's rmse: 4.39007\tvalid_1's rmse: 55.4884\n",
      "[1080]\ttraining's rmse: 4.16539\tvalid_1's rmse: 55.48\n",
      "[1110]\ttraining's rmse: 3.95236\tvalid_1's rmse: 55.4653\n",
      "[1140]\ttraining's rmse: 3.75372\tvalid_1's rmse: 55.4542\n",
      "[1170]\ttraining's rmse: 3.55904\tvalid_1's rmse: 55.4378\n",
      "[1200]\ttraining's rmse: 3.3784\tvalid_1's rmse: 55.426\n",
      "[1230]\ttraining's rmse: 3.20569\tvalid_1's rmse: 55.4198\n",
      "[1260]\ttraining's rmse: 3.04722\tvalid_1's rmse: 55.4094\n",
      "[1290]\ttraining's rmse: 2.89735\tvalid_1's rmse: 55.3916\n",
      "[1320]\ttraining's rmse: 2.75415\tvalid_1's rmse: 55.3862\n",
      "[1350]\ttraining's rmse: 2.62221\tvalid_1's rmse: 55.3781\n",
      "[1380]\ttraining's rmse: 2.49465\tvalid_1's rmse: 55.3724\n",
      "[1410]\ttraining's rmse: 2.37509\tvalid_1's rmse: 55.3637\n",
      "[1440]\ttraining's rmse: 2.26144\tvalid_1's rmse: 55.3554\n",
      "[1470]\ttraining's rmse: 2.15198\tvalid_1's rmse: 55.3477\n",
      "[1500]\ttraining's rmse: 2.05031\tvalid_1's rmse: 55.3425\n",
      "[1530]\ttraining's rmse: 1.95282\tvalid_1's rmse: 55.334\n",
      "[1560]\ttraining's rmse: 1.86033\tvalid_1's rmse: 55.331\n",
      "[1590]\ttraining's rmse: 1.7732\tvalid_1's rmse: 55.3296\n",
      "[1620]\ttraining's rmse: 1.69098\tvalid_1's rmse: 55.3271\n",
      "[1650]\ttraining's rmse: 1.61484\tvalid_1's rmse: 55.3234\n",
      "[1680]\ttraining's rmse: 1.54143\tvalid_1's rmse: 55.3217\n",
      "[1710]\ttraining's rmse: 1.47094\tvalid_1's rmse: 55.319\n",
      "[1740]\ttraining's rmse: 1.40624\tvalid_1's rmse: 55.3143\n",
      "[1770]\ttraining's rmse: 1.34219\tvalid_1's rmse: 55.3084\n",
      "[1800]\ttraining's rmse: 1.28158\tvalid_1's rmse: 55.3057\n",
      "[1830]\ttraining's rmse: 1.22309\tvalid_1's rmse: 55.3023\n",
      "[1860]\ttraining's rmse: 1.16815\tvalid_1's rmse: 55.2992\n",
      "[1890]\ttraining's rmse: 1.1174\tvalid_1's rmse: 55.2972\n",
      "[1920]\ttraining's rmse: 1.06835\tvalid_1's rmse: 55.294\n",
      "[1950]\ttraining's rmse: 1.02095\tvalid_1's rmse: 55.2914\n",
      "[1980]\ttraining's rmse: 0.976261\tvalid_1's rmse: 55.2886\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's rmse: 0.948059\tvalid_1's rmse: 55.289\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002937 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 20020\n",
      "[LightGBM] [Info] Number of data points in the train set: 9219, number of used features: 79\n",
      "[LightGBM] [Info] Start training from score 387.612263\n",
      "Training until validation scores don't improve for 125 rounds\n",
      "[30]\ttraining's rmse: 176.217\tvalid_1's rmse: 185.78\n",
      "[60]\ttraining's rmse: 108.714\tvalid_1's rmse: 122.304\n",
      "[90]\ttraining's rmse: 72.004\tvalid_1's rmse: 90.9484\n",
      "[120]\ttraining's rmse: 52.0566\tvalid_1's rmse: 76.1867\n",
      "[150]\ttraining's rmse: 41.021\tvalid_1's rmse: 69.1072\n",
      "[180]\ttraining's rmse: 34.3439\tvalid_1's rmse: 65.5522\n",
      "[210]\ttraining's rmse: 29.9265\tvalid_1's rmse: 63.5558\n",
      "[240]\ttraining's rmse: 26.5593\tvalid_1's rmse: 62.2608\n",
      "[270]\ttraining's rmse: 23.9217\tvalid_1's rmse: 61.2831\n",
      "[300]\ttraining's rmse: 21.7963\tvalid_1's rmse: 60.6725\n",
      "[330]\ttraining's rmse: 19.9964\tvalid_1's rmse: 60.2891\n",
      "[360]\ttraining's rmse: 18.3958\tvalid_1's rmse: 59.9066\n",
      "[390]\ttraining's rmse: 17.0076\tvalid_1's rmse: 59.6724\n",
      "[420]\ttraining's rmse: 15.7401\tvalid_1's rmse: 59.4708\n",
      "[450]\ttraining's rmse: 14.6184\tvalid_1's rmse: 59.3204\n",
      "[480]\ttraining's rmse: 13.5841\tvalid_1's rmse: 59.2154\n",
      "[510]\ttraining's rmse: 12.6676\tvalid_1's rmse: 59.0967\n",
      "[540]\ttraining's rmse: 11.8279\tvalid_1's rmse: 58.9906\n",
      "[570]\ttraining's rmse: 11.0689\tvalid_1's rmse: 58.9022\n",
      "[600]\ttraining's rmse: 10.3739\tvalid_1's rmse: 58.8332\n",
      "[630]\ttraining's rmse: 9.72189\tvalid_1's rmse: 58.7795\n",
      "[660]\ttraining's rmse: 9.13172\tvalid_1's rmse: 58.7281\n",
      "[690]\ttraining's rmse: 8.58941\tvalid_1's rmse: 58.6736\n",
      "[720]\ttraining's rmse: 8.0729\tvalid_1's rmse: 58.6199\n",
      "[750]\ttraining's rmse: 7.6036\tvalid_1's rmse: 58.5787\n",
      "[780]\ttraining's rmse: 7.17124\tvalid_1's rmse: 58.5332\n",
      "[810]\ttraining's rmse: 6.7581\tvalid_1's rmse: 58.508\n",
      "[840]\ttraining's rmse: 6.37892\tvalid_1's rmse: 58.4664\n",
      "[870]\ttraining's rmse: 6.0184\tvalid_1's rmse: 58.4359\n",
      "[900]\ttraining's rmse: 5.6954\tvalid_1's rmse: 58.4235\n",
      "[930]\ttraining's rmse: 5.38716\tvalid_1's rmse: 58.4173\n",
      "[960]\ttraining's rmse: 5.09576\tvalid_1's rmse: 58.3821\n",
      "[990]\ttraining's rmse: 4.82321\tvalid_1's rmse: 58.3665\n",
      "[1020]\ttraining's rmse: 4.57196\tvalid_1's rmse: 58.3508\n",
      "[1050]\ttraining's rmse: 4.33806\tvalid_1's rmse: 58.3458\n",
      "[1080]\ttraining's rmse: 4.11091\tvalid_1's rmse: 58.3252\n",
      "[1110]\ttraining's rmse: 3.89763\tvalid_1's rmse: 58.3126\n",
      "[1140]\ttraining's rmse: 3.69726\tvalid_1's rmse: 58.2942\n",
      "[1170]\ttraining's rmse: 3.50861\tvalid_1's rmse: 58.2826\n",
      "[1200]\ttraining's rmse: 3.32585\tvalid_1's rmse: 58.276\n",
      "[1230]\ttraining's rmse: 3.15345\tvalid_1's rmse: 58.2702\n",
      "[1260]\ttraining's rmse: 2.99107\tvalid_1's rmse: 58.263\n",
      "[1290]\ttraining's rmse: 2.84031\tvalid_1's rmse: 58.257\n",
      "[1320]\ttraining's rmse: 2.70006\tvalid_1's rmse: 58.2499\n",
      "[1350]\ttraining's rmse: 2.56817\tvalid_1's rmse: 58.2466\n",
      "[1380]\ttraining's rmse: 2.4408\tvalid_1's rmse: 58.2417\n",
      "[1410]\ttraining's rmse: 2.32035\tvalid_1's rmse: 58.2347\n",
      "[1440]\ttraining's rmse: 2.20643\tvalid_1's rmse: 58.2323\n",
      "[1470]\ttraining's rmse: 2.09698\tvalid_1's rmse: 58.2273\n",
      "[1500]\ttraining's rmse: 1.99276\tvalid_1's rmse: 58.2214\n",
      "[1530]\ttraining's rmse: 1.8933\tvalid_1's rmse: 58.2154\n",
      "[1560]\ttraining's rmse: 1.80131\tvalid_1's rmse: 58.2116\n",
      "[1590]\ttraining's rmse: 1.71519\tvalid_1's rmse: 58.2079\n",
      "[1620]\ttraining's rmse: 1.63267\tvalid_1's rmse: 58.2031\n",
      "[1650]\ttraining's rmse: 1.55334\tvalid_1's rmse: 58.1997\n",
      "[1680]\ttraining's rmse: 1.47836\tvalid_1's rmse: 58.2001\n",
      "[1710]\ttraining's rmse: 1.40775\tvalid_1's rmse: 58.1965\n",
      "[1740]\ttraining's rmse: 1.33902\tvalid_1's rmse: 58.1949\n",
      "[1770]\ttraining's rmse: 1.27533\tvalid_1's rmse: 58.1934\n",
      "[1800]\ttraining's rmse: 1.21364\tvalid_1's rmse: 58.1912\n",
      "[1830]\ttraining's rmse: 1.15546\tvalid_1's rmse: 58.1891\n",
      "[1860]\ttraining's rmse: 1.1026\tvalid_1's rmse: 58.1886\n",
      "[1890]\ttraining's rmse: 1.05123\tvalid_1's rmse: 58.1862\n",
      "[1920]\ttraining's rmse: 1.00251\tvalid_1's rmse: 58.187\n",
      "[1950]\ttraining's rmse: 0.955731\tvalid_1's rmse: 58.1857\n",
      "[1980]\ttraining's rmse: 0.911078\tvalid_1's rmse: 58.1827\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's rmse: 0.882588\tvalid_1's rmse: 58.1805\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002914 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 20020\n",
      "[LightGBM] [Info] Number of data points in the train set: 9219, number of used features: 79\n",
      "[LightGBM] [Info] Start training from score 382.928992\n",
      "Training until validation scores don't improve for 125 rounds\n",
      "[30]\ttraining's rmse: 175.744\tvalid_1's rmse: 187.086\n",
      "[60]\ttraining's rmse: 108.17\tvalid_1's rmse: 123.974\n",
      "[90]\ttraining's rmse: 71.2185\tvalid_1's rmse: 92.6488\n",
      "[120]\ttraining's rmse: 51.3647\tvalid_1's rmse: 77.9079\n",
      "[150]\ttraining's rmse: 40.4789\tvalid_1's rmse: 70.6721\n",
      "[180]\ttraining's rmse: 33.9922\tvalid_1's rmse: 66.9669\n",
      "[210]\ttraining's rmse: 29.6364\tvalid_1's rmse: 64.5402\n",
      "[240]\ttraining's rmse: 26.4103\tvalid_1's rmse: 63.2113\n",
      "[270]\ttraining's rmse: 23.8406\tvalid_1's rmse: 62.312\n",
      "[300]\ttraining's rmse: 21.705\tvalid_1's rmse: 61.7817\n",
      "[330]\ttraining's rmse: 19.8806\tvalid_1's rmse: 61.2673\n",
      "[360]\ttraining's rmse: 18.3277\tvalid_1's rmse: 60.9875\n",
      "[390]\ttraining's rmse: 16.9341\tvalid_1's rmse: 60.6851\n",
      "[420]\ttraining's rmse: 15.7235\tvalid_1's rmse: 60.5464\n",
      "[450]\ttraining's rmse: 14.5997\tvalid_1's rmse: 60.4061\n",
      "[480]\ttraining's rmse: 13.6049\tvalid_1's rmse: 60.2756\n",
      "[510]\ttraining's rmse: 12.6776\tvalid_1's rmse: 60.2015\n",
      "[540]\ttraining's rmse: 11.8408\tvalid_1's rmse: 60.0815\n",
      "[570]\ttraining's rmse: 11.0742\tvalid_1's rmse: 60.0195\n",
      "[600]\ttraining's rmse: 10.3725\tvalid_1's rmse: 59.9655\n",
      "[630]\ttraining's rmse: 9.74354\tvalid_1's rmse: 59.9363\n",
      "[660]\ttraining's rmse: 9.15002\tvalid_1's rmse: 59.8982\n",
      "[690]\ttraining's rmse: 8.59688\tvalid_1's rmse: 59.8748\n",
      "[720]\ttraining's rmse: 8.09009\tvalid_1's rmse: 59.8519\n",
      "[750]\ttraining's rmse: 7.62283\tvalid_1's rmse: 59.8005\n",
      "[780]\ttraining's rmse: 7.17671\tvalid_1's rmse: 59.7895\n",
      "[810]\ttraining's rmse: 6.76403\tvalid_1's rmse: 59.7584\n",
      "[840]\ttraining's rmse: 6.37842\tvalid_1's rmse: 59.7398\n",
      "[870]\ttraining's rmse: 6.01203\tvalid_1's rmse: 59.7165\n",
      "[900]\ttraining's rmse: 5.67823\tvalid_1's rmse: 59.6954\n",
      "[930]\ttraining's rmse: 5.36983\tvalid_1's rmse: 59.6818\n",
      "[960]\ttraining's rmse: 5.07572\tvalid_1's rmse: 59.6597\n",
      "[990]\ttraining's rmse: 4.79669\tvalid_1's rmse: 59.6399\n",
      "[1020]\ttraining's rmse: 4.53182\tvalid_1's rmse: 59.6231\n",
      "[1050]\ttraining's rmse: 4.2953\tvalid_1's rmse: 59.6086\n",
      "[1080]\ttraining's rmse: 4.07115\tvalid_1's rmse: 59.5934\n",
      "[1110]\ttraining's rmse: 3.85661\tvalid_1's rmse: 59.5806\n",
      "[1140]\ttraining's rmse: 3.65392\tvalid_1's rmse: 59.5797\n",
      "[1170]\ttraining's rmse: 3.46657\tvalid_1's rmse: 59.5692\n",
      "[1200]\ttraining's rmse: 3.289\tvalid_1's rmse: 59.5594\n",
      "[1230]\ttraining's rmse: 3.1158\tvalid_1's rmse: 59.553\n",
      "[1260]\ttraining's rmse: 2.95814\tvalid_1's rmse: 59.545\n",
      "[1290]\ttraining's rmse: 2.80898\tvalid_1's rmse: 59.5382\n",
      "[1320]\ttraining's rmse: 2.6705\tvalid_1's rmse: 59.5345\n",
      "[1350]\ttraining's rmse: 2.53635\tvalid_1's rmse: 59.5334\n",
      "[1380]\ttraining's rmse: 2.40967\tvalid_1's rmse: 59.5282\n",
      "[1410]\ttraining's rmse: 2.28633\tvalid_1's rmse: 59.5227\n",
      "[1440]\ttraining's rmse: 2.17593\tvalid_1's rmse: 59.516\n",
      "[1470]\ttraining's rmse: 2.06963\tvalid_1's rmse: 59.5108\n",
      "[1500]\ttraining's rmse: 1.97017\tvalid_1's rmse: 59.5103\n",
      "[1530]\ttraining's rmse: 1.87244\tvalid_1's rmse: 59.5056\n",
      "[1560]\ttraining's rmse: 1.78218\tvalid_1's rmse: 59.5032\n",
      "[1590]\ttraining's rmse: 1.69625\tvalid_1's rmse: 59.502\n",
      "[1620]\ttraining's rmse: 1.61758\tvalid_1's rmse: 59.4987\n",
      "[1650]\ttraining's rmse: 1.5423\tvalid_1's rmse: 59.4981\n",
      "[1680]\ttraining's rmse: 1.46808\tvalid_1's rmse: 59.4946\n",
      "[1710]\ttraining's rmse: 1.39826\tvalid_1's rmse: 59.4935\n",
      "[1740]\ttraining's rmse: 1.33233\tvalid_1's rmse: 59.4902\n",
      "[1770]\ttraining's rmse: 1.27064\tvalid_1's rmse: 59.4911\n",
      "[1800]\ttraining's rmse: 1.2118\tvalid_1's rmse: 59.4906\n",
      "[1830]\ttraining's rmse: 1.15726\tvalid_1's rmse: 59.49\n",
      "[1860]\ttraining's rmse: 1.10297\tvalid_1's rmse: 59.4907\n",
      "[1890]\ttraining's rmse: 1.05288\tvalid_1's rmse: 59.4864\n",
      "[1920]\ttraining's rmse: 1.00633\tvalid_1's rmse: 59.4866\n",
      "[1950]\ttraining's rmse: 0.960312\tvalid_1's rmse: 59.4838\n",
      "[1980]\ttraining's rmse: 0.91706\tvalid_1's rmse: 59.484\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's rmse: 0.889653\tvalid_1's rmse: 59.4829\n",
      "10\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002554 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 20020\n",
      "[LightGBM] [Info] Number of data points in the train set: 9219, number of used features: 79\n",
      "[LightGBM] [Info] Start training from score 382.639352\n",
      "Training until validation scores don't improve for 125 rounds\n",
      "[30]\ttraining's rmse: 169.34\tvalid_1's rmse: 174.996\n",
      "[60]\ttraining's rmse: 103.313\tvalid_1's rmse: 111.87\n",
      "[90]\ttraining's rmse: 67.6119\tvalid_1's rmse: 79.8472\n",
      "[120]\ttraining's rmse: 48.1952\tvalid_1's rmse: 64.6845\n",
      "[150]\ttraining's rmse: 37.7365\tvalid_1's rmse: 57.5879\n",
      "[180]\ttraining's rmse: 31.6578\tvalid_1's rmse: 54.2224\n",
      "[210]\ttraining's rmse: 27.6158\tvalid_1's rmse: 52.2424\n",
      "[240]\ttraining's rmse: 24.5314\tvalid_1's rmse: 51.0518\n",
      "[270]\ttraining's rmse: 22.1077\tvalid_1's rmse: 50.265\n",
      "[300]\ttraining's rmse: 20.1273\tvalid_1's rmse: 49.7929\n",
      "[330]\ttraining's rmse: 18.4629\tvalid_1's rmse: 49.5207\n",
      "[360]\ttraining's rmse: 17.0115\tvalid_1's rmse: 49.2799\n",
      "[390]\ttraining's rmse: 15.694\tvalid_1's rmse: 49.0781\n",
      "[420]\ttraining's rmse: 14.5783\tvalid_1's rmse: 48.9383\n",
      "[450]\ttraining's rmse: 13.5302\tvalid_1's rmse: 48.8291\n",
      "[480]\ttraining's rmse: 12.5993\tvalid_1's rmse: 48.726\n",
      "[510]\ttraining's rmse: 11.7348\tvalid_1's rmse: 48.6582\n",
      "[540]\ttraining's rmse: 10.9728\tvalid_1's rmse: 48.5873\n",
      "[570]\ttraining's rmse: 10.2805\tvalid_1's rmse: 48.521\n",
      "[600]\ttraining's rmse: 9.62951\tvalid_1's rmse: 48.4536\n",
      "[630]\ttraining's rmse: 9.01847\tvalid_1's rmse: 48.387\n",
      "[660]\ttraining's rmse: 8.46958\tvalid_1's rmse: 48.3434\n",
      "[690]\ttraining's rmse: 7.95785\tvalid_1's rmse: 48.2984\n",
      "[720]\ttraining's rmse: 7.48217\tvalid_1's rmse: 48.271\n",
      "[750]\ttraining's rmse: 7.05458\tvalid_1's rmse: 48.2298\n",
      "[780]\ttraining's rmse: 6.65121\tvalid_1's rmse: 48.2165\n",
      "[810]\ttraining's rmse: 6.27064\tvalid_1's rmse: 48.1934\n",
      "[840]\ttraining's rmse: 5.91092\tvalid_1's rmse: 48.1708\n",
      "[870]\ttraining's rmse: 5.58193\tvalid_1's rmse: 48.1576\n",
      "[900]\ttraining's rmse: 5.27084\tvalid_1's rmse: 48.1451\n",
      "[930]\ttraining's rmse: 4.97928\tvalid_1's rmse: 48.1273\n",
      "[960]\ttraining's rmse: 4.70837\tvalid_1's rmse: 48.1105\n",
      "[990]\ttraining's rmse: 4.44638\tvalid_1's rmse: 48.106\n",
      "[1020]\ttraining's rmse: 4.21075\tvalid_1's rmse: 48.0953\n",
      "[1050]\ttraining's rmse: 3.98745\tvalid_1's rmse: 48.0878\n",
      "[1080]\ttraining's rmse: 3.77622\tvalid_1's rmse: 48.0727\n",
      "[1110]\ttraining's rmse: 3.57525\tvalid_1's rmse: 48.0724\n",
      "[1140]\ttraining's rmse: 3.38829\tvalid_1's rmse: 48.0693\n",
      "[1170]\ttraining's rmse: 3.20661\tvalid_1's rmse: 48.0664\n",
      "[1200]\ttraining's rmse: 3.03813\tvalid_1's rmse: 48.0573\n",
      "[1230]\ttraining's rmse: 2.8813\tvalid_1's rmse: 48.0563\n",
      "[1260]\ttraining's rmse: 2.73451\tvalid_1's rmse: 48.0506\n",
      "[1290]\ttraining's rmse: 2.59572\tvalid_1's rmse: 48.0466\n",
      "[1320]\ttraining's rmse: 2.46632\tvalid_1's rmse: 48.0464\n",
      "[1350]\ttraining's rmse: 2.33943\tvalid_1's rmse: 48.0402\n",
      "[1380]\ttraining's rmse: 2.22265\tvalid_1's rmse: 48.0361\n",
      "[1410]\ttraining's rmse: 2.10888\tvalid_1's rmse: 48.0309\n",
      "[1440]\ttraining's rmse: 2.00697\tvalid_1's rmse: 48.0261\n",
      "[1470]\ttraining's rmse: 1.90385\tvalid_1's rmse: 48.0197\n",
      "[1500]\ttraining's rmse: 1.81135\tvalid_1's rmse: 48.0159\n",
      "[1530]\ttraining's rmse: 1.72\tvalid_1's rmse: 48.0146\n",
      "[1560]\ttraining's rmse: 1.6334\tvalid_1's rmse: 48.01\n",
      "[1590]\ttraining's rmse: 1.55316\tvalid_1's rmse: 48.0053\n",
      "[1620]\ttraining's rmse: 1.47651\tvalid_1's rmse: 48.0064\n",
      "[1650]\ttraining's rmse: 1.40612\tvalid_1's rmse: 48.0052\n",
      "[1680]\ttraining's rmse: 1.33855\tvalid_1's rmse: 48.0068\n",
      "[1710]\ttraining's rmse: 1.27324\tvalid_1's rmse: 48.0024\n",
      "[1740]\ttraining's rmse: 1.21084\tvalid_1's rmse: 47.9999\n",
      "[1770]\ttraining's rmse: 1.15329\tvalid_1's rmse: 47.999\n",
      "[1800]\ttraining's rmse: 1.09786\tvalid_1's rmse: 47.999\n",
      "[1830]\ttraining's rmse: 1.04405\tvalid_1's rmse: 47.9987\n",
      "[1860]\ttraining's rmse: 0.992856\tvalid_1's rmse: 48.0003\n",
      "Early stopping, best iteration is:\n",
      "[1759]\ttraining's rmse: 1.1741\tvalid_1's rmse: 47.9982\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003339 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 20020\n",
      "[LightGBM] [Info] Number of data points in the train set: 9219, number of used features: 79\n",
      "[LightGBM] [Info] Start training from score 381.134788\n",
      "Training until validation scores don't improve for 125 rounds\n",
      "[30]\ttraining's rmse: 172.064\tvalid_1's rmse: 175.982\n",
      "[60]\ttraining's rmse: 106.558\tvalid_1's rmse: 116.935\n",
      "[90]\ttraining's rmse: 70.9251\tvalid_1's rmse: 87.6299\n",
      "[120]\ttraining's rmse: 51.6155\tvalid_1's rmse: 74.1686\n",
      "[150]\ttraining's rmse: 40.9308\tvalid_1's rmse: 67.697\n",
      "[180]\ttraining's rmse: 34.4254\tvalid_1's rmse: 64.5252\n",
      "[210]\ttraining's rmse: 30.0036\tvalid_1's rmse: 62.6215\n",
      "[240]\ttraining's rmse: 26.7027\tvalid_1's rmse: 61.4818\n",
      "[270]\ttraining's rmse: 24.0445\tvalid_1's rmse: 60.8116\n",
      "[300]\ttraining's rmse: 21.8013\tvalid_1's rmse: 60.3009\n",
      "[330]\ttraining's rmse: 19.9121\tvalid_1's rmse: 59.952\n",
      "[360]\ttraining's rmse: 18.3218\tvalid_1's rmse: 59.6992\n",
      "[390]\ttraining's rmse: 16.8806\tvalid_1's rmse: 59.4859\n",
      "[420]\ttraining's rmse: 15.5949\tvalid_1's rmse: 59.3088\n",
      "[450]\ttraining's rmse: 14.4462\tvalid_1's rmse: 59.1708\n",
      "[480]\ttraining's rmse: 13.415\tvalid_1's rmse: 59.0756\n",
      "[510]\ttraining's rmse: 12.4911\tvalid_1's rmse: 58.9495\n",
      "[540]\ttraining's rmse: 11.6481\tvalid_1's rmse: 58.9063\n",
      "[570]\ttraining's rmse: 10.8881\tvalid_1's rmse: 58.8468\n",
      "[600]\ttraining's rmse: 10.1885\tvalid_1's rmse: 58.7854\n",
      "[630]\ttraining's rmse: 9.53881\tvalid_1's rmse: 58.7271\n",
      "[660]\ttraining's rmse: 8.94078\tvalid_1's rmse: 58.6586\n",
      "[690]\ttraining's rmse: 8.39694\tvalid_1's rmse: 58.6216\n",
      "[720]\ttraining's rmse: 7.89093\tvalid_1's rmse: 58.5994\n",
      "[750]\ttraining's rmse: 7.42675\tvalid_1's rmse: 58.5554\n",
      "[780]\ttraining's rmse: 6.98699\tvalid_1's rmse: 58.519\n",
      "[810]\ttraining's rmse: 6.56961\tvalid_1's rmse: 58.4861\n",
      "[840]\ttraining's rmse: 6.19643\tvalid_1's rmse: 58.4505\n",
      "[870]\ttraining's rmse: 5.84104\tvalid_1's rmse: 58.4226\n",
      "[900]\ttraining's rmse: 5.50518\tvalid_1's rmse: 58.4011\n",
      "[930]\ttraining's rmse: 5.19318\tvalid_1's rmse: 58.3768\n",
      "[960]\ttraining's rmse: 4.90453\tvalid_1's rmse: 58.3502\n",
      "[990]\ttraining's rmse: 4.63026\tvalid_1's rmse: 58.3376\n",
      "[1020]\ttraining's rmse: 4.3721\tvalid_1's rmse: 58.3236\n",
      "[1050]\ttraining's rmse: 4.13046\tvalid_1's rmse: 58.3086\n",
      "[1080]\ttraining's rmse: 3.90731\tvalid_1's rmse: 58.2939\n",
      "[1110]\ttraining's rmse: 3.69792\tvalid_1's rmse: 58.2817\n",
      "[1140]\ttraining's rmse: 3.50045\tvalid_1's rmse: 58.2733\n",
      "[1170]\ttraining's rmse: 3.311\tvalid_1's rmse: 58.2561\n",
      "[1200]\ttraining's rmse: 3.13542\tvalid_1's rmse: 58.2523\n",
      "[1230]\ttraining's rmse: 2.97577\tvalid_1's rmse: 58.2427\n",
      "[1260]\ttraining's rmse: 2.8182\tvalid_1's rmse: 58.2377\n",
      "[1290]\ttraining's rmse: 2.67072\tvalid_1's rmse: 58.2307\n",
      "[1320]\ttraining's rmse: 2.53195\tvalid_1's rmse: 58.2218\n",
      "[1350]\ttraining's rmse: 2.40384\tvalid_1's rmse: 58.2148\n",
      "[1380]\ttraining's rmse: 2.283\tvalid_1's rmse: 58.2079\n",
      "[1410]\ttraining's rmse: 2.16937\tvalid_1's rmse: 58.201\n",
      "[1440]\ttraining's rmse: 2.05883\tvalid_1's rmse: 58.1922\n",
      "[1470]\ttraining's rmse: 1.95427\tvalid_1's rmse: 58.1884\n",
      "[1500]\ttraining's rmse: 1.8551\tvalid_1's rmse: 58.1839\n",
      "[1530]\ttraining's rmse: 1.76069\tvalid_1's rmse: 58.1784\n",
      "[1560]\ttraining's rmse: 1.67123\tvalid_1's rmse: 58.1735\n",
      "[1590]\ttraining's rmse: 1.58824\tvalid_1's rmse: 58.1705\n",
      "[1620]\ttraining's rmse: 1.50843\tvalid_1's rmse: 58.1679\n",
      "[1650]\ttraining's rmse: 1.43239\tvalid_1's rmse: 58.1654\n",
      "[1680]\ttraining's rmse: 1.36159\tvalid_1's rmse: 58.1629\n",
      "[1710]\ttraining's rmse: 1.2944\tvalid_1's rmse: 58.1605\n",
      "[1740]\ttraining's rmse: 1.23017\tvalid_1's rmse: 58.1583\n",
      "[1770]\ttraining's rmse: 1.16977\tvalid_1's rmse: 58.1564\n",
      "[1800]\ttraining's rmse: 1.11367\tvalid_1's rmse: 58.1544\n",
      "[1830]\ttraining's rmse: 1.05944\tvalid_1's rmse: 58.1521\n",
      "[1860]\ttraining's rmse: 1.007\tvalid_1's rmse: 58.1517\n",
      "[1890]\ttraining's rmse: 0.958065\tvalid_1's rmse: 58.1499\n",
      "[1920]\ttraining's rmse: 0.911485\tvalid_1's rmse: 58.1491\n",
      "[1950]\ttraining's rmse: 0.867896\tvalid_1's rmse: 58.1461\n",
      "[1980]\ttraining's rmse: 0.826775\tvalid_1's rmse: 58.1445\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's rmse: 0.800482\tvalid_1's rmse: 58.1442\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002476 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 20020\n",
      "[LightGBM] [Info] Number of data points in the train set: 9219, number of used features: 79\n",
      "[LightGBM] [Info] Start training from score 379.459898\n",
      "Training until validation scores don't improve for 125 rounds\n",
      "[30]\ttraining's rmse: 171.188\tvalid_1's rmse: 176.788\n",
      "[60]\ttraining's rmse: 105.145\tvalid_1's rmse: 115.721\n",
      "[90]\ttraining's rmse: 69.1974\tvalid_1's rmse: 85.1418\n",
      "[120]\ttraining's rmse: 50.0522\tvalid_1's rmse: 70.8534\n",
      "[150]\ttraining's rmse: 39.4959\tvalid_1's rmse: 64.1073\n",
      "[180]\ttraining's rmse: 33.1327\tvalid_1's rmse: 60.5939\n",
      "[210]\ttraining's rmse: 28.9823\tvalid_1's rmse: 58.6832\n",
      "[240]\ttraining's rmse: 25.8182\tvalid_1's rmse: 57.5624\n",
      "[270]\ttraining's rmse: 23.3163\tvalid_1's rmse: 56.8567\n",
      "[300]\ttraining's rmse: 21.1717\tvalid_1's rmse: 56.274\n",
      "[330]\ttraining's rmse: 19.3651\tvalid_1's rmse: 55.8194\n",
      "[360]\ttraining's rmse: 17.8392\tvalid_1's rmse: 55.5497\n",
      "[390]\ttraining's rmse: 16.4471\tvalid_1's rmse: 55.3063\n",
      "[420]\ttraining's rmse: 15.2219\tvalid_1's rmse: 55.0648\n",
      "[450]\ttraining's rmse: 14.1197\tvalid_1's rmse: 54.8695\n",
      "[480]\ttraining's rmse: 13.1236\tvalid_1's rmse: 54.7066\n",
      "[510]\ttraining's rmse: 12.2129\tvalid_1's rmse: 54.5627\n",
      "[540]\ttraining's rmse: 11.4022\tvalid_1's rmse: 54.462\n",
      "[570]\ttraining's rmse: 10.6475\tvalid_1's rmse: 54.3175\n",
      "[600]\ttraining's rmse: 9.96575\tvalid_1's rmse: 54.2228\n",
      "[630]\ttraining's rmse: 9.32879\tvalid_1's rmse: 54.1412\n",
      "[660]\ttraining's rmse: 8.74968\tvalid_1's rmse: 54.0757\n",
      "[690]\ttraining's rmse: 8.21818\tvalid_1's rmse: 54.0222\n",
      "[720]\ttraining's rmse: 7.72136\tvalid_1's rmse: 53.9745\n",
      "[750]\ttraining's rmse: 7.25662\tvalid_1's rmse: 53.9103\n",
      "[780]\ttraining's rmse: 6.83165\tvalid_1's rmse: 53.8717\n",
      "[810]\ttraining's rmse: 6.4238\tvalid_1's rmse: 53.8285\n",
      "[840]\ttraining's rmse: 6.05658\tvalid_1's rmse: 53.7926\n",
      "[870]\ttraining's rmse: 5.70558\tvalid_1's rmse: 53.7605\n",
      "[900]\ttraining's rmse: 5.38025\tvalid_1's rmse: 53.7339\n",
      "[930]\ttraining's rmse: 5.07627\tvalid_1's rmse: 53.7076\n",
      "[960]\ttraining's rmse: 4.78783\tvalid_1's rmse: 53.6855\n",
      "[990]\ttraining's rmse: 4.52912\tvalid_1's rmse: 53.6667\n",
      "[1020]\ttraining's rmse: 4.28034\tvalid_1's rmse: 53.6557\n",
      "[1050]\ttraining's rmse: 4.04753\tvalid_1's rmse: 53.6447\n",
      "[1080]\ttraining's rmse: 3.83275\tvalid_1's rmse: 53.6281\n",
      "[1110]\ttraining's rmse: 3.62426\tvalid_1's rmse: 53.6082\n",
      "[1140]\ttraining's rmse: 3.43765\tvalid_1's rmse: 53.5987\n",
      "[1170]\ttraining's rmse: 3.25724\tvalid_1's rmse: 53.584\n",
      "[1200]\ttraining's rmse: 3.08539\tvalid_1's rmse: 53.5726\n",
      "[1230]\ttraining's rmse: 2.92096\tvalid_1's rmse: 53.5633\n",
      "[1260]\ttraining's rmse: 2.76746\tvalid_1's rmse: 53.553\n",
      "[1290]\ttraining's rmse: 2.62414\tvalid_1's rmse: 53.5469\n",
      "[1320]\ttraining's rmse: 2.49055\tvalid_1's rmse: 53.5386\n",
      "[1350]\ttraining's rmse: 2.36672\tvalid_1's rmse: 53.5284\n",
      "[1380]\ttraining's rmse: 2.24379\tvalid_1's rmse: 53.5173\n",
      "[1410]\ttraining's rmse: 2.131\tvalid_1's rmse: 53.5111\n",
      "[1440]\ttraining's rmse: 2.02542\tvalid_1's rmse: 53.5039\n",
      "[1470]\ttraining's rmse: 1.9228\tvalid_1's rmse: 53.5015\n",
      "[1500]\ttraining's rmse: 1.82656\tvalid_1's rmse: 53.4981\n",
      "[1530]\ttraining's rmse: 1.73461\tvalid_1's rmse: 53.4912\n",
      "[1560]\ttraining's rmse: 1.64797\tvalid_1's rmse: 53.4889\n",
      "[1590]\ttraining's rmse: 1.56704\tvalid_1's rmse: 53.4855\n",
      "[1620]\ttraining's rmse: 1.49175\tvalid_1's rmse: 53.4802\n",
      "[1650]\ttraining's rmse: 1.42071\tvalid_1's rmse: 53.478\n",
      "[1680]\ttraining's rmse: 1.35215\tvalid_1's rmse: 53.4739\n",
      "[1710]\ttraining's rmse: 1.28626\tvalid_1's rmse: 53.4714\n",
      "[1740]\ttraining's rmse: 1.22443\tvalid_1's rmse: 53.4692\n",
      "[1770]\ttraining's rmse: 1.1664\tvalid_1's rmse: 53.4667\n",
      "[1800]\ttraining's rmse: 1.11089\tvalid_1's rmse: 53.4645\n",
      "[1830]\ttraining's rmse: 1.05547\tvalid_1's rmse: 53.4598\n",
      "[1860]\ttraining's rmse: 1.00571\tvalid_1's rmse: 53.4566\n",
      "[1890]\ttraining's rmse: 0.957343\tvalid_1's rmse: 53.454\n",
      "[1920]\ttraining's rmse: 0.912332\tvalid_1's rmse: 53.453\n",
      "[1950]\ttraining's rmse: 0.868804\tvalid_1's rmse: 53.4517\n",
      "[1980]\ttraining's rmse: 0.827939\tvalid_1's rmse: 53.4498\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's rmse: 0.801179\tvalid_1's rmse: 53.4492\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003028 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 20020\n",
      "[LightGBM] [Info] Number of data points in the train set: 9219, number of used features: 79\n",
      "[LightGBM] [Info] Start training from score 380.308244\n",
      "Training until validation scores don't improve for 125 rounds\n",
      "[30]\ttraining's rmse: 172.51\tvalid_1's rmse: 176.629\n",
      "[60]\ttraining's rmse: 106.232\tvalid_1's rmse: 115.415\n",
      "[90]\ttraining's rmse: 70.1312\tvalid_1's rmse: 85.0112\n",
      "[120]\ttraining's rmse: 50.7031\tvalid_1's rmse: 70.9263\n",
      "[150]\ttraining's rmse: 39.9694\tvalid_1's rmse: 64.312\n",
      "[180]\ttraining's rmse: 33.5485\tvalid_1's rmse: 60.8865\n",
      "[210]\ttraining's rmse: 29.1557\tvalid_1's rmse: 58.6728\n",
      "[240]\ttraining's rmse: 25.9198\tvalid_1's rmse: 57.3333\n",
      "[270]\ttraining's rmse: 23.3736\tvalid_1's rmse: 56.4305\n",
      "[300]\ttraining's rmse: 21.252\tvalid_1's rmse: 55.7305\n",
      "[330]\ttraining's rmse: 19.4372\tvalid_1's rmse: 55.2787\n",
      "[360]\ttraining's rmse: 17.9054\tvalid_1's rmse: 54.8604\n",
      "[390]\ttraining's rmse: 16.56\tvalid_1's rmse: 54.5391\n",
      "[420]\ttraining's rmse: 15.3334\tvalid_1's rmse: 54.3202\n",
      "[450]\ttraining's rmse: 14.214\tvalid_1's rmse: 54.1104\n",
      "[480]\ttraining's rmse: 13.2067\tvalid_1's rmse: 53.9203\n",
      "[510]\ttraining's rmse: 12.2943\tvalid_1's rmse: 53.7732\n",
      "[540]\ttraining's rmse: 11.4744\tvalid_1's rmse: 53.6317\n",
      "[570]\ttraining's rmse: 10.7129\tvalid_1's rmse: 53.5329\n",
      "[600]\ttraining's rmse: 10.0179\tvalid_1's rmse: 53.4422\n",
      "[630]\ttraining's rmse: 9.38351\tvalid_1's rmse: 53.335\n",
      "[660]\ttraining's rmse: 8.78604\tvalid_1's rmse: 53.268\n",
      "[690]\ttraining's rmse: 8.2534\tvalid_1's rmse: 53.1713\n",
      "[720]\ttraining's rmse: 7.75844\tvalid_1's rmse: 53.1318\n",
      "[750]\ttraining's rmse: 7.29096\tvalid_1's rmse: 53.0808\n",
      "[780]\ttraining's rmse: 6.85995\tvalid_1's rmse: 53.0379\n",
      "[810]\ttraining's rmse: 6.45939\tvalid_1's rmse: 52.9944\n",
      "[840]\ttraining's rmse: 6.08901\tvalid_1's rmse: 52.9635\n",
      "[870]\ttraining's rmse: 5.74588\tvalid_1's rmse: 52.9297\n",
      "[900]\ttraining's rmse: 5.42738\tvalid_1's rmse: 52.8909\n",
      "[930]\ttraining's rmse: 5.12498\tvalid_1's rmse: 52.8633\n",
      "[960]\ttraining's rmse: 4.84392\tvalid_1's rmse: 52.8295\n",
      "[990]\ttraining's rmse: 4.57908\tvalid_1's rmse: 52.8092\n",
      "[1020]\ttraining's rmse: 4.33085\tvalid_1's rmse: 52.7915\n",
      "[1050]\ttraining's rmse: 4.09246\tvalid_1's rmse: 52.7744\n",
      "[1080]\ttraining's rmse: 3.87367\tvalid_1's rmse: 52.7585\n",
      "[1110]\ttraining's rmse: 3.6652\tvalid_1's rmse: 52.7517\n",
      "[1140]\ttraining's rmse: 3.46895\tvalid_1's rmse: 52.7428\n",
      "[1170]\ttraining's rmse: 3.28668\tvalid_1's rmse: 52.7291\n",
      "[1200]\ttraining's rmse: 3.11034\tvalid_1's rmse: 52.713\n",
      "[1230]\ttraining's rmse: 2.94518\tvalid_1's rmse: 52.7044\n",
      "[1260]\ttraining's rmse: 2.79154\tvalid_1's rmse: 52.6976\n",
      "[1290]\ttraining's rmse: 2.64215\tvalid_1's rmse: 52.6888\n",
      "[1320]\ttraining's rmse: 2.50474\tvalid_1's rmse: 52.6872\n",
      "[1350]\ttraining's rmse: 2.37682\tvalid_1's rmse: 52.6804\n",
      "[1380]\ttraining's rmse: 2.25801\tvalid_1's rmse: 52.6737\n",
      "[1410]\ttraining's rmse: 2.14642\tvalid_1's rmse: 52.666\n",
      "[1440]\ttraining's rmse: 2.0406\tvalid_1's rmse: 52.6605\n",
      "[1470]\ttraining's rmse: 1.93973\tvalid_1's rmse: 52.6574\n",
      "[1500]\ttraining's rmse: 1.84126\tvalid_1's rmse: 52.6502\n",
      "[1530]\ttraining's rmse: 1.75118\tvalid_1's rmse: 52.6475\n",
      "[1560]\ttraining's rmse: 1.6619\tvalid_1's rmse: 52.6397\n",
      "[1590]\ttraining's rmse: 1.57967\tvalid_1's rmse: 52.6366\n",
      "[1620]\ttraining's rmse: 1.50485\tvalid_1's rmse: 52.6318\n",
      "[1650]\ttraining's rmse: 1.43167\tvalid_1's rmse: 52.628\n",
      "[1680]\ttraining's rmse: 1.36319\tvalid_1's rmse: 52.6256\n",
      "[1710]\ttraining's rmse: 1.29691\tvalid_1's rmse: 52.6215\n",
      "[1740]\ttraining's rmse: 1.23398\tvalid_1's rmse: 52.6191\n",
      "[1770]\ttraining's rmse: 1.1738\tvalid_1's rmse: 52.6191\n",
      "[1800]\ttraining's rmse: 1.11828\tvalid_1's rmse: 52.6164\n",
      "[1830]\ttraining's rmse: 1.06456\tvalid_1's rmse: 52.6143\n",
      "[1860]\ttraining's rmse: 1.01448\tvalid_1's rmse: 52.6118\n",
      "[1890]\ttraining's rmse: 0.965747\tvalid_1's rmse: 52.6099\n",
      "[1920]\ttraining's rmse: 0.919429\tvalid_1's rmse: 52.6079\n",
      "[1950]\ttraining's rmse: 0.877459\tvalid_1's rmse: 52.6062\n",
      "[1980]\ttraining's rmse: 0.835583\tvalid_1's rmse: 52.6051\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's rmse: 0.809394\tvalid_1's rmse: 52.6031\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002975 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 20020\n",
      "[LightGBM] [Info] Number of data points in the train set: 9219, number of used features: 79\n",
      "[LightGBM] [Info] Start training from score 379.856393\n",
      "Training until validation scores don't improve for 125 rounds\n",
      "[30]\ttraining's rmse: 173.833\tvalid_1's rmse: 172.536\n",
      "[60]\ttraining's rmse: 106.926\tvalid_1's rmse: 113.848\n",
      "[90]\ttraining's rmse: 70.6668\tvalid_1's rmse: 84.2243\n",
      "[120]\ttraining's rmse: 51.2549\tvalid_1's rmse: 70.2631\n",
      "[150]\ttraining's rmse: 40.4458\tvalid_1's rmse: 63.4264\n",
      "[180]\ttraining's rmse: 34.0578\tvalid_1's rmse: 60.0382\n",
      "[210]\ttraining's rmse: 29.7021\tvalid_1's rmse: 57.9724\n",
      "[240]\ttraining's rmse: 26.4956\tvalid_1's rmse: 56.7514\n",
      "[270]\ttraining's rmse: 23.8584\tvalid_1's rmse: 55.89\n",
      "[300]\ttraining's rmse: 21.6977\tvalid_1's rmse: 55.233\n",
      "[330]\ttraining's rmse: 19.8565\tvalid_1's rmse: 54.8498\n",
      "[360]\ttraining's rmse: 18.2763\tvalid_1's rmse: 54.5481\n",
      "[390]\ttraining's rmse: 16.8605\tvalid_1's rmse: 54.203\n",
      "[420]\ttraining's rmse: 15.6116\tvalid_1's rmse: 53.992\n",
      "[450]\ttraining's rmse: 14.4717\tvalid_1's rmse: 53.8299\n",
      "[480]\ttraining's rmse: 13.4427\tvalid_1's rmse: 53.6536\n",
      "[510]\ttraining's rmse: 12.5211\tvalid_1's rmse: 53.5312\n",
      "[540]\ttraining's rmse: 11.6979\tvalid_1's rmse: 53.4533\n",
      "[570]\ttraining's rmse: 10.9391\tvalid_1's rmse: 53.3925\n",
      "[600]\ttraining's rmse: 10.2478\tvalid_1's rmse: 53.327\n",
      "[630]\ttraining's rmse: 9.59575\tvalid_1's rmse: 53.2795\n",
      "[660]\ttraining's rmse: 9.00442\tvalid_1's rmse: 53.2149\n",
      "[690]\ttraining's rmse: 8.4716\tvalid_1's rmse: 53.1476\n",
      "[720]\ttraining's rmse: 7.96239\tvalid_1's rmse: 53.1004\n",
      "[750]\ttraining's rmse: 7.49852\tvalid_1's rmse: 53.0559\n",
      "[780]\ttraining's rmse: 7.07163\tvalid_1's rmse: 53.0395\n",
      "[810]\ttraining's rmse: 6.67194\tvalid_1's rmse: 53.0158\n",
      "[840]\ttraining's rmse: 6.28911\tvalid_1's rmse: 52.9891\n",
      "[870]\ttraining's rmse: 5.94922\tvalid_1's rmse: 52.9748\n",
      "[900]\ttraining's rmse: 5.61772\tvalid_1's rmse: 52.9579\n",
      "[930]\ttraining's rmse: 5.30764\tvalid_1's rmse: 52.9459\n",
      "[960]\ttraining's rmse: 5.01309\tvalid_1's rmse: 52.9391\n",
      "[990]\ttraining's rmse: 4.74447\tvalid_1's rmse: 52.9163\n",
      "[1020]\ttraining's rmse: 4.49412\tvalid_1's rmse: 52.9069\n",
      "[1050]\ttraining's rmse: 4.25682\tvalid_1's rmse: 52.8966\n",
      "[1080]\ttraining's rmse: 4.02897\tvalid_1's rmse: 52.8814\n",
      "[1110]\ttraining's rmse: 3.8202\tvalid_1's rmse: 52.8737\n",
      "[1140]\ttraining's rmse: 3.62184\tvalid_1's rmse: 52.8697\n",
      "[1170]\ttraining's rmse: 3.43605\tvalid_1's rmse: 52.8693\n",
      "[1200]\ttraining's rmse: 3.2625\tvalid_1's rmse: 52.8592\n",
      "[1230]\ttraining's rmse: 3.09475\tvalid_1's rmse: 52.85\n",
      "[1260]\ttraining's rmse: 2.93479\tvalid_1's rmse: 52.8412\n",
      "[1290]\ttraining's rmse: 2.78722\tvalid_1's rmse: 52.8388\n",
      "[1320]\ttraining's rmse: 2.64845\tvalid_1's rmse: 52.8348\n",
      "[1350]\ttraining's rmse: 2.51997\tvalid_1's rmse: 52.8345\n",
      "[1380]\ttraining's rmse: 2.39578\tvalid_1's rmse: 52.8299\n",
      "[1410]\ttraining's rmse: 2.27919\tvalid_1's rmse: 52.8267\n",
      "[1440]\ttraining's rmse: 2.16783\tvalid_1's rmse: 52.8247\n",
      "[1470]\ttraining's rmse: 2.06159\tvalid_1's rmse: 52.8218\n",
      "[1500]\ttraining's rmse: 1.96145\tvalid_1's rmse: 52.8224\n",
      "[1530]\ttraining's rmse: 1.86851\tvalid_1's rmse: 52.8192\n",
      "[1560]\ttraining's rmse: 1.77635\tvalid_1's rmse: 52.8148\n",
      "[1590]\ttraining's rmse: 1.69154\tvalid_1's rmse: 52.8115\n",
      "[1620]\ttraining's rmse: 1.61141\tvalid_1's rmse: 52.8096\n",
      "[1650]\ttraining's rmse: 1.53589\tvalid_1's rmse: 52.8078\n",
      "[1680]\ttraining's rmse: 1.46309\tvalid_1's rmse: 52.8066\n",
      "[1710]\ttraining's rmse: 1.39402\tvalid_1's rmse: 52.8039\n",
      "[1740]\ttraining's rmse: 1.33034\tvalid_1's rmse: 52.7998\n",
      "[1770]\ttraining's rmse: 1.26957\tvalid_1's rmse: 52.799\n",
      "[1800]\ttraining's rmse: 1.21094\tvalid_1's rmse: 52.7987\n",
      "[1830]\ttraining's rmse: 1.15547\tvalid_1's rmse: 52.801\n",
      "[1860]\ttraining's rmse: 1.10331\tvalid_1's rmse: 52.7997\n",
      "[1890]\ttraining's rmse: 1.05246\tvalid_1's rmse: 52.7983\n",
      "Early stopping, best iteration is:\n",
      "[1793]\ttraining's rmse: 1.22503\tvalid_1's rmse: 52.7978\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002246 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 20020\n",
      "[LightGBM] [Info] Number of data points in the train set: 9219, number of used features: 79\n",
      "[LightGBM] [Info] Start training from score 387.720243\n",
      "Training until validation scores don't improve for 125 rounds\n",
      "[30]\ttraining's rmse: 177.254\tvalid_1's rmse: 175.049\n",
      "[60]\ttraining's rmse: 108.993\tvalid_1's rmse: 114.39\n",
      "[90]\ttraining's rmse: 71.8959\tvalid_1's rmse: 83.457\n",
      "[120]\ttraining's rmse: 51.9055\tvalid_1's rmse: 68.5306\n",
      "[150]\ttraining's rmse: 40.8167\tvalid_1's rmse: 61.3634\n",
      "[180]\ttraining's rmse: 34.2182\tvalid_1's rmse: 57.9788\n",
      "[210]\ttraining's rmse: 29.735\tvalid_1's rmse: 55.9902\n",
      "[240]\ttraining's rmse: 26.4245\tvalid_1's rmse: 54.9311\n",
      "[270]\ttraining's rmse: 23.7694\tvalid_1's rmse: 54.1455\n",
      "[300]\ttraining's rmse: 21.5951\tvalid_1's rmse: 53.6647\n",
      "[330]\ttraining's rmse: 19.7597\tvalid_1's rmse: 53.2774\n",
      "[360]\ttraining's rmse: 18.116\tvalid_1's rmse: 52.9791\n",
      "[390]\ttraining's rmse: 16.7442\tvalid_1's rmse: 52.7715\n",
      "[420]\ttraining's rmse: 15.5258\tvalid_1's rmse: 52.5552\n",
      "[450]\ttraining's rmse: 14.4196\tvalid_1's rmse: 52.3626\n",
      "[480]\ttraining's rmse: 13.3812\tvalid_1's rmse: 52.2374\n",
      "[510]\ttraining's rmse: 12.4801\tvalid_1's rmse: 52.1197\n",
      "[540]\ttraining's rmse: 11.6588\tvalid_1's rmse: 52.0135\n",
      "[570]\ttraining's rmse: 10.9185\tvalid_1's rmse: 51.9094\n",
      "[600]\ttraining's rmse: 10.2309\tvalid_1's rmse: 51.8419\n",
      "[630]\ttraining's rmse: 9.59923\tvalid_1's rmse: 51.8156\n",
      "[660]\ttraining's rmse: 9.00163\tvalid_1's rmse: 51.7309\n",
      "[690]\ttraining's rmse: 8.46036\tvalid_1's rmse: 51.6773\n",
      "[720]\ttraining's rmse: 7.95721\tvalid_1's rmse: 51.6153\n",
      "[750]\ttraining's rmse: 7.49476\tvalid_1's rmse: 51.5693\n",
      "[780]\ttraining's rmse: 7.06699\tvalid_1's rmse: 51.5253\n",
      "[810]\ttraining's rmse: 6.66021\tvalid_1's rmse: 51.5018\n",
      "[840]\ttraining's rmse: 6.28783\tvalid_1's rmse: 51.4754\n",
      "[870]\ttraining's rmse: 5.94271\tvalid_1's rmse: 51.4455\n",
      "[900]\ttraining's rmse: 5.62132\tvalid_1's rmse: 51.4116\n",
      "[930]\ttraining's rmse: 5.31882\tvalid_1's rmse: 51.3918\n",
      "[960]\ttraining's rmse: 5.03095\tvalid_1's rmse: 51.3853\n",
      "[990]\ttraining's rmse: 4.75627\tvalid_1's rmse: 51.359\n",
      "[1020]\ttraining's rmse: 4.50292\tvalid_1's rmse: 51.3349\n",
      "[1050]\ttraining's rmse: 4.26767\tvalid_1's rmse: 51.3161\n",
      "[1080]\ttraining's rmse: 4.04351\tvalid_1's rmse: 51.3034\n",
      "[1110]\ttraining's rmse: 3.83469\tvalid_1's rmse: 51.2811\n",
      "[1140]\ttraining's rmse: 3.6373\tvalid_1's rmse: 51.2662\n",
      "[1170]\ttraining's rmse: 3.45766\tvalid_1's rmse: 51.2573\n",
      "[1200]\ttraining's rmse: 3.28356\tvalid_1's rmse: 51.2426\n",
      "[1230]\ttraining's rmse: 3.11507\tvalid_1's rmse: 51.2316\n",
      "[1260]\ttraining's rmse: 2.95939\tvalid_1's rmse: 51.2293\n",
      "[1290]\ttraining's rmse: 2.81407\tvalid_1's rmse: 51.2167\n",
      "[1320]\ttraining's rmse: 2.67617\tvalid_1's rmse: 51.2112\n",
      "[1350]\ttraining's rmse: 2.54406\tvalid_1's rmse: 51.2034\n",
      "[1380]\ttraining's rmse: 2.41948\tvalid_1's rmse: 51.1973\n",
      "[1410]\ttraining's rmse: 2.3019\tvalid_1's rmse: 51.1898\n",
      "[1440]\ttraining's rmse: 2.19153\tvalid_1's rmse: 51.1829\n",
      "[1470]\ttraining's rmse: 2.08672\tvalid_1's rmse: 51.1754\n",
      "[1500]\ttraining's rmse: 1.98651\tvalid_1's rmse: 51.1753\n",
      "[1530]\ttraining's rmse: 1.89331\tvalid_1's rmse: 51.1697\n",
      "[1560]\ttraining's rmse: 1.80413\tvalid_1's rmse: 51.1671\n",
      "[1590]\ttraining's rmse: 1.71881\tvalid_1's rmse: 51.1644\n",
      "[1620]\ttraining's rmse: 1.63859\tvalid_1's rmse: 51.1608\n",
      "[1650]\ttraining's rmse: 1.56491\tvalid_1's rmse: 51.1576\n",
      "[1680]\ttraining's rmse: 1.49286\tvalid_1's rmse: 51.1515\n",
      "[1710]\ttraining's rmse: 1.42268\tvalid_1's rmse: 51.1432\n",
      "[1740]\ttraining's rmse: 1.35839\tvalid_1's rmse: 51.1392\n",
      "[1770]\ttraining's rmse: 1.297\tvalid_1's rmse: 51.1371\n",
      "[1800]\ttraining's rmse: 1.24007\tvalid_1's rmse: 51.1373\n",
      "[1830]\ttraining's rmse: 1.18348\tvalid_1's rmse: 51.1357\n",
      "[1860]\ttraining's rmse: 1.13057\tvalid_1's rmse: 51.1326\n",
      "[1890]\ttraining's rmse: 1.08007\tvalid_1's rmse: 51.1314\n",
      "[1920]\ttraining's rmse: 1.03221\tvalid_1's rmse: 51.1283\n",
      "[1950]\ttraining's rmse: 0.986048\tvalid_1's rmse: 51.126\n",
      "[1980]\ttraining's rmse: 0.94343\tvalid_1's rmse: 51.126\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's rmse: 0.915405\tvalid_1's rmse: 51.1246\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003869 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 20020\n",
      "[LightGBM] [Info] Number of data points in the train set: 9219, number of used features: 79\n",
      "[LightGBM] [Info] Start training from score 389.883047\n",
      "Training until validation scores don't improve for 125 rounds\n",
      "[30]\ttraining's rmse: 176.428\tvalid_1's rmse: 183.986\n",
      "[60]\ttraining's rmse: 108.545\tvalid_1's rmse: 121.741\n",
      "[90]\ttraining's rmse: 71.7277\tvalid_1's rmse: 90.0765\n",
      "[120]\ttraining's rmse: 51.8535\tvalid_1's rmse: 75.0396\n",
      "[150]\ttraining's rmse: 40.8918\tvalid_1's rmse: 67.6984\n",
      "[180]\ttraining's rmse: 34.3316\tvalid_1's rmse: 64.1997\n",
      "[210]\ttraining's rmse: 30.0037\tvalid_1's rmse: 62.0355\n",
      "[240]\ttraining's rmse: 26.7894\tvalid_1's rmse: 60.7565\n",
      "[270]\ttraining's rmse: 24.1654\tvalid_1's rmse: 59.8176\n",
      "[300]\ttraining's rmse: 21.9533\tvalid_1's rmse: 59.0233\n",
      "[330]\ttraining's rmse: 20.1412\tvalid_1's rmse: 58.5322\n",
      "[360]\ttraining's rmse: 18.5362\tvalid_1's rmse: 58.187\n",
      "[390]\ttraining's rmse: 17.1222\tvalid_1's rmse: 57.9576\n",
      "[420]\ttraining's rmse: 15.854\tvalid_1's rmse: 57.7014\n",
      "[450]\ttraining's rmse: 14.7111\tvalid_1's rmse: 57.5381\n",
      "[480]\ttraining's rmse: 13.6946\tvalid_1's rmse: 57.3971\n",
      "[510]\ttraining's rmse: 12.7646\tvalid_1's rmse: 57.2339\n",
      "[540]\ttraining's rmse: 11.9144\tvalid_1's rmse: 57.098\n",
      "[570]\ttraining's rmse: 11.1519\tvalid_1's rmse: 56.9823\n",
      "[600]\ttraining's rmse: 10.4664\tvalid_1's rmse: 56.902\n",
      "[630]\ttraining's rmse: 9.81903\tvalid_1's rmse: 56.8252\n",
      "[660]\ttraining's rmse: 9.21255\tvalid_1's rmse: 56.7609\n",
      "[690]\ttraining's rmse: 8.66071\tvalid_1's rmse: 56.7171\n",
      "[720]\ttraining's rmse: 8.14609\tvalid_1's rmse: 56.6914\n",
      "[750]\ttraining's rmse: 7.66855\tvalid_1's rmse: 56.6449\n",
      "[780]\ttraining's rmse: 7.22943\tvalid_1's rmse: 56.601\n",
      "[810]\ttraining's rmse: 6.81807\tvalid_1's rmse: 56.5671\n",
      "[840]\ttraining's rmse: 6.4309\tvalid_1's rmse: 56.5511\n",
      "[870]\ttraining's rmse: 6.08039\tvalid_1's rmse: 56.5116\n",
      "[900]\ttraining's rmse: 5.74878\tvalid_1's rmse: 56.4866\n",
      "[930]\ttraining's rmse: 5.4391\tvalid_1's rmse: 56.4628\n",
      "[960]\ttraining's rmse: 5.1391\tvalid_1's rmse: 56.4608\n",
      "[990]\ttraining's rmse: 4.86514\tvalid_1's rmse: 56.4404\n",
      "[1020]\ttraining's rmse: 4.61167\tvalid_1's rmse: 56.4052\n",
      "[1050]\ttraining's rmse: 4.37172\tvalid_1's rmse: 56.3864\n",
      "[1080]\ttraining's rmse: 4.1442\tvalid_1's rmse: 56.3686\n",
      "[1110]\ttraining's rmse: 3.92825\tvalid_1's rmse: 56.3513\n",
      "[1140]\ttraining's rmse: 3.73179\tvalid_1's rmse: 56.3463\n",
      "[1170]\ttraining's rmse: 3.54277\tvalid_1's rmse: 56.345\n",
      "[1200]\ttraining's rmse: 3.35989\tvalid_1's rmse: 56.3377\n",
      "[1230]\ttraining's rmse: 3.19084\tvalid_1's rmse: 56.3374\n",
      "[1260]\ttraining's rmse: 3.03149\tvalid_1's rmse: 56.326\n",
      "[1290]\ttraining's rmse: 2.88166\tvalid_1's rmse: 56.3192\n",
      "[1320]\ttraining's rmse: 2.73913\tvalid_1's rmse: 56.3126\n",
      "[1350]\ttraining's rmse: 2.60822\tvalid_1's rmse: 56.3063\n",
      "[1380]\ttraining's rmse: 2.48226\tvalid_1's rmse: 56.3036\n",
      "[1410]\ttraining's rmse: 2.36049\tvalid_1's rmse: 56.299\n",
      "[1440]\ttraining's rmse: 2.24773\tvalid_1's rmse: 56.295\n",
      "[1470]\ttraining's rmse: 2.14108\tvalid_1's rmse: 56.2892\n",
      "[1500]\ttraining's rmse: 2.04254\tvalid_1's rmse: 56.2808\n",
      "[1530]\ttraining's rmse: 1.94484\tvalid_1's rmse: 56.2736\n",
      "[1560]\ttraining's rmse: 1.85337\tvalid_1's rmse: 56.2693\n",
      "[1590]\ttraining's rmse: 1.76865\tvalid_1's rmse: 56.2632\n",
      "[1620]\ttraining's rmse: 1.68539\tvalid_1's rmse: 56.264\n",
      "[1650]\ttraining's rmse: 1.60989\tvalid_1's rmse: 56.261\n",
      "[1680]\ttraining's rmse: 1.53608\tvalid_1's rmse: 56.256\n",
      "[1710]\ttraining's rmse: 1.46581\tvalid_1's rmse: 56.252\n",
      "[1740]\ttraining's rmse: 1.39911\tvalid_1's rmse: 56.2499\n",
      "[1770]\ttraining's rmse: 1.33525\tvalid_1's rmse: 56.2465\n",
      "[1800]\ttraining's rmse: 1.27534\tvalid_1's rmse: 56.246\n",
      "[1830]\ttraining's rmse: 1.21858\tvalid_1's rmse: 56.2431\n",
      "[1860]\ttraining's rmse: 1.16335\tvalid_1's rmse: 56.2385\n",
      "[1890]\ttraining's rmse: 1.1135\tvalid_1's rmse: 56.2351\n",
      "[1920]\ttraining's rmse: 1.06428\tvalid_1's rmse: 56.2326\n",
      "[1950]\ttraining's rmse: 1.01801\tvalid_1's rmse: 56.2289\n",
      "[1980]\ttraining's rmse: 0.972651\tvalid_1's rmse: 56.2271\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's rmse: 0.944363\tvalid_1's rmse: 56.2256\n",
      "11\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002440 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 20019\n",
      "[LightGBM] [Info] Number of data points in the train set: 9219, number of used features: 79\n",
      "[LightGBM] [Info] Start training from score 374.552029\n",
      "Training until validation scores don't improve for 125 rounds\n",
      "[30]\ttraining's rmse: 164.865\tvalid_1's rmse: 168.141\n",
      "[60]\ttraining's rmse: 101.005\tvalid_1's rmse: 111.285\n",
      "[90]\ttraining's rmse: 66.4046\tvalid_1's rmse: 82.5314\n",
      "[120]\ttraining's rmse: 47.7676\tvalid_1's rmse: 68.765\n",
      "[150]\ttraining's rmse: 37.5879\tvalid_1's rmse: 62.1141\n",
      "[180]\ttraining's rmse: 31.6447\tvalid_1's rmse: 58.763\n",
      "[210]\ttraining's rmse: 27.5983\tvalid_1's rmse: 56.7807\n",
      "[240]\ttraining's rmse: 24.5654\tvalid_1's rmse: 55.5302\n",
      "[270]\ttraining's rmse: 22.1466\tvalid_1's rmse: 54.7256\n",
      "[300]\ttraining's rmse: 20.184\tvalid_1's rmse: 54.1237\n",
      "[330]\ttraining's rmse: 18.5192\tvalid_1's rmse: 53.8071\n",
      "[360]\ttraining's rmse: 17.0582\tvalid_1's rmse: 53.5346\n",
      "[390]\ttraining's rmse: 15.7649\tvalid_1's rmse: 53.2362\n",
      "[420]\ttraining's rmse: 14.6299\tvalid_1's rmse: 53.0548\n",
      "[450]\ttraining's rmse: 13.5876\tvalid_1's rmse: 52.9181\n",
      "[480]\ttraining's rmse: 12.6483\tvalid_1's rmse: 52.7454\n",
      "[510]\ttraining's rmse: 11.7991\tvalid_1's rmse: 52.615\n",
      "[540]\ttraining's rmse: 11.0204\tvalid_1's rmse: 52.5326\n",
      "[570]\ttraining's rmse: 10.3102\tvalid_1's rmse: 52.4302\n",
      "[600]\ttraining's rmse: 9.66648\tvalid_1's rmse: 52.3154\n",
      "[630]\ttraining's rmse: 9.08231\tvalid_1's rmse: 52.2573\n",
      "[660]\ttraining's rmse: 8.53034\tvalid_1's rmse: 52.1917\n",
      "[690]\ttraining's rmse: 8.01733\tvalid_1's rmse: 52.1383\n",
      "[720]\ttraining's rmse: 7.5629\tvalid_1's rmse: 52.0975\n",
      "[750]\ttraining's rmse: 7.12229\tvalid_1's rmse: 52.06\n",
      "[780]\ttraining's rmse: 6.71597\tvalid_1's rmse: 52.0225\n",
      "[810]\ttraining's rmse: 6.32375\tvalid_1's rmse: 51.9952\n",
      "[840]\ttraining's rmse: 5.96767\tvalid_1's rmse: 51.9629\n",
      "[870]\ttraining's rmse: 5.64046\tvalid_1's rmse: 51.9533\n",
      "[900]\ttraining's rmse: 5.33092\tvalid_1's rmse: 51.9193\n",
      "[930]\ttraining's rmse: 5.0408\tvalid_1's rmse: 51.904\n",
      "[960]\ttraining's rmse: 4.76924\tvalid_1's rmse: 51.8928\n",
      "[990]\ttraining's rmse: 4.51319\tvalid_1's rmse: 51.8836\n",
      "[1020]\ttraining's rmse: 4.27148\tvalid_1's rmse: 51.864\n",
      "[1050]\ttraining's rmse: 4.04327\tvalid_1's rmse: 51.8476\n",
      "[1080]\ttraining's rmse: 3.82745\tvalid_1's rmse: 51.8401\n",
      "[1110]\ttraining's rmse: 3.62951\tvalid_1's rmse: 51.8265\n",
      "[1140]\ttraining's rmse: 3.44012\tvalid_1's rmse: 51.8191\n",
      "[1170]\ttraining's rmse: 3.26362\tvalid_1's rmse: 51.8124\n",
      "[1200]\ttraining's rmse: 3.09378\tvalid_1's rmse: 51.805\n",
      "[1230]\ttraining's rmse: 2.93502\tvalid_1's rmse: 51.795\n",
      "[1260]\ttraining's rmse: 2.78114\tvalid_1's rmse: 51.7876\n",
      "[1290]\ttraining's rmse: 2.64441\tvalid_1's rmse: 51.7807\n",
      "[1320]\ttraining's rmse: 2.50993\tvalid_1's rmse: 51.7708\n",
      "[1350]\ttraining's rmse: 2.386\tvalid_1's rmse: 51.7627\n",
      "[1380]\ttraining's rmse: 2.26843\tvalid_1's rmse: 51.762\n",
      "[1410]\ttraining's rmse: 2.15928\tvalid_1's rmse: 51.759\n",
      "[1440]\ttraining's rmse: 2.05245\tvalid_1's rmse: 51.7558\n",
      "[1470]\ttraining's rmse: 1.95118\tvalid_1's rmse: 51.755\n",
      "[1500]\ttraining's rmse: 1.85376\tvalid_1's rmse: 51.7525\n",
      "[1530]\ttraining's rmse: 1.76307\tvalid_1's rmse: 51.7496\n",
      "[1560]\ttraining's rmse: 1.67587\tvalid_1's rmse: 51.7489\n",
      "[1590]\ttraining's rmse: 1.59479\tvalid_1's rmse: 51.7472\n",
      "[1620]\ttraining's rmse: 1.51629\tvalid_1's rmse: 51.7467\n",
      "[1650]\ttraining's rmse: 1.44204\tvalid_1's rmse: 51.7431\n",
      "[1680]\ttraining's rmse: 1.37326\tvalid_1's rmse: 51.7392\n",
      "[1710]\ttraining's rmse: 1.3075\tvalid_1's rmse: 51.7396\n",
      "[1740]\ttraining's rmse: 1.24566\tvalid_1's rmse: 51.7375\n",
      "[1770]\ttraining's rmse: 1.18818\tvalid_1's rmse: 51.7387\n",
      "[1800]\ttraining's rmse: 1.13185\tvalid_1's rmse: 51.7369\n",
      "[1830]\ttraining's rmse: 1.0772\tvalid_1's rmse: 51.7343\n",
      "[1860]\ttraining's rmse: 1.02504\tvalid_1's rmse: 51.7328\n",
      "[1890]\ttraining's rmse: 0.977608\tvalid_1's rmse: 51.7334\n",
      "[1920]\ttraining's rmse: 0.931622\tvalid_1's rmse: 51.7319\n",
      "[1950]\ttraining's rmse: 0.886606\tvalid_1's rmse: 51.7309\n",
      "[1980]\ttraining's rmse: 0.844784\tvalid_1's rmse: 51.729\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's rmse: 0.819009\tvalid_1's rmse: 51.7282\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002614 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 20019\n",
      "[LightGBM] [Info] Number of data points in the train set: 9219, number of used features: 79\n",
      "[LightGBM] [Info] Start training from score 380.531234\n",
      "Training until validation scores don't improve for 125 rounds\n",
      "[30]\ttraining's rmse: 170.991\tvalid_1's rmse: 174.601\n",
      "[60]\ttraining's rmse: 106.144\tvalid_1's rmse: 114.214\n",
      "[90]\ttraining's rmse: 70.9463\tvalid_1's rmse: 84.3824\n",
      "[120]\ttraining's rmse: 51.7781\tvalid_1's rmse: 69.6159\n",
      "[150]\ttraining's rmse: 41.1396\tvalid_1's rmse: 62.7337\n",
      "[180]\ttraining's rmse: 34.6163\tvalid_1's rmse: 59.2121\n",
      "[210]\ttraining's rmse: 30.2549\tvalid_1's rmse: 57.3303\n",
      "[240]\ttraining's rmse: 26.8836\tvalid_1's rmse: 56.119\n",
      "[270]\ttraining's rmse: 24.1729\tvalid_1's rmse: 55.1469\n",
      "[300]\ttraining's rmse: 21.9412\tvalid_1's rmse: 54.5271\n",
      "[330]\ttraining's rmse: 20.0548\tvalid_1's rmse: 54.058\n",
      "[360]\ttraining's rmse: 18.4387\tvalid_1's rmse: 53.7315\n",
      "[390]\ttraining's rmse: 16.979\tvalid_1's rmse: 53.4609\n",
      "[420]\ttraining's rmse: 15.7132\tvalid_1's rmse: 53.2547\n",
      "[450]\ttraining's rmse: 14.5718\tvalid_1's rmse: 53.0694\n",
      "[480]\ttraining's rmse: 13.534\tvalid_1's rmse: 52.9473\n",
      "[510]\ttraining's rmse: 12.5953\tvalid_1's rmse: 52.7895\n",
      "[540]\ttraining's rmse: 11.7296\tvalid_1's rmse: 52.7037\n",
      "[570]\ttraining's rmse: 10.9581\tvalid_1's rmse: 52.593\n",
      "[600]\ttraining's rmse: 10.2634\tvalid_1's rmse: 52.513\n",
      "[630]\ttraining's rmse: 9.61696\tvalid_1's rmse: 52.4399\n",
      "[660]\ttraining's rmse: 9.01996\tvalid_1's rmse: 52.3773\n",
      "[690]\ttraining's rmse: 8.47331\tvalid_1's rmse: 52.3332\n",
      "[720]\ttraining's rmse: 7.97184\tvalid_1's rmse: 52.2902\n",
      "[750]\ttraining's rmse: 7.491\tvalid_1's rmse: 52.2251\n",
      "[780]\ttraining's rmse: 7.05698\tvalid_1's rmse: 52.1889\n",
      "[810]\ttraining's rmse: 6.64706\tvalid_1's rmse: 52.1678\n",
      "[840]\ttraining's rmse: 6.2643\tvalid_1's rmse: 52.1405\n",
      "[870]\ttraining's rmse: 5.92045\tvalid_1's rmse: 52.1257\n",
      "[900]\ttraining's rmse: 5.58554\tvalid_1's rmse: 52.0904\n",
      "[930]\ttraining's rmse: 5.28152\tvalid_1's rmse: 52.0767\n",
      "[960]\ttraining's rmse: 4.99189\tvalid_1's rmse: 52.0596\n",
      "[990]\ttraining's rmse: 4.72463\tvalid_1's rmse: 52.0421\n",
      "[1020]\ttraining's rmse: 4.4741\tvalid_1's rmse: 52.0192\n",
      "[1050]\ttraining's rmse: 4.23485\tvalid_1's rmse: 52.0051\n",
      "[1080]\ttraining's rmse: 4.01148\tvalid_1's rmse: 51.9898\n",
      "[1110]\ttraining's rmse: 3.80004\tvalid_1's rmse: 51.9774\n",
      "[1140]\ttraining's rmse: 3.60461\tvalid_1's rmse: 51.9777\n",
      "[1170]\ttraining's rmse: 3.41793\tvalid_1's rmse: 51.9676\n",
      "[1200]\ttraining's rmse: 3.24235\tvalid_1's rmse: 51.9494\n",
      "[1230]\ttraining's rmse: 3.07926\tvalid_1's rmse: 51.9406\n",
      "[1260]\ttraining's rmse: 2.92498\tvalid_1's rmse: 51.932\n",
      "[1290]\ttraining's rmse: 2.77355\tvalid_1's rmse: 51.9248\n",
      "[1320]\ttraining's rmse: 2.63451\tvalid_1's rmse: 51.9143\n",
      "[1350]\ttraining's rmse: 2.50132\tvalid_1's rmse: 51.9059\n",
      "[1380]\ttraining's rmse: 2.37796\tvalid_1's rmse: 51.9058\n",
      "[1410]\ttraining's rmse: 2.2641\tvalid_1's rmse: 51.9014\n",
      "[1440]\ttraining's rmse: 2.15086\tvalid_1's rmse: 51.897\n",
      "[1470]\ttraining's rmse: 2.04513\tvalid_1's rmse: 51.8924\n",
      "[1500]\ttraining's rmse: 1.94516\tvalid_1's rmse: 51.8883\n",
      "[1530]\ttraining's rmse: 1.85243\tvalid_1's rmse: 51.8839\n",
      "[1560]\ttraining's rmse: 1.76308\tvalid_1's rmse: 51.8848\n",
      "[1590]\ttraining's rmse: 1.67872\tvalid_1's rmse: 51.883\n",
      "[1620]\ttraining's rmse: 1.60001\tvalid_1's rmse: 51.8814\n",
      "[1650]\ttraining's rmse: 1.52417\tvalid_1's rmse: 51.8769\n",
      "[1680]\ttraining's rmse: 1.45154\tvalid_1's rmse: 51.8742\n",
      "[1710]\ttraining's rmse: 1.38181\tvalid_1's rmse: 51.8715\n",
      "[1740]\ttraining's rmse: 1.31847\tvalid_1's rmse: 51.8705\n",
      "[1770]\ttraining's rmse: 1.25852\tvalid_1's rmse: 51.8686\n",
      "[1800]\ttraining's rmse: 1.19901\tvalid_1's rmse: 51.8654\n",
      "[1830]\ttraining's rmse: 1.14253\tvalid_1's rmse: 51.8625\n",
      "[1860]\ttraining's rmse: 1.08953\tvalid_1's rmse: 51.859\n",
      "[1890]\ttraining's rmse: 1.03922\tvalid_1's rmse: 51.8601\n",
      "[1920]\ttraining's rmse: 0.990744\tvalid_1's rmse: 51.8574\n",
      "[1950]\ttraining's rmse: 0.944971\tvalid_1's rmse: 51.8557\n",
      "[1980]\ttraining's rmse: 0.901708\tvalid_1's rmse: 51.8541\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's rmse: 0.872996\tvalid_1's rmse: 51.8544\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002343 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 20019\n",
      "[LightGBM] [Info] Number of data points in the train set: 9219, number of used features: 79\n",
      "[LightGBM] [Info] Start training from score 382.639352\n",
      "Training until validation scores don't improve for 125 rounds\n",
      "[30]\ttraining's rmse: 171.092\tvalid_1's rmse: 178.432\n",
      "[60]\ttraining's rmse: 105.971\tvalid_1's rmse: 117.701\n",
      "[90]\ttraining's rmse: 70.6031\tvalid_1's rmse: 86.9682\n",
      "[120]\ttraining's rmse: 51.4963\tvalid_1's rmse: 72.3996\n",
      "[150]\ttraining's rmse: 40.8773\tvalid_1's rmse: 65.4345\n",
      "[180]\ttraining's rmse: 34.5675\tvalid_1's rmse: 62.0497\n",
      "[210]\ttraining's rmse: 30.1884\tvalid_1's rmse: 59.9923\n",
      "[240]\ttraining's rmse: 26.8444\tvalid_1's rmse: 58.8298\n",
      "[270]\ttraining's rmse: 24.1768\tvalid_1's rmse: 57.9969\n",
      "[300]\ttraining's rmse: 21.9627\tvalid_1's rmse: 57.3679\n",
      "[330]\ttraining's rmse: 20.1251\tvalid_1's rmse: 56.952\n",
      "[360]\ttraining's rmse: 18.511\tvalid_1's rmse: 56.6173\n",
      "[390]\ttraining's rmse: 17.0575\tvalid_1's rmse: 56.3848\n",
      "[420]\ttraining's rmse: 15.7832\tvalid_1's rmse: 56.1901\n",
      "[450]\ttraining's rmse: 14.6366\tvalid_1's rmse: 56.044\n",
      "[480]\ttraining's rmse: 13.6025\tvalid_1's rmse: 55.8993\n",
      "[510]\ttraining's rmse: 12.6695\tvalid_1's rmse: 55.7954\n",
      "[540]\ttraining's rmse: 11.8267\tvalid_1's rmse: 55.6982\n",
      "[570]\ttraining's rmse: 11.0325\tvalid_1's rmse: 55.6179\n",
      "[600]\ttraining's rmse: 10.3285\tvalid_1's rmse: 55.5469\n",
      "[630]\ttraining's rmse: 9.67287\tvalid_1's rmse: 55.4702\n",
      "[660]\ttraining's rmse: 9.07531\tvalid_1's rmse: 55.4395\n",
      "[690]\ttraining's rmse: 8.50126\tvalid_1's rmse: 55.3661\n",
      "[720]\ttraining's rmse: 7.98879\tvalid_1's rmse: 55.318\n",
      "[750]\ttraining's rmse: 7.50849\tvalid_1's rmse: 55.2716\n",
      "[780]\ttraining's rmse: 7.07006\tvalid_1's rmse: 55.234\n",
      "[810]\ttraining's rmse: 6.6612\tvalid_1's rmse: 55.2131\n",
      "[840]\ttraining's rmse: 6.28132\tvalid_1's rmse: 55.1842\n",
      "[870]\ttraining's rmse: 5.92873\tvalid_1's rmse: 55.1515\n",
      "[900]\ttraining's rmse: 5.59893\tvalid_1's rmse: 55.1233\n",
      "[930]\ttraining's rmse: 5.28813\tvalid_1's rmse: 55.103\n",
      "[960]\ttraining's rmse: 4.99066\tvalid_1's rmse: 55.0925\n",
      "[990]\ttraining's rmse: 4.72468\tvalid_1's rmse: 55.0792\n",
      "[1020]\ttraining's rmse: 4.4712\tvalid_1's rmse: 55.0696\n",
      "[1050]\ttraining's rmse: 4.22929\tvalid_1's rmse: 55.0617\n",
      "[1080]\ttraining's rmse: 4.00611\tvalid_1's rmse: 55.0482\n",
      "[1110]\ttraining's rmse: 3.79079\tvalid_1's rmse: 55.0371\n",
      "[1140]\ttraining's rmse: 3.59286\tvalid_1's rmse: 55.0337\n",
      "[1170]\ttraining's rmse: 3.40697\tvalid_1's rmse: 55.0275\n",
      "[1200]\ttraining's rmse: 3.2297\tvalid_1's rmse: 55.0211\n",
      "[1230]\ttraining's rmse: 3.05963\tvalid_1's rmse: 55.0129\n",
      "[1260]\ttraining's rmse: 2.90508\tvalid_1's rmse: 55.0004\n",
      "[1290]\ttraining's rmse: 2.7585\tvalid_1's rmse: 54.9935\n",
      "[1320]\ttraining's rmse: 2.61967\tvalid_1's rmse: 54.9891\n",
      "[1350]\ttraining's rmse: 2.48806\tvalid_1's rmse: 54.984\n",
      "[1380]\ttraining's rmse: 2.36172\tvalid_1's rmse: 54.9733\n",
      "[1410]\ttraining's rmse: 2.24431\tvalid_1's rmse: 54.9681\n",
      "[1440]\ttraining's rmse: 2.13345\tvalid_1's rmse: 54.9627\n",
      "[1470]\ttraining's rmse: 2.0285\tvalid_1's rmse: 54.9617\n",
      "[1500]\ttraining's rmse: 1.92978\tvalid_1's rmse: 54.9586\n",
      "[1530]\ttraining's rmse: 1.83538\tvalid_1's rmse: 54.9575\n",
      "[1560]\ttraining's rmse: 1.74573\tvalid_1's rmse: 54.9548\n",
      "[1590]\ttraining's rmse: 1.66004\tvalid_1's rmse: 54.9535\n",
      "[1620]\ttraining's rmse: 1.57852\tvalid_1's rmse: 54.9523\n",
      "[1650]\ttraining's rmse: 1.50411\tvalid_1's rmse: 54.9506\n",
      "[1680]\ttraining's rmse: 1.43249\tvalid_1's rmse: 54.9485\n",
      "[1710]\ttraining's rmse: 1.36479\tvalid_1's rmse: 54.9467\n",
      "[1740]\ttraining's rmse: 1.30074\tvalid_1's rmse: 54.9461\n",
      "[1770]\ttraining's rmse: 1.24062\tvalid_1's rmse: 54.9443\n",
      "[1800]\ttraining's rmse: 1.18399\tvalid_1's rmse: 54.9442\n",
      "[1830]\ttraining's rmse: 1.12921\tvalid_1's rmse: 54.9435\n",
      "[1860]\ttraining's rmse: 1.07761\tvalid_1's rmse: 54.9421\n",
      "[1890]\ttraining's rmse: 1.02673\tvalid_1's rmse: 54.9401\n",
      "[1920]\ttraining's rmse: 0.978401\tvalid_1's rmse: 54.9389\n",
      "[1950]\ttraining's rmse: 0.933507\tvalid_1's rmse: 54.939\n",
      "[1980]\ttraining's rmse: 0.890101\tvalid_1's rmse: 54.9396\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's rmse: 0.862981\tvalid_1's rmse: 54.9384\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002349 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 20019\n",
      "[LightGBM] [Info] Number of data points in the train set: 9219, number of used features: 79\n",
      "[LightGBM] [Info] Start training from score 381.134788\n",
      "Training until validation scores don't improve for 125 rounds\n",
      "[30]\ttraining's rmse: 172.529\tvalid_1's rmse: 175.302\n",
      "[60]\ttraining's rmse: 106.511\tvalid_1's rmse: 114.702\n",
      "[90]\ttraining's rmse: 70.468\tvalid_1's rmse: 84.4962\n",
      "[120]\ttraining's rmse: 51.175\tvalid_1's rmse: 70.5806\n",
      "[150]\ttraining's rmse: 40.5165\tvalid_1's rmse: 63.8342\n",
      "[180]\ttraining's rmse: 34.0602\tvalid_1's rmse: 60.4868\n",
      "[210]\ttraining's rmse: 29.6694\tvalid_1's rmse: 58.6281\n",
      "[240]\ttraining's rmse: 26.3076\tvalid_1's rmse: 57.512\n",
      "[270]\ttraining's rmse: 23.6284\tvalid_1's rmse: 56.7378\n",
      "[300]\ttraining's rmse: 21.4543\tvalid_1's rmse: 56.2515\n",
      "[330]\ttraining's rmse: 19.627\tvalid_1's rmse: 55.8926\n",
      "[360]\ttraining's rmse: 18.047\tvalid_1's rmse: 55.5683\n",
      "[390]\ttraining's rmse: 16.6366\tvalid_1's rmse: 55.349\n",
      "[420]\ttraining's rmse: 15.3882\tvalid_1's rmse: 55.1963\n",
      "[450]\ttraining's rmse: 14.279\tvalid_1's rmse: 55.1204\n",
      "[480]\ttraining's rmse: 13.2659\tvalid_1's rmse: 54.9948\n",
      "[510]\ttraining's rmse: 12.3403\tvalid_1's rmse: 54.9153\n",
      "[540]\ttraining's rmse: 11.5076\tvalid_1's rmse: 54.8654\n",
      "[570]\ttraining's rmse: 10.7641\tvalid_1's rmse: 54.7925\n",
      "[600]\ttraining's rmse: 10.0587\tvalid_1's rmse: 54.7223\n",
      "[630]\ttraining's rmse: 9.41749\tvalid_1's rmse: 54.6436\n",
      "[660]\ttraining's rmse: 8.8319\tvalid_1's rmse: 54.6061\n",
      "[690]\ttraining's rmse: 8.28666\tvalid_1's rmse: 54.5496\n",
      "[720]\ttraining's rmse: 7.77712\tvalid_1's rmse: 54.5017\n",
      "[750]\ttraining's rmse: 7.31096\tvalid_1's rmse: 54.4646\n",
      "[780]\ttraining's rmse: 6.87673\tvalid_1's rmse: 54.4502\n",
      "[810]\ttraining's rmse: 6.47433\tvalid_1's rmse: 54.4154\n",
      "[840]\ttraining's rmse: 6.09751\tvalid_1's rmse: 54.3855\n",
      "[870]\ttraining's rmse: 5.74796\tvalid_1's rmse: 54.3685\n",
      "[900]\ttraining's rmse: 5.42076\tvalid_1's rmse: 54.3515\n",
      "[930]\ttraining's rmse: 5.12083\tvalid_1's rmse: 54.3378\n",
      "[960]\ttraining's rmse: 4.83573\tvalid_1's rmse: 54.3156\n",
      "[990]\ttraining's rmse: 4.57236\tvalid_1's rmse: 54.3092\n",
      "[1020]\ttraining's rmse: 4.31695\tvalid_1's rmse: 54.292\n",
      "[1050]\ttraining's rmse: 4.08273\tvalid_1's rmse: 54.2747\n",
      "[1080]\ttraining's rmse: 3.86171\tvalid_1's rmse: 54.2587\n",
      "[1110]\ttraining's rmse: 3.65563\tvalid_1's rmse: 54.2477\n",
      "[1140]\ttraining's rmse: 3.46402\tvalid_1's rmse: 54.239\n",
      "[1170]\ttraining's rmse: 3.28249\tvalid_1's rmse: 54.2296\n",
      "[1200]\ttraining's rmse: 3.10695\tvalid_1's rmse: 54.2218\n",
      "[1230]\ttraining's rmse: 2.94677\tvalid_1's rmse: 54.2224\n",
      "[1260]\ttraining's rmse: 2.79683\tvalid_1's rmse: 54.2197\n",
      "[1290]\ttraining's rmse: 2.65095\tvalid_1's rmse: 54.2161\n",
      "[1320]\ttraining's rmse: 2.51336\tvalid_1's rmse: 54.2092\n",
      "[1350]\ttraining's rmse: 2.38391\tvalid_1's rmse: 54.2015\n",
      "[1380]\ttraining's rmse: 2.26125\tvalid_1's rmse: 54.1974\n",
      "[1410]\ttraining's rmse: 2.14797\tvalid_1's rmse: 54.1969\n",
      "[1440]\ttraining's rmse: 2.03733\tvalid_1's rmse: 54.1937\n",
      "[1470]\ttraining's rmse: 1.93539\tvalid_1's rmse: 54.1936\n",
      "[1500]\ttraining's rmse: 1.83935\tvalid_1's rmse: 54.1917\n",
      "[1530]\ttraining's rmse: 1.74773\tvalid_1's rmse: 54.1882\n",
      "[1560]\ttraining's rmse: 1.66157\tvalid_1's rmse: 54.1818\n",
      "[1590]\ttraining's rmse: 1.58027\tvalid_1's rmse: 54.1783\n",
      "[1620]\ttraining's rmse: 1.5012\tvalid_1's rmse: 54.1772\n",
      "[1650]\ttraining's rmse: 1.42678\tvalid_1's rmse: 54.1751\n",
      "[1680]\ttraining's rmse: 1.35736\tvalid_1's rmse: 54.1749\n",
      "[1710]\ttraining's rmse: 1.29256\tvalid_1's rmse: 54.1725\n",
      "[1740]\ttraining's rmse: 1.22958\tvalid_1's rmse: 54.1728\n",
      "[1770]\ttraining's rmse: 1.17065\tvalid_1's rmse: 54.1672\n",
      "[1800]\ttraining's rmse: 1.11354\tvalid_1's rmse: 54.1648\n",
      "[1830]\ttraining's rmse: 1.06114\tvalid_1's rmse: 54.1635\n",
      "[1860]\ttraining's rmse: 1.01035\tvalid_1's rmse: 54.1613\n",
      "[1890]\ttraining's rmse: 0.962064\tvalid_1's rmse: 54.1606\n",
      "[1920]\ttraining's rmse: 0.916214\tvalid_1's rmse: 54.1584\n",
      "[1950]\ttraining's rmse: 0.872501\tvalid_1's rmse: 54.1554\n",
      "[1980]\ttraining's rmse: 0.830669\tvalid_1's rmse: 54.1528\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's rmse: 0.804667\tvalid_1's rmse: 54.1524\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003322 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 20019\n",
      "[LightGBM] [Info] Number of data points in the train set: 9219, number of used features: 79\n",
      "[LightGBM] [Info] Start training from score 379.459898\n",
      "Training until validation scores don't improve for 125 rounds\n",
      "[30]\ttraining's rmse: 172.14\tvalid_1's rmse: 177.551\n",
      "[60]\ttraining's rmse: 106.305\tvalid_1's rmse: 116.525\n",
      "[90]\ttraining's rmse: 70.472\tvalid_1's rmse: 85.9568\n",
      "[120]\ttraining's rmse: 51.1077\tvalid_1's rmse: 71.2423\n",
      "[150]\ttraining's rmse: 40.3593\tvalid_1's rmse: 64.3484\n",
      "[180]\ttraining's rmse: 33.8552\tvalid_1's rmse: 60.905\n",
      "[210]\ttraining's rmse: 29.585\tvalid_1's rmse: 59.0184\n",
      "[240]\ttraining's rmse: 26.4115\tvalid_1's rmse: 57.7202\n",
      "[270]\ttraining's rmse: 23.8597\tvalid_1's rmse: 56.8684\n",
      "[300]\ttraining's rmse: 21.7104\tvalid_1's rmse: 56.3527\n",
      "[330]\ttraining's rmse: 19.8723\tvalid_1's rmse: 55.908\n",
      "[360]\ttraining's rmse: 18.3255\tvalid_1's rmse: 55.5732\n",
      "[390]\ttraining's rmse: 16.9232\tvalid_1's rmse: 55.3742\n",
      "[420]\ttraining's rmse: 15.6863\tvalid_1's rmse: 55.1268\n",
      "[450]\ttraining's rmse: 14.5521\tvalid_1's rmse: 54.9061\n",
      "[480]\ttraining's rmse: 13.51\tvalid_1's rmse: 54.7447\n",
      "[510]\ttraining's rmse: 12.5944\tvalid_1's rmse: 54.6281\n",
      "[540]\ttraining's rmse: 11.7733\tvalid_1's rmse: 54.4968\n",
      "[570]\ttraining's rmse: 11.0038\tvalid_1's rmse: 54.4198\n",
      "[600]\ttraining's rmse: 10.3201\tvalid_1's rmse: 54.3178\n",
      "[630]\ttraining's rmse: 9.68274\tvalid_1's rmse: 54.2466\n",
      "[660]\ttraining's rmse: 9.09281\tvalid_1's rmse: 54.205\n",
      "[690]\ttraining's rmse: 8.52977\tvalid_1's rmse: 54.1512\n",
      "[720]\ttraining's rmse: 8.02042\tvalid_1's rmse: 54.1071\n",
      "[750]\ttraining's rmse: 7.54771\tvalid_1's rmse: 54.0607\n",
      "[780]\ttraining's rmse: 7.11188\tvalid_1's rmse: 54.03\n",
      "[810]\ttraining's rmse: 6.70776\tvalid_1's rmse: 53.9915\n",
      "[840]\ttraining's rmse: 6.33771\tvalid_1's rmse: 53.966\n",
      "[870]\ttraining's rmse: 5.97668\tvalid_1's rmse: 53.9368\n",
      "[900]\ttraining's rmse: 5.64427\tvalid_1's rmse: 53.907\n",
      "[930]\ttraining's rmse: 5.3381\tvalid_1's rmse: 53.8768\n",
      "[960]\ttraining's rmse: 5.04701\tvalid_1's rmse: 53.8561\n",
      "[990]\ttraining's rmse: 4.7835\tvalid_1's rmse: 53.8456\n",
      "[1020]\ttraining's rmse: 4.52682\tvalid_1's rmse: 53.8317\n",
      "[1050]\ttraining's rmse: 4.29368\tvalid_1's rmse: 53.8204\n",
      "[1080]\ttraining's rmse: 4.06735\tvalid_1's rmse: 53.811\n",
      "[1110]\ttraining's rmse: 3.8584\tvalid_1's rmse: 53.8014\n",
      "[1140]\ttraining's rmse: 3.65826\tvalid_1's rmse: 53.7864\n",
      "[1170]\ttraining's rmse: 3.47518\tvalid_1's rmse: 53.7814\n",
      "[1200]\ttraining's rmse: 3.29292\tvalid_1's rmse: 53.7697\n",
      "[1230]\ttraining's rmse: 3.12809\tvalid_1's rmse: 53.7611\n",
      "[1260]\ttraining's rmse: 2.96938\tvalid_1's rmse: 53.7536\n",
      "[1290]\ttraining's rmse: 2.82062\tvalid_1's rmse: 53.7424\n",
      "[1320]\ttraining's rmse: 2.67945\tvalid_1's rmse: 53.7342\n",
      "[1350]\ttraining's rmse: 2.54828\tvalid_1's rmse: 53.7254\n",
      "[1380]\ttraining's rmse: 2.42077\tvalid_1's rmse: 53.7167\n",
      "[1410]\ttraining's rmse: 2.30263\tvalid_1's rmse: 53.7116\n",
      "[1440]\ttraining's rmse: 2.19095\tvalid_1's rmse: 53.7086\n",
      "[1470]\ttraining's rmse: 2.08503\tvalid_1's rmse: 53.7025\n",
      "[1500]\ttraining's rmse: 1.98442\tvalid_1's rmse: 53.6943\n",
      "[1530]\ttraining's rmse: 1.89153\tvalid_1's rmse: 53.6917\n",
      "[1560]\ttraining's rmse: 1.80238\tvalid_1's rmse: 53.6885\n",
      "[1590]\ttraining's rmse: 1.71778\tvalid_1's rmse: 53.6881\n",
      "[1620]\ttraining's rmse: 1.63675\tvalid_1's rmse: 53.6867\n",
      "[1650]\ttraining's rmse: 1.56001\tvalid_1's rmse: 53.6863\n",
      "[1680]\ttraining's rmse: 1.48541\tvalid_1's rmse: 53.6855\n",
      "[1710]\ttraining's rmse: 1.41479\tvalid_1's rmse: 53.6816\n",
      "[1740]\ttraining's rmse: 1.34836\tvalid_1's rmse: 53.678\n",
      "[1770]\ttraining's rmse: 1.28651\tvalid_1's rmse: 53.673\n",
      "[1800]\ttraining's rmse: 1.22748\tvalid_1's rmse: 53.6719\n",
      "[1830]\ttraining's rmse: 1.16976\tvalid_1's rmse: 53.6667\n",
      "[1860]\ttraining's rmse: 1.1151\tvalid_1's rmse: 53.6668\n",
      "[1890]\ttraining's rmse: 1.06291\tvalid_1's rmse: 53.6652\n",
      "[1920]\ttraining's rmse: 1.01631\tvalid_1's rmse: 53.6618\n",
      "[1950]\ttraining's rmse: 0.969692\tvalid_1's rmse: 53.6604\n",
      "[1980]\ttraining's rmse: 0.924417\tvalid_1's rmse: 53.6602\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's rmse: 0.895816\tvalid_1's rmse: 53.658\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003499 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 20019\n",
      "[LightGBM] [Info] Number of data points in the train set: 9219, number of used features: 79\n",
      "[LightGBM] [Info] Start training from score 380.308244\n",
      "Training until validation scores don't improve for 125 rounds\n",
      "[30]\ttraining's rmse: 172.845\tvalid_1's rmse: 176.559\n",
      "[60]\ttraining's rmse: 106.195\tvalid_1's rmse: 114.61\n",
      "[90]\ttraining's rmse: 69.981\tvalid_1's rmse: 83.9505\n",
      "[120]\ttraining's rmse: 50.6349\tvalid_1's rmse: 69.3602\n",
      "[150]\ttraining's rmse: 39.9794\tvalid_1's rmse: 62.6632\n",
      "[180]\ttraining's rmse: 33.6298\tvalid_1's rmse: 59.3282\n",
      "[210]\ttraining's rmse: 29.3227\tvalid_1's rmse: 57.4693\n",
      "[240]\ttraining's rmse: 26.1571\tvalid_1's rmse: 56.0805\n",
      "[270]\ttraining's rmse: 23.5988\tvalid_1's rmse: 55.1839\n",
      "[300]\ttraining's rmse: 21.45\tvalid_1's rmse: 54.4754\n",
      "[330]\ttraining's rmse: 19.6436\tvalid_1's rmse: 53.9877\n",
      "[360]\ttraining's rmse: 18.1067\tvalid_1's rmse: 53.592\n",
      "[390]\ttraining's rmse: 16.7258\tvalid_1's rmse: 53.2717\n",
      "[420]\ttraining's rmse: 15.4784\tvalid_1's rmse: 53.0842\n",
      "[450]\ttraining's rmse: 14.3684\tvalid_1's rmse: 52.8435\n",
      "[480]\ttraining's rmse: 13.3445\tvalid_1's rmse: 52.6783\n",
      "[510]\ttraining's rmse: 12.4141\tvalid_1's rmse: 52.5413\n",
      "[540]\ttraining's rmse: 11.5962\tvalid_1's rmse: 52.4185\n",
      "[570]\ttraining's rmse: 10.8395\tvalid_1's rmse: 52.3275\n",
      "[600]\ttraining's rmse: 10.1407\tvalid_1's rmse: 52.227\n",
      "[630]\ttraining's rmse: 9.491\tvalid_1's rmse: 52.1447\n",
      "[660]\ttraining's rmse: 8.90413\tvalid_1's rmse: 52.0809\n",
      "[690]\ttraining's rmse: 8.35366\tvalid_1's rmse: 52.0316\n",
      "[720]\ttraining's rmse: 7.84539\tvalid_1's rmse: 51.9884\n",
      "[750]\ttraining's rmse: 7.37282\tvalid_1's rmse: 51.933\n",
      "[780]\ttraining's rmse: 6.93245\tvalid_1's rmse: 51.8825\n",
      "[810]\ttraining's rmse: 6.52546\tvalid_1's rmse: 51.8598\n",
      "[840]\ttraining's rmse: 6.14931\tvalid_1's rmse: 51.8163\n",
      "[870]\ttraining's rmse: 5.79704\tvalid_1's rmse: 51.786\n",
      "[900]\ttraining's rmse: 5.47238\tvalid_1's rmse: 51.7563\n",
      "[930]\ttraining's rmse: 5.16782\tvalid_1's rmse: 51.7279\n",
      "[960]\ttraining's rmse: 4.88245\tvalid_1's rmse: 51.7113\n",
      "[990]\ttraining's rmse: 4.61593\tvalid_1's rmse: 51.6911\n",
      "[1020]\ttraining's rmse: 4.3626\tvalid_1's rmse: 51.6678\n",
      "[1050]\ttraining's rmse: 4.12714\tvalid_1's rmse: 51.6472\n",
      "[1080]\ttraining's rmse: 3.90031\tvalid_1's rmse: 51.6278\n",
      "[1110]\ttraining's rmse: 3.69232\tvalid_1's rmse: 51.6111\n",
      "[1140]\ttraining's rmse: 3.49491\tvalid_1's rmse: 51.598\n",
      "[1170]\ttraining's rmse: 3.31205\tvalid_1's rmse: 51.5943\n",
      "[1200]\ttraining's rmse: 3.1388\tvalid_1's rmse: 51.5898\n",
      "[1230]\ttraining's rmse: 2.97925\tvalid_1's rmse: 51.5858\n",
      "[1260]\ttraining's rmse: 2.82705\tvalid_1's rmse: 51.5708\n",
      "[1290]\ttraining's rmse: 2.68152\tvalid_1's rmse: 51.5638\n",
      "[1320]\ttraining's rmse: 2.53683\tvalid_1's rmse: 51.5574\n",
      "[1350]\ttraining's rmse: 2.40606\tvalid_1's rmse: 51.5549\n",
      "[1380]\ttraining's rmse: 2.28375\tvalid_1's rmse: 51.5492\n",
      "[1410]\ttraining's rmse: 2.16815\tvalid_1's rmse: 51.5446\n",
      "[1440]\ttraining's rmse: 2.06284\tvalid_1's rmse: 51.5411\n",
      "[1470]\ttraining's rmse: 1.95914\tvalid_1's rmse: 51.5312\n",
      "[1500]\ttraining's rmse: 1.86128\tvalid_1's rmse: 51.5269\n",
      "[1530]\ttraining's rmse: 1.76737\tvalid_1's rmse: 51.5261\n",
      "[1560]\ttraining's rmse: 1.67967\tvalid_1's rmse: 51.5216\n",
      "[1590]\ttraining's rmse: 1.59891\tvalid_1's rmse: 51.5191\n",
      "[1620]\ttraining's rmse: 1.52082\tvalid_1's rmse: 51.5202\n",
      "[1650]\ttraining's rmse: 1.44601\tvalid_1's rmse: 51.5209\n",
      "[1680]\ttraining's rmse: 1.37707\tvalid_1's rmse: 51.521\n",
      "[1710]\ttraining's rmse: 1.30901\tvalid_1's rmse: 51.5179\n",
      "[1740]\ttraining's rmse: 1.24664\tvalid_1's rmse: 51.5172\n",
      "[1770]\ttraining's rmse: 1.18704\tvalid_1's rmse: 51.5144\n",
      "[1800]\ttraining's rmse: 1.13107\tvalid_1's rmse: 51.514\n",
      "[1830]\ttraining's rmse: 1.07685\tvalid_1's rmse: 51.5109\n",
      "[1860]\ttraining's rmse: 1.02535\tvalid_1's rmse: 51.507\n",
      "[1890]\ttraining's rmse: 0.976434\tvalid_1's rmse: 51.5059\n",
      "[1920]\ttraining's rmse: 0.929695\tvalid_1's rmse: 51.505\n",
      "[1950]\ttraining's rmse: 0.885607\tvalid_1's rmse: 51.5027\n",
      "[1980]\ttraining's rmse: 0.844179\tvalid_1's rmse: 51.5026\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's rmse: 0.818161\tvalid_1's rmse: 51.503\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002465 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 20019\n",
      "[LightGBM] [Info] Number of data points in the train set: 9219, number of used features: 79\n",
      "[LightGBM] [Info] Start training from score 379.856393\n",
      "Training until validation scores don't improve for 125 rounds\n",
      "[30]\ttraining's rmse: 173.551\tvalid_1's rmse: 172.488\n",
      "[60]\ttraining's rmse: 106.438\tvalid_1's rmse: 114.045\n",
      "[90]\ttraining's rmse: 70.0195\tvalid_1's rmse: 84.8538\n",
      "[120]\ttraining's rmse: 50.5433\tvalid_1's rmse: 70.9408\n",
      "[150]\ttraining's rmse: 39.8962\tvalid_1's rmse: 64.2996\n",
      "[180]\ttraining's rmse: 33.5648\tvalid_1's rmse: 60.8284\n",
      "[210]\ttraining's rmse: 29.3466\tvalid_1's rmse: 58.8373\n",
      "[240]\ttraining's rmse: 26.182\tvalid_1's rmse: 57.5789\n",
      "[270]\ttraining's rmse: 23.5618\tvalid_1's rmse: 56.6957\n",
      "[300]\ttraining's rmse: 21.4366\tvalid_1's rmse: 56.0859\n",
      "[330]\ttraining's rmse: 19.6402\tvalid_1's rmse: 55.7201\n",
      "[360]\ttraining's rmse: 18.1016\tvalid_1's rmse: 55.4964\n",
      "[390]\ttraining's rmse: 16.7149\tvalid_1's rmse: 55.2483\n",
      "[420]\ttraining's rmse: 15.4976\tvalid_1's rmse: 55.0024\n",
      "[450]\ttraining's rmse: 14.3797\tvalid_1's rmse: 54.8847\n",
      "[480]\ttraining's rmse: 13.3645\tvalid_1's rmse: 54.7274\n",
      "[510]\ttraining's rmse: 12.4564\tvalid_1's rmse: 54.6003\n",
      "[540]\ttraining's rmse: 11.6421\tvalid_1's rmse: 54.5001\n",
      "[570]\ttraining's rmse: 10.903\tvalid_1's rmse: 54.3796\n",
      "[600]\ttraining's rmse: 10.2172\tvalid_1's rmse: 54.2883\n",
      "[630]\ttraining's rmse: 9.5769\tvalid_1's rmse: 54.2234\n",
      "[660]\ttraining's rmse: 8.98369\tvalid_1's rmse: 54.1362\n",
      "[690]\ttraining's rmse: 8.43197\tvalid_1's rmse: 54.0904\n",
      "[720]\ttraining's rmse: 7.92781\tvalid_1's rmse: 54.0519\n",
      "[750]\ttraining's rmse: 7.46903\tvalid_1's rmse: 54.0356\n",
      "[780]\ttraining's rmse: 7.03897\tvalid_1's rmse: 53.9997\n",
      "[810]\ttraining's rmse: 6.63828\tvalid_1's rmse: 53.9837\n",
      "[840]\ttraining's rmse: 6.25799\tvalid_1's rmse: 53.957\n",
      "[870]\ttraining's rmse: 5.91913\tvalid_1's rmse: 53.9418\n",
      "[900]\ttraining's rmse: 5.59931\tvalid_1's rmse: 53.9333\n",
      "[930]\ttraining's rmse: 5.29172\tvalid_1's rmse: 53.9208\n",
      "[960]\ttraining's rmse: 5.00659\tvalid_1's rmse: 53.8991\n",
      "[990]\ttraining's rmse: 4.73882\tvalid_1's rmse: 53.8924\n",
      "[1020]\ttraining's rmse: 4.48888\tvalid_1's rmse: 53.8863\n",
      "[1050]\ttraining's rmse: 4.25334\tvalid_1's rmse: 53.8677\n",
      "[1080]\ttraining's rmse: 4.0261\tvalid_1's rmse: 53.8591\n",
      "[1110]\ttraining's rmse: 3.82164\tvalid_1's rmse: 53.8448\n",
      "[1140]\ttraining's rmse: 3.62493\tvalid_1's rmse: 53.8367\n",
      "[1170]\ttraining's rmse: 3.44166\tvalid_1's rmse: 53.8256\n",
      "[1200]\ttraining's rmse: 3.26553\tvalid_1's rmse: 53.82\n",
      "[1230]\ttraining's rmse: 3.10327\tvalid_1's rmse: 53.8146\n",
      "[1260]\ttraining's rmse: 2.94262\tvalid_1's rmse: 53.8021\n",
      "[1290]\ttraining's rmse: 2.79624\tvalid_1's rmse: 53.7993\n",
      "[1320]\ttraining's rmse: 2.65762\tvalid_1's rmse: 53.7899\n",
      "[1350]\ttraining's rmse: 2.52814\tvalid_1's rmse: 53.7828\n",
      "[1380]\ttraining's rmse: 2.40635\tvalid_1's rmse: 53.7747\n",
      "[1410]\ttraining's rmse: 2.28979\tvalid_1's rmse: 53.7721\n",
      "[1440]\ttraining's rmse: 2.18096\tvalid_1's rmse: 53.7703\n",
      "[1470]\ttraining's rmse: 2.07845\tvalid_1's rmse: 53.7689\n",
      "[1500]\ttraining's rmse: 1.97773\tvalid_1's rmse: 53.7647\n",
      "[1530]\ttraining's rmse: 1.88753\tvalid_1's rmse: 53.7617\n",
      "[1560]\ttraining's rmse: 1.79718\tvalid_1's rmse: 53.7595\n",
      "[1590]\ttraining's rmse: 1.71304\tvalid_1's rmse: 53.7599\n",
      "[1620]\ttraining's rmse: 1.63243\tvalid_1's rmse: 53.7577\n",
      "[1650]\ttraining's rmse: 1.55832\tvalid_1's rmse: 53.7535\n",
      "[1680]\ttraining's rmse: 1.48387\tvalid_1's rmse: 53.7549\n",
      "[1710]\ttraining's rmse: 1.41493\tvalid_1's rmse: 53.7522\n",
      "[1740]\ttraining's rmse: 1.35048\tvalid_1's rmse: 53.7507\n",
      "[1770]\ttraining's rmse: 1.28761\tvalid_1's rmse: 53.7514\n",
      "[1800]\ttraining's rmse: 1.22839\tvalid_1's rmse: 53.7495\n",
      "[1830]\ttraining's rmse: 1.17241\tvalid_1's rmse: 53.7485\n",
      "[1860]\ttraining's rmse: 1.11933\tvalid_1's rmse: 53.7494\n",
      "[1890]\ttraining's rmse: 1.06836\tvalid_1's rmse: 53.7486\n",
      "[1920]\ttraining's rmse: 1.01963\tvalid_1's rmse: 53.7487\n",
      "[1950]\ttraining's rmse: 0.973053\tvalid_1's rmse: 53.75\n",
      "Early stopping, best iteration is:\n",
      "[1837]\ttraining's rmse: 1.15998\tvalid_1's rmse: 53.7483\n",
      "12\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003564 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 20020\n",
      "[LightGBM] [Info] Number of data points in the train set: 9219, number of used features: 79\n",
      "[LightGBM] [Info] Start training from score 360.761837\n",
      "Training until validation scores don't improve for 125 rounds\n",
      "[30]\ttraining's rmse: 157.514\tvalid_1's rmse: 162.925\n",
      "[60]\ttraining's rmse: 96.7943\tvalid_1's rmse: 105.748\n",
      "[90]\ttraining's rmse: 63.8151\tvalid_1's rmse: 76.6913\n",
      "[120]\ttraining's rmse: 46.1464\tvalid_1's rmse: 63.0679\n",
      "[150]\ttraining's rmse: 36.4792\tvalid_1's rmse: 56.8129\n",
      "[180]\ttraining's rmse: 30.7989\tvalid_1's rmse: 53.8462\n",
      "[210]\ttraining's rmse: 26.966\tvalid_1's rmse: 52.2138\n",
      "[240]\ttraining's rmse: 24.1129\tvalid_1's rmse: 51.1935\n",
      "[270]\ttraining's rmse: 21.8024\tvalid_1's rmse: 50.5211\n",
      "[300]\ttraining's rmse: 19.9055\tvalid_1's rmse: 50.0861\n",
      "[330]\ttraining's rmse: 18.2626\tvalid_1's rmse: 49.7803\n",
      "[360]\ttraining's rmse: 16.8569\tvalid_1's rmse: 49.5853\n",
      "[390]\ttraining's rmse: 15.6188\tvalid_1's rmse: 49.3798\n",
      "[420]\ttraining's rmse: 14.4842\tvalid_1's rmse: 49.2083\n",
      "[450]\ttraining's rmse: 13.4679\tvalid_1's rmse: 49.0437\n",
      "[480]\ttraining's rmse: 12.5296\tvalid_1's rmse: 48.9275\n",
      "[510]\ttraining's rmse: 11.6994\tvalid_1's rmse: 48.8701\n",
      "[540]\ttraining's rmse: 10.9518\tvalid_1's rmse: 48.7648\n",
      "[570]\ttraining's rmse: 10.2747\tvalid_1's rmse: 48.719\n",
      "[600]\ttraining's rmse: 9.64009\tvalid_1's rmse: 48.6478\n",
      "[630]\ttraining's rmse: 9.04673\tvalid_1's rmse: 48.5938\n",
      "[660]\ttraining's rmse: 8.48751\tvalid_1's rmse: 48.5373\n",
      "[690]\ttraining's rmse: 7.98035\tvalid_1's rmse: 48.5277\n",
      "[720]\ttraining's rmse: 7.50563\tvalid_1's rmse: 48.4752\n",
      "[750]\ttraining's rmse: 7.06947\tvalid_1's rmse: 48.4422\n",
      "[780]\ttraining's rmse: 6.67721\tvalid_1's rmse: 48.4246\n",
      "[810]\ttraining's rmse: 6.30035\tvalid_1's rmse: 48.4043\n",
      "[840]\ttraining's rmse: 5.94834\tvalid_1's rmse: 48.3665\n",
      "[870]\ttraining's rmse: 5.61997\tvalid_1's rmse: 48.3336\n",
      "[900]\ttraining's rmse: 5.30984\tvalid_1's rmse: 48.3209\n",
      "[930]\ttraining's rmse: 5.02276\tvalid_1's rmse: 48.3045\n",
      "[960]\ttraining's rmse: 4.75345\tvalid_1's rmse: 48.298\n",
      "[990]\ttraining's rmse: 4.50021\tvalid_1's rmse: 48.2782\n",
      "[1020]\ttraining's rmse: 4.26591\tvalid_1's rmse: 48.2693\n",
      "[1050]\ttraining's rmse: 4.04231\tvalid_1's rmse: 48.2576\n",
      "[1080]\ttraining's rmse: 3.83502\tvalid_1's rmse: 48.249\n",
      "[1110]\ttraining's rmse: 3.64269\tvalid_1's rmse: 48.2346\n",
      "[1140]\ttraining's rmse: 3.45805\tvalid_1's rmse: 48.2263\n",
      "[1170]\ttraining's rmse: 3.2864\tvalid_1's rmse: 48.213\n",
      "[1200]\ttraining's rmse: 3.12436\tvalid_1's rmse: 48.2004\n",
      "[1230]\ttraining's rmse: 2.97194\tvalid_1's rmse: 48.2004\n",
      "[1260]\ttraining's rmse: 2.81986\tvalid_1's rmse: 48.1918\n",
      "[1290]\ttraining's rmse: 2.67963\tvalid_1's rmse: 48.1866\n",
      "[1320]\ttraining's rmse: 2.54455\tvalid_1's rmse: 48.1719\n",
      "[1350]\ttraining's rmse: 2.42137\tvalid_1's rmse: 48.1652\n",
      "[1380]\ttraining's rmse: 2.30083\tvalid_1's rmse: 48.1589\n",
      "[1410]\ttraining's rmse: 2.19054\tvalid_1's rmse: 48.1562\n",
      "[1440]\ttraining's rmse: 2.08334\tvalid_1's rmse: 48.1524\n",
      "[1470]\ttraining's rmse: 1.98199\tvalid_1's rmse: 48.1526\n",
      "[1500]\ttraining's rmse: 1.88698\tvalid_1's rmse: 48.1489\n",
      "[1530]\ttraining's rmse: 1.80032\tvalid_1's rmse: 48.141\n",
      "[1560]\ttraining's rmse: 1.71665\tvalid_1's rmse: 48.14\n",
      "[1590]\ttraining's rmse: 1.63432\tvalid_1's rmse: 48.1385\n",
      "[1620]\ttraining's rmse: 1.554\tvalid_1's rmse: 48.1321\n",
      "[1650]\ttraining's rmse: 1.48447\tvalid_1's rmse: 48.1301\n",
      "[1680]\ttraining's rmse: 1.41485\tvalid_1's rmse: 48.1243\n",
      "[1710]\ttraining's rmse: 1.34924\tvalid_1's rmse: 48.1179\n",
      "[1740]\ttraining's rmse: 1.2868\tvalid_1's rmse: 48.1137\n",
      "[1770]\ttraining's rmse: 1.22871\tvalid_1's rmse: 48.1089\n",
      "[1800]\ttraining's rmse: 1.17236\tvalid_1's rmse: 48.1047\n",
      "[1830]\ttraining's rmse: 1.11999\tvalid_1's rmse: 48.1023\n",
      "[1860]\ttraining's rmse: 1.06954\tvalid_1's rmse: 48.0993\n",
      "[1890]\ttraining's rmse: 1.02232\tvalid_1's rmse: 48.0976\n",
      "[1920]\ttraining's rmse: 0.977439\tvalid_1's rmse: 48.0948\n",
      "[1950]\ttraining's rmse: 0.933965\tvalid_1's rmse: 48.0937\n",
      "[1980]\ttraining's rmse: 0.89244\tvalid_1's rmse: 48.0891\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's rmse: 0.867643\tvalid_1's rmse: 48.0877\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002605 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 20020\n",
      "[LightGBM] [Info] Number of data points in the train set: 9219, number of used features: 79\n",
      "[LightGBM] [Info] Start training from score 361.654431\n",
      "Training until validation scores don't improve for 125 rounds\n",
      "[30]\ttraining's rmse: 160.598\tvalid_1's rmse: 163.609\n",
      "[60]\ttraining's rmse: 100.37\tvalid_1's rmse: 111.096\n",
      "[90]\ttraining's rmse: 67.7872\tvalid_1's rmse: 85.0797\n",
      "[120]\ttraining's rmse: 49.9154\tvalid_1's rmse: 72.6304\n",
      "[150]\ttraining's rmse: 39.8981\tvalid_1's rmse: 66.6555\n",
      "[180]\ttraining's rmse: 33.7868\tvalid_1's rmse: 63.6464\n",
      "[210]\ttraining's rmse: 29.6037\tvalid_1's rmse: 61.8288\n",
      "[240]\ttraining's rmse: 26.3646\tvalid_1's rmse: 60.5948\n",
      "[270]\ttraining's rmse: 23.778\tvalid_1's rmse: 59.8108\n",
      "[300]\ttraining's rmse: 21.5848\tvalid_1's rmse: 59.1458\n",
      "[330]\ttraining's rmse: 19.7358\tvalid_1's rmse: 58.7047\n",
      "[360]\ttraining's rmse: 18.1651\tvalid_1's rmse: 58.4638\n",
      "[390]\ttraining's rmse: 16.744\tvalid_1's rmse: 58.2191\n",
      "[420]\ttraining's rmse: 15.4695\tvalid_1's rmse: 58.0567\n",
      "[450]\ttraining's rmse: 14.3528\tvalid_1's rmse: 57.953\n",
      "[480]\ttraining's rmse: 13.3396\tvalid_1's rmse: 57.8339\n",
      "[510]\ttraining's rmse: 12.4217\tvalid_1's rmse: 57.7861\n",
      "[540]\ttraining's rmse: 11.5945\tvalid_1's rmse: 57.7208\n",
      "[570]\ttraining's rmse: 10.8292\tvalid_1's rmse: 57.6405\n",
      "[600]\ttraining's rmse: 10.1418\tvalid_1's rmse: 57.5827\n",
      "[630]\ttraining's rmse: 9.50611\tvalid_1's rmse: 57.562\n",
      "[660]\ttraining's rmse: 8.89914\tvalid_1's rmse: 57.5259\n",
      "[690]\ttraining's rmse: 8.3482\tvalid_1's rmse: 57.5077\n",
      "[720]\ttraining's rmse: 7.84939\tvalid_1's rmse: 57.4857\n",
      "[750]\ttraining's rmse: 7.38493\tvalid_1's rmse: 57.4766\n",
      "[780]\ttraining's rmse: 6.95965\tvalid_1's rmse: 57.4583\n",
      "[810]\ttraining's rmse: 6.55085\tvalid_1's rmse: 57.437\n",
      "[840]\ttraining's rmse: 6.17701\tvalid_1's rmse: 57.4301\n",
      "[870]\ttraining's rmse: 5.83133\tvalid_1's rmse: 57.3999\n",
      "[900]\ttraining's rmse: 5.50077\tvalid_1's rmse: 57.38\n",
      "[930]\ttraining's rmse: 5.19372\tvalid_1's rmse: 57.37\n",
      "[960]\ttraining's rmse: 4.90309\tvalid_1's rmse: 57.3594\n",
      "[990]\ttraining's rmse: 4.63789\tvalid_1's rmse: 57.3557\n",
      "[1020]\ttraining's rmse: 4.38692\tvalid_1's rmse: 57.3522\n",
      "[1050]\ttraining's rmse: 4.15164\tvalid_1's rmse: 57.3394\n",
      "[1080]\ttraining's rmse: 3.92795\tvalid_1's rmse: 57.3323\n",
      "[1110]\ttraining's rmse: 3.71854\tvalid_1's rmse: 57.3171\n",
      "[1140]\ttraining's rmse: 3.52284\tvalid_1's rmse: 57.3113\n",
      "[1170]\ttraining's rmse: 3.34422\tvalid_1's rmse: 57.3025\n",
      "[1200]\ttraining's rmse: 3.1693\tvalid_1's rmse: 57.3032\n",
      "[1230]\ttraining's rmse: 3.00749\tvalid_1's rmse: 57.3006\n",
      "[1260]\ttraining's rmse: 2.85466\tvalid_1's rmse: 57.2968\n",
      "[1290]\ttraining's rmse: 2.70768\tvalid_1's rmse: 57.2956\n",
      "[1320]\ttraining's rmse: 2.56772\tvalid_1's rmse: 57.2908\n",
      "[1350]\ttraining's rmse: 2.43656\tvalid_1's rmse: 57.2866\n",
      "[1380]\ttraining's rmse: 2.31451\tvalid_1's rmse: 57.2853\n",
      "[1410]\ttraining's rmse: 2.19731\tvalid_1's rmse: 57.2809\n",
      "[1440]\ttraining's rmse: 2.08655\tvalid_1's rmse: 57.2746\n",
      "[1470]\ttraining's rmse: 1.98135\tvalid_1's rmse: 57.2717\n",
      "[1500]\ttraining's rmse: 1.88457\tvalid_1's rmse: 57.2679\n",
      "[1530]\ttraining's rmse: 1.79338\tvalid_1's rmse: 57.2647\n",
      "[1560]\ttraining's rmse: 1.70594\tvalid_1's rmse: 57.2622\n",
      "[1590]\ttraining's rmse: 1.62109\tvalid_1's rmse: 57.2605\n",
      "[1620]\ttraining's rmse: 1.5407\tvalid_1's rmse: 57.2599\n",
      "[1650]\ttraining's rmse: 1.46953\tvalid_1's rmse: 57.2543\n",
      "[1680]\ttraining's rmse: 1.39885\tvalid_1's rmse: 57.2485\n",
      "[1710]\ttraining's rmse: 1.33108\tvalid_1's rmse: 57.2497\n",
      "[1740]\ttraining's rmse: 1.26672\tvalid_1's rmse: 57.2451\n",
      "[1770]\ttraining's rmse: 1.20704\tvalid_1's rmse: 57.2454\n",
      "[1800]\ttraining's rmse: 1.15001\tvalid_1's rmse: 57.247\n",
      "[1830]\ttraining's rmse: 1.09559\tvalid_1's rmse: 57.2464\n",
      "[1860]\ttraining's rmse: 1.04504\tvalid_1's rmse: 57.2457\n",
      "[1890]\ttraining's rmse: 0.996596\tvalid_1's rmse: 57.2397\n",
      "[1920]\ttraining's rmse: 0.950386\tvalid_1's rmse: 57.237\n",
      "[1950]\ttraining's rmse: 0.905952\tvalid_1's rmse: 57.2362\n",
      "[1980]\ttraining's rmse: 0.863312\tvalid_1's rmse: 57.2362\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's rmse: 0.837235\tvalid_1's rmse: 57.2354\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003578 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 20020\n",
      "[LightGBM] [Info] Number of data points in the train set: 9219, number of used features: 79\n",
      "[LightGBM] [Info] Start training from score 374.552029\n",
      "Training until validation scores don't improve for 125 rounds\n",
      "[30]\ttraining's rmse: 166.449\tvalid_1's rmse: 170.659\n",
      "[60]\ttraining's rmse: 103.224\tvalid_1's rmse: 114.98\n",
      "[90]\ttraining's rmse: 69.0816\tvalid_1's rmse: 87.6887\n",
      "[120]\ttraining's rmse: 50.5008\tvalid_1's rmse: 74.6442\n",
      "[150]\ttraining's rmse: 40.0943\tvalid_1's rmse: 67.9165\n",
      "[180]\ttraining's rmse: 33.8499\tvalid_1's rmse: 64.4847\n",
      "[210]\ttraining's rmse: 29.5114\tvalid_1's rmse: 62.2002\n",
      "[240]\ttraining's rmse: 26.2755\tvalid_1's rmse: 60.8113\n",
      "[270]\ttraining's rmse: 23.6624\tvalid_1's rmse: 60.0227\n",
      "[300]\ttraining's rmse: 21.5219\tvalid_1's rmse: 59.5093\n",
      "[330]\ttraining's rmse: 19.7247\tvalid_1's rmse: 59.0803\n",
      "[360]\ttraining's rmse: 18.1529\tvalid_1's rmse: 58.7316\n",
      "[390]\ttraining's rmse: 16.7425\tvalid_1's rmse: 58.4475\n",
      "[420]\ttraining's rmse: 15.4985\tvalid_1's rmse: 58.2574\n",
      "[450]\ttraining's rmse: 14.3709\tvalid_1's rmse: 58.0897\n",
      "[480]\ttraining's rmse: 13.3302\tvalid_1's rmse: 57.8969\n",
      "[510]\ttraining's rmse: 12.4155\tvalid_1's rmse: 57.7498\n",
      "[540]\ttraining's rmse: 11.5729\tvalid_1's rmse: 57.673\n",
      "[570]\ttraining's rmse: 10.8155\tvalid_1's rmse: 57.5679\n",
      "[600]\ttraining's rmse: 10.105\tvalid_1's rmse: 57.4947\n",
      "[630]\ttraining's rmse: 9.46402\tvalid_1's rmse: 57.4211\n",
      "[660]\ttraining's rmse: 8.87366\tvalid_1's rmse: 57.3689\n",
      "[690]\ttraining's rmse: 8.31093\tvalid_1's rmse: 57.3177\n",
      "[720]\ttraining's rmse: 7.81168\tvalid_1's rmse: 57.28\n",
      "[750]\ttraining's rmse: 7.3304\tvalid_1's rmse: 57.2419\n",
      "[780]\ttraining's rmse: 6.89891\tvalid_1's rmse: 57.186\n",
      "[810]\ttraining's rmse: 6.49145\tvalid_1's rmse: 57.1382\n",
      "[840]\ttraining's rmse: 6.12233\tvalid_1's rmse: 57.1061\n",
      "[870]\ttraining's rmse: 5.76388\tvalid_1's rmse: 57.0718\n",
      "[900]\ttraining's rmse: 5.43153\tvalid_1's rmse: 57.0514\n",
      "[930]\ttraining's rmse: 5.12206\tvalid_1's rmse: 57.0431\n",
      "[960]\ttraining's rmse: 4.83671\tvalid_1's rmse: 57.0242\n",
      "[990]\ttraining's rmse: 4.56216\tvalid_1's rmse: 56.998\n",
      "[1020]\ttraining's rmse: 4.31482\tvalid_1's rmse: 56.9681\n",
      "[1050]\ttraining's rmse: 4.07967\tvalid_1's rmse: 56.9573\n",
      "[1080]\ttraining's rmse: 3.85912\tvalid_1's rmse: 56.9387\n",
      "[1110]\ttraining's rmse: 3.65322\tvalid_1's rmse: 56.9236\n",
      "[1140]\ttraining's rmse: 3.45523\tvalid_1's rmse: 56.9164\n",
      "[1170]\ttraining's rmse: 3.27411\tvalid_1's rmse: 56.9115\n",
      "[1200]\ttraining's rmse: 3.10056\tvalid_1's rmse: 56.8922\n",
      "[1230]\ttraining's rmse: 2.93786\tvalid_1's rmse: 56.8844\n",
      "[1260]\ttraining's rmse: 2.78234\tvalid_1's rmse: 56.8753\n",
      "[1290]\ttraining's rmse: 2.63784\tvalid_1's rmse: 56.868\n",
      "[1320]\ttraining's rmse: 2.49656\tvalid_1's rmse: 56.8594\n",
      "[1350]\ttraining's rmse: 2.36808\tvalid_1's rmse: 56.8573\n",
      "[1380]\ttraining's rmse: 2.24606\tvalid_1's rmse: 56.854\n",
      "[1410]\ttraining's rmse: 2.12949\tvalid_1's rmse: 56.85\n",
      "[1440]\ttraining's rmse: 2.01969\tvalid_1's rmse: 56.8476\n",
      "[1470]\ttraining's rmse: 1.91857\tvalid_1's rmse: 56.8436\n",
      "[1500]\ttraining's rmse: 1.82256\tvalid_1's rmse: 56.8393\n",
      "[1530]\ttraining's rmse: 1.73205\tvalid_1's rmse: 56.8352\n",
      "[1560]\ttraining's rmse: 1.64335\tvalid_1's rmse: 56.8321\n",
      "[1590]\ttraining's rmse: 1.55982\tvalid_1's rmse: 56.8284\n",
      "[1620]\ttraining's rmse: 1.48422\tvalid_1's rmse: 56.8246\n",
      "[1650]\ttraining's rmse: 1.41101\tvalid_1's rmse: 56.8214\n",
      "[1680]\ttraining's rmse: 1.34075\tvalid_1's rmse: 56.8182\n",
      "[1710]\ttraining's rmse: 1.27327\tvalid_1's rmse: 56.8163\n",
      "[1740]\ttraining's rmse: 1.21049\tvalid_1's rmse: 56.8159\n",
      "[1770]\ttraining's rmse: 1.15142\tvalid_1's rmse: 56.8121\n",
      "[1800]\ttraining's rmse: 1.0938\tvalid_1's rmse: 56.8097\n",
      "[1830]\ttraining's rmse: 1.04033\tvalid_1's rmse: 56.8091\n",
      "[1860]\ttraining's rmse: 0.989224\tvalid_1's rmse: 56.8072\n",
      "[1890]\ttraining's rmse: 0.940815\tvalid_1's rmse: 56.8073\n",
      "[1920]\ttraining's rmse: 0.895767\tvalid_1's rmse: 56.8069\n",
      "[1950]\ttraining's rmse: 0.852872\tvalid_1's rmse: 56.8057\n",
      "[1980]\ttraining's rmse: 0.811647\tvalid_1's rmse: 56.8038\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's rmse: 0.78592\tvalid_1's rmse: 56.8027\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003649 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 20020\n",
      "[LightGBM] [Info] Number of data points in the train set: 9219, number of used features: 79\n",
      "[LightGBM] [Info] Start training from score 380.531234\n",
      "Training until validation scores don't improve for 125 rounds\n",
      "[30]\ttraining's rmse: 171.996\tvalid_1's rmse: 176.237\n",
      "[60]\ttraining's rmse: 106.763\tvalid_1's rmse: 116.536\n",
      "[90]\ttraining's rmse: 71.2443\tvalid_1's rmse: 86.9138\n",
      "[120]\ttraining's rmse: 51.9222\tvalid_1's rmse: 72.809\n",
      "[150]\ttraining's rmse: 41.0128\tvalid_1's rmse: 66.0574\n",
      "[180]\ttraining's rmse: 34.4522\tvalid_1's rmse: 62.3621\n",
      "[210]\ttraining's rmse: 30.0248\tvalid_1's rmse: 60.459\n",
      "[240]\ttraining's rmse: 26.6339\tvalid_1's rmse: 59.1922\n",
      "[270]\ttraining's rmse: 23.9404\tvalid_1's rmse: 58.3738\n",
      "[300]\ttraining's rmse: 21.7076\tvalid_1's rmse: 57.8073\n",
      "[330]\ttraining's rmse: 19.8414\tvalid_1's rmse: 57.3684\n",
      "[360]\ttraining's rmse: 18.252\tvalid_1's rmse: 57.0756\n",
      "[390]\ttraining's rmse: 16.8458\tvalid_1's rmse: 56.8615\n",
      "[420]\ttraining's rmse: 15.5848\tvalid_1's rmse: 56.6893\n",
      "[450]\ttraining's rmse: 14.4688\tvalid_1's rmse: 56.5368\n",
      "[480]\ttraining's rmse: 13.4451\tvalid_1's rmse: 56.3843\n",
      "[510]\ttraining's rmse: 12.5366\tvalid_1's rmse: 56.2688\n",
      "[540]\ttraining's rmse: 11.6816\tvalid_1's rmse: 56.188\n",
      "[570]\ttraining's rmse: 10.9213\tvalid_1's rmse: 56.1087\n",
      "[600]\ttraining's rmse: 10.2227\tvalid_1's rmse: 56.0359\n",
      "[630]\ttraining's rmse: 9.57794\tvalid_1's rmse: 55.9829\n",
      "[660]\ttraining's rmse: 8.99553\tvalid_1's rmse: 55.9365\n",
      "[690]\ttraining's rmse: 8.4431\tvalid_1's rmse: 55.873\n",
      "[720]\ttraining's rmse: 7.93535\tvalid_1's rmse: 55.8465\n",
      "[750]\ttraining's rmse: 7.46808\tvalid_1's rmse: 55.8114\n",
      "[780]\ttraining's rmse: 7.03701\tvalid_1's rmse: 55.7837\n",
      "[810]\ttraining's rmse: 6.62896\tvalid_1's rmse: 55.7578\n",
      "[840]\ttraining's rmse: 6.25224\tvalid_1's rmse: 55.7258\n",
      "[870]\ttraining's rmse: 5.89962\tvalid_1's rmse: 55.7194\n",
      "[900]\ttraining's rmse: 5.57205\tvalid_1's rmse: 55.6989\n",
      "[930]\ttraining's rmse: 5.26268\tvalid_1's rmse: 55.6708\n",
      "[960]\ttraining's rmse: 4.97914\tvalid_1's rmse: 55.6456\n",
      "[990]\ttraining's rmse: 4.71138\tvalid_1's rmse: 55.6261\n",
      "[1020]\ttraining's rmse: 4.45992\tvalid_1's rmse: 55.606\n",
      "[1050]\ttraining's rmse: 4.22413\tvalid_1's rmse: 55.5781\n",
      "[1080]\ttraining's rmse: 4.00073\tvalid_1's rmse: 55.5582\n",
      "[1110]\ttraining's rmse: 3.79255\tvalid_1's rmse: 55.5574\n",
      "[1140]\ttraining's rmse: 3.59923\tvalid_1's rmse: 55.5409\n",
      "[1170]\ttraining's rmse: 3.41597\tvalid_1's rmse: 55.5223\n",
      "[1200]\ttraining's rmse: 3.24123\tvalid_1's rmse: 55.5129\n",
      "[1230]\ttraining's rmse: 3.07518\tvalid_1's rmse: 55.5021\n",
      "[1260]\ttraining's rmse: 2.92618\tvalid_1's rmse: 55.4954\n",
      "[1290]\ttraining's rmse: 2.77779\tvalid_1's rmse: 55.487\n",
      "[1320]\ttraining's rmse: 2.64197\tvalid_1's rmse: 55.4806\n",
      "[1350]\ttraining's rmse: 2.51277\tvalid_1's rmse: 55.4755\n",
      "[1380]\ttraining's rmse: 2.39326\tvalid_1's rmse: 55.4738\n",
      "[1410]\ttraining's rmse: 2.2755\tvalid_1's rmse: 55.4721\n",
      "[1440]\ttraining's rmse: 2.16726\tvalid_1's rmse: 55.4625\n",
      "[1470]\ttraining's rmse: 2.06516\tvalid_1's rmse: 55.4562\n",
      "[1500]\ttraining's rmse: 1.96694\tvalid_1's rmse: 55.451\n",
      "[1530]\ttraining's rmse: 1.87268\tvalid_1's rmse: 55.4494\n",
      "[1560]\ttraining's rmse: 1.78358\tvalid_1's rmse: 55.4448\n",
      "[1590]\ttraining's rmse: 1.69683\tvalid_1's rmse: 55.4457\n",
      "[1620]\ttraining's rmse: 1.61699\tvalid_1's rmse: 55.4385\n",
      "[1650]\ttraining's rmse: 1.54152\tvalid_1's rmse: 55.4369\n",
      "[1680]\ttraining's rmse: 1.47052\tvalid_1's rmse: 55.4297\n",
      "[1710]\ttraining's rmse: 1.40142\tvalid_1's rmse: 55.4254\n",
      "[1740]\ttraining's rmse: 1.33787\tvalid_1's rmse: 55.4212\n",
      "[1770]\ttraining's rmse: 1.27545\tvalid_1's rmse: 55.4193\n",
      "[1800]\ttraining's rmse: 1.21767\tvalid_1's rmse: 55.4155\n",
      "[1830]\ttraining's rmse: 1.16384\tvalid_1's rmse: 55.4133\n",
      "[1860]\ttraining's rmse: 1.10989\tvalid_1's rmse: 55.4111\n",
      "[1890]\ttraining's rmse: 1.05987\tvalid_1's rmse: 55.4074\n",
      "[1920]\ttraining's rmse: 1.01215\tvalid_1's rmse: 55.4055\n",
      "[1950]\ttraining's rmse: 0.967368\tvalid_1's rmse: 55.4042\n",
      "[1980]\ttraining's rmse: 0.924657\tvalid_1's rmse: 55.4031\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's rmse: 0.896233\tvalid_1's rmse: 55.401\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002448 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 20020\n",
      "[LightGBM] [Info] Number of data points in the train set: 9219, number of used features: 79\n",
      "[LightGBM] [Info] Start training from score 382.639352\n",
      "Training until validation scores don't improve for 125 rounds\n",
      "[30]\ttraining's rmse: 171.78\tvalid_1's rmse: 179.543\n",
      "[60]\ttraining's rmse: 106.98\tvalid_1's rmse: 119.077\n",
      "[90]\ttraining's rmse: 71.4322\tvalid_1's rmse: 88.2796\n",
      "[120]\ttraining's rmse: 52.0628\tvalid_1's rmse: 73.1745\n",
      "[150]\ttraining's rmse: 41.3346\tvalid_1's rmse: 66.1226\n",
      "[180]\ttraining's rmse: 34.8266\tvalid_1's rmse: 62.6096\n",
      "[210]\ttraining's rmse: 30.3964\tvalid_1's rmse: 60.6138\n",
      "[240]\ttraining's rmse: 27.0516\tvalid_1's rmse: 59.357\n",
      "[270]\ttraining's rmse: 24.3532\tvalid_1's rmse: 58.5512\n",
      "[300]\ttraining's rmse: 22.1543\tvalid_1's rmse: 57.9457\n",
      "[330]\ttraining's rmse: 20.2791\tvalid_1's rmse: 57.5792\n",
      "[360]\ttraining's rmse: 18.6885\tvalid_1's rmse: 57.3058\n",
      "[390]\ttraining's rmse: 17.2556\tvalid_1's rmse: 57.0697\n",
      "[420]\ttraining's rmse: 15.9729\tvalid_1's rmse: 56.8921\n",
      "[450]\ttraining's rmse: 14.828\tvalid_1's rmse: 56.73\n",
      "[480]\ttraining's rmse: 13.7958\tvalid_1's rmse: 56.6074\n",
      "[510]\ttraining's rmse: 12.8475\tvalid_1's rmse: 56.4713\n",
      "[540]\ttraining's rmse: 12.0062\tvalid_1's rmse: 56.3911\n",
      "[570]\ttraining's rmse: 11.2269\tvalid_1's rmse: 56.3117\n",
      "[600]\ttraining's rmse: 10.5235\tvalid_1's rmse: 56.2498\n",
      "[630]\ttraining's rmse: 9.86448\tvalid_1's rmse: 56.1982\n",
      "[660]\ttraining's rmse: 9.24423\tvalid_1's rmse: 56.1534\n",
      "[690]\ttraining's rmse: 8.68834\tvalid_1's rmse: 56.1095\n",
      "[720]\ttraining's rmse: 8.16566\tvalid_1's rmse: 56.0666\n",
      "[750]\ttraining's rmse: 7.69185\tvalid_1's rmse: 56.0271\n",
      "[780]\ttraining's rmse: 7.24286\tvalid_1's rmse: 56.002\n",
      "[810]\ttraining's rmse: 6.82832\tvalid_1's rmse: 55.9623\n",
      "[840]\ttraining's rmse: 6.44331\tvalid_1's rmse: 55.9293\n",
      "[870]\ttraining's rmse: 6.08512\tvalid_1's rmse: 55.9003\n",
      "[900]\ttraining's rmse: 5.75441\tvalid_1's rmse: 55.8702\n",
      "[930]\ttraining's rmse: 5.43635\tvalid_1's rmse: 55.8567\n",
      "[960]\ttraining's rmse: 5.13425\tvalid_1's rmse: 55.8419\n",
      "[990]\ttraining's rmse: 4.8561\tvalid_1's rmse: 55.8254\n",
      "[1020]\ttraining's rmse: 4.5987\tvalid_1's rmse: 55.8052\n",
      "[1050]\ttraining's rmse: 4.35227\tvalid_1's rmse: 55.7971\n",
      "[1080]\ttraining's rmse: 4.12516\tvalid_1's rmse: 55.7806\n",
      "[1110]\ttraining's rmse: 3.91292\tvalid_1's rmse: 55.7678\n",
      "[1140]\ttraining's rmse: 3.71127\tvalid_1's rmse: 55.7566\n",
      "[1170]\ttraining's rmse: 3.52387\tvalid_1's rmse: 55.7475\n",
      "[1200]\ttraining's rmse: 3.34674\tvalid_1's rmse: 55.7388\n",
      "[1230]\ttraining's rmse: 3.17418\tvalid_1's rmse: 55.7327\n",
      "[1260]\ttraining's rmse: 3.01474\tvalid_1's rmse: 55.7252\n",
      "[1290]\ttraining's rmse: 2.8612\tvalid_1's rmse: 55.721\n",
      "[1320]\ttraining's rmse: 2.71765\tvalid_1's rmse: 55.7147\n",
      "[1350]\ttraining's rmse: 2.58067\tvalid_1's rmse: 55.709\n",
      "[1380]\ttraining's rmse: 2.45403\tvalid_1's rmse: 55.7035\n",
      "[1410]\ttraining's rmse: 2.33516\tvalid_1's rmse: 55.7035\n",
      "[1440]\ttraining's rmse: 2.22224\tvalid_1's rmse: 55.6977\n",
      "[1470]\ttraining's rmse: 2.11333\tvalid_1's rmse: 55.6963\n",
      "[1500]\ttraining's rmse: 2.01235\tvalid_1's rmse: 55.6952\n",
      "[1530]\ttraining's rmse: 1.91824\tvalid_1's rmse: 55.6934\n",
      "[1560]\ttraining's rmse: 1.82474\tvalid_1's rmse: 55.6905\n",
      "[1590]\ttraining's rmse: 1.74098\tvalid_1's rmse: 55.6881\n",
      "[1620]\ttraining's rmse: 1.65765\tvalid_1's rmse: 55.6878\n",
      "[1650]\ttraining's rmse: 1.58034\tvalid_1's rmse: 55.6861\n",
      "[1680]\ttraining's rmse: 1.50544\tvalid_1's rmse: 55.6822\n",
      "[1710]\ttraining's rmse: 1.43405\tvalid_1's rmse: 55.6799\n",
      "[1740]\ttraining's rmse: 1.36996\tvalid_1's rmse: 55.6777\n",
      "[1770]\ttraining's rmse: 1.30831\tvalid_1's rmse: 55.6736\n",
      "[1800]\ttraining's rmse: 1.24839\tvalid_1's rmse: 55.6712\n",
      "[1830]\ttraining's rmse: 1.19043\tvalid_1's rmse: 55.6703\n",
      "[1860]\ttraining's rmse: 1.13646\tvalid_1's rmse: 55.6699\n",
      "[1890]\ttraining's rmse: 1.08378\tvalid_1's rmse: 55.6704\n",
      "[1920]\ttraining's rmse: 1.03325\tvalid_1's rmse: 55.6707\n",
      "[1950]\ttraining's rmse: 0.984759\tvalid_1's rmse: 55.6689\n",
      "[1980]\ttraining's rmse: 0.939151\tvalid_1's rmse: 55.6691\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's rmse: 0.911768\tvalid_1's rmse: 55.6687\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002433 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 20020\n",
      "[LightGBM] [Info] Number of data points in the train set: 9219, number of used features: 79\n",
      "[LightGBM] [Info] Start training from score 381.134788\n",
      "Training until validation scores don't improve for 125 rounds\n",
      "[30]\ttraining's rmse: 172.606\tvalid_1's rmse: 175.147\n",
      "[60]\ttraining's rmse: 106.185\tvalid_1's rmse: 113.917\n",
      "[90]\ttraining's rmse: 70.3586\tvalid_1's rmse: 83.7652\n",
      "[120]\ttraining's rmse: 51.1322\tvalid_1's rmse: 69.7086\n",
      "[150]\ttraining's rmse: 40.4488\tvalid_1's rmse: 63.0997\n",
      "[180]\ttraining's rmse: 33.9121\tvalid_1's rmse: 59.6963\n",
      "[210]\ttraining's rmse: 29.6835\tvalid_1's rmse: 57.8355\n",
      "[240]\ttraining's rmse: 26.3557\tvalid_1's rmse: 56.6604\n",
      "[270]\ttraining's rmse: 23.7076\tvalid_1's rmse: 55.8731\n",
      "[300]\ttraining's rmse: 21.5089\tvalid_1's rmse: 55.4043\n",
      "[330]\ttraining's rmse: 19.6695\tvalid_1's rmse: 55.0775\n",
      "[360]\ttraining's rmse: 18.1298\tvalid_1's rmse: 54.7629\n",
      "[390]\ttraining's rmse: 16.7135\tvalid_1's rmse: 54.5203\n",
      "[420]\ttraining's rmse: 15.4668\tvalid_1's rmse: 54.3583\n",
      "[450]\ttraining's rmse: 14.3456\tvalid_1's rmse: 54.226\n",
      "[480]\ttraining's rmse: 13.3227\tvalid_1's rmse: 54.1018\n",
      "[510]\ttraining's rmse: 12.4111\tvalid_1's rmse: 53.9856\n",
      "[540]\ttraining's rmse: 11.5846\tvalid_1's rmse: 53.8875\n",
      "[570]\ttraining's rmse: 10.8312\tvalid_1's rmse: 53.8143\n",
      "[600]\ttraining's rmse: 10.1448\tvalid_1's rmse: 53.752\n",
      "[630]\ttraining's rmse: 9.5111\tvalid_1's rmse: 53.7032\n",
      "[660]\ttraining's rmse: 8.92467\tvalid_1's rmse: 53.6881\n",
      "[690]\ttraining's rmse: 8.37915\tvalid_1's rmse: 53.6362\n",
      "[720]\ttraining's rmse: 7.86603\tvalid_1's rmse: 53.5768\n",
      "[750]\ttraining's rmse: 7.39008\tvalid_1's rmse: 53.5409\n",
      "[780]\ttraining's rmse: 6.95336\tvalid_1's rmse: 53.5172\n",
      "[810]\ttraining's rmse: 6.54387\tvalid_1's rmse: 53.4988\n",
      "[840]\ttraining's rmse: 6.1666\tvalid_1's rmse: 53.4804\n",
      "[870]\ttraining's rmse: 5.82235\tvalid_1's rmse: 53.4617\n",
      "[900]\ttraining's rmse: 5.4883\tvalid_1's rmse: 53.4502\n",
      "[930]\ttraining's rmse: 5.18439\tvalid_1's rmse: 53.4334\n",
      "[960]\ttraining's rmse: 4.89701\tvalid_1's rmse: 53.4105\n",
      "[990]\ttraining's rmse: 4.62706\tvalid_1's rmse: 53.3965\n",
      "[1020]\ttraining's rmse: 4.38219\tvalid_1's rmse: 53.3815\n",
      "[1050]\ttraining's rmse: 4.14708\tvalid_1's rmse: 53.3701\n",
      "[1080]\ttraining's rmse: 3.92462\tvalid_1's rmse: 53.3621\n",
      "[1110]\ttraining's rmse: 3.71456\tvalid_1's rmse: 53.351\n",
      "[1140]\ttraining's rmse: 3.51774\tvalid_1's rmse: 53.3394\n",
      "[1170]\ttraining's rmse: 3.33106\tvalid_1's rmse: 53.3289\n",
      "[1200]\ttraining's rmse: 3.15781\tvalid_1's rmse: 53.3239\n",
      "[1230]\ttraining's rmse: 2.99412\tvalid_1's rmse: 53.3175\n",
      "[1260]\ttraining's rmse: 2.83722\tvalid_1's rmse: 53.3125\n",
      "[1290]\ttraining's rmse: 2.69389\tvalid_1's rmse: 53.3117\n",
      "[1320]\ttraining's rmse: 2.55156\tvalid_1's rmse: 53.3073\n",
      "[1350]\ttraining's rmse: 2.42345\tvalid_1's rmse: 53.305\n",
      "[1380]\ttraining's rmse: 2.3032\tvalid_1's rmse: 53.3052\n",
      "[1410]\ttraining's rmse: 2.18486\tvalid_1's rmse: 53.3057\n",
      "[1440]\ttraining's rmse: 2.07478\tvalid_1's rmse: 53.302\n",
      "[1470]\ttraining's rmse: 1.97027\tvalid_1's rmse: 53.2982\n",
      "[1500]\ttraining's rmse: 1.86879\tvalid_1's rmse: 53.293\n",
      "[1530]\ttraining's rmse: 1.77723\tvalid_1's rmse: 53.2927\n",
      "[1560]\ttraining's rmse: 1.68958\tvalid_1's rmse: 53.2926\n",
      "[1590]\ttraining's rmse: 1.60695\tvalid_1's rmse: 53.2882\n",
      "[1620]\ttraining's rmse: 1.52679\tvalid_1's rmse: 53.2837\n",
      "[1650]\ttraining's rmse: 1.4528\tvalid_1's rmse: 53.2811\n",
      "[1680]\ttraining's rmse: 1.38312\tvalid_1's rmse: 53.28\n",
      "[1710]\ttraining's rmse: 1.31586\tvalid_1's rmse: 53.2748\n",
      "[1740]\ttraining's rmse: 1.2508\tvalid_1's rmse: 53.273\n",
      "[1770]\ttraining's rmse: 1.18882\tvalid_1's rmse: 53.2719\n",
      "[1800]\ttraining's rmse: 1.13146\tvalid_1's rmse: 53.2711\n",
      "[1830]\ttraining's rmse: 1.07755\tvalid_1's rmse: 53.2697\n",
      "[1860]\ttraining's rmse: 1.02722\tvalid_1's rmse: 53.2685\n",
      "[1890]\ttraining's rmse: 0.978381\tvalid_1's rmse: 53.2682\n",
      "[1920]\ttraining's rmse: 0.932288\tvalid_1's rmse: 53.2667\n",
      "[1950]\ttraining's rmse: 0.887512\tvalid_1's rmse: 53.2661\n",
      "[1980]\ttraining's rmse: 0.844956\tvalid_1's rmse: 53.2656\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's rmse: 0.818316\tvalid_1's rmse: 53.2638\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002538 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 20020\n",
      "[LightGBM] [Info] Number of data points in the train set: 9219, number of used features: 79\n",
      "[LightGBM] [Info] Start training from score 379.459898\n",
      "Training until validation scores don't improve for 125 rounds\n",
      "[30]\ttraining's rmse: 171.72\tvalid_1's rmse: 175.689\n",
      "[60]\ttraining's rmse: 105.926\tvalid_1's rmse: 114.035\n",
      "[90]\ttraining's rmse: 70.0167\tvalid_1's rmse: 82.6802\n",
      "[120]\ttraining's rmse: 50.74\tvalid_1's rmse: 67.8784\n",
      "[150]\ttraining's rmse: 40.0388\tvalid_1's rmse: 61.0496\n",
      "[180]\ttraining's rmse: 33.6657\tvalid_1's rmse: 57.6318\n",
      "[210]\ttraining's rmse: 29.3705\tvalid_1's rmse: 55.7379\n",
      "[240]\ttraining's rmse: 26.1719\tvalid_1's rmse: 54.5907\n",
      "[270]\ttraining's rmse: 23.6413\tvalid_1's rmse: 53.785\n",
      "[300]\ttraining's rmse: 21.5219\tvalid_1's rmse: 53.2881\n",
      "[330]\ttraining's rmse: 19.7363\tvalid_1's rmse: 52.897\n",
      "[360]\ttraining's rmse: 18.1805\tvalid_1's rmse: 52.5566\n",
      "[390]\ttraining's rmse: 16.7747\tvalid_1's rmse: 52.3104\n",
      "[420]\ttraining's rmse: 15.5237\tvalid_1's rmse: 52.1325\n",
      "[450]\ttraining's rmse: 14.4262\tvalid_1's rmse: 51.9512\n",
      "[480]\ttraining's rmse: 13.4178\tvalid_1's rmse: 51.8122\n",
      "[510]\ttraining's rmse: 12.505\tvalid_1's rmse: 51.6766\n",
      "[540]\ttraining's rmse: 11.6696\tvalid_1's rmse: 51.5831\n",
      "[570]\ttraining's rmse: 10.9141\tvalid_1's rmse: 51.5198\n",
      "[600]\ttraining's rmse: 10.2344\tvalid_1's rmse: 51.4677\n",
      "[630]\ttraining's rmse: 9.60131\tvalid_1's rmse: 51.4005\n",
      "[660]\ttraining's rmse: 9.00885\tvalid_1's rmse: 51.3404\n",
      "[690]\ttraining's rmse: 8.46769\tvalid_1's rmse: 51.2805\n",
      "[720]\ttraining's rmse: 7.95907\tvalid_1's rmse: 51.2443\n",
      "[750]\ttraining's rmse: 7.49692\tvalid_1's rmse: 51.2059\n",
      "[780]\ttraining's rmse: 7.05276\tvalid_1's rmse: 51.1738\n",
      "[810]\ttraining's rmse: 6.64588\tvalid_1's rmse: 51.1507\n",
      "[840]\ttraining's rmse: 6.27337\tvalid_1's rmse: 51.1139\n",
      "[870]\ttraining's rmse: 5.91925\tvalid_1's rmse: 51.0947\n",
      "[900]\ttraining's rmse: 5.59203\tvalid_1's rmse: 51.0792\n",
      "[930]\ttraining's rmse: 5.28509\tvalid_1's rmse: 51.0645\n",
      "[960]\ttraining's rmse: 4.99681\tvalid_1's rmse: 51.0505\n",
      "[990]\ttraining's rmse: 4.73033\tvalid_1's rmse: 51.0428\n",
      "[1020]\ttraining's rmse: 4.47626\tvalid_1's rmse: 51.0241\n",
      "[1050]\ttraining's rmse: 4.23443\tvalid_1's rmse: 51.0142\n",
      "[1080]\ttraining's rmse: 4.01457\tvalid_1's rmse: 51.01\n",
      "[1110]\ttraining's rmse: 3.80393\tvalid_1's rmse: 51.0075\n",
      "[1140]\ttraining's rmse: 3.60802\tvalid_1's rmse: 50.9992\n",
      "[1170]\ttraining's rmse: 3.42405\tvalid_1's rmse: 50.9912\n",
      "[1200]\ttraining's rmse: 3.24558\tvalid_1's rmse: 50.9799\n",
      "[1230]\ttraining's rmse: 3.07888\tvalid_1's rmse: 50.9769\n",
      "[1260]\ttraining's rmse: 2.92195\tvalid_1's rmse: 50.9723\n",
      "[1290]\ttraining's rmse: 2.7749\tvalid_1's rmse: 50.9707\n",
      "[1320]\ttraining's rmse: 2.63597\tvalid_1's rmse: 50.9718\n",
      "[1350]\ttraining's rmse: 2.50418\tvalid_1's rmse: 50.9657\n",
      "[1380]\ttraining's rmse: 2.37677\tvalid_1's rmse: 50.9613\n",
      "[1410]\ttraining's rmse: 2.25825\tvalid_1's rmse: 50.9615\n",
      "[1440]\ttraining's rmse: 2.15077\tvalid_1's rmse: 50.9531\n",
      "[1470]\ttraining's rmse: 2.0462\tvalid_1's rmse: 50.9508\n",
      "[1500]\ttraining's rmse: 1.94808\tvalid_1's rmse: 50.9474\n",
      "[1530]\ttraining's rmse: 1.85261\tvalid_1's rmse: 50.9434\n",
      "[1560]\ttraining's rmse: 1.76257\tvalid_1's rmse: 50.943\n",
      "[1590]\ttraining's rmse: 1.67722\tvalid_1's rmse: 50.9407\n",
      "[1620]\ttraining's rmse: 1.59614\tvalid_1's rmse: 50.9382\n",
      "[1650]\ttraining's rmse: 1.52039\tvalid_1's rmse: 50.9334\n",
      "[1680]\ttraining's rmse: 1.44706\tvalid_1's rmse: 50.9301\n",
      "[1710]\ttraining's rmse: 1.37702\tvalid_1's rmse: 50.9285\n",
      "[1740]\ttraining's rmse: 1.31167\tvalid_1's rmse: 50.9236\n",
      "[1770]\ttraining's rmse: 1.24958\tvalid_1's rmse: 50.9223\n",
      "[1800]\ttraining's rmse: 1.19053\tvalid_1's rmse: 50.922\n",
      "[1830]\ttraining's rmse: 1.1321\tvalid_1's rmse: 50.9206\n",
      "[1860]\ttraining's rmse: 1.0787\tvalid_1's rmse: 50.9197\n",
      "[1890]\ttraining's rmse: 1.02794\tvalid_1's rmse: 50.9185\n",
      "[1920]\ttraining's rmse: 0.979828\tvalid_1's rmse: 50.9166\n",
      "[1950]\ttraining's rmse: 0.934842\tvalid_1's rmse: 50.9157\n",
      "[1980]\ttraining's rmse: 0.89\tvalid_1's rmse: 50.9139\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's rmse: 0.861973\tvalid_1's rmse: 50.9109\n",
      "13\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002360 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 20019\n",
      "[LightGBM] [Info] Number of data points in the train set: 9219, number of used features: 79\n",
      "[LightGBM] [Info] Start training from score 372.645781\n",
      "Training until validation scores don't improve for 125 rounds\n",
      "[30]\ttraining's rmse: 160.423\tvalid_1's rmse: 165.154\n",
      "[60]\ttraining's rmse: 98.5173\tvalid_1's rmse: 110.316\n",
      "[90]\ttraining's rmse: 64.7667\tvalid_1's rmse: 82.9678\n",
      "[120]\ttraining's rmse: 46.7571\tvalid_1's rmse: 70.1514\n",
      "[150]\ttraining's rmse: 36.9756\tvalid_1's rmse: 64.2116\n",
      "[180]\ttraining's rmse: 31.1743\tvalid_1's rmse: 61.2597\n",
      "[210]\ttraining's rmse: 27.2225\tvalid_1's rmse: 59.4826\n",
      "[240]\ttraining's rmse: 24.2473\tvalid_1's rmse: 58.4295\n",
      "[270]\ttraining's rmse: 21.9148\tvalid_1's rmse: 57.7228\n",
      "[300]\ttraining's rmse: 19.9728\tvalid_1's rmse: 57.1835\n",
      "[330]\ttraining's rmse: 18.2974\tvalid_1's rmse: 56.8583\n",
      "[360]\ttraining's rmse: 16.8904\tvalid_1's rmse: 56.6502\n",
      "[390]\ttraining's rmse: 15.6216\tvalid_1's rmse: 56.4139\n",
      "[420]\ttraining's rmse: 14.4806\tvalid_1's rmse: 56.2362\n",
      "[450]\ttraining's rmse: 13.4793\tvalid_1's rmse: 56.1202\n",
      "[480]\ttraining's rmse: 12.5489\tvalid_1's rmse: 55.9769\n",
      "[510]\ttraining's rmse: 11.7102\tvalid_1's rmse: 55.9115\n",
      "[540]\ttraining's rmse: 10.9433\tvalid_1's rmse: 55.8413\n",
      "[570]\ttraining's rmse: 10.2667\tvalid_1's rmse: 55.7914\n",
      "[600]\ttraining's rmse: 9.62845\tvalid_1's rmse: 55.7019\n",
      "[630]\ttraining's rmse: 9.05026\tvalid_1's rmse: 55.6358\n",
      "[660]\ttraining's rmse: 8.5102\tvalid_1's rmse: 55.5707\n",
      "[690]\ttraining's rmse: 8.01621\tvalid_1's rmse: 55.5065\n",
      "[720]\ttraining's rmse: 7.54196\tvalid_1's rmse: 55.4655\n",
      "[750]\ttraining's rmse: 7.10351\tvalid_1's rmse: 55.4401\n",
      "[780]\ttraining's rmse: 6.70185\tvalid_1's rmse: 55.3985\n",
      "[810]\ttraining's rmse: 6.32755\tvalid_1's rmse: 55.3779\n",
      "[840]\ttraining's rmse: 5.98336\tvalid_1's rmse: 55.3733\n",
      "[870]\ttraining's rmse: 5.65804\tvalid_1's rmse: 55.3443\n",
      "[900]\ttraining's rmse: 5.36294\tvalid_1's rmse: 55.3362\n",
      "[930]\ttraining's rmse: 5.08011\tvalid_1's rmse: 55.3145\n",
      "[960]\ttraining's rmse: 4.81988\tvalid_1's rmse: 55.2985\n",
      "[990]\ttraining's rmse: 4.56451\tvalid_1's rmse: 55.2705\n",
      "[1020]\ttraining's rmse: 4.32129\tvalid_1's rmse: 55.2703\n",
      "[1050]\ttraining's rmse: 4.09951\tvalid_1's rmse: 55.2719\n",
      "[1080]\ttraining's rmse: 3.88996\tvalid_1's rmse: 55.2689\n",
      "[1110]\ttraining's rmse: 3.6908\tvalid_1's rmse: 55.2553\n",
      "[1140]\ttraining's rmse: 3.50803\tvalid_1's rmse: 55.2422\n",
      "[1170]\ttraining's rmse: 3.33392\tvalid_1's rmse: 55.2503\n",
      "[1200]\ttraining's rmse: 3.16335\tvalid_1's rmse: 55.2374\n",
      "[1230]\ttraining's rmse: 3.00798\tvalid_1's rmse: 55.2293\n",
      "[1260]\ttraining's rmse: 2.86119\tvalid_1's rmse: 55.2265\n",
      "[1290]\ttraining's rmse: 2.72086\tvalid_1's rmse: 55.2242\n",
      "[1320]\ttraining's rmse: 2.58814\tvalid_1's rmse: 55.2211\n",
      "[1350]\ttraining's rmse: 2.46111\tvalid_1's rmse: 55.2168\n",
      "[1380]\ttraining's rmse: 2.34449\tvalid_1's rmse: 55.2126\n",
      "[1410]\ttraining's rmse: 2.23528\tvalid_1's rmse: 55.2143\n",
      "[1440]\ttraining's rmse: 2.12945\tvalid_1's rmse: 55.216\n",
      "[1470]\ttraining's rmse: 2.02752\tvalid_1's rmse: 55.2049\n",
      "[1500]\ttraining's rmse: 1.9334\tvalid_1's rmse: 55.1985\n",
      "[1530]\ttraining's rmse: 1.84319\tvalid_1's rmse: 55.1917\n",
      "[1560]\ttraining's rmse: 1.75799\tvalid_1's rmse: 55.1874\n",
      "[1590]\ttraining's rmse: 1.67211\tvalid_1's rmse: 55.1849\n",
      "[1620]\ttraining's rmse: 1.59714\tvalid_1's rmse: 55.1817\n",
      "[1650]\ttraining's rmse: 1.51905\tvalid_1's rmse: 55.1852\n",
      "[1680]\ttraining's rmse: 1.4508\tvalid_1's rmse: 55.1821\n",
      "[1710]\ttraining's rmse: 1.38301\tvalid_1's rmse: 55.1825\n",
      "[1740]\ttraining's rmse: 1.31861\tvalid_1's rmse: 55.184\n",
      "[1770]\ttraining's rmse: 1.26087\tvalid_1's rmse: 55.1783\n",
      "[1800]\ttraining's rmse: 1.20276\tvalid_1's rmse: 55.1786\n",
      "[1830]\ttraining's rmse: 1.14734\tvalid_1's rmse: 55.1767\n",
      "[1860]\ttraining's rmse: 1.09645\tvalid_1's rmse: 55.1738\n",
      "[1890]\ttraining's rmse: 1.04767\tvalid_1's rmse: 55.1721\n",
      "[1920]\ttraining's rmse: 1.00124\tvalid_1's rmse: 55.1687\n",
      "[1950]\ttraining's rmse: 0.955638\tvalid_1's rmse: 55.1688\n",
      "[1980]\ttraining's rmse: 0.913087\tvalid_1's rmse: 55.1699\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's rmse: 0.887065\tvalid_1's rmse: 55.1665\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002421 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 20019\n",
      "[LightGBM] [Info] Number of data points in the train set: 9219, number of used features: 79\n",
      "[LightGBM] [Info] Start training from score 361.501097\n",
      "Training until validation scores don't improve for 125 rounds\n",
      "[30]\ttraining's rmse: 158.786\tvalid_1's rmse: 166.772\n",
      "[60]\ttraining's rmse: 99.901\tvalid_1's rmse: 112.177\n",
      "[90]\ttraining's rmse: 67.7797\tvalid_1's rmse: 85.2883\n",
      "[120]\ttraining's rmse: 50.083\tvalid_1's rmse: 72.24\n",
      "[150]\ttraining's rmse: 40.1611\tvalid_1's rmse: 66.1328\n",
      "[180]\ttraining's rmse: 34.0004\tvalid_1's rmse: 62.905\n",
      "[210]\ttraining's rmse: 29.869\tvalid_1's rmse: 61.1672\n",
      "[240]\ttraining's rmse: 26.63\tvalid_1's rmse: 59.9458\n",
      "[270]\ttraining's rmse: 24.0049\tvalid_1's rmse: 59.1321\n",
      "[300]\ttraining's rmse: 21.8405\tvalid_1's rmse: 58.5569\n",
      "[330]\ttraining's rmse: 20.0006\tvalid_1's rmse: 58.1747\n",
      "[360]\ttraining's rmse: 18.4169\tvalid_1's rmse: 57.8228\n",
      "[390]\ttraining's rmse: 16.9707\tvalid_1's rmse: 57.5337\n",
      "[420]\ttraining's rmse: 15.7106\tvalid_1's rmse: 57.313\n",
      "[450]\ttraining's rmse: 14.5586\tvalid_1's rmse: 57.069\n",
      "[480]\ttraining's rmse: 13.517\tvalid_1's rmse: 56.9004\n",
      "[510]\ttraining's rmse: 12.5681\tvalid_1's rmse: 56.7721\n",
      "[540]\ttraining's rmse: 11.7444\tvalid_1's rmse: 56.698\n",
      "[570]\ttraining's rmse: 10.9868\tvalid_1's rmse: 56.6149\n",
      "[600]\ttraining's rmse: 10.2749\tvalid_1's rmse: 56.5366\n",
      "[630]\ttraining's rmse: 9.63014\tvalid_1's rmse: 56.4612\n",
      "[660]\ttraining's rmse: 9.02851\tvalid_1's rmse: 56.3798\n",
      "[690]\ttraining's rmse: 8.46853\tvalid_1's rmse: 56.3327\n",
      "[720]\ttraining's rmse: 7.94952\tvalid_1's rmse: 56.2809\n",
      "[750]\ttraining's rmse: 7.47112\tvalid_1's rmse: 56.2297\n",
      "[780]\ttraining's rmse: 7.03274\tvalid_1's rmse: 56.1956\n",
      "[810]\ttraining's rmse: 6.61725\tvalid_1's rmse: 56.1534\n",
      "[840]\ttraining's rmse: 6.24648\tvalid_1's rmse: 56.1162\n",
      "[870]\ttraining's rmse: 5.89247\tvalid_1's rmse: 56.0888\n",
      "[900]\ttraining's rmse: 5.56372\tvalid_1's rmse: 56.0569\n",
      "[930]\ttraining's rmse: 5.25068\tvalid_1's rmse: 56.0327\n",
      "[960]\ttraining's rmse: 4.96116\tvalid_1's rmse: 56.0024\n",
      "[990]\ttraining's rmse: 4.6845\tvalid_1's rmse: 55.9822\n",
      "[1020]\ttraining's rmse: 4.42623\tvalid_1's rmse: 55.9629\n",
      "[1050]\ttraining's rmse: 4.18317\tvalid_1's rmse: 55.9397\n",
      "[1080]\ttraining's rmse: 3.9571\tvalid_1's rmse: 55.9217\n",
      "[1110]\ttraining's rmse: 3.74795\tvalid_1's rmse: 55.9082\n",
      "[1140]\ttraining's rmse: 3.55323\tvalid_1's rmse: 55.9004\n",
      "[1170]\ttraining's rmse: 3.36302\tvalid_1's rmse: 55.8867\n",
      "[1200]\ttraining's rmse: 3.18171\tvalid_1's rmse: 55.8754\n",
      "[1230]\ttraining's rmse: 3.01674\tvalid_1's rmse: 55.8657\n",
      "[1260]\ttraining's rmse: 2.85485\tvalid_1's rmse: 55.8537\n",
      "[1290]\ttraining's rmse: 2.70732\tvalid_1's rmse: 55.8523\n",
      "[1320]\ttraining's rmse: 2.5665\tvalid_1's rmse: 55.8453\n",
      "[1350]\ttraining's rmse: 2.43352\tvalid_1's rmse: 55.8384\n",
      "[1380]\ttraining's rmse: 2.30771\tvalid_1's rmse: 55.8229\n",
      "[1410]\ttraining's rmse: 2.18795\tvalid_1's rmse: 55.8207\n",
      "[1440]\ttraining's rmse: 2.07572\tvalid_1's rmse: 55.8232\n",
      "[1470]\ttraining's rmse: 1.97048\tvalid_1's rmse: 55.8205\n",
      "[1500]\ttraining's rmse: 1.87434\tvalid_1's rmse: 55.819\n",
      "[1530]\ttraining's rmse: 1.78059\tvalid_1's rmse: 55.8157\n",
      "[1560]\ttraining's rmse: 1.69286\tvalid_1's rmse: 55.8081\n",
      "[1590]\ttraining's rmse: 1.61\tvalid_1's rmse: 55.7999\n",
      "[1620]\ttraining's rmse: 1.53173\tvalid_1's rmse: 55.7983\n",
      "[1650]\ttraining's rmse: 1.45673\tvalid_1's rmse: 55.7927\n",
      "[1680]\ttraining's rmse: 1.38808\tvalid_1's rmse: 55.7927\n",
      "[1710]\ttraining's rmse: 1.32057\tvalid_1's rmse: 55.7892\n",
      "[1740]\ttraining's rmse: 1.25468\tvalid_1's rmse: 55.7881\n",
      "[1770]\ttraining's rmse: 1.19327\tvalid_1's rmse: 55.7881\n",
      "[1800]\ttraining's rmse: 1.13612\tvalid_1's rmse: 55.7839\n",
      "[1830]\ttraining's rmse: 1.08026\tvalid_1's rmse: 55.7837\n",
      "[1860]\ttraining's rmse: 1.02974\tvalid_1's rmse: 55.7824\n",
      "[1890]\ttraining's rmse: 0.979397\tvalid_1's rmse: 55.7781\n",
      "[1920]\ttraining's rmse: 0.933884\tvalid_1's rmse: 55.7774\n",
      "[1950]\ttraining's rmse: 0.890079\tvalid_1's rmse: 55.7745\n",
      "[1980]\ttraining's rmse: 0.848884\tvalid_1's rmse: 55.7708\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's rmse: 0.822138\tvalid_1's rmse: 55.7697\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002258 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 20019\n",
      "[LightGBM] [Info] Number of data points in the train set: 9219, number of used features: 79\n",
      "[LightGBM] [Info] Start training from score 360.761837\n",
      "Training until validation scores don't improve for 125 rounds\n",
      "[30]\ttraining's rmse: 159.74\tvalid_1's rmse: 168.37\n",
      "[60]\ttraining's rmse: 99.9514\tvalid_1's rmse: 115.115\n",
      "[90]\ttraining's rmse: 67.6048\tvalid_1's rmse: 88.5959\n",
      "[120]\ttraining's rmse: 50.0981\tvalid_1's rmse: 75.8426\n",
      "[150]\ttraining's rmse: 40.165\tvalid_1's rmse: 69.4924\n",
      "[180]\ttraining's rmse: 34.0659\tvalid_1's rmse: 66.3076\n",
      "[210]\ttraining's rmse: 29.9329\tvalid_1's rmse: 64.4565\n",
      "[240]\ttraining's rmse: 26.8074\tvalid_1's rmse: 63.4567\n",
      "[270]\ttraining's rmse: 24.2403\tvalid_1's rmse: 62.5629\n",
      "[300]\ttraining's rmse: 22.0315\tvalid_1's rmse: 62.0192\n",
      "[330]\ttraining's rmse: 20.2004\tvalid_1's rmse: 61.5782\n",
      "[360]\ttraining's rmse: 18.5729\tvalid_1's rmse: 61.2752\n",
      "[390]\ttraining's rmse: 17.1492\tvalid_1's rmse: 61.0679\n",
      "[420]\ttraining's rmse: 15.8481\tvalid_1's rmse: 60.8766\n",
      "[450]\ttraining's rmse: 14.7123\tvalid_1's rmse: 60.7287\n",
      "[480]\ttraining's rmse: 13.6591\tvalid_1's rmse: 60.5998\n",
      "[510]\ttraining's rmse: 12.7217\tvalid_1's rmse: 60.5156\n",
      "[540]\ttraining's rmse: 11.8867\tvalid_1's rmse: 60.4152\n",
      "[570]\ttraining's rmse: 11.1018\tvalid_1's rmse: 60.3295\n",
      "[600]\ttraining's rmse: 10.4058\tvalid_1's rmse: 60.2614\n",
      "[630]\ttraining's rmse: 9.75314\tvalid_1's rmse: 60.1903\n",
      "[660]\ttraining's rmse: 9.13084\tvalid_1's rmse: 60.1005\n",
      "[690]\ttraining's rmse: 8.56748\tvalid_1's rmse: 60.032\n",
      "[720]\ttraining's rmse: 8.04418\tvalid_1's rmse: 60.0082\n",
      "[750]\ttraining's rmse: 7.55948\tvalid_1's rmse: 59.9756\n",
      "[780]\ttraining's rmse: 7.12897\tvalid_1's rmse: 59.9459\n",
      "[810]\ttraining's rmse: 6.70632\tvalid_1's rmse: 59.9297\n",
      "[840]\ttraining's rmse: 6.31904\tvalid_1's rmse: 59.9027\n",
      "[870]\ttraining's rmse: 5.96013\tvalid_1's rmse: 59.8769\n",
      "[900]\ttraining's rmse: 5.62397\tvalid_1's rmse: 59.8417\n",
      "[930]\ttraining's rmse: 5.31204\tvalid_1's rmse: 59.8282\n",
      "[960]\ttraining's rmse: 5.01655\tvalid_1's rmse: 59.8122\n",
      "[990]\ttraining's rmse: 4.74635\tvalid_1's rmse: 59.7903\n",
      "[1020]\ttraining's rmse: 4.48766\tvalid_1's rmse: 59.7665\n",
      "[1050]\ttraining's rmse: 4.24762\tvalid_1's rmse: 59.7497\n",
      "[1080]\ttraining's rmse: 4.02231\tvalid_1's rmse: 59.7332\n",
      "[1110]\ttraining's rmse: 3.80526\tvalid_1's rmse: 59.7086\n",
      "[1140]\ttraining's rmse: 3.6068\tvalid_1's rmse: 59.7037\n",
      "[1170]\ttraining's rmse: 3.42164\tvalid_1's rmse: 59.6911\n",
      "[1200]\ttraining's rmse: 3.24975\tvalid_1's rmse: 59.6826\n",
      "[1230]\ttraining's rmse: 3.08139\tvalid_1's rmse: 59.6667\n",
      "[1260]\ttraining's rmse: 2.92217\tvalid_1's rmse: 59.6543\n",
      "[1290]\ttraining's rmse: 2.77178\tvalid_1's rmse: 59.6434\n",
      "[1320]\ttraining's rmse: 2.62711\tvalid_1's rmse: 59.6416\n",
      "[1350]\ttraining's rmse: 2.49422\tvalid_1's rmse: 59.6276\n",
      "[1380]\ttraining's rmse: 2.36992\tvalid_1's rmse: 59.6238\n",
      "[1410]\ttraining's rmse: 2.25004\tvalid_1's rmse: 59.6187\n",
      "[1440]\ttraining's rmse: 2.1373\tvalid_1's rmse: 59.6154\n",
      "[1470]\ttraining's rmse: 2.03135\tvalid_1's rmse: 59.6056\n",
      "[1500]\ttraining's rmse: 1.93058\tvalid_1's rmse: 59.5992\n",
      "[1530]\ttraining's rmse: 1.83711\tvalid_1's rmse: 59.5938\n",
      "[1560]\ttraining's rmse: 1.748\tvalid_1's rmse: 59.5888\n",
      "[1590]\ttraining's rmse: 1.66197\tvalid_1's rmse: 59.5857\n",
      "[1620]\ttraining's rmse: 1.58148\tvalid_1's rmse: 59.5815\n",
      "[1650]\ttraining's rmse: 1.50849\tvalid_1's rmse: 59.5777\n",
      "[1680]\ttraining's rmse: 1.43446\tvalid_1's rmse: 59.5758\n",
      "[1710]\ttraining's rmse: 1.36419\tvalid_1's rmse: 59.5744\n",
      "[1740]\ttraining's rmse: 1.29859\tvalid_1's rmse: 59.5732\n",
      "[1770]\ttraining's rmse: 1.23684\tvalid_1's rmse: 59.5693\n",
      "[1800]\ttraining's rmse: 1.1791\tvalid_1's rmse: 59.5677\n",
      "[1830]\ttraining's rmse: 1.12618\tvalid_1's rmse: 59.5657\n",
      "[1860]\ttraining's rmse: 1.07331\tvalid_1's rmse: 59.5626\n",
      "[1890]\ttraining's rmse: 1.02207\tvalid_1's rmse: 59.5622\n",
      "[1920]\ttraining's rmse: 0.974863\tvalid_1's rmse: 59.5596\n",
      "[1950]\ttraining's rmse: 0.929439\tvalid_1's rmse: 59.5585\n",
      "[1980]\ttraining's rmse: 0.885757\tvalid_1's rmse: 59.5583\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's rmse: 0.858615\tvalid_1's rmse: 59.5567\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003549 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 20019\n",
      "[LightGBM] [Info] Number of data points in the train set: 9219, number of used features: 79\n",
      "[LightGBM] [Info] Start training from score 361.654431\n",
      "Training until validation scores don't improve for 125 rounds\n",
      "[30]\ttraining's rmse: 161.351\tvalid_1's rmse: 165.191\n",
      "[60]\ttraining's rmse: 101.029\tvalid_1's rmse: 112.828\n",
      "[90]\ttraining's rmse: 68.0858\tvalid_1's rmse: 86.403\n",
      "[120]\ttraining's rmse: 49.9884\tvalid_1's rmse: 73.2129\n",
      "[150]\ttraining's rmse: 39.8249\tvalid_1's rmse: 66.6508\n",
      "[180]\ttraining's rmse: 33.6567\tvalid_1's rmse: 63.164\n",
      "[210]\ttraining's rmse: 29.3429\tvalid_1's rmse: 60.9676\n",
      "[240]\ttraining's rmse: 26.0788\tvalid_1's rmse: 59.6257\n",
      "[270]\ttraining's rmse: 23.4733\tvalid_1's rmse: 58.7052\n",
      "[300]\ttraining's rmse: 21.3219\tvalid_1's rmse: 58.0799\n",
      "[330]\ttraining's rmse: 19.5211\tvalid_1's rmse: 57.663\n",
      "[360]\ttraining's rmse: 17.9188\tvalid_1's rmse: 57.2911\n",
      "[390]\ttraining's rmse: 16.5192\tvalid_1's rmse: 57.0475\n",
      "[420]\ttraining's rmse: 15.2837\tvalid_1's rmse: 56.8608\n",
      "[450]\ttraining's rmse: 14.1691\tvalid_1's rmse: 56.722\n",
      "[480]\ttraining's rmse: 13.1831\tvalid_1's rmse: 56.5918\n",
      "[510]\ttraining's rmse: 12.2659\tvalid_1's rmse: 56.4722\n",
      "[540]\ttraining's rmse: 11.4502\tvalid_1's rmse: 56.3994\n",
      "[570]\ttraining's rmse: 10.6857\tvalid_1's rmse: 56.2828\n",
      "[600]\ttraining's rmse: 10.0036\tvalid_1's rmse: 56.1985\n",
      "[630]\ttraining's rmse: 9.37852\tvalid_1's rmse: 56.1323\n",
      "[660]\ttraining's rmse: 8.80335\tvalid_1's rmse: 56.0953\n",
      "[690]\ttraining's rmse: 8.26504\tvalid_1's rmse: 56.0563\n",
      "[720]\ttraining's rmse: 7.7696\tvalid_1's rmse: 56.0005\n",
      "[750]\ttraining's rmse: 7.30964\tvalid_1's rmse: 55.9594\n",
      "[780]\ttraining's rmse: 6.89382\tvalid_1's rmse: 55.9206\n",
      "[810]\ttraining's rmse: 6.48632\tvalid_1's rmse: 55.8876\n",
      "[840]\ttraining's rmse: 6.11155\tvalid_1's rmse: 55.833\n",
      "[870]\ttraining's rmse: 5.76417\tvalid_1's rmse: 55.8113\n",
      "[900]\ttraining's rmse: 5.43184\tvalid_1's rmse: 55.7833\n",
      "[930]\ttraining's rmse: 5.12861\tvalid_1's rmse: 55.7649\n",
      "[960]\ttraining's rmse: 4.84577\tvalid_1's rmse: 55.7461\n",
      "[990]\ttraining's rmse: 4.58351\tvalid_1's rmse: 55.7295\n",
      "[1020]\ttraining's rmse: 4.33933\tvalid_1's rmse: 55.7157\n",
      "[1050]\ttraining's rmse: 4.10304\tvalid_1's rmse: 55.6966\n",
      "[1080]\ttraining's rmse: 3.88664\tvalid_1's rmse: 55.6844\n",
      "[1110]\ttraining's rmse: 3.68387\tvalid_1's rmse: 55.6708\n",
      "[1140]\ttraining's rmse: 3.48747\tvalid_1's rmse: 55.6643\n",
      "[1170]\ttraining's rmse: 3.31009\tvalid_1's rmse: 55.6549\n",
      "[1200]\ttraining's rmse: 3.14353\tvalid_1's rmse: 55.6436\n",
      "[1230]\ttraining's rmse: 2.97974\tvalid_1's rmse: 55.6335\n",
      "[1260]\ttraining's rmse: 2.82768\tvalid_1's rmse: 55.6238\n",
      "[1290]\ttraining's rmse: 2.68402\tvalid_1's rmse: 55.6177\n",
      "[1320]\ttraining's rmse: 2.5492\tvalid_1's rmse: 55.6113\n",
      "[1350]\ttraining's rmse: 2.4228\tvalid_1's rmse: 55.6069\n",
      "[1380]\ttraining's rmse: 2.30087\tvalid_1's rmse: 55.5981\n",
      "[1410]\ttraining's rmse: 2.1865\tvalid_1's rmse: 55.5904\n",
      "[1440]\ttraining's rmse: 2.08123\tvalid_1's rmse: 55.5853\n",
      "[1470]\ttraining's rmse: 1.98126\tvalid_1's rmse: 55.5799\n",
      "[1500]\ttraining's rmse: 1.88306\tvalid_1's rmse: 55.5756\n",
      "[1530]\ttraining's rmse: 1.79295\tvalid_1's rmse: 55.5708\n",
      "[1560]\ttraining's rmse: 1.70434\tvalid_1's rmse: 55.565\n",
      "[1590]\ttraining's rmse: 1.62333\tvalid_1's rmse: 55.5611\n",
      "[1620]\ttraining's rmse: 1.54468\tvalid_1's rmse: 55.5587\n",
      "[1650]\ttraining's rmse: 1.47217\tvalid_1's rmse: 55.5565\n",
      "[1680]\ttraining's rmse: 1.4008\tvalid_1's rmse: 55.5539\n",
      "[1710]\ttraining's rmse: 1.33615\tvalid_1's rmse: 55.5486\n",
      "[1740]\ttraining's rmse: 1.27298\tvalid_1's rmse: 55.5466\n",
      "[1770]\ttraining's rmse: 1.21239\tvalid_1's rmse: 55.5448\n",
      "[1800]\ttraining's rmse: 1.15572\tvalid_1's rmse: 55.5442\n",
      "[1830]\ttraining's rmse: 1.10291\tvalid_1's rmse: 55.5415\n",
      "[1860]\ttraining's rmse: 1.05187\tvalid_1's rmse: 55.5403\n",
      "[1890]\ttraining's rmse: 1.00375\tvalid_1's rmse: 55.5382\n",
      "[1920]\ttraining's rmse: 0.956994\tvalid_1's rmse: 55.5379\n",
      "[1950]\ttraining's rmse: 0.913664\tvalid_1's rmse: 55.5351\n",
      "[1980]\ttraining's rmse: 0.872321\tvalid_1's rmse: 55.534\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's rmse: 0.846693\tvalid_1's rmse: 55.5324\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003290 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 20019\n",
      "[LightGBM] [Info] Number of data points in the train set: 9219, number of used features: 79\n",
      "[LightGBM] [Info] Start training from score 374.552029\n",
      "Training until validation scores don't improve for 125 rounds\n",
      "[30]\ttraining's rmse: 168.041\tvalid_1's rmse: 171.884\n",
      "[60]\ttraining's rmse: 105.293\tvalid_1's rmse: 116.311\n",
      "[90]\ttraining's rmse: 70.7888\tvalid_1's rmse: 88.4917\n",
      "[120]\ttraining's rmse: 51.8927\tvalid_1's rmse: 75.184\n",
      "[150]\ttraining's rmse: 41.3164\tvalid_1's rmse: 68.4699\n",
      "[180]\ttraining's rmse: 34.9117\tvalid_1's rmse: 64.8265\n",
      "[210]\ttraining's rmse: 30.557\tvalid_1's rmse: 62.5803\n",
      "[240]\ttraining's rmse: 27.2704\tvalid_1's rmse: 61.2629\n",
      "[270]\ttraining's rmse: 24.6159\tvalid_1's rmse: 60.3868\n",
      "[300]\ttraining's rmse: 22.4231\tvalid_1's rmse: 59.799\n",
      "[330]\ttraining's rmse: 20.5141\tvalid_1's rmse: 59.3077\n",
      "[360]\ttraining's rmse: 18.878\tvalid_1's rmse: 58.963\n",
      "[390]\ttraining's rmse: 17.3942\tvalid_1's rmse: 58.6294\n",
      "[420]\ttraining's rmse: 16.1124\tvalid_1's rmse: 58.4306\n",
      "[450]\ttraining's rmse: 14.9262\tvalid_1's rmse: 58.1898\n",
      "[480]\ttraining's rmse: 13.8698\tvalid_1's rmse: 58.0005\n",
      "[510]\ttraining's rmse: 12.9266\tvalid_1's rmse: 57.8216\n",
      "[540]\ttraining's rmse: 12.0598\tvalid_1's rmse: 57.7313\n",
      "[570]\ttraining's rmse: 11.2652\tvalid_1's rmse: 57.635\n",
      "[600]\ttraining's rmse: 10.5363\tvalid_1's rmse: 57.5452\n",
      "[630]\ttraining's rmse: 9.86921\tvalid_1's rmse: 57.4652\n",
      "[660]\ttraining's rmse: 9.25371\tvalid_1's rmse: 57.4083\n",
      "[690]\ttraining's rmse: 8.68453\tvalid_1's rmse: 57.3636\n",
      "[720]\ttraining's rmse: 8.16194\tvalid_1's rmse: 57.308\n",
      "[750]\ttraining's rmse: 7.67486\tvalid_1's rmse: 57.2829\n",
      "[780]\ttraining's rmse: 7.2184\tvalid_1's rmse: 57.2505\n",
      "[810]\ttraining's rmse: 6.78742\tvalid_1's rmse: 57.238\n",
      "[840]\ttraining's rmse: 6.40029\tvalid_1's rmse: 57.2049\n",
      "[870]\ttraining's rmse: 6.02801\tvalid_1's rmse: 57.1713\n",
      "[900]\ttraining's rmse: 5.6868\tvalid_1's rmse: 57.1538\n",
      "[930]\ttraining's rmse: 5.36441\tvalid_1's rmse: 57.1323\n",
      "[960]\ttraining's rmse: 5.06458\tvalid_1's rmse: 57.1198\n",
      "[990]\ttraining's rmse: 4.78489\tvalid_1's rmse: 57.1038\n",
      "[1020]\ttraining's rmse: 4.52661\tvalid_1's rmse: 57.0966\n",
      "[1050]\ttraining's rmse: 4.27437\tvalid_1's rmse: 57.0777\n",
      "[1080]\ttraining's rmse: 4.0382\tvalid_1's rmse: 57.0611\n",
      "[1110]\ttraining's rmse: 3.82446\tvalid_1's rmse: 57.0537\n",
      "[1140]\ttraining's rmse: 3.61902\tvalid_1's rmse: 57.0407\n",
      "[1170]\ttraining's rmse: 3.42528\tvalid_1's rmse: 57.0318\n",
      "[1200]\ttraining's rmse: 3.2455\tvalid_1's rmse: 57.0211\n",
      "[1230]\ttraining's rmse: 3.07617\tvalid_1's rmse: 57.0136\n",
      "[1260]\ttraining's rmse: 2.91478\tvalid_1's rmse: 57.003\n",
      "[1290]\ttraining's rmse: 2.76257\tvalid_1's rmse: 56.9896\n",
      "[1320]\ttraining's rmse: 2.62215\tvalid_1's rmse: 56.989\n",
      "[1350]\ttraining's rmse: 2.48752\tvalid_1's rmse: 56.9781\n",
      "[1380]\ttraining's rmse: 2.35705\tvalid_1's rmse: 56.9726\n",
      "[1410]\ttraining's rmse: 2.23706\tvalid_1's rmse: 56.9707\n",
      "[1440]\ttraining's rmse: 2.12278\tvalid_1's rmse: 56.9714\n",
      "[1470]\ttraining's rmse: 2.01489\tvalid_1's rmse: 56.9703\n",
      "[1500]\ttraining's rmse: 1.91344\tvalid_1's rmse: 56.9665\n",
      "[1530]\ttraining's rmse: 1.81782\tvalid_1's rmse: 56.9608\n",
      "[1560]\ttraining's rmse: 1.72728\tvalid_1's rmse: 56.9583\n",
      "[1590]\ttraining's rmse: 1.64201\tvalid_1's rmse: 56.9551\n",
      "[1620]\ttraining's rmse: 1.56123\tvalid_1's rmse: 56.9559\n",
      "[1650]\ttraining's rmse: 1.48402\tvalid_1's rmse: 56.9525\n",
      "[1680]\ttraining's rmse: 1.41084\tvalid_1's rmse: 56.9528\n",
      "[1710]\ttraining's rmse: 1.34178\tvalid_1's rmse: 56.9521\n",
      "[1740]\ttraining's rmse: 1.27454\tvalid_1's rmse: 56.9497\n",
      "[1770]\ttraining's rmse: 1.2128\tvalid_1's rmse: 56.9475\n",
      "[1800]\ttraining's rmse: 1.15424\tvalid_1's rmse: 56.9474\n",
      "[1830]\ttraining's rmse: 1.09974\tvalid_1's rmse: 56.9458\n",
      "[1860]\ttraining's rmse: 1.04597\tvalid_1's rmse: 56.9449\n",
      "[1890]\ttraining's rmse: 0.995572\tvalid_1's rmse: 56.9412\n",
      "[1920]\ttraining's rmse: 0.946142\tvalid_1's rmse: 56.9392\n",
      "[1950]\ttraining's rmse: 0.900251\tvalid_1's rmse: 56.9388\n",
      "[1980]\ttraining's rmse: 0.858241\tvalid_1's rmse: 56.9386\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's rmse: 0.830879\tvalid_1's rmse: 56.937\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002814 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 20019\n",
      "[LightGBM] [Info] Number of data points in the train set: 9219, number of used features: 79\n",
      "[LightGBM] [Info] Start training from score 380.531234\n",
      "Training until validation scores don't improve for 125 rounds\n",
      "[30]\ttraining's rmse: 171.393\tvalid_1's rmse: 175.091\n",
      "[60]\ttraining's rmse: 105.559\tvalid_1's rmse: 114.16\n",
      "[90]\ttraining's rmse: 70.1332\tvalid_1's rmse: 83.9672\n",
      "[120]\ttraining's rmse: 51.0288\tvalid_1's rmse: 69.6193\n",
      "[150]\ttraining's rmse: 40.2176\tvalid_1's rmse: 62.9661\n",
      "[180]\ttraining's rmse: 33.7774\tvalid_1's rmse: 59.6234\n",
      "[210]\ttraining's rmse: 29.4866\tvalid_1's rmse: 57.8067\n",
      "[240]\ttraining's rmse: 26.1259\tvalid_1's rmse: 56.4576\n",
      "[270]\ttraining's rmse: 23.507\tvalid_1's rmse: 55.5875\n",
      "[300]\ttraining's rmse: 21.3099\tvalid_1's rmse: 54.9688\n",
      "[330]\ttraining's rmse: 19.5072\tvalid_1's rmse: 54.5114\n",
      "[360]\ttraining's rmse: 17.9614\tvalid_1's rmse: 54.189\n",
      "[390]\ttraining's rmse: 16.5817\tvalid_1's rmse: 53.925\n",
      "[420]\ttraining's rmse: 15.3526\tvalid_1's rmse: 53.7463\n",
      "[450]\ttraining's rmse: 14.2546\tvalid_1's rmse: 53.6273\n",
      "[480]\ttraining's rmse: 13.2518\tvalid_1's rmse: 53.4914\n",
      "[510]\ttraining's rmse: 12.3429\tvalid_1's rmse: 53.3911\n",
      "[540]\ttraining's rmse: 11.5016\tvalid_1's rmse: 53.2813\n",
      "[570]\ttraining's rmse: 10.7498\tvalid_1's rmse: 53.1892\n",
      "[600]\ttraining's rmse: 10.0496\tvalid_1's rmse: 53.0959\n",
      "[630]\ttraining's rmse: 9.43311\tvalid_1's rmse: 53.0376\n",
      "[660]\ttraining's rmse: 8.8611\tvalid_1's rmse: 52.9849\n",
      "[690]\ttraining's rmse: 8.31386\tvalid_1's rmse: 52.9167\n",
      "[720]\ttraining's rmse: 7.80715\tvalid_1's rmse: 52.8987\n",
      "[750]\ttraining's rmse: 7.33882\tvalid_1's rmse: 52.869\n",
      "[780]\ttraining's rmse: 6.90836\tvalid_1's rmse: 52.8504\n",
      "[810]\ttraining's rmse: 6.5131\tvalid_1's rmse: 52.8337\n",
      "[840]\ttraining's rmse: 6.13801\tvalid_1's rmse: 52.8102\n",
      "[870]\ttraining's rmse: 5.79605\tvalid_1's rmse: 52.7939\n",
      "[900]\ttraining's rmse: 5.47176\tvalid_1's rmse: 52.7653\n",
      "[930]\ttraining's rmse: 5.17006\tvalid_1's rmse: 52.7304\n",
      "[960]\ttraining's rmse: 4.88238\tvalid_1's rmse: 52.7051\n",
      "[990]\ttraining's rmse: 4.61586\tvalid_1's rmse: 52.6847\n",
      "[1020]\ttraining's rmse: 4.37103\tvalid_1's rmse: 52.6731\n",
      "[1050]\ttraining's rmse: 4.13541\tvalid_1's rmse: 52.6561\n",
      "[1080]\ttraining's rmse: 3.91648\tvalid_1's rmse: 52.6412\n",
      "[1110]\ttraining's rmse: 3.71152\tvalid_1's rmse: 52.6433\n",
      "[1140]\ttraining's rmse: 3.52312\tvalid_1's rmse: 52.6242\n",
      "[1170]\ttraining's rmse: 3.34113\tvalid_1's rmse: 52.6103\n",
      "[1200]\ttraining's rmse: 3.1677\tvalid_1's rmse: 52.5958\n",
      "[1230]\ttraining's rmse: 3.00511\tvalid_1's rmse: 52.593\n",
      "[1260]\ttraining's rmse: 2.85217\tvalid_1's rmse: 52.5863\n",
      "[1290]\ttraining's rmse: 2.70774\tvalid_1's rmse: 52.584\n",
      "[1320]\ttraining's rmse: 2.57312\tvalid_1's rmse: 52.5748\n",
      "[1350]\ttraining's rmse: 2.44515\tvalid_1's rmse: 52.5736\n",
      "[1380]\ttraining's rmse: 2.32352\tvalid_1's rmse: 52.5713\n",
      "[1410]\ttraining's rmse: 2.20711\tvalid_1's rmse: 52.5679\n",
      "[1440]\ttraining's rmse: 2.09847\tvalid_1's rmse: 52.5633\n",
      "[1470]\ttraining's rmse: 1.994\tvalid_1's rmse: 52.5594\n",
      "[1500]\ttraining's rmse: 1.89802\tvalid_1's rmse: 52.5546\n",
      "[1530]\ttraining's rmse: 1.80674\tvalid_1's rmse: 52.5495\n",
      "[1560]\ttraining's rmse: 1.71753\tvalid_1's rmse: 52.5466\n",
      "[1590]\ttraining's rmse: 1.63458\tvalid_1's rmse: 52.5417\n",
      "[1620]\ttraining's rmse: 1.55724\tvalid_1's rmse: 52.5377\n",
      "[1650]\ttraining's rmse: 1.48322\tvalid_1's rmse: 52.5335\n",
      "[1680]\ttraining's rmse: 1.41513\tvalid_1's rmse: 52.5274\n",
      "[1710]\ttraining's rmse: 1.34624\tvalid_1's rmse: 52.5259\n",
      "[1740]\ttraining's rmse: 1.2835\tvalid_1's rmse: 52.5236\n",
      "[1770]\ttraining's rmse: 1.22219\tvalid_1's rmse: 52.5207\n",
      "[1800]\ttraining's rmse: 1.16452\tvalid_1's rmse: 52.5184\n",
      "[1830]\ttraining's rmse: 1.11109\tvalid_1's rmse: 52.5174\n",
      "[1860]\ttraining's rmse: 1.05958\tvalid_1's rmse: 52.5148\n",
      "[1890]\ttraining's rmse: 1.0107\tvalid_1's rmse: 52.5145\n",
      "[1920]\ttraining's rmse: 0.966134\tvalid_1's rmse: 52.5133\n",
      "[1950]\ttraining's rmse: 0.921445\tvalid_1's rmse: 52.5118\n",
      "[1980]\ttraining's rmse: 0.881149\tvalid_1's rmse: 52.5115\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's rmse: 0.853569\tvalid_1's rmse: 52.5105\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002619 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 20019\n",
      "[LightGBM] [Info] Number of data points in the train set: 9219, number of used features: 79\n",
      "[LightGBM] [Info] Start training from score 382.639352\n",
      "Training until validation scores don't improve for 125 rounds\n",
      "[30]\ttraining's rmse: 171.533\tvalid_1's rmse: 177.841\n",
      "[60]\ttraining's rmse: 106.475\tvalid_1's rmse: 115.902\n",
      "[90]\ttraining's rmse: 70.8398\tvalid_1's rmse: 84.5627\n",
      "[120]\ttraining's rmse: 51.5906\tvalid_1's rmse: 70.0879\n",
      "[150]\ttraining's rmse: 40.8864\tvalid_1's rmse: 63.3971\n",
      "[180]\ttraining's rmse: 34.3934\tvalid_1's rmse: 59.9574\n",
      "[210]\ttraining's rmse: 30.0148\tvalid_1's rmse: 57.9702\n",
      "[240]\ttraining's rmse: 26.6733\tvalid_1's rmse: 56.7391\n",
      "[270]\ttraining's rmse: 24.0404\tvalid_1's rmse: 55.975\n",
      "[300]\ttraining's rmse: 21.8136\tvalid_1's rmse: 55.4004\n",
      "[330]\ttraining's rmse: 19.9921\tvalid_1's rmse: 55.0116\n",
      "[360]\ttraining's rmse: 18.4099\tvalid_1's rmse: 54.7386\n",
      "[390]\ttraining's rmse: 16.9856\tvalid_1's rmse: 54.548\n",
      "[420]\ttraining's rmse: 15.7674\tvalid_1's rmse: 54.3921\n",
      "[450]\ttraining's rmse: 14.6075\tvalid_1's rmse: 54.2954\n",
      "[480]\ttraining's rmse: 13.5709\tvalid_1's rmse: 54.233\n",
      "[510]\ttraining's rmse: 12.638\tvalid_1's rmse: 54.1426\n",
      "[540]\ttraining's rmse: 11.8013\tvalid_1's rmse: 54.1098\n",
      "[570]\ttraining's rmse: 11.0249\tvalid_1's rmse: 54.0492\n",
      "[600]\ttraining's rmse: 10.325\tvalid_1's rmse: 54.0129\n",
      "[630]\ttraining's rmse: 9.69325\tvalid_1's rmse: 53.9746\n",
      "[660]\ttraining's rmse: 9.08421\tvalid_1's rmse: 53.9355\n",
      "[690]\ttraining's rmse: 8.52681\tvalid_1's rmse: 53.8775\n",
      "[720]\ttraining's rmse: 8.01678\tvalid_1's rmse: 53.835\n",
      "[750]\ttraining's rmse: 7.5475\tvalid_1's rmse: 53.7972\n",
      "[780]\ttraining's rmse: 7.10287\tvalid_1's rmse: 53.7791\n",
      "[810]\ttraining's rmse: 6.69019\tvalid_1's rmse: 53.7555\n",
      "[840]\ttraining's rmse: 6.30976\tvalid_1's rmse: 53.7283\n",
      "[870]\ttraining's rmse: 5.95144\tvalid_1's rmse: 53.7057\n",
      "[900]\ttraining's rmse: 5.61974\tvalid_1's rmse: 53.6969\n",
      "[930]\ttraining's rmse: 5.31092\tvalid_1's rmse: 53.676\n",
      "[960]\ttraining's rmse: 5.01929\tvalid_1's rmse: 53.6684\n",
      "[990]\ttraining's rmse: 4.74427\tvalid_1's rmse: 53.6618\n",
      "[1020]\ttraining's rmse: 4.49031\tvalid_1's rmse: 53.6467\n",
      "[1050]\ttraining's rmse: 4.24523\tvalid_1's rmse: 53.6394\n",
      "[1080]\ttraining's rmse: 4.02537\tvalid_1's rmse: 53.6353\n",
      "[1110]\ttraining's rmse: 3.81537\tvalid_1's rmse: 53.6264\n",
      "[1140]\ttraining's rmse: 3.61709\tvalid_1's rmse: 53.6187\n",
      "[1170]\ttraining's rmse: 3.43271\tvalid_1's rmse: 53.6121\n",
      "[1200]\ttraining's rmse: 3.25626\tvalid_1's rmse: 53.6069\n",
      "[1230]\ttraining's rmse: 3.08644\tvalid_1's rmse: 53.5969\n",
      "[1260]\ttraining's rmse: 2.93111\tvalid_1's rmse: 53.5929\n",
      "[1290]\ttraining's rmse: 2.78266\tvalid_1's rmse: 53.5906\n",
      "[1320]\ttraining's rmse: 2.64182\tvalid_1's rmse: 53.5836\n",
      "[1350]\ttraining's rmse: 2.51152\tvalid_1's rmse: 53.5725\n",
      "[1380]\ttraining's rmse: 2.38785\tvalid_1's rmse: 53.5727\n",
      "[1410]\ttraining's rmse: 2.26834\tvalid_1's rmse: 53.5715\n",
      "[1440]\ttraining's rmse: 2.15556\tvalid_1's rmse: 53.5658\n",
      "[1470]\ttraining's rmse: 2.05157\tvalid_1's rmse: 53.5639\n",
      "[1500]\ttraining's rmse: 1.95296\tvalid_1's rmse: 53.5647\n",
      "[1530]\ttraining's rmse: 1.8566\tvalid_1's rmse: 53.5609\n",
      "[1560]\ttraining's rmse: 1.76641\tvalid_1's rmse: 53.5593\n",
      "[1590]\ttraining's rmse: 1.68368\tvalid_1's rmse: 53.562\n",
      "[1620]\ttraining's rmse: 1.60257\tvalid_1's rmse: 53.5628\n",
      "[1650]\ttraining's rmse: 1.52588\tvalid_1's rmse: 53.5608\n",
      "[1680]\ttraining's rmse: 1.45211\tvalid_1's rmse: 53.5592\n",
      "[1710]\ttraining's rmse: 1.38176\tvalid_1's rmse: 53.5573\n",
      "[1740]\ttraining's rmse: 1.31758\tvalid_1's rmse: 53.5541\n",
      "[1770]\ttraining's rmse: 1.25614\tvalid_1's rmse: 53.5536\n",
      "[1800]\ttraining's rmse: 1.19689\tvalid_1's rmse: 53.5527\n",
      "[1830]\ttraining's rmse: 1.13987\tvalid_1's rmse: 53.5526\n",
      "[1860]\ttraining's rmse: 1.08586\tvalid_1's rmse: 53.553\n",
      "[1890]\ttraining's rmse: 1.0361\tvalid_1's rmse: 53.5511\n",
      "[1920]\ttraining's rmse: 0.988284\tvalid_1's rmse: 53.5503\n",
      "[1950]\ttraining's rmse: 0.942833\tvalid_1's rmse: 53.5486\n",
      "[1980]\ttraining's rmse: 0.899823\tvalid_1's rmse: 53.5475\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's rmse: 0.872776\tvalid_1's rmse: 53.5465\n",
      "14\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003429 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 20018\n",
      "[LightGBM] [Info] Number of data points in the train set: 9219, number of used features: 79\n",
      "[LightGBM] [Info] Start training from score 375.469807\n",
      "Training until validation scores don't improve for 125 rounds\n",
      "[30]\ttraining's rmse: 160.928\tvalid_1's rmse: 161.622\n",
      "[60]\ttraining's rmse: 99.4341\tvalid_1's rmse: 106.807\n",
      "[90]\ttraining's rmse: 66.218\tvalid_1's rmse: 79.3798\n",
      "[120]\ttraining's rmse: 48.3209\tvalid_1's rmse: 66.2375\n",
      "[150]\ttraining's rmse: 38.4616\tvalid_1's rmse: 59.6733\n",
      "[180]\ttraining's rmse: 32.4854\tvalid_1's rmse: 56.2391\n",
      "[210]\ttraining's rmse: 28.5204\tvalid_1's rmse: 54.2747\n",
      "[240]\ttraining's rmse: 25.4318\tvalid_1's rmse: 52.9014\n",
      "[270]\ttraining's rmse: 22.9424\tvalid_1's rmse: 51.9937\n",
      "[300]\ttraining's rmse: 20.9064\tvalid_1's rmse: 51.3239\n",
      "[330]\ttraining's rmse: 19.1678\tvalid_1's rmse: 50.7972\n",
      "[360]\ttraining's rmse: 17.6795\tvalid_1's rmse: 50.3797\n",
      "[390]\ttraining's rmse: 16.3449\tvalid_1's rmse: 50.1144\n",
      "[420]\ttraining's rmse: 15.131\tvalid_1's rmse: 49.8335\n",
      "[450]\ttraining's rmse: 14.022\tvalid_1's rmse: 49.5841\n",
      "[480]\ttraining's rmse: 13.0419\tvalid_1's rmse: 49.4514\n",
      "[510]\ttraining's rmse: 12.1478\tvalid_1's rmse: 49.3343\n",
      "[540]\ttraining's rmse: 11.3338\tvalid_1's rmse: 49.2073\n",
      "[570]\ttraining's rmse: 10.6057\tvalid_1's rmse: 49.0999\n",
      "[600]\ttraining's rmse: 9.91777\tvalid_1's rmse: 49.0103\n",
      "[630]\ttraining's rmse: 9.29967\tvalid_1's rmse: 48.944\n",
      "[660]\ttraining's rmse: 8.7238\tvalid_1's rmse: 48.8647\n",
      "[690]\ttraining's rmse: 8.19204\tvalid_1's rmse: 48.8217\n",
      "[720]\ttraining's rmse: 7.69814\tvalid_1's rmse: 48.7641\n",
      "[750]\ttraining's rmse: 7.25682\tvalid_1's rmse: 48.7212\n",
      "[780]\ttraining's rmse: 6.83673\tvalid_1's rmse: 48.6759\n",
      "[810]\ttraining's rmse: 6.43779\tvalid_1's rmse: 48.6236\n",
      "[840]\ttraining's rmse: 6.06932\tvalid_1's rmse: 48.5802\n",
      "[870]\ttraining's rmse: 5.7296\tvalid_1's rmse: 48.5515\n",
      "[900]\ttraining's rmse: 5.40449\tvalid_1's rmse: 48.529\n",
      "[930]\ttraining's rmse: 5.11139\tvalid_1's rmse: 48.5141\n",
      "[960]\ttraining's rmse: 4.82637\tvalid_1's rmse: 48.4935\n",
      "[990]\ttraining's rmse: 4.57195\tvalid_1's rmse: 48.4786\n",
      "[1020]\ttraining's rmse: 4.32916\tvalid_1's rmse: 48.4728\n",
      "[1050]\ttraining's rmse: 4.09896\tvalid_1's rmse: 48.4547\n",
      "[1080]\ttraining's rmse: 3.88245\tvalid_1's rmse: 48.4378\n",
      "[1110]\ttraining's rmse: 3.67615\tvalid_1's rmse: 48.4242\n",
      "[1140]\ttraining's rmse: 3.48137\tvalid_1's rmse: 48.4085\n",
      "[1170]\ttraining's rmse: 3.29852\tvalid_1's rmse: 48.3974\n",
      "[1200]\ttraining's rmse: 3.12279\tvalid_1's rmse: 48.3863\n",
      "[1230]\ttraining's rmse: 2.96061\tvalid_1's rmse: 48.3759\n",
      "[1260]\ttraining's rmse: 2.80488\tvalid_1's rmse: 48.3617\n",
      "[1290]\ttraining's rmse: 2.65996\tvalid_1's rmse: 48.3494\n",
      "[1320]\ttraining's rmse: 2.52526\tvalid_1's rmse: 48.3439\n",
      "[1350]\ttraining's rmse: 2.39769\tvalid_1's rmse: 48.3342\n",
      "[1380]\ttraining's rmse: 2.27849\tvalid_1's rmse: 48.3318\n",
      "[1410]\ttraining's rmse: 2.16558\tvalid_1's rmse: 48.3244\n",
      "[1440]\ttraining's rmse: 2.05638\tvalid_1's rmse: 48.3162\n",
      "[1470]\ttraining's rmse: 1.95268\tvalid_1's rmse: 48.3103\n",
      "[1500]\ttraining's rmse: 1.85721\tvalid_1's rmse: 48.306\n",
      "[1530]\ttraining's rmse: 1.76409\tvalid_1's rmse: 48.2963\n",
      "[1560]\ttraining's rmse: 1.67704\tvalid_1's rmse: 48.2942\n",
      "[1590]\ttraining's rmse: 1.59429\tvalid_1's rmse: 48.2919\n",
      "[1620]\ttraining's rmse: 1.51616\tvalid_1's rmse: 48.2851\n",
      "[1650]\ttraining's rmse: 1.44242\tvalid_1's rmse: 48.2824\n",
      "[1680]\ttraining's rmse: 1.3722\tvalid_1's rmse: 48.2808\n",
      "[1710]\ttraining's rmse: 1.30528\tvalid_1's rmse: 48.2777\n",
      "[1740]\ttraining's rmse: 1.23974\tvalid_1's rmse: 48.2734\n",
      "[1770]\ttraining's rmse: 1.18201\tvalid_1's rmse: 48.2694\n",
      "[1800]\ttraining's rmse: 1.12434\tvalid_1's rmse: 48.265\n",
      "[1830]\ttraining's rmse: 1.06984\tvalid_1's rmse: 48.2618\n",
      "[1860]\ttraining's rmse: 1.0192\tvalid_1's rmse: 48.2573\n",
      "[1890]\ttraining's rmse: 0.97067\tvalid_1's rmse: 48.2541\n",
      "[1920]\ttraining's rmse: 0.924508\tvalid_1's rmse: 48.253\n",
      "[1950]\ttraining's rmse: 0.880081\tvalid_1's rmse: 48.251\n",
      "[1980]\ttraining's rmse: 0.837151\tvalid_1's rmse: 48.2494\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's rmse: 0.809916\tvalid_1's rmse: 48.248\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002574 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 20018\n",
      "[LightGBM] [Info] Number of data points in the train set: 9219, number of used features: 79\n",
      "[LightGBM] [Info] Start training from score 375.571784\n",
      "Training until validation scores don't improve for 125 rounds\n",
      "[30]\ttraining's rmse: 161.436\tvalid_1's rmse: 170.462\n",
      "[60]\ttraining's rmse: 101.787\tvalid_1's rmse: 117.339\n",
      "[90]\ttraining's rmse: 69.3549\tvalid_1's rmse: 90.9829\n",
      "[120]\ttraining's rmse: 51.6185\tvalid_1's rmse: 78.3576\n",
      "[150]\ttraining's rmse: 41.4216\tvalid_1's rmse: 72.0743\n",
      "[180]\ttraining's rmse: 35.1169\tvalid_1's rmse: 69.0371\n",
      "[210]\ttraining's rmse: 30.7864\tvalid_1's rmse: 67.2981\n",
      "[240]\ttraining's rmse: 27.5183\tvalid_1's rmse: 66.2873\n",
      "[270]\ttraining's rmse: 24.8511\tvalid_1's rmse: 65.6452\n",
      "[300]\ttraining's rmse: 22.6065\tvalid_1's rmse: 65.0108\n",
      "[330]\ttraining's rmse: 20.6859\tvalid_1's rmse: 64.6468\n",
      "[360]\ttraining's rmse: 19.0242\tvalid_1's rmse: 64.3761\n",
      "[390]\ttraining's rmse: 17.5668\tvalid_1's rmse: 64.1152\n",
      "[420]\ttraining's rmse: 16.2961\tvalid_1's rmse: 63.9374\n",
      "[450]\ttraining's rmse: 15.1164\tvalid_1's rmse: 63.7578\n",
      "[480]\ttraining's rmse: 14.0572\tvalid_1's rmse: 63.6521\n",
      "[510]\ttraining's rmse: 13.094\tvalid_1's rmse: 63.5808\n",
      "[540]\ttraining's rmse: 12.2145\tvalid_1's rmse: 63.4957\n",
      "[570]\ttraining's rmse: 11.4182\tvalid_1's rmse: 63.4071\n",
      "[600]\ttraining's rmse: 10.6866\tvalid_1's rmse: 63.3135\n",
      "[630]\ttraining's rmse: 10.0039\tvalid_1's rmse: 63.2585\n",
      "[660]\ttraining's rmse: 9.37946\tvalid_1's rmse: 63.1873\n",
      "[690]\ttraining's rmse: 8.79713\tvalid_1's rmse: 63.1126\n",
      "[720]\ttraining's rmse: 8.26937\tvalid_1's rmse: 63.058\n",
      "[750]\ttraining's rmse: 7.76149\tvalid_1's rmse: 63.0244\n",
      "[780]\ttraining's rmse: 7.30163\tvalid_1's rmse: 63.0117\n",
      "[810]\ttraining's rmse: 6.86956\tvalid_1's rmse: 62.9969\n",
      "[840]\ttraining's rmse: 6.46953\tvalid_1's rmse: 62.9794\n",
      "[870]\ttraining's rmse: 6.08786\tvalid_1's rmse: 62.9645\n",
      "[900]\ttraining's rmse: 5.74336\tvalid_1's rmse: 62.9556\n",
      "[930]\ttraining's rmse: 5.41774\tvalid_1's rmse: 62.9351\n",
      "[960]\ttraining's rmse: 5.1176\tvalid_1's rmse: 62.9107\n",
      "[990]\ttraining's rmse: 4.83331\tvalid_1's rmse: 62.8886\n",
      "[1020]\ttraining's rmse: 4.56974\tvalid_1's rmse: 62.8714\n",
      "[1050]\ttraining's rmse: 4.31703\tvalid_1's rmse: 62.867\n",
      "[1080]\ttraining's rmse: 4.08212\tvalid_1's rmse: 62.8567\n",
      "[1110]\ttraining's rmse: 3.86561\tvalid_1's rmse: 62.8511\n",
      "[1140]\ttraining's rmse: 3.65368\tvalid_1's rmse: 62.8464\n",
      "[1170]\ttraining's rmse: 3.46324\tvalid_1's rmse: 62.839\n",
      "[1200]\ttraining's rmse: 3.27533\tvalid_1's rmse: 62.8313\n",
      "[1230]\ttraining's rmse: 3.10348\tvalid_1's rmse: 62.8227\n",
      "[1260]\ttraining's rmse: 2.93733\tvalid_1's rmse: 62.8115\n",
      "[1290]\ttraining's rmse: 2.78628\tvalid_1's rmse: 62.806\n",
      "[1320]\ttraining's rmse: 2.6427\tvalid_1's rmse: 62.7977\n",
      "[1350]\ttraining's rmse: 2.50446\tvalid_1's rmse: 62.7863\n",
      "[1380]\ttraining's rmse: 2.37771\tvalid_1's rmse: 62.7794\n",
      "[1410]\ttraining's rmse: 2.25613\tvalid_1's rmse: 62.7736\n",
      "[1440]\ttraining's rmse: 2.14305\tvalid_1's rmse: 62.7605\n",
      "[1470]\ttraining's rmse: 2.03187\tvalid_1's rmse: 62.7564\n",
      "[1500]\ttraining's rmse: 1.93056\tvalid_1's rmse: 62.7513\n",
      "[1530]\ttraining's rmse: 1.83483\tvalid_1's rmse: 62.7456\n",
      "[1560]\ttraining's rmse: 1.74446\tvalid_1's rmse: 62.7435\n",
      "[1590]\ttraining's rmse: 1.65659\tvalid_1's rmse: 62.7429\n",
      "[1620]\ttraining's rmse: 1.57353\tvalid_1's rmse: 62.7396\n",
      "[1650]\ttraining's rmse: 1.49623\tvalid_1's rmse: 62.7398\n",
      "[1680]\ttraining's rmse: 1.42322\tvalid_1's rmse: 62.7367\n",
      "[1710]\ttraining's rmse: 1.35359\tvalid_1's rmse: 62.7337\n",
      "[1740]\ttraining's rmse: 1.28554\tvalid_1's rmse: 62.7291\n",
      "[1770]\ttraining's rmse: 1.22195\tvalid_1's rmse: 62.7266\n",
      "[1800]\ttraining's rmse: 1.16254\tvalid_1's rmse: 62.7247\n",
      "[1830]\ttraining's rmse: 1.10692\tvalid_1's rmse: 62.7221\n",
      "[1860]\ttraining's rmse: 1.05373\tvalid_1's rmse: 62.7204\n",
      "[1890]\ttraining's rmse: 1.00476\tvalid_1's rmse: 62.7163\n",
      "[1920]\ttraining's rmse: 0.956912\tvalid_1's rmse: 62.7126\n",
      "[1950]\ttraining's rmse: 0.910581\tvalid_1's rmse: 62.7106\n",
      "[1980]\ttraining's rmse: 0.867139\tvalid_1's rmse: 62.7111\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's rmse: 0.839303\tvalid_1's rmse: 62.7106\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003526 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 20018\n",
      "[LightGBM] [Info] Number of data points in the train set: 9219, number of used features: 79\n",
      "[LightGBM] [Info] Start training from score 372.645781\n",
      "Training until validation scores don't improve for 125 rounds\n",
      "[30]\ttraining's rmse: 162.527\tvalid_1's rmse: 167.406\n",
      "[60]\ttraining's rmse: 101.869\tvalid_1's rmse: 114.023\n",
      "[90]\ttraining's rmse: 68.8133\tvalid_1's rmse: 87.5277\n",
      "[120]\ttraining's rmse: 50.916\tvalid_1's rmse: 75.1803\n",
      "[150]\ttraining's rmse: 40.7156\tvalid_1's rmse: 69.0101\n",
      "[180]\ttraining's rmse: 34.4729\tvalid_1's rmse: 65.7055\n",
      "[210]\ttraining's rmse: 30.1702\tvalid_1's rmse: 63.8108\n",
      "[240]\ttraining's rmse: 26.9394\tvalid_1's rmse: 62.6655\n",
      "[270]\ttraining's rmse: 24.2852\tvalid_1's rmse: 61.8388\n",
      "[300]\ttraining's rmse: 22.1251\tvalid_1's rmse: 61.3673\n",
      "[330]\ttraining's rmse: 20.2257\tvalid_1's rmse: 60.9789\n",
      "[360]\ttraining's rmse: 18.6296\tvalid_1's rmse: 60.8081\n",
      "[390]\ttraining's rmse: 17.1694\tvalid_1's rmse: 60.5423\n",
      "[420]\ttraining's rmse: 15.9121\tvalid_1's rmse: 60.3628\n",
      "[450]\ttraining's rmse: 14.7565\tvalid_1's rmse: 60.1987\n",
      "[480]\ttraining's rmse: 13.7217\tvalid_1's rmse: 60.1133\n",
      "[510]\ttraining's rmse: 12.7654\tvalid_1's rmse: 59.9764\n",
      "[540]\ttraining's rmse: 11.8984\tvalid_1's rmse: 59.9046\n",
      "[570]\ttraining's rmse: 11.1221\tvalid_1's rmse: 59.8283\n",
      "[600]\ttraining's rmse: 10.4102\tvalid_1's rmse: 59.7764\n",
      "[630]\ttraining's rmse: 9.74757\tvalid_1's rmse: 59.6896\n",
      "[660]\ttraining's rmse: 9.13661\tvalid_1's rmse: 59.6277\n",
      "[690]\ttraining's rmse: 8.57691\tvalid_1's rmse: 59.5638\n",
      "[720]\ttraining's rmse: 8.06639\tvalid_1's rmse: 59.5222\n",
      "[750]\ttraining's rmse: 7.57852\tvalid_1's rmse: 59.4811\n",
      "[780]\ttraining's rmse: 7.13482\tvalid_1's rmse: 59.4496\n",
      "[810]\ttraining's rmse: 6.7056\tvalid_1's rmse: 59.4082\n",
      "[840]\ttraining's rmse: 6.3189\tvalid_1's rmse: 59.3902\n",
      "[870]\ttraining's rmse: 5.95394\tvalid_1's rmse: 59.3679\n",
      "[900]\ttraining's rmse: 5.62054\tvalid_1's rmse: 59.3539\n",
      "[930]\ttraining's rmse: 5.30277\tvalid_1's rmse: 59.3265\n",
      "[960]\ttraining's rmse: 5.00341\tvalid_1's rmse: 59.2989\n",
      "[990]\ttraining's rmse: 4.7252\tvalid_1's rmse: 59.2857\n",
      "[1020]\ttraining's rmse: 4.46614\tvalid_1's rmse: 59.2733\n",
      "[1050]\ttraining's rmse: 4.2227\tvalid_1's rmse: 59.254\n",
      "[1080]\ttraining's rmse: 3.99167\tvalid_1's rmse: 59.2434\n",
      "[1110]\ttraining's rmse: 3.78198\tvalid_1's rmse: 59.2341\n",
      "[1140]\ttraining's rmse: 3.57817\tvalid_1's rmse: 59.2211\n",
      "[1170]\ttraining's rmse: 3.39046\tvalid_1's rmse: 59.2137\n",
      "[1200]\ttraining's rmse: 3.21069\tvalid_1's rmse: 59.2003\n",
      "[1230]\ttraining's rmse: 3.04911\tvalid_1's rmse: 59.1831\n",
      "[1260]\ttraining's rmse: 2.88732\tvalid_1's rmse: 59.1814\n",
      "[1290]\ttraining's rmse: 2.73848\tvalid_1's rmse: 59.1793\n",
      "[1320]\ttraining's rmse: 2.59834\tvalid_1's rmse: 59.1727\n",
      "[1350]\ttraining's rmse: 2.46401\tvalid_1's rmse: 59.1651\n",
      "[1380]\ttraining's rmse: 2.33425\tvalid_1's rmse: 59.153\n",
      "[1410]\ttraining's rmse: 2.21751\tvalid_1's rmse: 59.1471\n",
      "[1440]\ttraining's rmse: 2.10319\tvalid_1's rmse: 59.1403\n",
      "[1470]\ttraining's rmse: 1.9942\tvalid_1's rmse: 59.1366\n",
      "[1500]\ttraining's rmse: 1.89492\tvalid_1's rmse: 59.1324\n",
      "[1530]\ttraining's rmse: 1.79793\tvalid_1's rmse: 59.1252\n",
      "[1560]\ttraining's rmse: 1.70796\tvalid_1's rmse: 59.1222\n",
      "[1590]\ttraining's rmse: 1.62134\tvalid_1's rmse: 59.1196\n",
      "[1620]\ttraining's rmse: 1.54088\tvalid_1's rmse: 59.1171\n",
      "[1650]\ttraining's rmse: 1.46366\tvalid_1's rmse: 59.1109\n",
      "[1680]\ttraining's rmse: 1.39035\tvalid_1's rmse: 59.1095\n",
      "[1710]\ttraining's rmse: 1.32165\tvalid_1's rmse: 59.1084\n",
      "[1740]\ttraining's rmse: 1.25542\tvalid_1's rmse: 59.1061\n",
      "[1770]\ttraining's rmse: 1.19268\tvalid_1's rmse: 59.1009\n",
      "[1800]\ttraining's rmse: 1.134\tvalid_1's rmse: 59.0979\n",
      "[1830]\ttraining's rmse: 1.07809\tvalid_1's rmse: 59.0974\n",
      "[1860]\ttraining's rmse: 1.02636\tvalid_1's rmse: 59.0951\n",
      "[1890]\ttraining's rmse: 0.977575\tvalid_1's rmse: 59.095\n",
      "[1920]\ttraining's rmse: 0.931077\tvalid_1's rmse: 59.0946\n",
      "[1950]\ttraining's rmse: 0.885312\tvalid_1's rmse: 59.0938\n",
      "[1980]\ttraining's rmse: 0.843352\tvalid_1's rmse: 59.0924\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's rmse: 0.815802\tvalid_1's rmse: 59.0912\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003471 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 20018\n",
      "[LightGBM] [Info] Number of data points in the train set: 9219, number of used features: 79\n",
      "[LightGBM] [Info] Start training from score 361.501097\n",
      "Training until validation scores don't improve for 125 rounds\n",
      "[30]\ttraining's rmse: 159.9\tvalid_1's rmse: 169.098\n",
      "[60]\ttraining's rmse: 100.388\tvalid_1's rmse: 114.738\n",
      "[90]\ttraining's rmse: 67.5708\tvalid_1's rmse: 88.1301\n",
      "[120]\ttraining's rmse: 49.763\tvalid_1's rmse: 75.4209\n",
      "[150]\ttraining's rmse: 39.7487\tvalid_1's rmse: 69.2062\n",
      "[180]\ttraining's rmse: 33.6001\tvalid_1's rmse: 65.9564\n",
      "[210]\ttraining's rmse: 29.4276\tvalid_1's rmse: 64.2116\n",
      "[240]\ttraining's rmse: 26.2244\tvalid_1's rmse: 62.9261\n",
      "[270]\ttraining's rmse: 23.6476\tvalid_1's rmse: 62.1279\n",
      "[300]\ttraining's rmse: 21.5125\tvalid_1's rmse: 61.5091\n",
      "[330]\ttraining's rmse: 19.7034\tvalid_1's rmse: 61.07\n",
      "[360]\ttraining's rmse: 18.1058\tvalid_1's rmse: 60.707\n",
      "[390]\ttraining's rmse: 16.7191\tvalid_1's rmse: 60.4889\n",
      "[420]\ttraining's rmse: 15.4783\tvalid_1's rmse: 60.2809\n",
      "[450]\ttraining's rmse: 14.3777\tvalid_1's rmse: 60.1411\n",
      "[480]\ttraining's rmse: 13.3614\tvalid_1's rmse: 60.0352\n",
      "[510]\ttraining's rmse: 12.4422\tvalid_1's rmse: 59.8981\n",
      "[540]\ttraining's rmse: 11.6211\tvalid_1's rmse: 59.816\n",
      "[570]\ttraining's rmse: 10.8659\tvalid_1's rmse: 59.7169\n",
      "[600]\ttraining's rmse: 10.1752\tvalid_1's rmse: 59.6254\n",
      "[630]\ttraining's rmse: 9.54238\tvalid_1's rmse: 59.5465\n",
      "[660]\ttraining's rmse: 8.94802\tvalid_1's rmse: 59.5024\n",
      "[690]\ttraining's rmse: 8.40736\tvalid_1's rmse: 59.4725\n",
      "[720]\ttraining's rmse: 7.90315\tvalid_1's rmse: 59.4384\n",
      "[750]\ttraining's rmse: 7.4326\tvalid_1's rmse: 59.4153\n",
      "[780]\ttraining's rmse: 7.00756\tvalid_1's rmse: 59.3838\n",
      "[810]\ttraining's rmse: 6.60103\tvalid_1's rmse: 59.3417\n",
      "[840]\ttraining's rmse: 6.22549\tvalid_1's rmse: 59.3148\n",
      "[870]\ttraining's rmse: 5.87712\tvalid_1's rmse: 59.2839\n",
      "[900]\ttraining's rmse: 5.55175\tvalid_1's rmse: 59.2575\n",
      "[930]\ttraining's rmse: 5.24986\tvalid_1's rmse: 59.2349\n",
      "[960]\ttraining's rmse: 4.95562\tvalid_1's rmse: 59.219\n",
      "[990]\ttraining's rmse: 4.68525\tvalid_1's rmse: 59.1993\n",
      "[1020]\ttraining's rmse: 4.43091\tvalid_1's rmse: 59.1855\n",
      "[1050]\ttraining's rmse: 4.19523\tvalid_1's rmse: 59.168\n",
      "[1080]\ttraining's rmse: 3.97386\tvalid_1's rmse: 59.1533\n",
      "[1110]\ttraining's rmse: 3.76664\tvalid_1's rmse: 59.1436\n",
      "[1140]\ttraining's rmse: 3.56616\tvalid_1's rmse: 59.1344\n",
      "[1170]\ttraining's rmse: 3.38126\tvalid_1's rmse: 59.1304\n",
      "[1200]\ttraining's rmse: 3.20457\tvalid_1's rmse: 59.1218\n",
      "[1230]\ttraining's rmse: 3.04489\tvalid_1's rmse: 59.1091\n",
      "[1260]\ttraining's rmse: 2.89111\tvalid_1's rmse: 59.1053\n",
      "[1290]\ttraining's rmse: 2.74499\tvalid_1's rmse: 59.0898\n",
      "[1320]\ttraining's rmse: 2.60468\tvalid_1's rmse: 59.0805\n",
      "[1350]\ttraining's rmse: 2.47471\tvalid_1's rmse: 59.071\n",
      "[1380]\ttraining's rmse: 2.34857\tvalid_1's rmse: 59.0663\n",
      "[1410]\ttraining's rmse: 2.22986\tvalid_1's rmse: 59.0555\n",
      "[1440]\ttraining's rmse: 2.12041\tvalid_1's rmse: 59.0523\n",
      "[1470]\ttraining's rmse: 2.01425\tvalid_1's rmse: 59.0475\n",
      "[1500]\ttraining's rmse: 1.91636\tvalid_1's rmse: 59.0403\n",
      "[1530]\ttraining's rmse: 1.82148\tvalid_1's rmse: 59.0314\n",
      "[1560]\ttraining's rmse: 1.73225\tvalid_1's rmse: 59.0294\n",
      "[1590]\ttraining's rmse: 1.64959\tvalid_1's rmse: 59.0261\n",
      "[1620]\ttraining's rmse: 1.5697\tvalid_1's rmse: 59.0227\n",
      "[1650]\ttraining's rmse: 1.49554\tvalid_1's rmse: 59.0188\n",
      "[1680]\ttraining's rmse: 1.42437\tvalid_1's rmse: 59.0181\n",
      "[1710]\ttraining's rmse: 1.35504\tvalid_1's rmse: 59.0139\n",
      "[1740]\ttraining's rmse: 1.29108\tvalid_1's rmse: 59.0088\n",
      "[1770]\ttraining's rmse: 1.23012\tvalid_1's rmse: 59.0065\n",
      "[1800]\ttraining's rmse: 1.17138\tvalid_1's rmse: 59.0034\n",
      "[1830]\ttraining's rmse: 1.1165\tvalid_1's rmse: 59.0001\n",
      "[1860]\ttraining's rmse: 1.06342\tvalid_1's rmse: 58.9974\n",
      "[1890]\ttraining's rmse: 1.01452\tvalid_1's rmse: 58.9967\n",
      "[1920]\ttraining's rmse: 0.967604\tvalid_1's rmse: 58.996\n",
      "[1950]\ttraining's rmse: 0.924088\tvalid_1's rmse: 58.9929\n",
      "[1980]\ttraining's rmse: 0.882719\tvalid_1's rmse: 58.9914\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's rmse: 0.855778\tvalid_1's rmse: 58.99\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002607 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 20018\n",
      "[LightGBM] [Info] Number of data points in the train set: 9219, number of used features: 79\n",
      "[LightGBM] [Info] Start training from score 360.761837\n",
      "Training until validation scores don't improve for 125 rounds\n",
      "[30]\ttraining's rmse: 160.853\tvalid_1's rmse: 170.168\n",
      "[60]\ttraining's rmse: 101.435\tvalid_1's rmse: 116.625\n",
      "[90]\ttraining's rmse: 68.8794\tvalid_1's rmse: 89.5527\n",
      "[120]\ttraining's rmse: 50.8257\tvalid_1's rmse: 76.3627\n",
      "[150]\ttraining's rmse: 40.5676\tvalid_1's rmse: 69.5965\n",
      "[180]\ttraining's rmse: 34.4228\tvalid_1's rmse: 66.0996\n",
      "[210]\ttraining's rmse: 30.2113\tvalid_1's rmse: 64.1037\n",
      "[240]\ttraining's rmse: 27.0085\tvalid_1's rmse: 62.8742\n",
      "[270]\ttraining's rmse: 24.3087\tvalid_1's rmse: 61.9986\n",
      "[300]\ttraining's rmse: 22.0825\tvalid_1's rmse: 61.4905\n",
      "[330]\ttraining's rmse: 20.2412\tvalid_1's rmse: 61.0397\n",
      "[360]\ttraining's rmse: 18.6132\tvalid_1's rmse: 60.7651\n",
      "[390]\ttraining's rmse: 17.1842\tvalid_1's rmse: 60.4755\n",
      "[420]\ttraining's rmse: 15.9137\tvalid_1's rmse: 60.2626\n",
      "[450]\ttraining's rmse: 14.744\tvalid_1's rmse: 60.0898\n",
      "[480]\ttraining's rmse: 13.7027\tvalid_1's rmse: 59.93\n",
      "[510]\ttraining's rmse: 12.7703\tvalid_1's rmse: 59.8425\n",
      "[540]\ttraining's rmse: 11.9233\tvalid_1's rmse: 59.758\n",
      "[570]\ttraining's rmse: 11.1454\tvalid_1's rmse: 59.6514\n",
      "[600]\ttraining's rmse: 10.4449\tvalid_1's rmse: 59.5623\n",
      "[630]\ttraining's rmse: 9.80319\tvalid_1's rmse: 59.525\n",
      "[660]\ttraining's rmse: 9.19818\tvalid_1's rmse: 59.485\n",
      "[690]\ttraining's rmse: 8.6412\tvalid_1's rmse: 59.4537\n",
      "[720]\ttraining's rmse: 8.13163\tvalid_1's rmse: 59.409\n",
      "[750]\ttraining's rmse: 7.64899\tvalid_1's rmse: 59.3686\n",
      "[780]\ttraining's rmse: 7.21488\tvalid_1's rmse: 59.3461\n",
      "[810]\ttraining's rmse: 6.8021\tvalid_1's rmse: 59.3219\n",
      "[840]\ttraining's rmse: 6.41513\tvalid_1's rmse: 59.3036\n",
      "[870]\ttraining's rmse: 6.05499\tvalid_1's rmse: 59.2823\n",
      "[900]\ttraining's rmse: 5.71849\tvalid_1's rmse: 59.2695\n",
      "[930]\ttraining's rmse: 5.40548\tvalid_1's rmse: 59.254\n",
      "[960]\ttraining's rmse: 5.11648\tvalid_1's rmse: 59.2462\n",
      "[990]\ttraining's rmse: 4.84489\tvalid_1's rmse: 59.2251\n",
      "[1020]\ttraining's rmse: 4.59105\tvalid_1's rmse: 59.2114\n",
      "[1050]\ttraining's rmse: 4.34704\tvalid_1's rmse: 59.1983\n",
      "[1080]\ttraining's rmse: 4.12658\tvalid_1's rmse: 59.1886\n",
      "[1110]\ttraining's rmse: 3.91658\tvalid_1's rmse: 59.1809\n",
      "[1140]\ttraining's rmse: 3.71321\tvalid_1's rmse: 59.1607\n",
      "[1170]\ttraining's rmse: 3.52752\tvalid_1's rmse: 59.1432\n",
      "[1200]\ttraining's rmse: 3.35355\tvalid_1's rmse: 59.1375\n",
      "[1230]\ttraining's rmse: 3.19263\tvalid_1's rmse: 59.1295\n",
      "[1260]\ttraining's rmse: 3.02904\tvalid_1's rmse: 59.1245\n",
      "[1290]\ttraining's rmse: 2.88144\tvalid_1's rmse: 59.1205\n",
      "[1320]\ttraining's rmse: 2.73757\tvalid_1's rmse: 59.1071\n",
      "[1350]\ttraining's rmse: 2.6028\tvalid_1's rmse: 59.0985\n",
      "[1380]\ttraining's rmse: 2.4784\tvalid_1's rmse: 59.0924\n",
      "[1410]\ttraining's rmse: 2.35929\tvalid_1's rmse: 59.0872\n",
      "[1440]\ttraining's rmse: 2.24533\tvalid_1's rmse: 59.0838\n",
      "[1470]\ttraining's rmse: 2.13394\tvalid_1's rmse: 59.0806\n",
      "[1500]\ttraining's rmse: 2.03161\tvalid_1's rmse: 59.0765\n",
      "[1530]\ttraining's rmse: 1.93538\tvalid_1's rmse: 59.074\n",
      "[1560]\ttraining's rmse: 1.84278\tvalid_1's rmse: 59.0712\n",
      "[1590]\ttraining's rmse: 1.75526\tvalid_1's rmse: 59.0644\n",
      "[1620]\ttraining's rmse: 1.67183\tvalid_1's rmse: 59.0609\n",
      "[1650]\ttraining's rmse: 1.5963\tvalid_1's rmse: 59.0558\n",
      "[1680]\ttraining's rmse: 1.52184\tvalid_1's rmse: 59.05\n",
      "[1710]\ttraining's rmse: 1.45146\tvalid_1's rmse: 59.0469\n",
      "[1740]\ttraining's rmse: 1.38718\tvalid_1's rmse: 59.0456\n",
      "[1770]\ttraining's rmse: 1.32395\tvalid_1's rmse: 59.0428\n",
      "[1800]\ttraining's rmse: 1.26355\tvalid_1's rmse: 59.0448\n",
      "[1830]\ttraining's rmse: 1.20741\tvalid_1's rmse: 59.0419\n",
      "[1860]\ttraining's rmse: 1.15321\tvalid_1's rmse: 59.0428\n",
      "[1890]\ttraining's rmse: 1.10156\tvalid_1's rmse: 59.0404\n",
      "[1920]\ttraining's rmse: 1.05221\tvalid_1's rmse: 59.0363\n",
      "[1950]\ttraining's rmse: 1.0057\tvalid_1's rmse: 59.0341\n",
      "[1980]\ttraining's rmse: 0.960014\tvalid_1's rmse: 59.0325\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's rmse: 0.93122\tvalid_1's rmse: 59.032\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002470 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 20018\n",
      "[LightGBM] [Info] Number of data points in the train set: 9219, number of used features: 79\n",
      "[LightGBM] [Info] Start training from score 361.654431\n",
      "Training until validation scores don't improve for 125 rounds\n",
      "[30]\ttraining's rmse: 160.987\tvalid_1's rmse: 164.067\n",
      "[60]\ttraining's rmse: 99.9048\tvalid_1's rmse: 110.186\n",
      "[90]\ttraining's rmse: 66.9611\tvalid_1's rmse: 82.9602\n",
      "[120]\ttraining's rmse: 49.1972\tvalid_1's rmse: 70.0536\n",
      "[150]\ttraining's rmse: 39.2528\tvalid_1's rmse: 63.7972\n",
      "[180]\ttraining's rmse: 33.1798\tvalid_1's rmse: 60.4463\n",
      "[210]\ttraining's rmse: 29.0091\tvalid_1's rmse: 58.4843\n",
      "[240]\ttraining's rmse: 25.8397\tvalid_1's rmse: 57.3083\n",
      "[270]\ttraining's rmse: 23.2438\tvalid_1's rmse: 56.5188\n",
      "[300]\ttraining's rmse: 21.1389\tvalid_1's rmse: 56.0036\n",
      "[330]\ttraining's rmse: 19.3783\tvalid_1's rmse: 55.7054\n",
      "[360]\ttraining's rmse: 17.8186\tvalid_1's rmse: 55.4719\n",
      "[390]\ttraining's rmse: 16.4281\tvalid_1's rmse: 55.1705\n",
      "[420]\ttraining's rmse: 15.1974\tvalid_1's rmse: 54.9482\n",
      "[450]\ttraining's rmse: 14.1206\tvalid_1's rmse: 54.8345\n",
      "[480]\ttraining's rmse: 13.1141\tvalid_1's rmse: 54.7519\n",
      "[510]\ttraining's rmse: 12.2184\tvalid_1's rmse: 54.6884\n",
      "[540]\ttraining's rmse: 11.42\tvalid_1's rmse: 54.6145\n",
      "[570]\ttraining's rmse: 10.6639\tvalid_1's rmse: 54.558\n",
      "[600]\ttraining's rmse: 9.97607\tvalid_1's rmse: 54.5146\n",
      "[630]\ttraining's rmse: 9.35012\tvalid_1's rmse: 54.4708\n",
      "[660]\ttraining's rmse: 8.7818\tvalid_1's rmse: 54.4653\n",
      "[690]\ttraining's rmse: 8.24911\tvalid_1's rmse: 54.4353\n",
      "[720]\ttraining's rmse: 7.74813\tvalid_1's rmse: 54.4114\n",
      "[750]\ttraining's rmse: 7.29561\tvalid_1's rmse: 54.3931\n",
      "[780]\ttraining's rmse: 6.87456\tvalid_1's rmse: 54.3445\n",
      "[810]\ttraining's rmse: 6.47346\tvalid_1's rmse: 54.3166\n",
      "[840]\ttraining's rmse: 6.10282\tvalid_1's rmse: 54.2919\n",
      "[870]\ttraining's rmse: 5.75454\tvalid_1's rmse: 54.2682\n",
      "[900]\ttraining's rmse: 5.43105\tvalid_1's rmse: 54.2433\n",
      "[930]\ttraining's rmse: 5.1279\tvalid_1's rmse: 54.2311\n",
      "[960]\ttraining's rmse: 4.85211\tvalid_1's rmse: 54.2108\n",
      "[990]\ttraining's rmse: 4.5837\tvalid_1's rmse: 54.2025\n",
      "[1020]\ttraining's rmse: 4.33792\tvalid_1's rmse: 54.199\n",
      "[1050]\ttraining's rmse: 4.10293\tvalid_1's rmse: 54.1919\n",
      "[1080]\ttraining's rmse: 3.88492\tvalid_1's rmse: 54.1903\n",
      "[1110]\ttraining's rmse: 3.67953\tvalid_1's rmse: 54.1841\n",
      "[1140]\ttraining's rmse: 3.4863\tvalid_1's rmse: 54.1738\n",
      "[1170]\ttraining's rmse: 3.30584\tvalid_1's rmse: 54.1618\n",
      "[1200]\ttraining's rmse: 3.13359\tvalid_1's rmse: 54.1627\n",
      "[1230]\ttraining's rmse: 2.973\tvalid_1's rmse: 54.1563\n",
      "[1260]\ttraining's rmse: 2.82088\tvalid_1's rmse: 54.1527\n",
      "[1290]\ttraining's rmse: 2.67856\tvalid_1's rmse: 54.1466\n",
      "[1320]\ttraining's rmse: 2.53794\tvalid_1's rmse: 54.1437\n",
      "[1350]\ttraining's rmse: 2.41182\tvalid_1's rmse: 54.1395\n",
      "[1380]\ttraining's rmse: 2.29153\tvalid_1's rmse: 54.1349\n",
      "[1410]\ttraining's rmse: 2.17571\tvalid_1's rmse: 54.1289\n",
      "[1440]\ttraining's rmse: 2.06899\tvalid_1's rmse: 54.1241\n",
      "[1470]\ttraining's rmse: 1.96758\tvalid_1's rmse: 54.1224\n",
      "[1500]\ttraining's rmse: 1.87063\tvalid_1's rmse: 54.12\n",
      "[1530]\ttraining's rmse: 1.77884\tvalid_1's rmse: 54.1166\n",
      "[1560]\ttraining's rmse: 1.69151\tvalid_1's rmse: 54.1155\n",
      "[1590]\ttraining's rmse: 1.60962\tvalid_1's rmse: 54.115\n",
      "[1620]\ttraining's rmse: 1.53124\tvalid_1's rmse: 54.1137\n",
      "[1650]\ttraining's rmse: 1.45935\tvalid_1's rmse: 54.1118\n",
      "[1680]\ttraining's rmse: 1.39085\tvalid_1's rmse: 54.1098\n",
      "[1710]\ttraining's rmse: 1.32516\tvalid_1's rmse: 54.1106\n",
      "[1740]\ttraining's rmse: 1.26253\tvalid_1's rmse: 54.109\n",
      "[1770]\ttraining's rmse: 1.20194\tvalid_1's rmse: 54.1092\n",
      "[1800]\ttraining's rmse: 1.14514\tvalid_1's rmse: 54.1069\n",
      "[1830]\ttraining's rmse: 1.09333\tvalid_1's rmse: 54.1085\n",
      "[1860]\ttraining's rmse: 1.04298\tvalid_1's rmse: 54.1079\n",
      "[1890]\ttraining's rmse: 0.994359\tvalid_1's rmse: 54.1094\n",
      "Early stopping, best iteration is:\n",
      "[1792]\ttraining's rmse: 1.16033\tvalid_1's rmse: 54.1067\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003709 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 20018\n",
      "[LightGBM] [Info] Number of data points in the train set: 9219, number of used features: 79\n",
      "[LightGBM] [Info] Start training from score 374.552029\n",
      "Training until validation scores don't improve for 125 rounds\n",
      "[30]\ttraining's rmse: 167.285\tvalid_1's rmse: 170.483\n",
      "[60]\ttraining's rmse: 104.301\tvalid_1's rmse: 113.874\n",
      "[90]\ttraining's rmse: 70.0733\tvalid_1's rmse: 86.2587\n",
      "[120]\ttraining's rmse: 51.5804\tvalid_1's rmse: 73.2043\n",
      "[150]\ttraining's rmse: 41.0964\tvalid_1's rmse: 66.8559\n",
      "[180]\ttraining's rmse: 34.8546\tvalid_1's rmse: 63.7233\n",
      "[210]\ttraining's rmse: 30.5103\tvalid_1's rmse: 61.8994\n",
      "[240]\ttraining's rmse: 27.3392\tvalid_1's rmse: 60.8743\n",
      "[270]\ttraining's rmse: 24.6932\tvalid_1's rmse: 60.0193\n",
      "[300]\ttraining's rmse: 22.4853\tvalid_1's rmse: 59.4834\n",
      "[330]\ttraining's rmse: 20.6063\tvalid_1's rmse: 59.052\n",
      "[360]\ttraining's rmse: 18.9587\tvalid_1's rmse: 58.7784\n",
      "[390]\ttraining's rmse: 17.5266\tvalid_1's rmse: 58.5027\n",
      "[420]\ttraining's rmse: 16.2727\tvalid_1's rmse: 58.3253\n",
      "[450]\ttraining's rmse: 15.1484\tvalid_1's rmse: 58.1801\n",
      "[480]\ttraining's rmse: 14.0822\tvalid_1's rmse: 58.0698\n",
      "[510]\ttraining's rmse: 13.1258\tvalid_1's rmse: 57.9384\n",
      "[540]\ttraining's rmse: 12.2631\tvalid_1's rmse: 57.8508\n",
      "[570]\ttraining's rmse: 11.462\tvalid_1's rmse: 57.7451\n",
      "[600]\ttraining's rmse: 10.7528\tvalid_1's rmse: 57.6606\n",
      "[630]\ttraining's rmse: 10.0954\tvalid_1's rmse: 57.6141\n",
      "[660]\ttraining's rmse: 9.48214\tvalid_1's rmse: 57.5733\n",
      "[690]\ttraining's rmse: 8.92253\tvalid_1's rmse: 57.5134\n",
      "[720]\ttraining's rmse: 8.38841\tvalid_1's rmse: 57.4912\n",
      "[750]\ttraining's rmse: 7.8941\tvalid_1's rmse: 57.4657\n",
      "[780]\ttraining's rmse: 7.44398\tvalid_1's rmse: 57.4314\n",
      "[810]\ttraining's rmse: 7.01481\tvalid_1's rmse: 57.4052\n",
      "[840]\ttraining's rmse: 6.62418\tvalid_1's rmse: 57.364\n",
      "[870]\ttraining's rmse: 6.26597\tvalid_1's rmse: 57.3542\n",
      "[900]\ttraining's rmse: 5.91727\tvalid_1's rmse: 57.35\n",
      "[930]\ttraining's rmse: 5.59317\tvalid_1's rmse: 57.3285\n",
      "[960]\ttraining's rmse: 5.29217\tvalid_1's rmse: 57.3246\n",
      "[990]\ttraining's rmse: 5.01209\tvalid_1's rmse: 57.308\n",
      "[1020]\ttraining's rmse: 4.75372\tvalid_1's rmse: 57.2929\n",
      "[1050]\ttraining's rmse: 4.50671\tvalid_1's rmse: 57.2866\n",
      "[1080]\ttraining's rmse: 4.26733\tvalid_1's rmse: 57.2792\n",
      "[1110]\ttraining's rmse: 4.04695\tvalid_1's rmse: 57.2674\n",
      "[1140]\ttraining's rmse: 3.83526\tvalid_1's rmse: 57.2609\n",
      "[1170]\ttraining's rmse: 3.63625\tvalid_1's rmse: 57.2535\n",
      "[1200]\ttraining's rmse: 3.44975\tvalid_1's rmse: 57.2393\n",
      "[1230]\ttraining's rmse: 3.28\tvalid_1's rmse: 57.2289\n",
      "[1260]\ttraining's rmse: 3.11386\tvalid_1's rmse: 57.23\n",
      "[1290]\ttraining's rmse: 2.9582\tvalid_1's rmse: 57.219\n",
      "[1320]\ttraining's rmse: 2.81356\tvalid_1's rmse: 57.2047\n",
      "[1350]\ttraining's rmse: 2.67623\tvalid_1's rmse: 57.2005\n",
      "[1380]\ttraining's rmse: 2.54136\tvalid_1's rmse: 57.1929\n",
      "[1410]\ttraining's rmse: 2.41569\tvalid_1's rmse: 57.1889\n",
      "[1440]\ttraining's rmse: 2.29865\tvalid_1's rmse: 57.1896\n",
      "[1470]\ttraining's rmse: 2.18851\tvalid_1's rmse: 57.1848\n",
      "[1500]\ttraining's rmse: 2.08113\tvalid_1's rmse: 57.1831\n",
      "[1530]\ttraining's rmse: 1.98435\tvalid_1's rmse: 57.1798\n",
      "[1560]\ttraining's rmse: 1.88829\tvalid_1's rmse: 57.1819\n",
      "[1590]\ttraining's rmse: 1.79722\tvalid_1's rmse: 57.1778\n",
      "[1620]\ttraining's rmse: 1.71124\tvalid_1's rmse: 57.1766\n",
      "[1650]\ttraining's rmse: 1.63171\tvalid_1's rmse: 57.1714\n",
      "[1680]\ttraining's rmse: 1.55578\tvalid_1's rmse: 57.1693\n",
      "[1710]\ttraining's rmse: 1.48357\tvalid_1's rmse: 57.1712\n",
      "[1740]\ttraining's rmse: 1.41461\tvalid_1's rmse: 57.1737\n",
      "[1770]\ttraining's rmse: 1.34996\tvalid_1's rmse: 57.1708\n",
      "[1800]\ttraining's rmse: 1.28773\tvalid_1's rmse: 57.17\n",
      "Early stopping, best iteration is:\n",
      "[1678]\ttraining's rmse: 1.56114\tvalid_1's rmse: 57.1685\n",
      "15\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003238 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 20018\n",
      "[LightGBM] [Info] Number of data points in the train set: 9219, number of used features: 79\n",
      "[LightGBM] [Info] Start training from score 370.159354\n",
      "Training until validation scores don't improve for 125 rounds\n",
      "[30]\ttraining's rmse: 158.701\tvalid_1's rmse: 156.38\n",
      "[60]\ttraining's rmse: 98.5463\tvalid_1's rmse: 102.727\n",
      "[90]\ttraining's rmse: 65.8649\tvalid_1's rmse: 76.1232\n",
      "[120]\ttraining's rmse: 48.2045\tvalid_1's rmse: 63.6321\n",
      "[150]\ttraining's rmse: 38.4217\tvalid_1's rmse: 57.6523\n",
      "[180]\ttraining's rmse: 32.5945\tvalid_1's rmse: 54.8\n",
      "[210]\ttraining's rmse: 28.5599\tvalid_1's rmse: 53.1922\n",
      "[240]\ttraining's rmse: 25.311\tvalid_1's rmse: 51.9929\n",
      "[270]\ttraining's rmse: 22.7703\tvalid_1's rmse: 51.1637\n",
      "[300]\ttraining's rmse: 20.6977\tvalid_1's rmse: 50.6675\n",
      "[330]\ttraining's rmse: 18.9581\tvalid_1's rmse: 50.3348\n",
      "[360]\ttraining's rmse: 17.4304\tvalid_1's rmse: 50.0795\n",
      "[390]\ttraining's rmse: 16.1025\tvalid_1's rmse: 49.864\n",
      "[420]\ttraining's rmse: 14.9127\tvalid_1's rmse: 49.6886\n",
      "[450]\ttraining's rmse: 13.8374\tvalid_1's rmse: 49.5831\n",
      "[480]\ttraining's rmse: 12.8732\tvalid_1's rmse: 49.4791\n",
      "[510]\ttraining's rmse: 12.0075\tvalid_1's rmse: 49.4262\n",
      "[540]\ttraining's rmse: 11.1762\tvalid_1's rmse: 49.3626\n",
      "[570]\ttraining's rmse: 10.4503\tvalid_1's rmse: 49.2682\n",
      "[600]\ttraining's rmse: 9.77932\tvalid_1's rmse: 49.2061\n",
      "[630]\ttraining's rmse: 9.16193\tvalid_1's rmse: 49.1531\n",
      "[660]\ttraining's rmse: 8.58857\tvalid_1's rmse: 49.1276\n",
      "[690]\ttraining's rmse: 8.05181\tvalid_1's rmse: 49.0969\n",
      "[720]\ttraining's rmse: 7.56312\tvalid_1's rmse: 49.0768\n",
      "[750]\ttraining's rmse: 7.1125\tvalid_1's rmse: 49.0658\n",
      "[780]\ttraining's rmse: 6.68997\tvalid_1's rmse: 49.0517\n",
      "[810]\ttraining's rmse: 6.29434\tvalid_1's rmse: 49.04\n",
      "[840]\ttraining's rmse: 5.92769\tvalid_1's rmse: 49.0276\n",
      "[870]\ttraining's rmse: 5.58945\tvalid_1's rmse: 49.0083\n",
      "[900]\ttraining's rmse: 5.27529\tvalid_1's rmse: 49.0076\n",
      "[930]\ttraining's rmse: 4.97821\tvalid_1's rmse: 49.0002\n",
      "[960]\ttraining's rmse: 4.7012\tvalid_1's rmse: 48.978\n",
      "[990]\ttraining's rmse: 4.43223\tvalid_1's rmse: 48.9593\n",
      "[1020]\ttraining's rmse: 4.18545\tvalid_1's rmse: 48.937\n",
      "[1050]\ttraining's rmse: 3.96024\tvalid_1's rmse: 48.9269\n",
      "[1080]\ttraining's rmse: 3.75278\tvalid_1's rmse: 48.9129\n",
      "[1110]\ttraining's rmse: 3.55336\tvalid_1's rmse: 48.9104\n",
      "[1140]\ttraining's rmse: 3.36783\tvalid_1's rmse: 48.9022\n",
      "[1170]\ttraining's rmse: 3.19292\tvalid_1's rmse: 48.8981\n",
      "[1200]\ttraining's rmse: 3.02441\tvalid_1's rmse: 48.9047\n",
      "[1230]\ttraining's rmse: 2.86708\tvalid_1's rmse: 48.8997\n",
      "[1260]\ttraining's rmse: 2.72145\tvalid_1's rmse: 48.8962\n",
      "[1290]\ttraining's rmse: 2.58185\tvalid_1's rmse: 48.8885\n",
      "[1320]\ttraining's rmse: 2.45123\tvalid_1's rmse: 48.8878\n",
      "[1350]\ttraining's rmse: 2.32645\tvalid_1's rmse: 48.8844\n",
      "[1380]\ttraining's rmse: 2.20725\tvalid_1's rmse: 48.8813\n",
      "[1410]\ttraining's rmse: 2.09487\tvalid_1's rmse: 48.8779\n",
      "[1440]\ttraining's rmse: 1.98852\tvalid_1's rmse: 48.8731\n",
      "[1470]\ttraining's rmse: 1.88741\tvalid_1's rmse: 48.8674\n",
      "[1500]\ttraining's rmse: 1.79266\tvalid_1's rmse: 48.8657\n",
      "[1530]\ttraining's rmse: 1.70332\tvalid_1's rmse: 48.8613\n",
      "[1560]\ttraining's rmse: 1.61787\tvalid_1's rmse: 48.8569\n",
      "[1590]\ttraining's rmse: 1.53789\tvalid_1's rmse: 48.8556\n",
      "[1620]\ttraining's rmse: 1.46383\tvalid_1's rmse: 48.8515\n",
      "[1650]\ttraining's rmse: 1.39178\tvalid_1's rmse: 48.8487\n",
      "[1680]\ttraining's rmse: 1.32184\tvalid_1's rmse: 48.8466\n",
      "[1710]\ttraining's rmse: 1.25894\tvalid_1's rmse: 48.846\n",
      "[1740]\ttraining's rmse: 1.19765\tvalid_1's rmse: 48.8435\n",
      "[1770]\ttraining's rmse: 1.1399\tvalid_1's rmse: 48.8438\n",
      "[1800]\ttraining's rmse: 1.08559\tvalid_1's rmse: 48.8411\n",
      "[1830]\ttraining's rmse: 1.03233\tvalid_1's rmse: 48.8405\n",
      "[1860]\ttraining's rmse: 0.982549\tvalid_1's rmse: 48.839\n",
      "[1890]\ttraining's rmse: 0.934803\tvalid_1's rmse: 48.837\n",
      "[1920]\ttraining's rmse: 0.889912\tvalid_1's rmse: 48.8362\n",
      "[1950]\ttraining's rmse: 0.847876\tvalid_1's rmse: 48.8356\n",
      "[1980]\ttraining's rmse: 0.807282\tvalid_1's rmse: 48.8355\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's rmse: 0.781583\tvalid_1's rmse: 48.835\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003485 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 20018\n",
      "[LightGBM] [Info] Number of data points in the train set: 9219, number of used features: 79\n",
      "[LightGBM] [Info] Start training from score 376.196971\n",
      "Training until validation scores don't improve for 125 rounds\n",
      "[30]\ttraining's rmse: 163.403\tvalid_1's rmse: 163.63\n",
      "[60]\ttraining's rmse: 102.772\tvalid_1's rmse: 111.673\n",
      "[90]\ttraining's rmse: 70.0605\tvalid_1's rmse: 85.8363\n",
      "[120]\ttraining's rmse: 51.9035\tvalid_1's rmse: 73.0665\n",
      "[150]\ttraining's rmse: 41.5888\tvalid_1's rmse: 67.052\n",
      "[180]\ttraining's rmse: 35.2911\tvalid_1's rmse: 63.7863\n",
      "[210]\ttraining's rmse: 30.8611\tvalid_1's rmse: 61.7279\n",
      "[240]\ttraining's rmse: 27.5202\tvalid_1's rmse: 60.4707\n",
      "[270]\ttraining's rmse: 24.7835\tvalid_1's rmse: 59.5472\n",
      "[300]\ttraining's rmse: 22.4628\tvalid_1's rmse: 58.9682\n",
      "[330]\ttraining's rmse: 20.5329\tvalid_1's rmse: 58.5239\n",
      "[360]\ttraining's rmse: 18.8531\tvalid_1's rmse: 58.2163\n",
      "[390]\ttraining's rmse: 17.3426\tvalid_1's rmse: 57.9373\n",
      "[420]\ttraining's rmse: 16.0452\tvalid_1's rmse: 57.7318\n",
      "[450]\ttraining's rmse: 14.8883\tvalid_1's rmse: 57.5569\n",
      "[480]\ttraining's rmse: 13.8327\tvalid_1's rmse: 57.4164\n",
      "[510]\ttraining's rmse: 12.89\tvalid_1's rmse: 57.2896\n",
      "[540]\ttraining's rmse: 12.0007\tvalid_1's rmse: 57.1677\n",
      "[570]\ttraining's rmse: 11.1908\tvalid_1's rmse: 57.0837\n",
      "[600]\ttraining's rmse: 10.4739\tvalid_1's rmse: 56.9888\n",
      "[630]\ttraining's rmse: 9.79499\tvalid_1's rmse: 56.8914\n",
      "[660]\ttraining's rmse: 9.17684\tvalid_1's rmse: 56.8238\n",
      "[690]\ttraining's rmse: 8.60333\tvalid_1's rmse: 56.7717\n",
      "[720]\ttraining's rmse: 8.07277\tvalid_1's rmse: 56.7316\n",
      "[750]\ttraining's rmse: 7.58827\tvalid_1's rmse: 56.6974\n",
      "[780]\ttraining's rmse: 7.13048\tvalid_1's rmse: 56.6479\n",
      "[810]\ttraining's rmse: 6.70453\tvalid_1's rmse: 56.612\n",
      "[840]\ttraining's rmse: 6.319\tvalid_1's rmse: 56.5922\n",
      "[870]\ttraining's rmse: 5.94909\tvalid_1's rmse: 56.5671\n",
      "[900]\ttraining's rmse: 5.60972\tvalid_1's rmse: 56.5418\n",
      "[930]\ttraining's rmse: 5.28698\tvalid_1's rmse: 56.5209\n",
      "[960]\ttraining's rmse: 4.98797\tvalid_1's rmse: 56.5035\n",
      "[990]\ttraining's rmse: 4.70963\tvalid_1's rmse: 56.4753\n",
      "[1020]\ttraining's rmse: 4.45095\tvalid_1's rmse: 56.4628\n",
      "[1050]\ttraining's rmse: 4.20252\tvalid_1's rmse: 56.4497\n",
      "[1080]\ttraining's rmse: 3.97211\tvalid_1's rmse: 56.4325\n",
      "[1110]\ttraining's rmse: 3.75435\tvalid_1's rmse: 56.4226\n",
      "[1140]\ttraining's rmse: 3.55542\tvalid_1's rmse: 56.4168\n",
      "[1170]\ttraining's rmse: 3.36543\tvalid_1's rmse: 56.3995\n",
      "[1200]\ttraining's rmse: 3.18634\tvalid_1's rmse: 56.388\n",
      "[1230]\ttraining's rmse: 3.01963\tvalid_1's rmse: 56.3774\n",
      "[1260]\ttraining's rmse: 2.86017\tvalid_1's rmse: 56.3632\n",
      "[1290]\ttraining's rmse: 2.70961\tvalid_1's rmse: 56.3521\n",
      "[1320]\ttraining's rmse: 2.56996\tvalid_1's rmse: 56.3466\n",
      "[1350]\ttraining's rmse: 2.43392\tvalid_1's rmse: 56.3371\n",
      "[1380]\ttraining's rmse: 2.30714\tvalid_1's rmse: 56.3314\n",
      "[1410]\ttraining's rmse: 2.18655\tvalid_1's rmse: 56.3253\n",
      "[1440]\ttraining's rmse: 2.07606\tvalid_1's rmse: 56.3228\n",
      "[1470]\ttraining's rmse: 1.97075\tvalid_1's rmse: 56.3196\n",
      "[1500]\ttraining's rmse: 1.86978\tvalid_1's rmse: 56.3172\n",
      "[1530]\ttraining's rmse: 1.77478\tvalid_1's rmse: 56.3113\n",
      "[1560]\ttraining's rmse: 1.68545\tvalid_1's rmse: 56.3098\n",
      "[1590]\ttraining's rmse: 1.60236\tvalid_1's rmse: 56.3098\n",
      "[1620]\ttraining's rmse: 1.52409\tvalid_1's rmse: 56.3051\n",
      "[1650]\ttraining's rmse: 1.44707\tvalid_1's rmse: 56.3003\n",
      "[1680]\ttraining's rmse: 1.37329\tvalid_1's rmse: 56.2966\n",
      "[1710]\ttraining's rmse: 1.30638\tvalid_1's rmse: 56.2929\n",
      "[1740]\ttraining's rmse: 1.24244\tvalid_1's rmse: 56.2905\n",
      "[1770]\ttraining's rmse: 1.1818\tvalid_1's rmse: 56.2887\n",
      "[1800]\ttraining's rmse: 1.12386\tvalid_1's rmse: 56.2859\n",
      "[1830]\ttraining's rmse: 1.06899\tvalid_1's rmse: 56.2845\n",
      "[1860]\ttraining's rmse: 1.01669\tvalid_1's rmse: 56.2821\n",
      "[1890]\ttraining's rmse: 0.966586\tvalid_1's rmse: 56.2783\n",
      "[1920]\ttraining's rmse: 0.92031\tvalid_1's rmse: 56.2772\n",
      "[1950]\ttraining's rmse: 0.876021\tvalid_1's rmse: 56.2764\n",
      "[1980]\ttraining's rmse: 0.834968\tvalid_1's rmse: 56.2758\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's rmse: 0.808684\tvalid_1's rmse: 56.2751\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003420 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 20018\n",
      "[LightGBM] [Info] Number of data points in the train set: 9219, number of used features: 79\n",
      "[LightGBM] [Info] Start training from score 375.469807\n",
      "Training until validation scores don't improve for 125 rounds\n",
      "[30]\ttraining's rmse: 162.524\tvalid_1's rmse: 165.563\n",
      "[60]\ttraining's rmse: 101.992\tvalid_1's rmse: 113.148\n",
      "[90]\ttraining's rmse: 69.534\tvalid_1's rmse: 87.3631\n",
      "[120]\ttraining's rmse: 51.6934\tvalid_1's rmse: 74.6298\n",
      "[150]\ttraining's rmse: 41.4385\tvalid_1's rmse: 67.8749\n",
      "[180]\ttraining's rmse: 35.1343\tvalid_1's rmse: 64.3351\n",
      "[210]\ttraining's rmse: 30.8299\tvalid_1's rmse: 62.1796\n",
      "[240]\ttraining's rmse: 27.5876\tvalid_1's rmse: 60.8189\n",
      "[270]\ttraining's rmse: 24.8954\tvalid_1's rmse: 59.7621\n",
      "[300]\ttraining's rmse: 22.669\tvalid_1's rmse: 59.1202\n",
      "[330]\ttraining's rmse: 20.7873\tvalid_1's rmse: 58.5764\n",
      "[360]\ttraining's rmse: 19.1326\tvalid_1's rmse: 58.2566\n",
      "[390]\ttraining's rmse: 17.66\tvalid_1's rmse: 57.9501\n",
      "[420]\ttraining's rmse: 16.3321\tvalid_1's rmse: 57.7011\n",
      "[450]\ttraining's rmse: 15.1349\tvalid_1's rmse: 57.5197\n",
      "[480]\ttraining's rmse: 14.0694\tvalid_1's rmse: 57.3109\n",
      "[510]\ttraining's rmse: 13.1158\tvalid_1's rmse: 57.1725\n",
      "[540]\ttraining's rmse: 12.2119\tvalid_1's rmse: 57.0512\n",
      "[570]\ttraining's rmse: 11.4012\tvalid_1's rmse: 56.9552\n",
      "[600]\ttraining's rmse: 10.653\tvalid_1's rmse: 56.8755\n",
      "[630]\ttraining's rmse: 9.97669\tvalid_1's rmse: 56.8056\n",
      "[660]\ttraining's rmse: 9.36176\tvalid_1's rmse: 56.7414\n",
      "[690]\ttraining's rmse: 8.78976\tvalid_1's rmse: 56.7053\n",
      "[720]\ttraining's rmse: 8.26361\tvalid_1's rmse: 56.6626\n",
      "[750]\ttraining's rmse: 7.77374\tvalid_1's rmse: 56.6235\n",
      "[780]\ttraining's rmse: 7.31691\tvalid_1's rmse: 56.6023\n",
      "[810]\ttraining's rmse: 6.88238\tvalid_1's rmse: 56.5463\n",
      "[840]\ttraining's rmse: 6.48847\tvalid_1's rmse: 56.5361\n",
      "[870]\ttraining's rmse: 6.12775\tvalid_1's rmse: 56.5224\n",
      "[900]\ttraining's rmse: 5.77982\tvalid_1's rmse: 56.4988\n",
      "[930]\ttraining's rmse: 5.4657\tvalid_1's rmse: 56.4753\n",
      "[960]\ttraining's rmse: 5.16031\tvalid_1's rmse: 56.4596\n",
      "[990]\ttraining's rmse: 4.87936\tvalid_1's rmse: 56.4566\n",
      "[1020]\ttraining's rmse: 4.61659\tvalid_1's rmse: 56.4414\n",
      "[1050]\ttraining's rmse: 4.36544\tvalid_1's rmse: 56.4178\n",
      "[1080]\ttraining's rmse: 4.1318\tvalid_1's rmse: 56.4016\n",
      "[1110]\ttraining's rmse: 3.90354\tvalid_1's rmse: 56.3777\n",
      "[1140]\ttraining's rmse: 3.69856\tvalid_1's rmse: 56.3691\n",
      "[1170]\ttraining's rmse: 3.5063\tvalid_1's rmse: 56.3505\n",
      "[1200]\ttraining's rmse: 3.32462\tvalid_1's rmse: 56.34\n",
      "[1230]\ttraining's rmse: 3.15481\tvalid_1's rmse: 56.3358\n",
      "[1260]\ttraining's rmse: 2.99104\tvalid_1's rmse: 56.3214\n",
      "[1290]\ttraining's rmse: 2.84067\tvalid_1's rmse: 56.318\n",
      "[1320]\ttraining's rmse: 2.69842\tvalid_1's rmse: 56.3066\n",
      "[1350]\ttraining's rmse: 2.55565\tvalid_1's rmse: 56.2998\n",
      "[1380]\ttraining's rmse: 2.42541\tvalid_1's rmse: 56.2974\n",
      "[1410]\ttraining's rmse: 2.30471\tvalid_1's rmse: 56.2974\n",
      "[1440]\ttraining's rmse: 2.19048\tvalid_1's rmse: 56.2886\n",
      "[1470]\ttraining's rmse: 2.08037\tvalid_1's rmse: 56.2827\n",
      "[1500]\ttraining's rmse: 1.97765\tvalid_1's rmse: 56.2747\n",
      "[1530]\ttraining's rmse: 1.87866\tvalid_1's rmse: 56.2687\n",
      "[1560]\ttraining's rmse: 1.78687\tvalid_1's rmse: 56.2644\n",
      "[1590]\ttraining's rmse: 1.69698\tvalid_1's rmse: 56.2581\n",
      "[1620]\ttraining's rmse: 1.61432\tvalid_1's rmse: 56.2542\n",
      "[1650]\ttraining's rmse: 1.53573\tvalid_1's rmse: 56.2499\n",
      "[1680]\ttraining's rmse: 1.46185\tvalid_1's rmse: 56.245\n",
      "[1710]\ttraining's rmse: 1.39155\tvalid_1's rmse: 56.2434\n",
      "[1740]\ttraining's rmse: 1.32323\tvalid_1's rmse: 56.2393\n",
      "[1770]\ttraining's rmse: 1.2583\tvalid_1's rmse: 56.2392\n",
      "[1800]\ttraining's rmse: 1.19652\tvalid_1's rmse: 56.2364\n",
      "[1830]\ttraining's rmse: 1.13923\tvalid_1's rmse: 56.2325\n",
      "[1860]\ttraining's rmse: 1.08512\tvalid_1's rmse: 56.2322\n",
      "[1890]\ttraining's rmse: 1.03441\tvalid_1's rmse: 56.2286\n",
      "[1920]\ttraining's rmse: 0.984813\tvalid_1's rmse: 56.2268\n",
      "[1950]\ttraining's rmse: 0.937978\tvalid_1's rmse: 56.224\n",
      "[1980]\ttraining's rmse: 0.894165\tvalid_1's rmse: 56.2217\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's rmse: 0.866128\tvalid_1's rmse: 56.2206\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002332 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 20018\n",
      "[LightGBM] [Info] Number of data points in the train set: 9219, number of used features: 79\n",
      "[LightGBM] [Info] Start training from score 375.571784\n",
      "Training until validation scores don't improve for 125 rounds\n",
      "[30]\ttraining's rmse: 162.481\tvalid_1's rmse: 171.621\n",
      "[60]\ttraining's rmse: 101.991\tvalid_1's rmse: 117.244\n",
      "[90]\ttraining's rmse: 69.0717\tvalid_1's rmse: 89.9955\n",
      "[120]\ttraining's rmse: 50.9201\tvalid_1's rmse: 76.4858\n",
      "[150]\ttraining's rmse: 40.6451\tvalid_1's rmse: 69.9033\n",
      "[180]\ttraining's rmse: 34.4059\tvalid_1's rmse: 66.4963\n",
      "[210]\ttraining's rmse: 30.0657\tvalid_1's rmse: 64.5972\n",
      "[240]\ttraining's rmse: 26.764\tvalid_1's rmse: 63.4072\n",
      "[270]\ttraining's rmse: 24.1195\tvalid_1's rmse: 62.505\n",
      "[300]\ttraining's rmse: 21.9528\tvalid_1's rmse: 61.907\n",
      "[330]\ttraining's rmse: 20.0781\tvalid_1's rmse: 61.4506\n",
      "[360]\ttraining's rmse: 18.4925\tvalid_1's rmse: 61.0841\n",
      "[390]\ttraining's rmse: 17.0962\tvalid_1's rmse: 60.8903\n",
      "[420]\ttraining's rmse: 15.8103\tvalid_1's rmse: 60.6816\n",
      "[450]\ttraining's rmse: 14.6603\tvalid_1's rmse: 60.5376\n",
      "[480]\ttraining's rmse: 13.619\tvalid_1's rmse: 60.3916\n",
      "[510]\ttraining's rmse: 12.6764\tvalid_1's rmse: 60.2809\n",
      "[540]\ttraining's rmse: 11.8145\tvalid_1's rmse: 60.1768\n",
      "[570]\ttraining's rmse: 11.0364\tvalid_1's rmse: 60.1022\n",
      "[600]\ttraining's rmse: 10.3315\tvalid_1's rmse: 60.0379\n",
      "[630]\ttraining's rmse: 9.67183\tvalid_1's rmse: 59.9681\n",
      "[660]\ttraining's rmse: 9.07198\tvalid_1's rmse: 59.91\n",
      "[690]\ttraining's rmse: 8.52048\tvalid_1's rmse: 59.8588\n",
      "[720]\ttraining's rmse: 7.99664\tvalid_1's rmse: 59.8281\n",
      "[750]\ttraining's rmse: 7.5041\tvalid_1's rmse: 59.7818\n",
      "[780]\ttraining's rmse: 7.06303\tvalid_1's rmse: 59.7673\n",
      "[810]\ttraining's rmse: 6.65335\tvalid_1's rmse: 59.7379\n",
      "[840]\ttraining's rmse: 6.27035\tvalid_1's rmse: 59.7045\n",
      "[870]\ttraining's rmse: 5.90681\tvalid_1's rmse: 59.6723\n",
      "[900]\ttraining's rmse: 5.56605\tvalid_1's rmse: 59.6576\n",
      "[930]\ttraining's rmse: 5.25695\tvalid_1's rmse: 59.6465\n",
      "[960]\ttraining's rmse: 4.95963\tvalid_1's rmse: 59.633\n",
      "[990]\ttraining's rmse: 4.68148\tvalid_1's rmse: 59.6084\n",
      "[1020]\ttraining's rmse: 4.4255\tvalid_1's rmse: 59.5956\n",
      "[1050]\ttraining's rmse: 4.18235\tvalid_1's rmse: 59.5876\n",
      "[1080]\ttraining's rmse: 3.95867\tvalid_1's rmse: 59.5835\n",
      "[1110]\ttraining's rmse: 3.74159\tvalid_1's rmse: 59.5735\n",
      "[1140]\ttraining's rmse: 3.54276\tvalid_1's rmse: 59.5734\n",
      "[1170]\ttraining's rmse: 3.35868\tvalid_1's rmse: 59.5595\n",
      "[1200]\ttraining's rmse: 3.18223\tvalid_1's rmse: 59.5494\n",
      "[1230]\ttraining's rmse: 3.01396\tvalid_1's rmse: 59.5405\n",
      "[1260]\ttraining's rmse: 2.85789\tvalid_1's rmse: 59.534\n",
      "[1290]\ttraining's rmse: 2.71213\tvalid_1's rmse: 59.5316\n",
      "[1320]\ttraining's rmse: 2.57212\tvalid_1's rmse: 59.525\n",
      "[1350]\ttraining's rmse: 2.43857\tvalid_1's rmse: 59.5215\n",
      "[1380]\ttraining's rmse: 2.30926\tvalid_1's rmse: 59.516\n",
      "[1410]\ttraining's rmse: 2.19133\tvalid_1's rmse: 59.512\n",
      "[1440]\ttraining's rmse: 2.08177\tvalid_1's rmse: 59.5043\n",
      "[1470]\ttraining's rmse: 1.97331\tvalid_1's rmse: 59.499\n",
      "[1500]\ttraining's rmse: 1.87296\tvalid_1's rmse: 59.4948\n",
      "[1530]\ttraining's rmse: 1.77943\tvalid_1's rmse: 59.492\n",
      "[1560]\ttraining's rmse: 1.69317\tvalid_1's rmse: 59.488\n",
      "[1590]\ttraining's rmse: 1.60933\tvalid_1's rmse: 59.4849\n",
      "[1620]\ttraining's rmse: 1.52843\tvalid_1's rmse: 59.4806\n",
      "[1650]\ttraining's rmse: 1.45428\tvalid_1's rmse: 59.478\n",
      "[1680]\ttraining's rmse: 1.38387\tvalid_1's rmse: 59.4746\n",
      "[1710]\ttraining's rmse: 1.3152\tvalid_1's rmse: 59.4731\n",
      "[1740]\ttraining's rmse: 1.2517\tvalid_1's rmse: 59.4707\n",
      "[1770]\ttraining's rmse: 1.19051\tvalid_1's rmse: 59.4682\n",
      "[1800]\ttraining's rmse: 1.13164\tvalid_1's rmse: 59.4664\n",
      "[1830]\ttraining's rmse: 1.07703\tvalid_1's rmse: 59.4641\n",
      "[1860]\ttraining's rmse: 1.02589\tvalid_1's rmse: 59.4626\n",
      "[1890]\ttraining's rmse: 0.977839\tvalid_1's rmse: 59.4603\n",
      "[1920]\ttraining's rmse: 0.931471\tvalid_1's rmse: 59.4605\n",
      "[1950]\ttraining's rmse: 0.887426\tvalid_1's rmse: 59.4595\n",
      "[1980]\ttraining's rmse: 0.844838\tvalid_1's rmse: 59.4576\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's rmse: 0.817566\tvalid_1's rmse: 59.4558\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003669 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 20018\n",
      "[LightGBM] [Info] Number of data points in the train set: 9219, number of used features: 79\n",
      "[LightGBM] [Info] Start training from score 372.645781\n",
      "Training until validation scores don't improve for 125 rounds\n",
      "[30]\ttraining's rmse: 163.447\tvalid_1's rmse: 169.54\n",
      "[60]\ttraining's rmse: 102.574\tvalid_1's rmse: 116.301\n",
      "[90]\ttraining's rmse: 69.4779\tvalid_1's rmse: 89.5388\n",
      "[120]\ttraining's rmse: 51.2169\tvalid_1's rmse: 76.4049\n",
      "[150]\ttraining's rmse: 40.8771\tvalid_1's rmse: 69.5899\n",
      "[180]\ttraining's rmse: 34.5355\tvalid_1's rmse: 66.1759\n",
      "[210]\ttraining's rmse: 30.1373\tvalid_1's rmse: 64.1994\n",
      "[240]\ttraining's rmse: 26.8831\tvalid_1's rmse: 62.9162\n",
      "[270]\ttraining's rmse: 24.2323\tvalid_1's rmse: 62.1278\n",
      "[300]\ttraining's rmse: 22.0901\tvalid_1's rmse: 61.5816\n",
      "[330]\ttraining's rmse: 20.2267\tvalid_1's rmse: 61.1105\n",
      "[360]\ttraining's rmse: 18.6439\tvalid_1's rmse: 60.8327\n",
      "[390]\ttraining's rmse: 17.2126\tvalid_1's rmse: 60.5596\n",
      "[420]\ttraining's rmse: 15.961\tvalid_1's rmse: 60.3786\n",
      "[450]\ttraining's rmse: 14.8193\tvalid_1's rmse: 60.227\n",
      "[480]\ttraining's rmse: 13.7673\tvalid_1's rmse: 60.1252\n",
      "[510]\ttraining's rmse: 12.8308\tvalid_1's rmse: 60.0492\n",
      "[540]\ttraining's rmse: 11.997\tvalid_1's rmse: 59.9441\n",
      "[570]\ttraining's rmse: 11.2194\tvalid_1's rmse: 59.8501\n",
      "[600]\ttraining's rmse: 10.5029\tvalid_1's rmse: 59.799\n",
      "[630]\ttraining's rmse: 9.85633\tvalid_1's rmse: 59.7416\n",
      "[660]\ttraining's rmse: 9.24412\tvalid_1's rmse: 59.6808\n",
      "[690]\ttraining's rmse: 8.68556\tvalid_1's rmse: 59.6279\n",
      "[720]\ttraining's rmse: 8.15186\tvalid_1's rmse: 59.5797\n",
      "[750]\ttraining's rmse: 7.66189\tvalid_1's rmse: 59.5261\n",
      "[780]\ttraining's rmse: 7.21555\tvalid_1's rmse: 59.4999\n",
      "[810]\ttraining's rmse: 6.79334\tvalid_1's rmse: 59.4612\n",
      "[840]\ttraining's rmse: 6.40739\tvalid_1's rmse: 59.4262\n",
      "[870]\ttraining's rmse: 6.04982\tvalid_1's rmse: 59.3916\n",
      "[900]\ttraining's rmse: 5.71512\tvalid_1's rmse: 59.3801\n",
      "[930]\ttraining's rmse: 5.39373\tvalid_1's rmse: 59.3372\n",
      "[960]\ttraining's rmse: 5.09599\tvalid_1's rmse: 59.3197\n",
      "[990]\ttraining's rmse: 4.81767\tvalid_1's rmse: 59.3068\n",
      "[1020]\ttraining's rmse: 4.55519\tvalid_1's rmse: 59.2867\n",
      "[1050]\ttraining's rmse: 4.31327\tvalid_1's rmse: 59.2702\n",
      "[1080]\ttraining's rmse: 4.07369\tvalid_1's rmse: 59.2543\n",
      "[1110]\ttraining's rmse: 3.86037\tvalid_1's rmse: 59.2338\n",
      "[1140]\ttraining's rmse: 3.65763\tvalid_1's rmse: 59.2197\n",
      "[1170]\ttraining's rmse: 3.47217\tvalid_1's rmse: 59.2124\n",
      "[1200]\ttraining's rmse: 3.28969\tvalid_1's rmse: 59.2065\n",
      "[1230]\ttraining's rmse: 3.12183\tvalid_1's rmse: 59.2002\n",
      "[1260]\ttraining's rmse: 2.96335\tvalid_1's rmse: 59.1929\n",
      "[1290]\ttraining's rmse: 2.8109\tvalid_1's rmse: 59.1868\n",
      "[1320]\ttraining's rmse: 2.66686\tvalid_1's rmse: 59.1854\n",
      "[1350]\ttraining's rmse: 2.53113\tvalid_1's rmse: 59.181\n",
      "[1380]\ttraining's rmse: 2.40442\tvalid_1's rmse: 59.1777\n",
      "[1410]\ttraining's rmse: 2.2835\tvalid_1's rmse: 59.1738\n",
      "[1440]\ttraining's rmse: 2.16669\tvalid_1's rmse: 59.1687\n",
      "[1470]\ttraining's rmse: 2.05795\tvalid_1's rmse: 59.1703\n",
      "[1500]\ttraining's rmse: 1.9567\tvalid_1's rmse: 59.1619\n",
      "[1530]\ttraining's rmse: 1.85961\tvalid_1's rmse: 59.1545\n",
      "[1560]\ttraining's rmse: 1.76778\tvalid_1's rmse: 59.1529\n",
      "[1590]\ttraining's rmse: 1.68028\tvalid_1's rmse: 59.1508\n",
      "[1620]\ttraining's rmse: 1.59947\tvalid_1's rmse: 59.1488\n",
      "[1650]\ttraining's rmse: 1.52078\tvalid_1's rmse: 59.1447\n",
      "[1680]\ttraining's rmse: 1.44902\tvalid_1's rmse: 59.1391\n",
      "[1710]\ttraining's rmse: 1.37712\tvalid_1's rmse: 59.1383\n",
      "[1740]\ttraining's rmse: 1.30932\tvalid_1's rmse: 59.1363\n",
      "[1770]\ttraining's rmse: 1.24624\tvalid_1's rmse: 59.134\n",
      "[1800]\ttraining's rmse: 1.18734\tvalid_1's rmse: 59.131\n",
      "[1830]\ttraining's rmse: 1.13023\tvalid_1's rmse: 59.1286\n",
      "[1860]\ttraining's rmse: 1.07623\tvalid_1's rmse: 59.1273\n",
      "[1890]\ttraining's rmse: 1.02493\tvalid_1's rmse: 59.1262\n",
      "[1920]\ttraining's rmse: 0.975361\tvalid_1's rmse: 59.1251\n",
      "[1950]\ttraining's rmse: 0.928931\tvalid_1's rmse: 59.123\n",
      "[1980]\ttraining's rmse: 0.885252\tvalid_1's rmse: 59.1216\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's rmse: 0.857077\tvalid_1's rmse: 59.1222\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003206 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 20018\n",
      "[LightGBM] [Info] Number of data points in the train set: 9219, number of used features: 79\n",
      "[LightGBM] [Info] Start training from score 361.501097\n",
      "Training until validation scores don't improve for 125 rounds\n",
      "[30]\ttraining's rmse: 159.324\tvalid_1's rmse: 168.619\n",
      "[60]\ttraining's rmse: 99.5036\tvalid_1's rmse: 113.285\n",
      "[90]\ttraining's rmse: 66.9022\tvalid_1's rmse: 86.2814\n",
      "[120]\ttraining's rmse: 49.4381\tvalid_1's rmse: 73.7355\n",
      "[150]\ttraining's rmse: 39.5464\tvalid_1's rmse: 67.7495\n",
      "[180]\ttraining's rmse: 33.526\tvalid_1's rmse: 64.6432\n",
      "[210]\ttraining's rmse: 29.3598\tvalid_1's rmse: 62.9105\n",
      "[240]\ttraining's rmse: 26.1381\tvalid_1's rmse: 61.7459\n",
      "[270]\ttraining's rmse: 23.6077\tvalid_1's rmse: 60.956\n",
      "[300]\ttraining's rmse: 21.4948\tvalid_1's rmse: 60.4693\n",
      "[330]\ttraining's rmse: 19.6896\tvalid_1's rmse: 60.0714\n",
      "[360]\ttraining's rmse: 18.1199\tvalid_1's rmse: 59.7676\n",
      "[390]\ttraining's rmse: 16.7313\tvalid_1's rmse: 59.5828\n",
      "[420]\ttraining's rmse: 15.5073\tvalid_1's rmse: 59.3766\n",
      "[450]\ttraining's rmse: 14.3876\tvalid_1's rmse: 59.2151\n",
      "[480]\ttraining's rmse: 13.3855\tvalid_1's rmse: 59.0503\n",
      "[510]\ttraining's rmse: 12.4889\tvalid_1's rmse: 58.9173\n",
      "[540]\ttraining's rmse: 11.6647\tvalid_1's rmse: 58.8286\n",
      "[570]\ttraining's rmse: 10.9152\tvalid_1's rmse: 58.7475\n",
      "[600]\ttraining's rmse: 10.2169\tvalid_1's rmse: 58.6505\n",
      "[630]\ttraining's rmse: 9.58154\tvalid_1's rmse: 58.5915\n",
      "[660]\ttraining's rmse: 8.9876\tvalid_1's rmse: 58.5324\n",
      "[690]\ttraining's rmse: 8.44941\tvalid_1's rmse: 58.5218\n",
      "[720]\ttraining's rmse: 7.95591\tvalid_1's rmse: 58.4667\n",
      "[750]\ttraining's rmse: 7.50093\tvalid_1's rmse: 58.4128\n",
      "[780]\ttraining's rmse: 7.07319\tvalid_1's rmse: 58.3853\n",
      "[810]\ttraining's rmse: 6.66763\tvalid_1's rmse: 58.3677\n",
      "[840]\ttraining's rmse: 6.29338\tvalid_1's rmse: 58.3335\n",
      "[870]\ttraining's rmse: 5.947\tvalid_1's rmse: 58.3153\n",
      "[900]\ttraining's rmse: 5.61784\tvalid_1's rmse: 58.2943\n",
      "[930]\ttraining's rmse: 5.30723\tvalid_1's rmse: 58.272\n",
      "[960]\ttraining's rmse: 5.02209\tvalid_1's rmse: 58.2439\n",
      "[990]\ttraining's rmse: 4.75417\tvalid_1's rmse: 58.2305\n",
      "[1020]\ttraining's rmse: 4.49949\tvalid_1's rmse: 58.2057\n",
      "[1050]\ttraining's rmse: 4.26705\tvalid_1's rmse: 58.1974\n",
      "[1080]\ttraining's rmse: 4.03738\tvalid_1's rmse: 58.1796\n",
      "[1110]\ttraining's rmse: 3.8235\tvalid_1's rmse: 58.1583\n",
      "[1140]\ttraining's rmse: 3.62069\tvalid_1's rmse: 58.1446\n",
      "[1170]\ttraining's rmse: 3.4321\tvalid_1's rmse: 58.1287\n",
      "[1200]\ttraining's rmse: 3.25597\tvalid_1's rmse: 58.1098\n",
      "[1230]\ttraining's rmse: 3.09235\tvalid_1's rmse: 58.1012\n",
      "[1260]\ttraining's rmse: 2.93539\tvalid_1's rmse: 58.0914\n",
      "[1290]\ttraining's rmse: 2.78657\tvalid_1's rmse: 58.0806\n",
      "[1320]\ttraining's rmse: 2.64616\tvalid_1's rmse: 58.0779\n",
      "[1350]\ttraining's rmse: 2.51482\tvalid_1's rmse: 58.0672\n",
      "[1380]\ttraining's rmse: 2.39073\tvalid_1's rmse: 58.0618\n",
      "[1410]\ttraining's rmse: 2.2723\tvalid_1's rmse: 58.0575\n",
      "[1440]\ttraining's rmse: 2.16064\tvalid_1's rmse: 58.056\n",
      "[1470]\ttraining's rmse: 2.05043\tvalid_1's rmse: 58.0509\n",
      "[1500]\ttraining's rmse: 1.95022\tvalid_1's rmse: 58.0454\n",
      "[1530]\ttraining's rmse: 1.85455\tvalid_1's rmse: 58.04\n",
      "[1560]\ttraining's rmse: 1.76271\tvalid_1's rmse: 58.0352\n",
      "[1590]\ttraining's rmse: 1.67883\tvalid_1's rmse: 58.0344\n",
      "[1620]\ttraining's rmse: 1.59822\tvalid_1's rmse: 58.0304\n",
      "[1650]\ttraining's rmse: 1.52067\tvalid_1's rmse: 58.0238\n",
      "[1680]\ttraining's rmse: 1.44894\tvalid_1's rmse: 58.0196\n",
      "[1710]\ttraining's rmse: 1.37897\tvalid_1's rmse: 58.0152\n",
      "[1740]\ttraining's rmse: 1.31194\tvalid_1's rmse: 58.0106\n",
      "[1770]\ttraining's rmse: 1.2504\tvalid_1's rmse: 58.0061\n",
      "[1800]\ttraining's rmse: 1.19092\tvalid_1's rmse: 58.0053\n",
      "[1830]\ttraining's rmse: 1.13475\tvalid_1's rmse: 58.0023\n",
      "[1860]\ttraining's rmse: 1.08197\tvalid_1's rmse: 57.9986\n",
      "[1890]\ttraining's rmse: 1.03079\tvalid_1's rmse: 57.9954\n",
      "[1920]\ttraining's rmse: 0.984401\tvalid_1's rmse: 57.9939\n",
      "[1950]\ttraining's rmse: 0.939215\tvalid_1's rmse: 57.9937\n",
      "[1980]\ttraining's rmse: 0.896166\tvalid_1's rmse: 57.9912\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's rmse: 0.867929\tvalid_1's rmse: 57.9893\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002570 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 20018\n",
      "[LightGBM] [Info] Number of data points in the train set: 9219, number of used features: 79\n",
      "[LightGBM] [Info] Start training from score 360.761837\n",
      "Training until validation scores don't improve for 125 rounds\n",
      "[30]\ttraining's rmse: 160.265\tvalid_1's rmse: 168.476\n",
      "[60]\ttraining's rmse: 100.456\tvalid_1's rmse: 113.995\n",
      "[90]\ttraining's rmse: 67.7463\tvalid_1's rmse: 87.2524\n",
      "[120]\ttraining's rmse: 50.0436\tvalid_1's rmse: 74.4338\n",
      "[150]\ttraining's rmse: 40.0945\tvalid_1's rmse: 68.2167\n",
      "[180]\ttraining's rmse: 34.0083\tvalid_1's rmse: 65.0964\n",
      "[210]\ttraining's rmse: 29.8032\tvalid_1's rmse: 63.3065\n",
      "[240]\ttraining's rmse: 26.6643\tvalid_1's rmse: 62.1068\n",
      "[270]\ttraining's rmse: 24.0739\tvalid_1's rmse: 61.0542\n",
      "[300]\ttraining's rmse: 21.9521\tvalid_1's rmse: 60.464\n",
      "[330]\ttraining's rmse: 20.1187\tvalid_1's rmse: 60.0554\n",
      "[360]\ttraining's rmse: 18.5218\tvalid_1's rmse: 59.7974\n",
      "[390]\ttraining's rmse: 17.1319\tvalid_1's rmse: 59.5864\n",
      "[420]\ttraining's rmse: 15.865\tvalid_1's rmse: 59.362\n",
      "[450]\ttraining's rmse: 14.7428\tvalid_1's rmse: 59.1899\n",
      "[480]\ttraining's rmse: 13.6772\tvalid_1's rmse: 59.0922\n",
      "[510]\ttraining's rmse: 12.745\tvalid_1's rmse: 59.0336\n",
      "[540]\ttraining's rmse: 11.9107\tvalid_1's rmse: 58.9222\n",
      "[570]\ttraining's rmse: 11.1412\tvalid_1's rmse: 58.844\n",
      "[600]\ttraining's rmse: 10.4453\tvalid_1's rmse: 58.774\n",
      "[630]\ttraining's rmse: 9.78726\tvalid_1's rmse: 58.6751\n",
      "[660]\ttraining's rmse: 9.17037\tvalid_1's rmse: 58.6657\n",
      "[690]\ttraining's rmse: 8.6135\tvalid_1's rmse: 58.6227\n",
      "[720]\ttraining's rmse: 8.10322\tvalid_1's rmse: 58.5731\n",
      "[750]\ttraining's rmse: 7.62128\tvalid_1's rmse: 58.5447\n",
      "[780]\ttraining's rmse: 7.1964\tvalid_1's rmse: 58.4985\n",
      "[810]\ttraining's rmse: 6.78095\tvalid_1's rmse: 58.444\n",
      "[840]\ttraining's rmse: 6.38879\tvalid_1's rmse: 58.4293\n",
      "[870]\ttraining's rmse: 6.02273\tvalid_1's rmse: 58.4112\n",
      "[900]\ttraining's rmse: 5.68457\tvalid_1's rmse: 58.3839\n",
      "[930]\ttraining's rmse: 5.36859\tvalid_1's rmse: 58.3763\n",
      "[960]\ttraining's rmse: 5.07254\tvalid_1's rmse: 58.3504\n",
      "[990]\ttraining's rmse: 4.79968\tvalid_1's rmse: 58.3344\n",
      "[1020]\ttraining's rmse: 4.53391\tvalid_1's rmse: 58.3159\n",
      "[1050]\ttraining's rmse: 4.28953\tvalid_1's rmse: 58.2883\n",
      "[1080]\ttraining's rmse: 4.05795\tvalid_1's rmse: 58.2725\n",
      "[1110]\ttraining's rmse: 3.84015\tvalid_1's rmse: 58.2551\n",
      "[1140]\ttraining's rmse: 3.63243\tvalid_1's rmse: 58.2442\n",
      "[1170]\ttraining's rmse: 3.44301\tvalid_1's rmse: 58.2318\n",
      "[1200]\ttraining's rmse: 3.26452\tvalid_1's rmse: 58.2266\n",
      "[1230]\ttraining's rmse: 3.09619\tvalid_1's rmse: 58.2184\n",
      "[1260]\ttraining's rmse: 2.93349\tvalid_1's rmse: 58.2134\n",
      "[1290]\ttraining's rmse: 2.77945\tvalid_1's rmse: 58.2134\n",
      "[1320]\ttraining's rmse: 2.63564\tvalid_1's rmse: 58.2109\n",
      "[1350]\ttraining's rmse: 2.5009\tvalid_1's rmse: 58.2059\n",
      "[1380]\ttraining's rmse: 2.3748\tvalid_1's rmse: 58.2011\n",
      "[1410]\ttraining's rmse: 2.25518\tvalid_1's rmse: 58.1928\n",
      "[1440]\ttraining's rmse: 2.14185\tvalid_1's rmse: 58.1896\n",
      "[1470]\ttraining's rmse: 2.03607\tvalid_1's rmse: 58.1882\n",
      "[1500]\ttraining's rmse: 1.93358\tvalid_1's rmse: 58.183\n",
      "[1530]\ttraining's rmse: 1.83729\tvalid_1's rmse: 58.1756\n",
      "[1560]\ttraining's rmse: 1.74753\tvalid_1's rmse: 58.1674\n",
      "[1590]\ttraining's rmse: 1.66337\tvalid_1's rmse: 58.1633\n",
      "[1620]\ttraining's rmse: 1.58207\tvalid_1's rmse: 58.1607\n",
      "[1650]\ttraining's rmse: 1.50541\tvalid_1's rmse: 58.1599\n",
      "[1680]\ttraining's rmse: 1.43177\tvalid_1's rmse: 58.1572\n",
      "[1710]\ttraining's rmse: 1.36178\tvalid_1's rmse: 58.1539\n",
      "[1740]\ttraining's rmse: 1.29549\tvalid_1's rmse: 58.1503\n",
      "[1770]\ttraining's rmse: 1.23466\tvalid_1's rmse: 58.1447\n",
      "[1800]\ttraining's rmse: 1.17596\tvalid_1's rmse: 58.1401\n",
      "[1830]\ttraining's rmse: 1.12026\tvalid_1's rmse: 58.1378\n",
      "[1860]\ttraining's rmse: 1.06784\tvalid_1's rmse: 58.1366\n",
      "[1890]\ttraining's rmse: 1.01696\tvalid_1's rmse: 58.1345\n",
      "[1920]\ttraining's rmse: 0.969521\tvalid_1's rmse: 58.133\n",
      "[1950]\ttraining's rmse: 0.924423\tvalid_1's rmse: 58.1323\n",
      "[1980]\ttraining's rmse: 0.880879\tvalid_1's rmse: 58.1332\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's rmse: 0.85363\tvalid_1's rmse: 58.1319\n",
      "16\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003343 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 20018\n",
      "[LightGBM] [Info] Number of data points in the train set: 9219, number of used features: 79\n",
      "[LightGBM] [Info] Start training from score 363.655210\n",
      "Training until validation scores don't improve for 125 rounds\n",
      "[30]\ttraining's rmse: 152.137\tvalid_1's rmse: 157.432\n",
      "[60]\ttraining's rmse: 94.4201\tvalid_1's rmse: 104.274\n",
      "[90]\ttraining's rmse: 63.2444\tvalid_1's rmse: 78.4209\n",
      "[120]\ttraining's rmse: 46.4515\tvalid_1's rmse: 66.3775\n",
      "[150]\ttraining's rmse: 37.0862\tvalid_1's rmse: 60.6427\n",
      "[180]\ttraining's rmse: 31.4684\tvalid_1's rmse: 57.7623\n",
      "[210]\ttraining's rmse: 27.5461\tvalid_1's rmse: 56.0619\n",
      "[240]\ttraining's rmse: 24.4794\tvalid_1's rmse: 54.961\n",
      "[270]\ttraining's rmse: 22.0521\tvalid_1's rmse: 54.0589\n",
      "[300]\ttraining's rmse: 20.0395\tvalid_1's rmse: 53.5299\n",
      "[330]\ttraining's rmse: 18.3724\tvalid_1's rmse: 53.1268\n",
      "[360]\ttraining's rmse: 16.8922\tvalid_1's rmse: 52.8452\n",
      "[390]\ttraining's rmse: 15.6084\tvalid_1's rmse: 52.5984\n",
      "[420]\ttraining's rmse: 14.4566\tvalid_1's rmse: 52.4206\n",
      "[450]\ttraining's rmse: 13.4111\tvalid_1's rmse: 52.2833\n",
      "[480]\ttraining's rmse: 12.4862\tvalid_1's rmse: 52.1836\n",
      "[510]\ttraining's rmse: 11.657\tvalid_1's rmse: 52.1363\n",
      "[540]\ttraining's rmse: 10.8936\tvalid_1's rmse: 52.051\n",
      "[570]\ttraining's rmse: 10.1856\tvalid_1's rmse: 51.9918\n",
      "[600]\ttraining's rmse: 9.54189\tvalid_1's rmse: 51.9243\n",
      "[630]\ttraining's rmse: 8.95288\tvalid_1's rmse: 51.8903\n",
      "[660]\ttraining's rmse: 8.39933\tvalid_1's rmse: 51.825\n",
      "[690]\ttraining's rmse: 7.88883\tvalid_1's rmse: 51.7866\n",
      "[720]\ttraining's rmse: 7.42614\tvalid_1's rmse: 51.7466\n",
      "[750]\ttraining's rmse: 6.98755\tvalid_1's rmse: 51.6978\n",
      "[780]\ttraining's rmse: 6.57373\tvalid_1's rmse: 51.6647\n",
      "[810]\ttraining's rmse: 6.18356\tvalid_1's rmse: 51.6225\n",
      "[840]\ttraining's rmse: 5.82257\tvalid_1's rmse: 51.5921\n",
      "[870]\ttraining's rmse: 5.49421\tvalid_1's rmse: 51.5683\n",
      "[900]\ttraining's rmse: 5.18401\tvalid_1's rmse: 51.5409\n",
      "[930]\ttraining's rmse: 4.89363\tvalid_1's rmse: 51.5208\n",
      "[960]\ttraining's rmse: 4.6268\tvalid_1's rmse: 51.5073\n",
      "[990]\ttraining's rmse: 4.3801\tvalid_1's rmse: 51.501\n",
      "[1020]\ttraining's rmse: 4.1419\tvalid_1's rmse: 51.495\n",
      "[1050]\ttraining's rmse: 3.91892\tvalid_1's rmse: 51.4806\n",
      "[1080]\ttraining's rmse: 3.71132\tvalid_1's rmse: 51.4737\n",
      "[1110]\ttraining's rmse: 3.517\tvalid_1's rmse: 51.4698\n",
      "[1140]\ttraining's rmse: 3.33328\tvalid_1's rmse: 51.4647\n",
      "[1170]\ttraining's rmse: 3.15748\tvalid_1's rmse: 51.4599\n",
      "[1200]\ttraining's rmse: 2.99222\tvalid_1's rmse: 51.4615\n",
      "[1230]\ttraining's rmse: 2.83391\tvalid_1's rmse: 51.452\n",
      "[1260]\ttraining's rmse: 2.68307\tvalid_1's rmse: 51.4457\n",
      "[1290]\ttraining's rmse: 2.54709\tvalid_1's rmse: 51.4419\n",
      "[1320]\ttraining's rmse: 2.41787\tvalid_1's rmse: 51.4352\n",
      "[1350]\ttraining's rmse: 2.29488\tvalid_1's rmse: 51.4347\n",
      "[1380]\ttraining's rmse: 2.18019\tvalid_1's rmse: 51.4259\n",
      "[1410]\ttraining's rmse: 2.07062\tvalid_1's rmse: 51.423\n",
      "[1440]\ttraining's rmse: 1.96412\tvalid_1's rmse: 51.4193\n",
      "[1470]\ttraining's rmse: 1.86637\tvalid_1's rmse: 51.4202\n",
      "[1500]\ttraining's rmse: 1.77363\tvalid_1's rmse: 51.4168\n",
      "[1530]\ttraining's rmse: 1.68561\tvalid_1's rmse: 51.4146\n",
      "[1560]\ttraining's rmse: 1.60456\tvalid_1's rmse: 51.4128\n",
      "[1590]\ttraining's rmse: 1.52467\tvalid_1's rmse: 51.408\n",
      "[1620]\ttraining's rmse: 1.44999\tvalid_1's rmse: 51.4043\n",
      "[1650]\ttraining's rmse: 1.38014\tvalid_1's rmse: 51.4031\n",
      "[1680]\ttraining's rmse: 1.31302\tvalid_1's rmse: 51.4014\n",
      "[1710]\ttraining's rmse: 1.24988\tvalid_1's rmse: 51.4026\n",
      "[1740]\ttraining's rmse: 1.1901\tvalid_1's rmse: 51.3999\n",
      "[1770]\ttraining's rmse: 1.13266\tvalid_1's rmse: 51.3957\n",
      "[1800]\ttraining's rmse: 1.07937\tvalid_1's rmse: 51.397\n",
      "[1830]\ttraining's rmse: 1.02747\tvalid_1's rmse: 51.3985\n",
      "[1860]\ttraining's rmse: 0.977501\tvalid_1's rmse: 51.3975\n",
      "[1890]\ttraining's rmse: 0.930509\tvalid_1's rmse: 51.3957\n",
      "[1920]\ttraining's rmse: 0.886589\tvalid_1's rmse: 51.393\n",
      "[1950]\ttraining's rmse: 0.845755\tvalid_1's rmse: 51.3915\n",
      "[1980]\ttraining's rmse: 0.806503\tvalid_1's rmse: 51.3912\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's rmse: 0.780433\tvalid_1's rmse: 51.3911\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003556 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 20018\n",
      "[LightGBM] [Info] Number of data points in the train set: 9219, number of used features: 79\n",
      "[LightGBM] [Info] Start training from score 361.183391\n",
      "Training until validation scores don't improve for 125 rounds\n",
      "[30]\ttraining's rmse: 151.899\tvalid_1's rmse: 160.839\n",
      "[60]\ttraining's rmse: 95.2625\tvalid_1's rmse: 107.285\n",
      "[90]\ttraining's rmse: 64.8194\tvalid_1's rmse: 80.977\n",
      "[120]\ttraining's rmse: 48.0592\tvalid_1's rmse: 67.9971\n",
      "[150]\ttraining's rmse: 38.5825\tvalid_1's rmse: 61.6058\n",
      "[180]\ttraining's rmse: 32.7168\tvalid_1's rmse: 58.3998\n",
      "[210]\ttraining's rmse: 28.657\tvalid_1's rmse: 56.4902\n",
      "[240]\ttraining's rmse: 25.5092\tvalid_1's rmse: 55.2213\n",
      "[270]\ttraining's rmse: 22.9781\tvalid_1's rmse: 54.3042\n",
      "[300]\ttraining's rmse: 20.86\tvalid_1's rmse: 53.6948\n",
      "[330]\ttraining's rmse: 19.0794\tvalid_1's rmse: 53.2302\n",
      "[360]\ttraining's rmse: 17.5485\tvalid_1's rmse: 52.8969\n",
      "[390]\ttraining's rmse: 16.1861\tvalid_1's rmse: 52.6088\n",
      "[420]\ttraining's rmse: 14.9818\tvalid_1's rmse: 52.3976\n",
      "[450]\ttraining's rmse: 13.9275\tvalid_1's rmse: 52.2313\n",
      "[480]\ttraining's rmse: 12.9564\tvalid_1's rmse: 52.0852\n",
      "[510]\ttraining's rmse: 12.0505\tvalid_1's rmse: 51.9785\n",
      "[540]\ttraining's rmse: 11.2496\tvalid_1's rmse: 51.8408\n",
      "[570]\ttraining's rmse: 10.5169\tvalid_1's rmse: 51.7442\n",
      "[600]\ttraining's rmse: 9.83855\tvalid_1's rmse: 51.6691\n",
      "[630]\ttraining's rmse: 9.21641\tvalid_1's rmse: 51.6157\n",
      "[660]\ttraining's rmse: 8.63293\tvalid_1's rmse: 51.5672\n",
      "[690]\ttraining's rmse: 8.10304\tvalid_1's rmse: 51.5002\n",
      "[720]\ttraining's rmse: 7.61811\tvalid_1's rmse: 51.4605\n",
      "[750]\ttraining's rmse: 7.16026\tvalid_1's rmse: 51.4209\n",
      "[780]\ttraining's rmse: 6.74948\tvalid_1's rmse: 51.3741\n",
      "[810]\ttraining's rmse: 6.35485\tvalid_1's rmse: 51.3437\n",
      "[840]\ttraining's rmse: 5.98109\tvalid_1's rmse: 51.3085\n",
      "[870]\ttraining's rmse: 5.6397\tvalid_1's rmse: 51.2696\n",
      "[900]\ttraining's rmse: 5.32317\tvalid_1's rmse: 51.2406\n",
      "[930]\ttraining's rmse: 5.02356\tvalid_1's rmse: 51.2197\n",
      "[960]\ttraining's rmse: 4.74097\tvalid_1's rmse: 51.1917\n",
      "[990]\ttraining's rmse: 4.48158\tvalid_1's rmse: 51.1782\n",
      "[1020]\ttraining's rmse: 4.24068\tvalid_1's rmse: 51.1568\n",
      "[1050]\ttraining's rmse: 4.00514\tvalid_1's rmse: 51.1474\n",
      "[1080]\ttraining's rmse: 3.78893\tvalid_1's rmse: 51.1297\n",
      "[1110]\ttraining's rmse: 3.58193\tvalid_1's rmse: 51.1063\n",
      "[1140]\ttraining's rmse: 3.38765\tvalid_1's rmse: 51.0987\n",
      "[1170]\ttraining's rmse: 3.21206\tvalid_1's rmse: 51.0943\n",
      "[1200]\ttraining's rmse: 3.04247\tvalid_1's rmse: 51.0856\n",
      "[1230]\ttraining's rmse: 2.88545\tvalid_1's rmse: 51.0807\n",
      "[1260]\ttraining's rmse: 2.73309\tvalid_1's rmse: 51.0701\n",
      "[1290]\ttraining's rmse: 2.59083\tvalid_1's rmse: 51.0645\n",
      "[1320]\ttraining's rmse: 2.45607\tvalid_1's rmse: 51.0571\n",
      "[1350]\ttraining's rmse: 2.32864\tvalid_1's rmse: 51.0498\n",
      "[1380]\ttraining's rmse: 2.20805\tvalid_1's rmse: 51.0414\n",
      "[1410]\ttraining's rmse: 2.09655\tvalid_1's rmse: 51.0368\n",
      "[1440]\ttraining's rmse: 1.99036\tvalid_1's rmse: 51.031\n",
      "[1470]\ttraining's rmse: 1.89385\tvalid_1's rmse: 51.0273\n",
      "[1500]\ttraining's rmse: 1.79768\tvalid_1's rmse: 51.0229\n",
      "[1530]\ttraining's rmse: 1.7085\tvalid_1's rmse: 51.0186\n",
      "[1560]\ttraining's rmse: 1.62355\tvalid_1's rmse: 51.0138\n",
      "[1590]\ttraining's rmse: 1.54156\tvalid_1's rmse: 51.0118\n",
      "[1620]\ttraining's rmse: 1.46516\tvalid_1's rmse: 51.0072\n",
      "[1650]\ttraining's rmse: 1.39252\tvalid_1's rmse: 51.0035\n",
      "[1680]\ttraining's rmse: 1.32341\tvalid_1's rmse: 51.0012\n",
      "[1710]\ttraining's rmse: 1.25727\tvalid_1's rmse: 50.9981\n",
      "[1740]\ttraining's rmse: 1.1939\tvalid_1's rmse: 50.9936\n",
      "[1770]\ttraining's rmse: 1.13539\tvalid_1's rmse: 50.9905\n",
      "[1800]\ttraining's rmse: 1.08058\tvalid_1's rmse: 50.9889\n",
      "[1830]\ttraining's rmse: 1.02729\tvalid_1's rmse: 50.9882\n",
      "[1860]\ttraining's rmse: 0.976997\tvalid_1's rmse: 50.9861\n",
      "[1890]\ttraining's rmse: 0.929907\tvalid_1's rmse: 50.9832\n",
      "[1920]\ttraining's rmse: 0.884282\tvalid_1's rmse: 50.9802\n",
      "[1950]\ttraining's rmse: 0.840811\tvalid_1's rmse: 50.9794\n",
      "[1980]\ttraining's rmse: 0.799787\tvalid_1's rmse: 50.9767\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's rmse: 0.77369\tvalid_1's rmse: 50.9759\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003321 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 20018\n",
      "[LightGBM] [Info] Number of data points in the train set: 9219, number of used features: 79\n",
      "[LightGBM] [Info] Start training from score 370.159354\n",
      "Training until validation scores don't improve for 125 rounds\n",
      "[30]\ttraining's rmse: 159.676\tvalid_1's rmse: 158.906\n",
      "[60]\ttraining's rmse: 99.8757\tvalid_1's rmse: 106.25\n",
      "[90]\ttraining's rmse: 67.5097\tvalid_1's rmse: 79.9354\n",
      "[120]\ttraining's rmse: 49.97\tvalid_1's rmse: 67.1905\n",
      "[150]\ttraining's rmse: 40.0867\tvalid_1's rmse: 61.3226\n",
      "[180]\ttraining's rmse: 33.994\tvalid_1's rmse: 58.3446\n",
      "[210]\ttraining's rmse: 29.7628\tvalid_1's rmse: 56.5113\n",
      "[240]\ttraining's rmse: 26.4842\tvalid_1's rmse: 55.3289\n",
      "[270]\ttraining's rmse: 23.8741\tvalid_1's rmse: 54.5429\n",
      "[300]\ttraining's rmse: 21.7208\tvalid_1's rmse: 54.0143\n",
      "[330]\ttraining's rmse: 19.9227\tvalid_1's rmse: 53.6058\n",
      "[360]\ttraining's rmse: 18.333\tvalid_1's rmse: 53.3477\n",
      "[390]\ttraining's rmse: 16.9362\tvalid_1's rmse: 53.1509\n",
      "[420]\ttraining's rmse: 15.7009\tvalid_1's rmse: 52.9463\n",
      "[450]\ttraining's rmse: 14.5835\tvalid_1's rmse: 52.8226\n",
      "[480]\ttraining's rmse: 13.5827\tvalid_1's rmse: 52.6821\n",
      "[510]\ttraining's rmse: 12.6617\tvalid_1's rmse: 52.5926\n",
      "[540]\ttraining's rmse: 11.7888\tvalid_1's rmse: 52.5102\n",
      "[570]\ttraining's rmse: 11.0165\tvalid_1's rmse: 52.4316\n",
      "[600]\ttraining's rmse: 10.313\tvalid_1's rmse: 52.3585\n",
      "[630]\ttraining's rmse: 9.65441\tvalid_1's rmse: 52.282\n",
      "[660]\ttraining's rmse: 9.04748\tvalid_1's rmse: 52.2272\n",
      "[690]\ttraining's rmse: 8.47927\tvalid_1's rmse: 52.1757\n",
      "[720]\ttraining's rmse: 7.9676\tvalid_1's rmse: 52.1213\n",
      "[750]\ttraining's rmse: 7.49401\tvalid_1's rmse: 52.0914\n",
      "[780]\ttraining's rmse: 7.04341\tvalid_1's rmse: 52.0611\n",
      "[810]\ttraining's rmse: 6.62581\tvalid_1's rmse: 52.0344\n",
      "[840]\ttraining's rmse: 6.24332\tvalid_1's rmse: 52.0214\n",
      "[870]\ttraining's rmse: 5.87986\tvalid_1's rmse: 51.9743\n",
      "[900]\ttraining's rmse: 5.54203\tvalid_1's rmse: 51.9552\n",
      "[930]\ttraining's rmse: 5.23502\tvalid_1's rmse: 51.9385\n",
      "[960]\ttraining's rmse: 4.94352\tvalid_1's rmse: 51.9279\n",
      "[990]\ttraining's rmse: 4.66598\tvalid_1's rmse: 51.9131\n",
      "[1020]\ttraining's rmse: 4.41114\tvalid_1's rmse: 51.8949\n",
      "[1050]\ttraining's rmse: 4.17374\tvalid_1's rmse: 51.8811\n",
      "[1080]\ttraining's rmse: 3.94884\tvalid_1's rmse: 51.8707\n",
      "[1110]\ttraining's rmse: 3.74039\tvalid_1's rmse: 51.8601\n",
      "[1140]\ttraining's rmse: 3.54738\tvalid_1's rmse: 51.8485\n",
      "[1170]\ttraining's rmse: 3.35925\tvalid_1's rmse: 51.8442\n",
      "[1200]\ttraining's rmse: 3.18268\tvalid_1's rmse: 51.8313\n",
      "[1230]\ttraining's rmse: 3.0199\tvalid_1's rmse: 51.8282\n",
      "[1260]\ttraining's rmse: 2.86091\tvalid_1's rmse: 51.8304\n",
      "[1290]\ttraining's rmse: 2.71693\tvalid_1's rmse: 51.821\n",
      "[1320]\ttraining's rmse: 2.5786\tvalid_1's rmse: 51.8121\n",
      "[1350]\ttraining's rmse: 2.44579\tvalid_1's rmse: 51.8055\n",
      "[1380]\ttraining's rmse: 2.32041\tvalid_1's rmse: 51.7983\n",
      "[1410]\ttraining's rmse: 2.20092\tvalid_1's rmse: 51.7972\n",
      "[1440]\ttraining's rmse: 2.09167\tvalid_1's rmse: 51.7941\n",
      "[1470]\ttraining's rmse: 1.98564\tvalid_1's rmse: 51.7918\n",
      "[1500]\ttraining's rmse: 1.88702\tvalid_1's rmse: 51.7895\n",
      "[1530]\ttraining's rmse: 1.79183\tvalid_1's rmse: 51.7803\n",
      "[1560]\ttraining's rmse: 1.70336\tvalid_1's rmse: 51.7788\n",
      "[1590]\ttraining's rmse: 1.617\tvalid_1's rmse: 51.7763\n",
      "[1620]\ttraining's rmse: 1.53719\tvalid_1's rmse: 51.7728\n",
      "[1650]\ttraining's rmse: 1.46218\tvalid_1's rmse: 51.77\n",
      "[1680]\ttraining's rmse: 1.39144\tvalid_1's rmse: 51.769\n",
      "[1710]\ttraining's rmse: 1.32341\tvalid_1's rmse: 51.7663\n",
      "[1740]\ttraining's rmse: 1.25958\tvalid_1's rmse: 51.7643\n",
      "[1770]\ttraining's rmse: 1.20045\tvalid_1's rmse: 51.7624\n",
      "[1800]\ttraining's rmse: 1.1436\tvalid_1's rmse: 51.7597\n",
      "[1830]\ttraining's rmse: 1.08912\tvalid_1's rmse: 51.7584\n",
      "[1860]\ttraining's rmse: 1.03721\tvalid_1's rmse: 51.7556\n",
      "[1890]\ttraining's rmse: 0.987616\tvalid_1's rmse: 51.7551\n",
      "[1920]\ttraining's rmse: 0.940988\tvalid_1's rmse: 51.7543\n",
      "[1950]\ttraining's rmse: 0.896944\tvalid_1's rmse: 51.754\n",
      "[1980]\ttraining's rmse: 0.854252\tvalid_1's rmse: 51.7514\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's rmse: 0.827185\tvalid_1's rmse: 51.7506\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002190 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 20018\n",
      "[LightGBM] [Info] Number of data points in the train set: 9219, number of used features: 79\n",
      "[LightGBM] [Info] Start training from score 376.196971\n",
      "Training until validation scores don't improve for 125 rounds\n",
      "[30]\ttraining's rmse: 164.398\tvalid_1's rmse: 164.152\n",
      "[60]\ttraining's rmse: 103.357\tvalid_1's rmse: 111.734\n",
      "[90]\ttraining's rmse: 69.9666\tvalid_1's rmse: 85.3302\n",
      "[120]\ttraining's rmse: 51.9603\tvalid_1's rmse: 72.6091\n",
      "[150]\ttraining's rmse: 41.678\tvalid_1's rmse: 66.5978\n",
      "[180]\ttraining's rmse: 35.1738\tvalid_1's rmse: 62.9932\n",
      "[210]\ttraining's rmse: 30.658\tvalid_1's rmse: 60.8212\n",
      "[240]\ttraining's rmse: 27.3343\tvalid_1's rmse: 59.5133\n",
      "[270]\ttraining's rmse: 24.6447\tvalid_1's rmse: 58.4794\n",
      "[300]\ttraining's rmse: 22.35\tvalid_1's rmse: 57.9296\n",
      "[330]\ttraining's rmse: 20.4667\tvalid_1's rmse: 57.4799\n",
      "[360]\ttraining's rmse: 18.82\tvalid_1's rmse: 57.1323\n",
      "[390]\ttraining's rmse: 17.3638\tvalid_1's rmse: 56.8651\n",
      "[420]\ttraining's rmse: 16.1063\tvalid_1's rmse: 56.6869\n",
      "[450]\ttraining's rmse: 14.9567\tvalid_1's rmse: 56.5194\n",
      "[480]\ttraining's rmse: 13.8873\tvalid_1's rmse: 56.3666\n",
      "[510]\ttraining's rmse: 12.9348\tvalid_1's rmse: 56.2093\n",
      "[540]\ttraining's rmse: 12.0785\tvalid_1's rmse: 56.1216\n",
      "[570]\ttraining's rmse: 11.2831\tvalid_1's rmse: 56.0299\n",
      "[600]\ttraining's rmse: 10.5636\tvalid_1's rmse: 55.9672\n",
      "[630]\ttraining's rmse: 9.88899\tvalid_1's rmse: 55.9188\n",
      "[660]\ttraining's rmse: 9.26416\tvalid_1's rmse: 55.8588\n",
      "[690]\ttraining's rmse: 8.68599\tvalid_1's rmse: 55.7912\n",
      "[720]\ttraining's rmse: 8.15284\tvalid_1's rmse: 55.7298\n",
      "[750]\ttraining's rmse: 7.66099\tvalid_1's rmse: 55.6729\n",
      "[780]\ttraining's rmse: 7.2021\tvalid_1's rmse: 55.624\n",
      "[810]\ttraining's rmse: 6.78069\tvalid_1's rmse: 55.5842\n",
      "[840]\ttraining's rmse: 6.39256\tvalid_1's rmse: 55.557\n",
      "[870]\ttraining's rmse: 6.01881\tvalid_1's rmse: 55.5368\n",
      "[900]\ttraining's rmse: 5.67411\tvalid_1's rmse: 55.5181\n",
      "[930]\ttraining's rmse: 5.35477\tvalid_1's rmse: 55.5158\n",
      "[960]\ttraining's rmse: 5.05023\tvalid_1's rmse: 55.4873\n",
      "[990]\ttraining's rmse: 4.76694\tvalid_1's rmse: 55.4677\n",
      "[1020]\ttraining's rmse: 4.50813\tvalid_1's rmse: 55.4455\n",
      "[1050]\ttraining's rmse: 4.25866\tvalid_1's rmse: 55.4382\n",
      "[1080]\ttraining's rmse: 4.02902\tvalid_1's rmse: 55.4123\n",
      "[1110]\ttraining's rmse: 3.81097\tvalid_1's rmse: 55.3994\n",
      "[1140]\ttraining's rmse: 3.61113\tvalid_1's rmse: 55.3934\n",
      "[1170]\ttraining's rmse: 3.41625\tvalid_1's rmse: 55.3869\n",
      "[1200]\ttraining's rmse: 3.23593\tvalid_1's rmse: 55.3734\n",
      "[1230]\ttraining's rmse: 3.06541\tvalid_1's rmse: 55.3683\n",
      "[1260]\ttraining's rmse: 2.90393\tvalid_1's rmse: 55.3614\n",
      "[1290]\ttraining's rmse: 2.75357\tvalid_1's rmse: 55.3508\n",
      "[1320]\ttraining's rmse: 2.61264\tvalid_1's rmse: 55.3421\n",
      "[1350]\ttraining's rmse: 2.47677\tvalid_1's rmse: 55.338\n",
      "[1380]\ttraining's rmse: 2.35078\tvalid_1's rmse: 55.3299\n",
      "[1410]\ttraining's rmse: 2.23064\tvalid_1's rmse: 55.3224\n",
      "[1440]\ttraining's rmse: 2.11794\tvalid_1's rmse: 55.3205\n",
      "[1470]\ttraining's rmse: 2.01335\tvalid_1's rmse: 55.3143\n",
      "[1500]\ttraining's rmse: 1.9131\tvalid_1's rmse: 55.307\n",
      "[1530]\ttraining's rmse: 1.81935\tvalid_1's rmse: 55.3014\n",
      "[1560]\ttraining's rmse: 1.7304\tvalid_1's rmse: 55.2968\n",
      "[1590]\ttraining's rmse: 1.64522\tvalid_1's rmse: 55.2927\n",
      "[1620]\ttraining's rmse: 1.56531\tvalid_1's rmse: 55.2901\n",
      "[1650]\ttraining's rmse: 1.48919\tvalid_1's rmse: 55.2864\n",
      "[1680]\ttraining's rmse: 1.41463\tvalid_1's rmse: 55.2857\n",
      "[1710]\ttraining's rmse: 1.34605\tvalid_1's rmse: 55.2816\n",
      "[1740]\ttraining's rmse: 1.28112\tvalid_1's rmse: 55.2782\n",
      "[1770]\ttraining's rmse: 1.21976\tvalid_1's rmse: 55.2754\n",
      "[1800]\ttraining's rmse: 1.16183\tvalid_1's rmse: 55.2733\n",
      "[1830]\ttraining's rmse: 1.1063\tvalid_1's rmse: 55.2716\n",
      "[1860]\ttraining's rmse: 1.05353\tvalid_1's rmse: 55.2706\n",
      "[1890]\ttraining's rmse: 1.0035\tvalid_1's rmse: 55.2686\n",
      "[1920]\ttraining's rmse: 0.955283\tvalid_1's rmse: 55.2666\n",
      "[1950]\ttraining's rmse: 0.909537\tvalid_1's rmse: 55.2657\n",
      "[1980]\ttraining's rmse: 0.865985\tvalid_1's rmse: 55.2639\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's rmse: 0.838911\tvalid_1's rmse: 55.2635\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002165 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 20018\n",
      "[LightGBM] [Info] Number of data points in the train set: 9219, number of used features: 79\n",
      "[LightGBM] [Info] Start training from score 375.469807\n",
      "Training until validation scores don't improve for 125 rounds\n",
      "[30]\ttraining's rmse: 162.947\tvalid_1's rmse: 164.739\n",
      "[60]\ttraining's rmse: 102.061\tvalid_1's rmse: 111.764\n",
      "[90]\ttraining's rmse: 69.0655\tvalid_1's rmse: 85.4798\n",
      "[120]\ttraining's rmse: 51.0126\tvalid_1's rmse: 72.9175\n",
      "[150]\ttraining's rmse: 40.759\tvalid_1's rmse: 66.7222\n",
      "[180]\ttraining's rmse: 34.5538\tvalid_1's rmse: 63.5886\n",
      "[210]\ttraining's rmse: 30.3612\tvalid_1's rmse: 61.7139\n",
      "[240]\ttraining's rmse: 27.0805\tvalid_1's rmse: 60.3702\n",
      "[270]\ttraining's rmse: 24.4014\tvalid_1's rmse: 59.4597\n",
      "[300]\ttraining's rmse: 22.234\tvalid_1's rmse: 58.8744\n",
      "[330]\ttraining's rmse: 20.4111\tvalid_1's rmse: 58.4034\n",
      "[360]\ttraining's rmse: 18.7977\tvalid_1's rmse: 57.9924\n",
      "[390]\ttraining's rmse: 17.357\tvalid_1's rmse: 57.7172\n",
      "[420]\ttraining's rmse: 16.072\tvalid_1's rmse: 57.5118\n",
      "[450]\ttraining's rmse: 14.9119\tvalid_1's rmse: 57.3422\n",
      "[480]\ttraining's rmse: 13.8631\tvalid_1's rmse: 57.1722\n",
      "[510]\ttraining's rmse: 12.9054\tvalid_1's rmse: 57.0736\n",
      "[540]\ttraining's rmse: 12.0391\tvalid_1's rmse: 56.9346\n",
      "[570]\ttraining's rmse: 11.2487\tvalid_1's rmse: 56.8163\n",
      "[600]\ttraining's rmse: 10.5499\tvalid_1's rmse: 56.7633\n",
      "[630]\ttraining's rmse: 9.89019\tvalid_1's rmse: 56.7209\n",
      "[660]\ttraining's rmse: 9.27992\tvalid_1's rmse: 56.6412\n",
      "[690]\ttraining's rmse: 8.71485\tvalid_1's rmse: 56.5747\n",
      "[720]\ttraining's rmse: 8.19603\tvalid_1's rmse: 56.5394\n",
      "[750]\ttraining's rmse: 7.71646\tvalid_1's rmse: 56.5064\n",
      "[780]\ttraining's rmse: 7.26738\tvalid_1's rmse: 56.4791\n",
      "[810]\ttraining's rmse: 6.84082\tvalid_1's rmse: 56.4329\n",
      "[840]\ttraining's rmse: 6.4505\tvalid_1's rmse: 56.4165\n",
      "[870]\ttraining's rmse: 6.09247\tvalid_1's rmse: 56.3928\n",
      "[900]\ttraining's rmse: 5.74773\tvalid_1's rmse: 56.3726\n",
      "[930]\ttraining's rmse: 5.42824\tvalid_1's rmse: 56.3422\n",
      "[960]\ttraining's rmse: 5.13029\tvalid_1's rmse: 56.3325\n",
      "[990]\ttraining's rmse: 4.85518\tvalid_1's rmse: 56.3269\n",
      "[1020]\ttraining's rmse: 4.58873\tvalid_1's rmse: 56.3152\n",
      "[1050]\ttraining's rmse: 4.34699\tvalid_1's rmse: 56.2968\n",
      "[1080]\ttraining's rmse: 4.12051\tvalid_1's rmse: 56.2855\n",
      "[1110]\ttraining's rmse: 3.89882\tvalid_1's rmse: 56.2731\n",
      "[1140]\ttraining's rmse: 3.69413\tvalid_1's rmse: 56.2643\n",
      "[1170]\ttraining's rmse: 3.50239\tvalid_1's rmse: 56.2515\n",
      "[1200]\ttraining's rmse: 3.32298\tvalid_1's rmse: 56.2459\n",
      "[1230]\ttraining's rmse: 3.1528\tvalid_1's rmse: 56.2373\n",
      "[1260]\ttraining's rmse: 2.99094\tvalid_1's rmse: 56.2286\n",
      "[1290]\ttraining's rmse: 2.84323\tvalid_1's rmse: 56.2219\n",
      "[1320]\ttraining's rmse: 2.69558\tvalid_1's rmse: 56.2202\n",
      "[1350]\ttraining's rmse: 2.55877\tvalid_1's rmse: 56.2137\n",
      "[1380]\ttraining's rmse: 2.4294\tvalid_1's rmse: 56.2074\n",
      "[1410]\ttraining's rmse: 2.31116\tvalid_1's rmse: 56.2046\n",
      "[1440]\ttraining's rmse: 2.19489\tvalid_1's rmse: 56.2032\n",
      "[1470]\ttraining's rmse: 2.09016\tvalid_1's rmse: 56.2002\n",
      "[1500]\ttraining's rmse: 1.98755\tvalid_1's rmse: 56.1928\n",
      "[1530]\ttraining's rmse: 1.89116\tvalid_1's rmse: 56.1916\n",
      "[1560]\ttraining's rmse: 1.80002\tvalid_1's rmse: 56.1891\n",
      "[1590]\ttraining's rmse: 1.71311\tvalid_1's rmse: 56.1862\n",
      "[1620]\ttraining's rmse: 1.62955\tvalid_1's rmse: 56.1796\n",
      "[1650]\ttraining's rmse: 1.55147\tvalid_1's rmse: 56.177\n",
      "[1680]\ttraining's rmse: 1.47779\tvalid_1's rmse: 56.1756\n",
      "[1710]\ttraining's rmse: 1.40801\tvalid_1's rmse: 56.1764\n",
      "[1740]\ttraining's rmse: 1.33944\tvalid_1's rmse: 56.1754\n",
      "[1770]\ttraining's rmse: 1.27686\tvalid_1's rmse: 56.1752\n",
      "[1800]\ttraining's rmse: 1.21714\tvalid_1's rmse: 56.1716\n",
      "[1830]\ttraining's rmse: 1.15814\tvalid_1's rmse: 56.1723\n",
      "[1860]\ttraining's rmse: 1.1033\tvalid_1's rmse: 56.1687\n",
      "[1890]\ttraining's rmse: 1.05247\tvalid_1's rmse: 56.1678\n",
      "[1920]\ttraining's rmse: 1.0038\tvalid_1's rmse: 56.1672\n",
      "[1950]\ttraining's rmse: 0.957413\tvalid_1's rmse: 56.166\n",
      "[1980]\ttraining's rmse: 0.913766\tvalid_1's rmse: 56.1648\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's rmse: 0.885424\tvalid_1's rmse: 56.1653\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002273 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 20018\n",
      "[LightGBM] [Info] Number of data points in the train set: 9219, number of used features: 79\n",
      "[LightGBM] [Info] Start training from score 375.571784\n",
      "Training until validation scores don't improve for 125 rounds\n",
      "[30]\ttraining's rmse: 161.856\tvalid_1's rmse: 168.493\n",
      "[60]\ttraining's rmse: 101.254\tvalid_1's rmse: 113.123\n",
      "[90]\ttraining's rmse: 68.3791\tvalid_1's rmse: 85.4571\n",
      "[120]\ttraining's rmse: 50.556\tvalid_1's rmse: 72.1237\n",
      "[150]\ttraining's rmse: 40.4415\tvalid_1's rmse: 65.7854\n",
      "[180]\ttraining's rmse: 34.3519\tvalid_1's rmse: 62.5958\n",
      "[210]\ttraining's rmse: 30.1513\tvalid_1's rmse: 60.8911\n",
      "[240]\ttraining's rmse: 26.9282\tvalid_1's rmse: 59.7055\n",
      "[270]\ttraining's rmse: 24.2652\tvalid_1's rmse: 58.9674\n",
      "[300]\ttraining's rmse: 22.0449\tvalid_1's rmse: 58.4025\n",
      "[330]\ttraining's rmse: 20.1835\tvalid_1's rmse: 57.9647\n",
      "[360]\ttraining's rmse: 18.5452\tvalid_1's rmse: 57.73\n",
      "[390]\ttraining's rmse: 17.1294\tvalid_1's rmse: 57.5874\n",
      "[420]\ttraining's rmse: 15.8649\tvalid_1's rmse: 57.3969\n",
      "[450]\ttraining's rmse: 14.7246\tvalid_1's rmse: 57.2574\n",
      "[480]\ttraining's rmse: 13.6987\tvalid_1's rmse: 57.1468\n",
      "[510]\ttraining's rmse: 12.7495\tvalid_1's rmse: 57.0363\n",
      "[540]\ttraining's rmse: 11.896\tvalid_1's rmse: 56.992\n",
      "[570]\ttraining's rmse: 11.123\tvalid_1's rmse: 56.9418\n",
      "[600]\ttraining's rmse: 10.404\tvalid_1's rmse: 56.9027\n",
      "[630]\ttraining's rmse: 9.7298\tvalid_1's rmse: 56.8503\n",
      "[660]\ttraining's rmse: 9.11132\tvalid_1's rmse: 56.7995\n",
      "[690]\ttraining's rmse: 8.54338\tvalid_1's rmse: 56.7628\n",
      "[720]\ttraining's rmse: 8.02597\tvalid_1's rmse: 56.7172\n",
      "[750]\ttraining's rmse: 7.54504\tvalid_1's rmse: 56.6982\n",
      "[780]\ttraining's rmse: 7.09658\tvalid_1's rmse: 56.6749\n",
      "[810]\ttraining's rmse: 6.68172\tvalid_1's rmse: 56.6647\n",
      "[840]\ttraining's rmse: 6.28898\tvalid_1's rmse: 56.6325\n",
      "[870]\ttraining's rmse: 5.92938\tvalid_1's rmse: 56.6177\n",
      "[900]\ttraining's rmse: 5.58585\tvalid_1's rmse: 56.6031\n",
      "[930]\ttraining's rmse: 5.27074\tvalid_1's rmse: 56.6059\n",
      "[960]\ttraining's rmse: 4.97521\tvalid_1's rmse: 56.6033\n",
      "[990]\ttraining's rmse: 4.69649\tvalid_1's rmse: 56.59\n",
      "[1020]\ttraining's rmse: 4.43287\tvalid_1's rmse: 56.564\n",
      "[1050]\ttraining's rmse: 4.18763\tvalid_1's rmse: 56.5562\n",
      "[1080]\ttraining's rmse: 3.96553\tvalid_1's rmse: 56.5429\n",
      "[1110]\ttraining's rmse: 3.74581\tvalid_1's rmse: 56.5309\n",
      "[1140]\ttraining's rmse: 3.54633\tvalid_1's rmse: 56.5226\n",
      "[1170]\ttraining's rmse: 3.36153\tvalid_1's rmse: 56.5124\n",
      "[1200]\ttraining's rmse: 3.1815\tvalid_1's rmse: 56.5048\n",
      "[1230]\ttraining's rmse: 3.01337\tvalid_1's rmse: 56.4961\n",
      "[1260]\ttraining's rmse: 2.85229\tvalid_1's rmse: 56.4917\n",
      "[1290]\ttraining's rmse: 2.7047\tvalid_1's rmse: 56.4913\n",
      "[1320]\ttraining's rmse: 2.5638\tvalid_1's rmse: 56.4867\n",
      "[1350]\ttraining's rmse: 2.43321\tvalid_1's rmse: 56.4824\n",
      "[1380]\ttraining's rmse: 2.30491\tvalid_1's rmse: 56.4786\n",
      "[1410]\ttraining's rmse: 2.18815\tvalid_1's rmse: 56.474\n",
      "[1440]\ttraining's rmse: 2.07647\tvalid_1's rmse: 56.4679\n",
      "[1470]\ttraining's rmse: 1.97243\tvalid_1's rmse: 56.4641\n",
      "[1500]\ttraining's rmse: 1.87463\tvalid_1's rmse: 56.4605\n",
      "[1530]\ttraining's rmse: 1.77952\tvalid_1's rmse: 56.4565\n",
      "[1560]\ttraining's rmse: 1.69053\tvalid_1's rmse: 56.4512\n",
      "[1590]\ttraining's rmse: 1.60421\tvalid_1's rmse: 56.45\n",
      "[1620]\ttraining's rmse: 1.52292\tvalid_1's rmse: 56.4489\n",
      "[1650]\ttraining's rmse: 1.44782\tvalid_1's rmse: 56.45\n",
      "[1680]\ttraining's rmse: 1.37623\tvalid_1's rmse: 56.4496\n",
      "[1710]\ttraining's rmse: 1.30778\tvalid_1's rmse: 56.4464\n",
      "[1740]\ttraining's rmse: 1.24332\tvalid_1's rmse: 56.4457\n",
      "[1770]\ttraining's rmse: 1.18084\tvalid_1's rmse: 56.4446\n",
      "[1800]\ttraining's rmse: 1.12345\tvalid_1's rmse: 56.444\n",
      "[1830]\ttraining's rmse: 1.0687\tvalid_1's rmse: 56.4423\n",
      "[1860]\ttraining's rmse: 1.01604\tvalid_1's rmse: 56.4415\n",
      "[1890]\ttraining's rmse: 0.966722\tvalid_1's rmse: 56.4387\n",
      "[1920]\ttraining's rmse: 0.919499\tvalid_1's rmse: 56.4383\n",
      "[1950]\ttraining's rmse: 0.875021\tvalid_1's rmse: 56.4384\n",
      "[1980]\ttraining's rmse: 0.832024\tvalid_1's rmse: 56.4367\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's rmse: 0.804498\tvalid_1's rmse: 56.4361\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002399 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 20018\n",
      "[LightGBM] [Info] Number of data points in the train set: 9219, number of used features: 79\n",
      "[LightGBM] [Info] Start training from score 372.645781\n",
      "Training until validation scores don't improve for 125 rounds\n",
      "[30]\ttraining's rmse: 162.81\tvalid_1's rmse: 168.835\n",
      "[60]\ttraining's rmse: 101.763\tvalid_1's rmse: 115.822\n",
      "[90]\ttraining's rmse: 68.5819\tvalid_1's rmse: 89.6972\n",
      "[120]\ttraining's rmse: 50.6974\tvalid_1's rmse: 77.2174\n",
      "[150]\ttraining's rmse: 40.6151\tvalid_1's rmse: 70.9666\n",
      "[180]\ttraining's rmse: 34.4349\tvalid_1's rmse: 67.8237\n",
      "[210]\ttraining's rmse: 30.2125\tvalid_1's rmse: 65.9667\n",
      "[240]\ttraining's rmse: 26.9745\tvalid_1's rmse: 64.8513\n",
      "[270]\ttraining's rmse: 24.3404\tvalid_1's rmse: 64.111\n",
      "[300]\ttraining's rmse: 22.1538\tvalid_1's rmse: 63.5592\n",
      "[330]\ttraining's rmse: 20.273\tvalid_1's rmse: 63.1189\n",
      "[360]\ttraining's rmse: 18.654\tvalid_1's rmse: 62.916\n",
      "[390]\ttraining's rmse: 17.2342\tvalid_1's rmse: 62.7434\n",
      "[420]\ttraining's rmse: 15.9865\tvalid_1's rmse: 62.6141\n",
      "[450]\ttraining's rmse: 14.8269\tvalid_1's rmse: 62.4286\n",
      "[480]\ttraining's rmse: 13.7829\tvalid_1's rmse: 62.3027\n",
      "[510]\ttraining's rmse: 12.8532\tvalid_1's rmse: 62.1938\n",
      "[540]\ttraining's rmse: 12.0019\tvalid_1's rmse: 62.1148\n",
      "[570]\ttraining's rmse: 11.2247\tvalid_1's rmse: 62.0342\n",
      "[600]\ttraining's rmse: 10.5247\tvalid_1's rmse: 62.0047\n",
      "[630]\ttraining's rmse: 9.86941\tvalid_1's rmse: 61.9126\n",
      "[660]\ttraining's rmse: 9.26288\tvalid_1's rmse: 61.9014\n",
      "[690]\ttraining's rmse: 8.69554\tvalid_1's rmse: 61.8615\n",
      "[720]\ttraining's rmse: 8.1708\tvalid_1's rmse: 61.8216\n",
      "[750]\ttraining's rmse: 7.68692\tvalid_1's rmse: 61.7825\n",
      "[780]\ttraining's rmse: 7.23232\tvalid_1's rmse: 61.7317\n",
      "[810]\ttraining's rmse: 6.81068\tvalid_1's rmse: 61.6894\n",
      "[840]\ttraining's rmse: 6.42124\tvalid_1's rmse: 61.6798\n",
      "[870]\ttraining's rmse: 6.05268\tvalid_1's rmse: 61.6635\n",
      "[900]\ttraining's rmse: 5.70846\tvalid_1's rmse: 61.6388\n",
      "[930]\ttraining's rmse: 5.3909\tvalid_1's rmse: 61.621\n",
      "[960]\ttraining's rmse: 5.09516\tvalid_1's rmse: 61.6114\n",
      "[990]\ttraining's rmse: 4.81423\tvalid_1's rmse: 61.604\n",
      "[1020]\ttraining's rmse: 4.5502\tvalid_1's rmse: 61.5809\n",
      "[1050]\ttraining's rmse: 4.2992\tvalid_1's rmse: 61.5667\n",
      "[1080]\ttraining's rmse: 4.06639\tvalid_1's rmse: 61.5614\n",
      "[1110]\ttraining's rmse: 3.85613\tvalid_1's rmse: 61.56\n",
      "[1140]\ttraining's rmse: 3.6536\tvalid_1's rmse: 61.5491\n",
      "[1170]\ttraining's rmse: 3.46282\tvalid_1's rmse: 61.5416\n",
      "[1200]\ttraining's rmse: 3.27716\tvalid_1's rmse: 61.5318\n",
      "[1230]\ttraining's rmse: 3.10848\tvalid_1's rmse: 61.5252\n",
      "[1260]\ttraining's rmse: 2.94825\tvalid_1's rmse: 61.5186\n",
      "[1290]\ttraining's rmse: 2.79182\tvalid_1's rmse: 61.5191\n",
      "[1320]\ttraining's rmse: 2.64776\tvalid_1's rmse: 61.5129\n",
      "[1350]\ttraining's rmse: 2.51259\tvalid_1's rmse: 61.5099\n",
      "[1380]\ttraining's rmse: 2.38455\tvalid_1's rmse: 61.5011\n",
      "[1410]\ttraining's rmse: 2.26299\tvalid_1's rmse: 61.4977\n",
      "[1440]\ttraining's rmse: 2.14576\tvalid_1's rmse: 61.4885\n",
      "[1470]\ttraining's rmse: 2.03755\tvalid_1's rmse: 61.486\n",
      "[1500]\ttraining's rmse: 1.93546\tvalid_1's rmse: 61.4793\n",
      "[1530]\ttraining's rmse: 1.83856\tvalid_1's rmse: 61.477\n",
      "[1560]\ttraining's rmse: 1.74491\tvalid_1's rmse: 61.4729\n",
      "[1590]\ttraining's rmse: 1.65759\tvalid_1's rmse: 61.4673\n",
      "[1620]\ttraining's rmse: 1.57759\tvalid_1's rmse: 61.4621\n",
      "[1650]\ttraining's rmse: 1.49911\tvalid_1's rmse: 61.4591\n",
      "[1680]\ttraining's rmse: 1.42637\tvalid_1's rmse: 61.461\n",
      "[1710]\ttraining's rmse: 1.35407\tvalid_1's rmse: 61.4603\n",
      "[1740]\ttraining's rmse: 1.28789\tvalid_1's rmse: 61.4559\n",
      "[1770]\ttraining's rmse: 1.2254\tvalid_1's rmse: 61.4552\n",
      "[1800]\ttraining's rmse: 1.16662\tvalid_1's rmse: 61.4551\n",
      "[1830]\ttraining's rmse: 1.10913\tvalid_1's rmse: 61.454\n",
      "[1860]\ttraining's rmse: 1.05559\tvalid_1's rmse: 61.4526\n",
      "[1890]\ttraining's rmse: 1.00378\tvalid_1's rmse: 61.4484\n",
      "[1920]\ttraining's rmse: 0.955692\tvalid_1's rmse: 61.4471\n",
      "[1950]\ttraining's rmse: 0.909844\tvalid_1's rmse: 61.4452\n",
      "[1980]\ttraining's rmse: 0.866859\tvalid_1's rmse: 61.4435\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's rmse: 0.83973\tvalid_1's rmse: 61.4432\n",
      "17\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003389 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 20020\n",
      "[LightGBM] [Info] Number of data points in the train set: 9219, number of used features: 79\n",
      "[LightGBM] [Info] Start training from score 370.680730\n",
      "Training until validation scores don't improve for 125 rounds\n",
      "[30]\ttraining's rmse: 151.427\tvalid_1's rmse: 151.837\n",
      "[60]\ttraining's rmse: 94.2363\tvalid_1's rmse: 101.355\n",
      "[90]\ttraining's rmse: 63.4581\tvalid_1's rmse: 76.1718\n",
      "[120]\ttraining's rmse: 46.7605\tvalid_1's rmse: 64.2763\n",
      "[150]\ttraining's rmse: 37.528\tvalid_1's rmse: 58.6424\n",
      "[180]\ttraining's rmse: 31.958\tvalid_1's rmse: 55.6382\n",
      "[210]\ttraining's rmse: 28.0501\tvalid_1's rmse: 53.8712\n",
      "[240]\ttraining's rmse: 24.9624\tvalid_1's rmse: 52.5418\n",
      "[270]\ttraining's rmse: 22.4698\tvalid_1's rmse: 51.6262\n",
      "[300]\ttraining's rmse: 20.4327\tvalid_1's rmse: 50.9303\n",
      "[330]\ttraining's rmse: 18.652\tvalid_1's rmse: 50.4298\n",
      "[360]\ttraining's rmse: 17.1401\tvalid_1's rmse: 50.0904\n",
      "[390]\ttraining's rmse: 15.8177\tvalid_1's rmse: 49.7818\n",
      "[420]\ttraining's rmse: 14.6471\tvalid_1's rmse: 49.6043\n",
      "[450]\ttraining's rmse: 13.5856\tvalid_1's rmse: 49.4087\n",
      "[480]\ttraining's rmse: 12.6181\tvalid_1's rmse: 49.2717\n",
      "[510]\ttraining's rmse: 11.745\tvalid_1's rmse: 49.1722\n",
      "[540]\ttraining's rmse: 10.9568\tvalid_1's rmse: 49.09\n",
      "[570]\ttraining's rmse: 10.2306\tvalid_1's rmse: 49.0116\n",
      "[600]\ttraining's rmse: 9.57323\tvalid_1's rmse: 48.9527\n",
      "[630]\ttraining's rmse: 8.9597\tvalid_1's rmse: 48.8734\n",
      "[660]\ttraining's rmse: 8.40198\tvalid_1's rmse: 48.8225\n",
      "[690]\ttraining's rmse: 7.88998\tvalid_1's rmse: 48.7568\n",
      "[720]\ttraining's rmse: 7.41507\tvalid_1's rmse: 48.7295\n",
      "[750]\ttraining's rmse: 6.97531\tvalid_1's rmse: 48.6778\n",
      "[780]\ttraining's rmse: 6.56403\tvalid_1's rmse: 48.6524\n",
      "[810]\ttraining's rmse: 6.1879\tvalid_1's rmse: 48.6456\n",
      "[840]\ttraining's rmse: 5.83435\tvalid_1's rmse: 48.6107\n",
      "[870]\ttraining's rmse: 5.50236\tvalid_1's rmse: 48.5921\n",
      "[900]\ttraining's rmse: 5.19476\tvalid_1's rmse: 48.5732\n",
      "[930]\ttraining's rmse: 4.9021\tvalid_1's rmse: 48.5558\n",
      "[960]\ttraining's rmse: 4.62451\tvalid_1's rmse: 48.5352\n",
      "[990]\ttraining's rmse: 4.36529\tvalid_1's rmse: 48.526\n",
      "[1020]\ttraining's rmse: 4.1308\tvalid_1's rmse: 48.5136\n",
      "[1050]\ttraining's rmse: 3.90312\tvalid_1's rmse: 48.512\n",
      "[1080]\ttraining's rmse: 3.69483\tvalid_1's rmse: 48.501\n",
      "[1110]\ttraining's rmse: 3.49453\tvalid_1's rmse: 48.4995\n",
      "[1140]\ttraining's rmse: 3.30798\tvalid_1's rmse: 48.4907\n",
      "[1170]\ttraining's rmse: 3.13516\tvalid_1's rmse: 48.4866\n",
      "[1200]\ttraining's rmse: 2.97211\tvalid_1's rmse: 48.4817\n",
      "[1230]\ttraining's rmse: 2.81204\tvalid_1's rmse: 48.4774\n",
      "[1260]\ttraining's rmse: 2.66661\tvalid_1's rmse: 48.4733\n",
      "[1290]\ttraining's rmse: 2.52711\tvalid_1's rmse: 48.4675\n",
      "[1320]\ttraining's rmse: 2.39761\tvalid_1's rmse: 48.4667\n",
      "[1350]\ttraining's rmse: 2.27461\tvalid_1's rmse: 48.4638\n",
      "[1380]\ttraining's rmse: 2.16213\tvalid_1's rmse: 48.4614\n",
      "[1410]\ttraining's rmse: 2.05376\tvalid_1's rmse: 48.4551\n",
      "[1440]\ttraining's rmse: 1.95088\tvalid_1's rmse: 48.4475\n",
      "[1470]\ttraining's rmse: 1.85107\tvalid_1's rmse: 48.4451\n",
      "[1500]\ttraining's rmse: 1.76016\tvalid_1's rmse: 48.4435\n",
      "[1530]\ttraining's rmse: 1.67169\tvalid_1's rmse: 48.4399\n",
      "[1560]\ttraining's rmse: 1.58965\tvalid_1's rmse: 48.436\n",
      "[1590]\ttraining's rmse: 1.50974\tvalid_1's rmse: 48.4343\n",
      "[1620]\ttraining's rmse: 1.43475\tvalid_1's rmse: 48.4331\n",
      "[1650]\ttraining's rmse: 1.36418\tvalid_1's rmse: 48.4307\n",
      "[1680]\ttraining's rmse: 1.29689\tvalid_1's rmse: 48.4294\n",
      "[1710]\ttraining's rmse: 1.23352\tvalid_1's rmse: 48.43\n",
      "[1740]\ttraining's rmse: 1.17254\tvalid_1's rmse: 48.4276\n",
      "[1770]\ttraining's rmse: 1.11436\tvalid_1's rmse: 48.4271\n",
      "[1800]\ttraining's rmse: 1.0609\tvalid_1's rmse: 48.4253\n",
      "[1830]\ttraining's rmse: 1.00848\tvalid_1's rmse: 48.4248\n",
      "[1860]\ttraining's rmse: 0.959863\tvalid_1's rmse: 48.4222\n",
      "[1890]\ttraining's rmse: 0.913131\tvalid_1's rmse: 48.4203\n",
      "[1920]\ttraining's rmse: 0.869529\tvalid_1's rmse: 48.4199\n",
      "[1950]\ttraining's rmse: 0.826858\tvalid_1's rmse: 48.4184\n",
      "[1980]\ttraining's rmse: 0.786212\tvalid_1's rmse: 48.4179\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's rmse: 0.760399\tvalid_1's rmse: 48.4182\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003300 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 20020\n",
      "[LightGBM] [Info] Number of data points in the train set: 9219, number of used features: 79\n",
      "[LightGBM] [Info] Start training from score 367.729997\n",
      "Training until validation scores don't improve for 125 rounds\n",
      "[30]\ttraining's rmse: 152.805\tvalid_1's rmse: 158.968\n",
      "[60]\ttraining's rmse: 96.1325\tvalid_1's rmse: 109.761\n",
      "[90]\ttraining's rmse: 65.6877\tvalid_1's rmse: 85.7391\n",
      "[120]\ttraining's rmse: 48.9203\tvalid_1's rmse: 73.3232\n",
      "[150]\ttraining's rmse: 39.5218\tvalid_1's rmse: 67.2469\n",
      "[180]\ttraining's rmse: 33.6968\tvalid_1's rmse: 64.0172\n",
      "[210]\ttraining's rmse: 29.6867\tvalid_1's rmse: 62.1159\n",
      "[240]\ttraining's rmse: 26.5176\tvalid_1's rmse: 60.7134\n",
      "[270]\ttraining's rmse: 23.9336\tvalid_1's rmse: 59.7895\n",
      "[300]\ttraining's rmse: 21.7642\tvalid_1's rmse: 59.1084\n",
      "[330]\ttraining's rmse: 19.9023\tvalid_1's rmse: 58.6969\n",
      "[360]\ttraining's rmse: 18.2802\tvalid_1's rmse: 58.3779\n",
      "[390]\ttraining's rmse: 16.8607\tvalid_1's rmse: 58.1241\n",
      "[420]\ttraining's rmse: 15.6104\tvalid_1's rmse: 57.8645\n",
      "[450]\ttraining's rmse: 14.5021\tvalid_1's rmse: 57.6803\n",
      "[480]\ttraining's rmse: 13.4852\tvalid_1's rmse: 57.5552\n",
      "[510]\ttraining's rmse: 12.5584\tvalid_1's rmse: 57.3994\n",
      "[540]\ttraining's rmse: 11.7204\tvalid_1's rmse: 57.2912\n",
      "[570]\ttraining's rmse: 10.944\tvalid_1's rmse: 57.217\n",
      "[600]\ttraining's rmse: 10.2487\tvalid_1's rmse: 57.0935\n",
      "[630]\ttraining's rmse: 9.59522\tvalid_1's rmse: 57.0012\n",
      "[660]\ttraining's rmse: 8.99948\tvalid_1's rmse: 56.9455\n",
      "[690]\ttraining's rmse: 8.44127\tvalid_1's rmse: 56.8886\n",
      "[720]\ttraining's rmse: 7.93589\tvalid_1's rmse: 56.8375\n",
      "[750]\ttraining's rmse: 7.45841\tvalid_1's rmse: 56.8022\n",
      "[780]\ttraining's rmse: 7.02439\tvalid_1's rmse: 56.7718\n",
      "[810]\ttraining's rmse: 6.60825\tvalid_1's rmse: 56.7358\n",
      "[840]\ttraining's rmse: 6.22869\tvalid_1's rmse: 56.6938\n",
      "[870]\ttraining's rmse: 5.87885\tvalid_1's rmse: 56.6707\n",
      "[900]\ttraining's rmse: 5.5494\tvalid_1's rmse: 56.6526\n",
      "[930]\ttraining's rmse: 5.24241\tvalid_1's rmse: 56.6383\n",
      "[960]\ttraining's rmse: 4.95691\tvalid_1's rmse: 56.6182\n",
      "[990]\ttraining's rmse: 4.68454\tvalid_1's rmse: 56.5931\n",
      "[1020]\ttraining's rmse: 4.42824\tvalid_1's rmse: 56.5801\n",
      "[1050]\ttraining's rmse: 4.19105\tvalid_1's rmse: 56.5691\n",
      "[1080]\ttraining's rmse: 3.96697\tvalid_1's rmse: 56.5702\n",
      "[1110]\ttraining's rmse: 3.75955\tvalid_1's rmse: 56.5555\n",
      "[1140]\ttraining's rmse: 3.56105\tvalid_1's rmse: 56.544\n",
      "[1170]\ttraining's rmse: 3.37827\tvalid_1's rmse: 56.5327\n",
      "[1200]\ttraining's rmse: 3.20167\tvalid_1's rmse: 56.5132\n",
      "[1230]\ttraining's rmse: 3.04334\tvalid_1's rmse: 56.5026\n",
      "[1260]\ttraining's rmse: 2.88773\tvalid_1's rmse: 56.4923\n",
      "[1290]\ttraining's rmse: 2.74127\tvalid_1's rmse: 56.4821\n",
      "[1320]\ttraining's rmse: 2.60082\tvalid_1's rmse: 56.4789\n",
      "[1350]\ttraining's rmse: 2.46942\tvalid_1's rmse: 56.4709\n",
      "[1380]\ttraining's rmse: 2.34843\tvalid_1's rmse: 56.464\n",
      "[1410]\ttraining's rmse: 2.23406\tvalid_1's rmse: 56.4616\n",
      "[1440]\ttraining's rmse: 2.12702\tvalid_1's rmse: 56.4605\n",
      "[1470]\ttraining's rmse: 2.02268\tvalid_1's rmse: 56.4571\n",
      "[1500]\ttraining's rmse: 1.92756\tvalid_1's rmse: 56.4544\n",
      "[1530]\ttraining's rmse: 1.83702\tvalid_1's rmse: 56.4486\n",
      "[1560]\ttraining's rmse: 1.75166\tvalid_1's rmse: 56.4494\n",
      "[1590]\ttraining's rmse: 1.67137\tvalid_1's rmse: 56.4467\n",
      "[1620]\ttraining's rmse: 1.59528\tvalid_1's rmse: 56.4446\n",
      "[1650]\ttraining's rmse: 1.52222\tvalid_1's rmse: 56.4438\n",
      "[1680]\ttraining's rmse: 1.45181\tvalid_1's rmse: 56.4427\n",
      "[1710]\ttraining's rmse: 1.38487\tvalid_1's rmse: 56.4432\n",
      "[1740]\ttraining's rmse: 1.32402\tvalid_1's rmse: 56.4428\n",
      "[1770]\ttraining's rmse: 1.26508\tvalid_1's rmse: 56.4415\n",
      "[1800]\ttraining's rmse: 1.20751\tvalid_1's rmse: 56.4384\n",
      "[1830]\ttraining's rmse: 1.15233\tvalid_1's rmse: 56.4362\n",
      "[1860]\ttraining's rmse: 1.09974\tvalid_1's rmse: 56.4349\n",
      "[1890]\ttraining's rmse: 1.05028\tvalid_1's rmse: 56.4353\n",
      "[1920]\ttraining's rmse: 1.00449\tvalid_1's rmse: 56.4331\n",
      "[1950]\ttraining's rmse: 0.962205\tvalid_1's rmse: 56.4322\n",
      "[1980]\ttraining's rmse: 0.919936\tvalid_1's rmse: 56.4309\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's rmse: 0.894068\tvalid_1's rmse: 56.4314\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003247 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 20020\n",
      "[LightGBM] [Info] Number of data points in the train set: 9219, number of used features: 79\n",
      "[LightGBM] [Info] Start training from score 363.655210\n",
      "Training until validation scores don't improve for 125 rounds\n",
      "[30]\ttraining's rmse: 153.38\tvalid_1's rmse: 159.906\n",
      "[60]\ttraining's rmse: 96.134\tvalid_1's rmse: 108.189\n",
      "[90]\ttraining's rmse: 65.0114\tvalid_1's rmse: 82.9914\n",
      "[120]\ttraining's rmse: 48.2425\tvalid_1's rmse: 71.4953\n",
      "[150]\ttraining's rmse: 38.665\tvalid_1's rmse: 65.9639\n",
      "[180]\ttraining's rmse: 32.9316\tvalid_1's rmse: 63.2773\n",
      "[210]\ttraining's rmse: 28.892\tvalid_1's rmse: 61.6486\n",
      "[240]\ttraining's rmse: 25.7292\tvalid_1's rmse: 60.6434\n",
      "[270]\ttraining's rmse: 23.1606\tvalid_1's rmse: 59.7751\n",
      "[300]\ttraining's rmse: 21.052\tvalid_1's rmse: 59.1887\n",
      "[330]\ttraining's rmse: 19.2621\tvalid_1's rmse: 58.8586\n",
      "[360]\ttraining's rmse: 17.6909\tvalid_1's rmse: 58.5677\n",
      "[390]\ttraining's rmse: 16.3177\tvalid_1's rmse: 58.2914\n",
      "[420]\ttraining's rmse: 15.076\tvalid_1's rmse: 58.1064\n",
      "[450]\ttraining's rmse: 13.9687\tvalid_1's rmse: 57.992\n",
      "[480]\ttraining's rmse: 12.9706\tvalid_1's rmse: 57.8671\n",
      "[510]\ttraining's rmse: 12.0714\tvalid_1's rmse: 57.7211\n",
      "[540]\ttraining's rmse: 11.2476\tvalid_1's rmse: 57.6279\n",
      "[570]\ttraining's rmse: 10.4883\tvalid_1's rmse: 57.5114\n",
      "[600]\ttraining's rmse: 9.80671\tvalid_1's rmse: 57.448\n",
      "[630]\ttraining's rmse: 9.17768\tvalid_1's rmse: 57.3848\n",
      "[660]\ttraining's rmse: 8.59913\tvalid_1's rmse: 57.3266\n",
      "[690]\ttraining's rmse: 8.07267\tvalid_1's rmse: 57.2873\n",
      "[720]\ttraining's rmse: 7.58255\tvalid_1's rmse: 57.2544\n",
      "[750]\ttraining's rmse: 7.11981\tvalid_1's rmse: 57.2387\n",
      "[780]\ttraining's rmse: 6.70294\tvalid_1's rmse: 57.1952\n",
      "[810]\ttraining's rmse: 6.30611\tvalid_1's rmse: 57.1782\n",
      "[840]\ttraining's rmse: 5.93415\tvalid_1's rmse: 57.1539\n",
      "[870]\ttraining's rmse: 5.59403\tvalid_1's rmse: 57.1238\n",
      "[900]\ttraining's rmse: 5.277\tvalid_1's rmse: 57.1104\n",
      "[930]\ttraining's rmse: 4.98347\tvalid_1's rmse: 57.101\n",
      "[960]\ttraining's rmse: 4.71168\tvalid_1's rmse: 57.0904\n",
      "[990]\ttraining's rmse: 4.4523\tvalid_1's rmse: 57.0763\n",
      "[1020]\ttraining's rmse: 4.21011\tvalid_1's rmse: 57.0611\n",
      "[1050]\ttraining's rmse: 3.98246\tvalid_1's rmse: 57.0476\n",
      "[1080]\ttraining's rmse: 3.76772\tvalid_1's rmse: 57.0337\n",
      "[1110]\ttraining's rmse: 3.56054\tvalid_1's rmse: 57.0217\n",
      "[1140]\ttraining's rmse: 3.36961\tvalid_1's rmse: 57.0173\n",
      "[1170]\ttraining's rmse: 3.19606\tvalid_1's rmse: 57.0097\n",
      "[1200]\ttraining's rmse: 3.03346\tvalid_1's rmse: 57.002\n",
      "[1230]\ttraining's rmse: 2.87732\tvalid_1's rmse: 56.9979\n",
      "[1260]\ttraining's rmse: 2.72939\tvalid_1's rmse: 56.9961\n",
      "[1290]\ttraining's rmse: 2.58915\tvalid_1's rmse: 56.9894\n",
      "[1320]\ttraining's rmse: 2.45788\tvalid_1's rmse: 56.9853\n",
      "[1350]\ttraining's rmse: 2.3315\tvalid_1's rmse: 56.9779\n",
      "[1380]\ttraining's rmse: 2.21458\tvalid_1's rmse: 56.9712\n",
      "[1410]\ttraining's rmse: 2.10084\tvalid_1's rmse: 56.9617\n",
      "[1440]\ttraining's rmse: 1.99613\tvalid_1's rmse: 56.9588\n",
      "[1470]\ttraining's rmse: 1.89955\tvalid_1's rmse: 56.9556\n",
      "[1500]\ttraining's rmse: 1.8061\tvalid_1's rmse: 56.9523\n",
      "[1530]\ttraining's rmse: 1.71801\tvalid_1's rmse: 56.9506\n",
      "[1560]\ttraining's rmse: 1.63491\tvalid_1's rmse: 56.9491\n",
      "[1590]\ttraining's rmse: 1.55682\tvalid_1's rmse: 56.9483\n",
      "[1620]\ttraining's rmse: 1.48131\tvalid_1's rmse: 56.9445\n",
      "[1650]\ttraining's rmse: 1.41116\tvalid_1's rmse: 56.9416\n",
      "[1680]\ttraining's rmse: 1.34408\tvalid_1's rmse: 56.9377\n",
      "[1710]\ttraining's rmse: 1.2795\tvalid_1's rmse: 56.9354\n",
      "[1740]\ttraining's rmse: 1.21951\tvalid_1's rmse: 56.9322\n",
      "[1770]\ttraining's rmse: 1.1635\tvalid_1's rmse: 56.9301\n",
      "[1800]\ttraining's rmse: 1.10953\tvalid_1's rmse: 56.9292\n",
      "[1830]\ttraining's rmse: 1.05736\tvalid_1's rmse: 56.9287\n",
      "[1860]\ttraining's rmse: 1.00703\tvalid_1's rmse: 56.9288\n",
      "[1890]\ttraining's rmse: 0.960405\tvalid_1's rmse: 56.9292\n",
      "[1920]\ttraining's rmse: 0.915749\tvalid_1's rmse: 56.9261\n",
      "[1950]\ttraining's rmse: 0.873721\tvalid_1's rmse: 56.9244\n",
      "[1980]\ttraining's rmse: 0.833668\tvalid_1's rmse: 56.9222\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's rmse: 0.808722\tvalid_1's rmse: 56.9221\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002289 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 20020\n",
      "[LightGBM] [Info] Number of data points in the train set: 9219, number of used features: 79\n",
      "[LightGBM] [Info] Start training from score 361.183391\n",
      "Training until validation scores don't improve for 125 rounds\n",
      "[30]\ttraining's rmse: 152.581\tvalid_1's rmse: 161.233\n",
      "[60]\ttraining's rmse: 96.0199\tvalid_1's rmse: 108.613\n",
      "[90]\ttraining's rmse: 65.2974\tvalid_1's rmse: 82.188\n",
      "[120]\ttraining's rmse: 48.5977\tvalid_1's rmse: 69.4589\n",
      "[150]\ttraining's rmse: 39.0562\tvalid_1's rmse: 63.2112\n",
      "[180]\ttraining's rmse: 33.1299\tvalid_1's rmse: 59.9205\n",
      "[210]\ttraining's rmse: 29.0223\tvalid_1's rmse: 58.0812\n",
      "[240]\ttraining's rmse: 25.9209\tvalid_1's rmse: 56.8069\n",
      "[270]\ttraining's rmse: 23.3781\tvalid_1's rmse: 55.9025\n",
      "[300]\ttraining's rmse: 21.2747\tvalid_1's rmse: 55.2903\n",
      "[330]\ttraining's rmse: 19.4597\tvalid_1's rmse: 54.8779\n",
      "[360]\ttraining's rmse: 17.8968\tvalid_1's rmse: 54.6593\n",
      "[390]\ttraining's rmse: 16.5283\tvalid_1's rmse: 54.4018\n",
      "[420]\ttraining's rmse: 15.2961\tvalid_1's rmse: 54.1959\n",
      "[450]\ttraining's rmse: 14.2208\tvalid_1's rmse: 54.0612\n",
      "[480]\ttraining's rmse: 13.2157\tvalid_1's rmse: 53.9146\n",
      "[510]\ttraining's rmse: 12.3188\tvalid_1's rmse: 53.8515\n",
      "[540]\ttraining's rmse: 11.4866\tvalid_1's rmse: 53.7808\n",
      "[570]\ttraining's rmse: 10.7241\tvalid_1's rmse: 53.717\n",
      "[600]\ttraining's rmse: 10.0273\tvalid_1's rmse: 53.6315\n",
      "[630]\ttraining's rmse: 9.38855\tvalid_1's rmse: 53.5591\n",
      "[660]\ttraining's rmse: 8.80522\tvalid_1's rmse: 53.5047\n",
      "[690]\ttraining's rmse: 8.26594\tvalid_1's rmse: 53.4506\n",
      "[720]\ttraining's rmse: 7.76075\tvalid_1's rmse: 53.4084\n",
      "[750]\ttraining's rmse: 7.28562\tvalid_1's rmse: 53.3585\n",
      "[780]\ttraining's rmse: 6.86456\tvalid_1's rmse: 53.3216\n",
      "[810]\ttraining's rmse: 6.46275\tvalid_1's rmse: 53.2865\n",
      "[840]\ttraining's rmse: 6.08464\tvalid_1's rmse: 53.2673\n",
      "[870]\ttraining's rmse: 5.73454\tvalid_1's rmse: 53.2424\n",
      "[900]\ttraining's rmse: 5.40902\tvalid_1's rmse: 53.2174\n",
      "[930]\ttraining's rmse: 5.10438\tvalid_1's rmse: 53.1961\n",
      "[960]\ttraining's rmse: 4.82375\tvalid_1's rmse: 53.1836\n",
      "[990]\ttraining's rmse: 4.56838\tvalid_1's rmse: 53.1763\n",
      "[1020]\ttraining's rmse: 4.31735\tvalid_1's rmse: 53.1629\n",
      "[1050]\ttraining's rmse: 4.0806\tvalid_1's rmse: 53.1509\n",
      "[1080]\ttraining's rmse: 3.86128\tvalid_1's rmse: 53.152\n",
      "[1110]\ttraining's rmse: 3.65896\tvalid_1's rmse: 53.1419\n",
      "[1140]\ttraining's rmse: 3.46434\tvalid_1's rmse: 53.132\n",
      "[1170]\ttraining's rmse: 3.28073\tvalid_1's rmse: 53.1315\n",
      "[1200]\ttraining's rmse: 3.10391\tvalid_1's rmse: 53.1305\n",
      "[1230]\ttraining's rmse: 2.94285\tvalid_1's rmse: 53.1291\n",
      "[1260]\ttraining's rmse: 2.78893\tvalid_1's rmse: 53.1229\n",
      "[1290]\ttraining's rmse: 2.64411\tvalid_1's rmse: 53.1167\n",
      "[1320]\ttraining's rmse: 2.51035\tvalid_1's rmse: 53.1104\n",
      "[1350]\ttraining's rmse: 2.38164\tvalid_1's rmse: 53.1115\n",
      "[1380]\ttraining's rmse: 2.25942\tvalid_1's rmse: 53.1073\n",
      "[1410]\ttraining's rmse: 2.14316\tvalid_1's rmse: 53.1038\n",
      "[1440]\ttraining's rmse: 2.03649\tvalid_1's rmse: 53.0987\n",
      "[1470]\ttraining's rmse: 1.93438\tvalid_1's rmse: 53.0927\n",
      "[1500]\ttraining's rmse: 1.83569\tvalid_1's rmse: 53.0908\n",
      "[1530]\ttraining's rmse: 1.74482\tvalid_1's rmse: 53.0859\n",
      "[1560]\ttraining's rmse: 1.65785\tvalid_1's rmse: 53.0858\n",
      "[1590]\ttraining's rmse: 1.57488\tvalid_1's rmse: 53.08\n",
      "[1620]\ttraining's rmse: 1.49739\tvalid_1's rmse: 53.0774\n",
      "[1650]\ttraining's rmse: 1.42508\tvalid_1's rmse: 53.0774\n",
      "[1680]\ttraining's rmse: 1.35618\tvalid_1's rmse: 53.072\n",
      "[1710]\ttraining's rmse: 1.2903\tvalid_1's rmse: 53.0748\n",
      "[1740]\ttraining's rmse: 1.22687\tvalid_1's rmse: 53.0702\n",
      "[1770]\ttraining's rmse: 1.16758\tvalid_1's rmse: 53.0674\n",
      "[1800]\ttraining's rmse: 1.11084\tvalid_1's rmse: 53.0668\n",
      "[1830]\ttraining's rmse: 1.05784\tvalid_1's rmse: 53.0662\n",
      "[1860]\ttraining's rmse: 1.00566\tvalid_1's rmse: 53.0669\n",
      "[1890]\ttraining's rmse: 0.958898\tvalid_1's rmse: 53.0677\n",
      "[1920]\ttraining's rmse: 0.913416\tvalid_1's rmse: 53.066\n",
      "[1950]\ttraining's rmse: 0.870356\tvalid_1's rmse: 53.0648\n",
      "[1980]\ttraining's rmse: 0.829839\tvalid_1's rmse: 53.0628\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's rmse: 0.803524\tvalid_1's rmse: 53.0627\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003673 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 20020\n",
      "[LightGBM] [Info] Number of data points in the train set: 9219, number of used features: 79\n",
      "[LightGBM] [Info] Start training from score 370.159354\n",
      "Training until validation scores don't improve for 125 rounds\n",
      "[30]\ttraining's rmse: 160.712\tvalid_1's rmse: 161.549\n",
      "[60]\ttraining's rmse: 100.939\tvalid_1's rmse: 109.367\n",
      "[90]\ttraining's rmse: 68.5225\tvalid_1's rmse: 83.4167\n",
      "[120]\ttraining's rmse: 50.8074\tvalid_1's rmse: 70.5847\n",
      "[150]\ttraining's rmse: 40.8112\tvalid_1's rmse: 64.3327\n",
      "[180]\ttraining's rmse: 34.7539\tvalid_1's rmse: 61.2764\n",
      "[210]\ttraining's rmse: 30.4785\tvalid_1's rmse: 59.3483\n",
      "[240]\ttraining's rmse: 27.1903\tvalid_1's rmse: 58.1358\n",
      "[270]\ttraining's rmse: 24.5587\tvalid_1's rmse: 57.3518\n",
      "[300]\ttraining's rmse: 22.3078\tvalid_1's rmse: 56.7786\n",
      "[330]\ttraining's rmse: 20.4679\tvalid_1's rmse: 56.4696\n",
      "[360]\ttraining's rmse: 18.8645\tvalid_1's rmse: 56.2667\n",
      "[390]\ttraining's rmse: 17.4399\tvalid_1's rmse: 56.0385\n",
      "[420]\ttraining's rmse: 16.1447\tvalid_1's rmse: 55.8209\n",
      "[450]\ttraining's rmse: 14.9975\tvalid_1's rmse: 55.6867\n",
      "[480]\ttraining's rmse: 13.9451\tvalid_1's rmse: 55.6196\n",
      "[510]\ttraining's rmse: 13.0056\tvalid_1's rmse: 55.5153\n",
      "[540]\ttraining's rmse: 12.1277\tvalid_1's rmse: 55.4075\n",
      "[570]\ttraining's rmse: 11.3395\tvalid_1's rmse: 55.3268\n",
      "[600]\ttraining's rmse: 10.6282\tvalid_1's rmse: 55.2322\n",
      "[630]\ttraining's rmse: 9.95471\tvalid_1's rmse: 55.1579\n",
      "[660]\ttraining's rmse: 9.33771\tvalid_1's rmse: 55.1034\n",
      "[690]\ttraining's rmse: 8.76125\tvalid_1's rmse: 55.0336\n",
      "[720]\ttraining's rmse: 8.23623\tvalid_1's rmse: 55.0024\n",
      "[750]\ttraining's rmse: 7.74852\tvalid_1's rmse: 54.9748\n",
      "[780]\ttraining's rmse: 7.28753\tvalid_1's rmse: 54.9477\n",
      "[810]\ttraining's rmse: 6.86823\tvalid_1's rmse: 54.8932\n",
      "[840]\ttraining's rmse: 6.46869\tvalid_1's rmse: 54.87\n",
      "[870]\ttraining's rmse: 6.10428\tvalid_1's rmse: 54.8521\n",
      "[900]\ttraining's rmse: 5.7657\tvalid_1's rmse: 54.8376\n",
      "[930]\ttraining's rmse: 5.45046\tvalid_1's rmse: 54.8113\n",
      "[960]\ttraining's rmse: 5.15235\tvalid_1's rmse: 54.792\n",
      "[990]\ttraining's rmse: 4.86695\tvalid_1's rmse: 54.7782\n",
      "[1020]\ttraining's rmse: 4.60201\tvalid_1's rmse: 54.7704\n",
      "[1050]\ttraining's rmse: 4.35529\tvalid_1's rmse: 54.7581\n",
      "[1080]\ttraining's rmse: 4.12317\tvalid_1's rmse: 54.7446\n",
      "[1110]\ttraining's rmse: 3.91021\tvalid_1's rmse: 54.737\n",
      "[1140]\ttraining's rmse: 3.70365\tvalid_1's rmse: 54.7312\n",
      "[1170]\ttraining's rmse: 3.50968\tvalid_1's rmse: 54.7224\n",
      "[1200]\ttraining's rmse: 3.32754\tvalid_1's rmse: 54.7111\n",
      "[1230]\ttraining's rmse: 3.15369\tvalid_1's rmse: 54.7004\n",
      "[1260]\ttraining's rmse: 2.993\tvalid_1's rmse: 54.6878\n",
      "[1290]\ttraining's rmse: 2.84102\tvalid_1's rmse: 54.6805\n",
      "[1320]\ttraining's rmse: 2.6959\tvalid_1's rmse: 54.6798\n",
      "[1350]\ttraining's rmse: 2.55556\tvalid_1's rmse: 54.6859\n",
      "[1380]\ttraining's rmse: 2.42795\tvalid_1's rmse: 54.6843\n",
      "[1410]\ttraining's rmse: 2.3047\tvalid_1's rmse: 54.6771\n",
      "[1440]\ttraining's rmse: 2.18845\tvalid_1's rmse: 54.6728\n",
      "[1470]\ttraining's rmse: 2.07979\tvalid_1's rmse: 54.6721\n",
      "[1500]\ttraining's rmse: 1.97807\tvalid_1's rmse: 54.6682\n",
      "[1530]\ttraining's rmse: 1.87909\tvalid_1's rmse: 54.6658\n",
      "[1560]\ttraining's rmse: 1.78682\tvalid_1's rmse: 54.6623\n",
      "[1590]\ttraining's rmse: 1.70033\tvalid_1's rmse: 54.6579\n",
      "[1620]\ttraining's rmse: 1.61743\tvalid_1's rmse: 54.6537\n",
      "[1650]\ttraining's rmse: 1.53865\tvalid_1's rmse: 54.6518\n",
      "[1680]\ttraining's rmse: 1.46399\tvalid_1's rmse: 54.6513\n",
      "[1710]\ttraining's rmse: 1.39374\tvalid_1's rmse: 54.6483\n",
      "[1740]\ttraining's rmse: 1.32649\tvalid_1's rmse: 54.6473\n",
      "[1770]\ttraining's rmse: 1.26405\tvalid_1's rmse: 54.6463\n",
      "[1800]\ttraining's rmse: 1.20475\tvalid_1's rmse: 54.6455\n",
      "[1830]\ttraining's rmse: 1.14573\tvalid_1's rmse: 54.6436\n",
      "[1860]\ttraining's rmse: 1.09327\tvalid_1's rmse: 54.6453\n",
      "[1890]\ttraining's rmse: 1.0425\tvalid_1's rmse: 54.6429\n",
      "[1920]\ttraining's rmse: 0.99387\tvalid_1's rmse: 54.6417\n",
      "[1950]\ttraining's rmse: 0.947423\tvalid_1's rmse: 54.6414\n",
      "[1980]\ttraining's rmse: 0.902522\tvalid_1's rmse: 54.6409\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's rmse: 0.874851\tvalid_1's rmse: 54.6406\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002156 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 20020\n",
      "[LightGBM] [Info] Number of data points in the train set: 9219, number of used features: 79\n",
      "[LightGBM] [Info] Start training from score 376.196971\n",
      "Training until validation scores don't improve for 125 rounds\n",
      "[30]\ttraining's rmse: 163.816\tvalid_1's rmse: 163.865\n",
      "[60]\ttraining's rmse: 102.382\tvalid_1's rmse: 110.125\n",
      "[90]\ttraining's rmse: 69.209\tvalid_1's rmse: 83.2317\n",
      "[120]\ttraining's rmse: 51.1793\tvalid_1's rmse: 70.1933\n",
      "[150]\ttraining's rmse: 41.0135\tvalid_1's rmse: 63.9852\n",
      "[180]\ttraining's rmse: 34.7498\tvalid_1's rmse: 60.4816\n",
      "[210]\ttraining's rmse: 30.3779\tvalid_1's rmse: 58.4042\n",
      "[240]\ttraining's rmse: 27.1073\tvalid_1's rmse: 57.0642\n",
      "[270]\ttraining's rmse: 24.4464\tvalid_1's rmse: 56.2485\n",
      "[300]\ttraining's rmse: 22.2539\tvalid_1's rmse: 55.6972\n",
      "[330]\ttraining's rmse: 20.3975\tvalid_1's rmse: 55.2958\n",
      "[360]\ttraining's rmse: 18.7514\tvalid_1's rmse: 55.023\n",
      "[390]\ttraining's rmse: 17.3245\tvalid_1's rmse: 54.8534\n",
      "[420]\ttraining's rmse: 16.0627\tvalid_1's rmse: 54.6845\n",
      "[450]\ttraining's rmse: 14.8959\tvalid_1's rmse: 54.5285\n",
      "[480]\ttraining's rmse: 13.8531\tvalid_1's rmse: 54.3839\n",
      "[510]\ttraining's rmse: 12.9175\tvalid_1's rmse: 54.2766\n",
      "[540]\ttraining's rmse: 12.0533\tvalid_1's rmse: 54.1888\n",
      "[570]\ttraining's rmse: 11.2726\tvalid_1's rmse: 54.1207\n",
      "[600]\ttraining's rmse: 10.532\tvalid_1's rmse: 54.0597\n",
      "[630]\ttraining's rmse: 9.86358\tvalid_1's rmse: 53.9738\n",
      "[660]\ttraining's rmse: 9.2348\tvalid_1's rmse: 53.9125\n",
      "[690]\ttraining's rmse: 8.67491\tvalid_1's rmse: 53.8648\n",
      "[720]\ttraining's rmse: 8.15228\tvalid_1's rmse: 53.8141\n",
      "[750]\ttraining's rmse: 7.65587\tvalid_1's rmse: 53.7772\n",
      "[780]\ttraining's rmse: 7.19784\tvalid_1's rmse: 53.7455\n",
      "[810]\ttraining's rmse: 6.7688\tvalid_1's rmse: 53.7178\n",
      "[840]\ttraining's rmse: 6.37903\tvalid_1's rmse: 53.6965\n",
      "[870]\ttraining's rmse: 6.01026\tvalid_1's rmse: 53.6642\n",
      "[900]\ttraining's rmse: 5.66502\tvalid_1's rmse: 53.6413\n",
      "[930]\ttraining's rmse: 5.3479\tvalid_1's rmse: 53.616\n",
      "[960]\ttraining's rmse: 5.0474\tvalid_1's rmse: 53.5882\n",
      "[990]\ttraining's rmse: 4.76235\tvalid_1's rmse: 53.5662\n",
      "[1020]\ttraining's rmse: 4.50167\tvalid_1's rmse: 53.5621\n",
      "[1050]\ttraining's rmse: 4.25082\tvalid_1's rmse: 53.5387\n",
      "[1080]\ttraining's rmse: 4.01901\tvalid_1's rmse: 53.5197\n",
      "[1110]\ttraining's rmse: 3.80108\tvalid_1's rmse: 53.5194\n",
      "[1140]\ttraining's rmse: 3.59832\tvalid_1's rmse: 53.5082\n",
      "[1170]\ttraining's rmse: 3.40443\tvalid_1's rmse: 53.4964\n",
      "[1200]\ttraining's rmse: 3.22691\tvalid_1's rmse: 53.4854\n",
      "[1230]\ttraining's rmse: 3.05454\tvalid_1's rmse: 53.4737\n",
      "[1260]\ttraining's rmse: 2.88829\tvalid_1's rmse: 53.4638\n",
      "[1290]\ttraining's rmse: 2.7359\tvalid_1's rmse: 53.4549\n",
      "[1320]\ttraining's rmse: 2.59426\tvalid_1's rmse: 53.4455\n",
      "[1350]\ttraining's rmse: 2.45828\tvalid_1's rmse: 53.4389\n",
      "[1380]\ttraining's rmse: 2.33292\tvalid_1's rmse: 53.4319\n",
      "[1410]\ttraining's rmse: 2.21205\tvalid_1's rmse: 53.4274\n",
      "[1440]\ttraining's rmse: 2.10094\tvalid_1's rmse: 53.4201\n",
      "[1470]\ttraining's rmse: 1.99729\tvalid_1's rmse: 53.4174\n",
      "[1500]\ttraining's rmse: 1.89785\tvalid_1's rmse: 53.4129\n",
      "[1530]\ttraining's rmse: 1.80121\tvalid_1's rmse: 53.4075\n",
      "[1560]\ttraining's rmse: 1.70963\tvalid_1's rmse: 53.4014\n",
      "[1590]\ttraining's rmse: 1.6246\tvalid_1's rmse: 53.3947\n",
      "[1620]\ttraining's rmse: 1.54382\tvalid_1's rmse: 53.3939\n",
      "[1650]\ttraining's rmse: 1.46612\tvalid_1's rmse: 53.3882\n",
      "[1680]\ttraining's rmse: 1.39378\tvalid_1's rmse: 53.3839\n",
      "[1710]\ttraining's rmse: 1.32553\tvalid_1's rmse: 53.3813\n",
      "[1740]\ttraining's rmse: 1.26156\tvalid_1's rmse: 53.3776\n",
      "[1770]\ttraining's rmse: 1.19995\tvalid_1's rmse: 53.3751\n",
      "[1800]\ttraining's rmse: 1.1421\tvalid_1's rmse: 53.3737\n",
      "[1830]\ttraining's rmse: 1.08602\tvalid_1's rmse: 53.3717\n",
      "[1860]\ttraining's rmse: 1.03264\tvalid_1's rmse: 53.3684\n",
      "[1890]\ttraining's rmse: 0.9818\tvalid_1's rmse: 53.3677\n",
      "[1920]\ttraining's rmse: 0.934987\tvalid_1's rmse: 53.3653\n",
      "[1950]\ttraining's rmse: 0.890435\tvalid_1's rmse: 53.3645\n",
      "[1980]\ttraining's rmse: 0.848108\tvalid_1's rmse: 53.3626\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's rmse: 0.821633\tvalid_1's rmse: 53.3623\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002178 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 20020\n",
      "[LightGBM] [Info] Number of data points in the train set: 9219, number of used features: 79\n",
      "[LightGBM] [Info] Start training from score 375.469807\n",
      "Training until validation scores don't improve for 125 rounds\n",
      "[30]\ttraining's rmse: 162.773\tvalid_1's rmse: 164.739\n",
      "[60]\ttraining's rmse: 101.728\tvalid_1's rmse: 111.419\n",
      "[90]\ttraining's rmse: 68.5777\tvalid_1's rmse: 84.7913\n",
      "[120]\ttraining's rmse: 50.498\tvalid_1's rmse: 72.2547\n",
      "[150]\ttraining's rmse: 40.466\tvalid_1's rmse: 65.9848\n",
      "[180]\ttraining's rmse: 34.3051\tvalid_1's rmse: 62.6834\n",
      "[210]\ttraining's rmse: 30.1536\tvalid_1's rmse: 60.7937\n",
      "[240]\ttraining's rmse: 26.9511\tvalid_1's rmse: 59.5154\n",
      "[270]\ttraining's rmse: 24.2998\tvalid_1's rmse: 58.5751\n",
      "[300]\ttraining's rmse: 22.113\tvalid_1's rmse: 57.9425\n",
      "[330]\ttraining's rmse: 20.2885\tvalid_1's rmse: 57.5609\n",
      "[360]\ttraining's rmse: 18.6866\tvalid_1's rmse: 57.3102\n",
      "[390]\ttraining's rmse: 17.2762\tvalid_1's rmse: 57.1025\n",
      "[420]\ttraining's rmse: 16.0015\tvalid_1's rmse: 56.8826\n",
      "[450]\ttraining's rmse: 14.8322\tvalid_1's rmse: 56.7569\n",
      "[480]\ttraining's rmse: 13.7963\tvalid_1's rmse: 56.6011\n",
      "[510]\ttraining's rmse: 12.844\tvalid_1's rmse: 56.5164\n",
      "[540]\ttraining's rmse: 11.9907\tvalid_1's rmse: 56.4036\n",
      "[570]\ttraining's rmse: 11.2152\tvalid_1's rmse: 56.3409\n",
      "[600]\ttraining's rmse: 10.4943\tvalid_1's rmse: 56.2412\n",
      "[630]\ttraining's rmse: 9.80301\tvalid_1's rmse: 56.1841\n",
      "[660]\ttraining's rmse: 9.20591\tvalid_1's rmse: 56.1693\n",
      "[690]\ttraining's rmse: 8.65315\tvalid_1's rmse: 56.1214\n",
      "[720]\ttraining's rmse: 8.13195\tvalid_1's rmse: 56.0654\n",
      "[750]\ttraining's rmse: 7.66429\tvalid_1's rmse: 56.0246\n",
      "[780]\ttraining's rmse: 7.2118\tvalid_1's rmse: 55.9777\n",
      "[810]\ttraining's rmse: 6.7929\tvalid_1's rmse: 55.9548\n",
      "[840]\ttraining's rmse: 6.40409\tvalid_1's rmse: 55.9285\n",
      "[870]\ttraining's rmse: 6.03695\tvalid_1's rmse: 55.908\n",
      "[900]\ttraining's rmse: 5.69853\tvalid_1's rmse: 55.8856\n",
      "[930]\ttraining's rmse: 5.38308\tvalid_1's rmse: 55.8581\n",
      "[960]\ttraining's rmse: 5.07915\tvalid_1's rmse: 55.8228\n",
      "[990]\ttraining's rmse: 4.8074\tvalid_1's rmse: 55.811\n",
      "[1020]\ttraining's rmse: 4.54251\tvalid_1's rmse: 55.7964\n",
      "[1050]\ttraining's rmse: 4.29365\tvalid_1's rmse: 55.7822\n",
      "[1080]\ttraining's rmse: 4.06083\tvalid_1's rmse: 55.7601\n",
      "[1110]\ttraining's rmse: 3.85347\tvalid_1's rmse: 55.7481\n",
      "[1140]\ttraining's rmse: 3.65509\tvalid_1's rmse: 55.7377\n",
      "[1170]\ttraining's rmse: 3.46655\tvalid_1's rmse: 55.7272\n",
      "[1200]\ttraining's rmse: 3.283\tvalid_1's rmse: 55.7142\n",
      "[1230]\ttraining's rmse: 3.1124\tvalid_1's rmse: 55.7057\n",
      "[1260]\ttraining's rmse: 2.94573\tvalid_1's rmse: 55.6899\n",
      "[1290]\ttraining's rmse: 2.79408\tvalid_1's rmse: 55.6829\n",
      "[1320]\ttraining's rmse: 2.65224\tvalid_1's rmse: 55.6702\n",
      "[1350]\ttraining's rmse: 2.51554\tvalid_1's rmse: 55.6633\n",
      "[1380]\ttraining's rmse: 2.3864\tvalid_1's rmse: 55.6491\n",
      "[1410]\ttraining's rmse: 2.26644\tvalid_1's rmse: 55.6418\n",
      "[1440]\ttraining's rmse: 2.15329\tvalid_1's rmse: 55.6379\n",
      "[1470]\ttraining's rmse: 2.04391\tvalid_1's rmse: 55.6301\n",
      "[1500]\ttraining's rmse: 1.94406\tvalid_1's rmse: 55.6277\n",
      "[1530]\ttraining's rmse: 1.84819\tvalid_1's rmse: 55.6306\n",
      "[1560]\ttraining's rmse: 1.75754\tvalid_1's rmse: 55.6216\n",
      "[1590]\ttraining's rmse: 1.66852\tvalid_1's rmse: 55.6171\n",
      "[1620]\ttraining's rmse: 1.58689\tvalid_1's rmse: 55.6136\n",
      "[1650]\ttraining's rmse: 1.50978\tvalid_1's rmse: 55.6117\n",
      "[1680]\ttraining's rmse: 1.43556\tvalid_1's rmse: 55.6086\n",
      "[1710]\ttraining's rmse: 1.36707\tvalid_1's rmse: 55.6068\n",
      "[1740]\ttraining's rmse: 1.29991\tvalid_1's rmse: 55.6035\n",
      "[1770]\ttraining's rmse: 1.23703\tvalid_1's rmse: 55.6007\n",
      "[1800]\ttraining's rmse: 1.17926\tvalid_1's rmse: 55.5989\n",
      "[1830]\ttraining's rmse: 1.1227\tvalid_1's rmse: 55.5952\n",
      "[1860]\ttraining's rmse: 1.0698\tvalid_1's rmse: 55.593\n",
      "[1890]\ttraining's rmse: 1.0195\tvalid_1's rmse: 55.5883\n",
      "[1920]\ttraining's rmse: 0.971459\tvalid_1's rmse: 55.5847\n",
      "[1950]\ttraining's rmse: 0.926886\tvalid_1's rmse: 55.5847\n",
      "[1980]\ttraining's rmse: 0.882806\tvalid_1's rmse: 55.5815\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's rmse: 0.855711\tvalid_1's rmse: 55.5809\n",
      "18\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002326 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 20022\n",
      "[LightGBM] [Info] Number of data points in the train set: 9219, number of used features: 79\n",
      "[LightGBM] [Info] Start training from score 369.976424\n",
      "Training until validation scores don't improve for 125 rounds\n",
      "[30]\ttraining's rmse: 150.932\tvalid_1's rmse: 151.668\n",
      "[60]\ttraining's rmse: 93.4522\tvalid_1's rmse: 99.8188\n",
      "[90]\ttraining's rmse: 62.6007\tvalid_1's rmse: 74.6249\n",
      "[120]\ttraining's rmse: 46.0024\tvalid_1's rmse: 63.1093\n",
      "[150]\ttraining's rmse: 36.8151\tvalid_1's rmse: 57.7779\n",
      "[180]\ttraining's rmse: 31.2253\tvalid_1's rmse: 55.2254\n",
      "[210]\ttraining's rmse: 27.3176\tvalid_1's rmse: 53.7017\n",
      "[240]\ttraining's rmse: 24.3332\tvalid_1's rmse: 52.7575\n",
      "[270]\ttraining's rmse: 21.8969\tvalid_1's rmse: 52.005\n",
      "[300]\ttraining's rmse: 19.9339\tvalid_1's rmse: 51.5702\n",
      "[330]\ttraining's rmse: 18.239\tvalid_1's rmse: 51.1614\n",
      "[360]\ttraining's rmse: 16.8254\tvalid_1's rmse: 50.8957\n",
      "[390]\ttraining's rmse: 15.5114\tvalid_1's rmse: 50.675\n",
      "[420]\ttraining's rmse: 14.3888\tvalid_1's rmse: 50.5226\n",
      "[450]\ttraining's rmse: 13.359\tvalid_1's rmse: 50.3564\n",
      "[480]\ttraining's rmse: 12.4333\tvalid_1's rmse: 50.2263\n",
      "[510]\ttraining's rmse: 11.594\tvalid_1's rmse: 50.114\n",
      "[540]\ttraining's rmse: 10.8215\tvalid_1's rmse: 50.0088\n",
      "[570]\ttraining's rmse: 10.1171\tvalid_1's rmse: 49.9398\n",
      "[600]\ttraining's rmse: 9.46386\tvalid_1's rmse: 49.8733\n",
      "[630]\ttraining's rmse: 8.86305\tvalid_1's rmse: 49.8297\n",
      "[660]\ttraining's rmse: 8.31179\tvalid_1's rmse: 49.7829\n",
      "[690]\ttraining's rmse: 7.81342\tvalid_1's rmse: 49.7375\n",
      "[720]\ttraining's rmse: 7.34576\tvalid_1's rmse: 49.6959\n",
      "[750]\ttraining's rmse: 6.8996\tvalid_1's rmse: 49.6591\n",
      "[780]\ttraining's rmse: 6.50084\tvalid_1's rmse: 49.6292\n",
      "[810]\ttraining's rmse: 6.12927\tvalid_1's rmse: 49.5986\n",
      "[840]\ttraining's rmse: 5.7783\tvalid_1's rmse: 49.5844\n",
      "[870]\ttraining's rmse: 5.44456\tvalid_1's rmse: 49.5512\n",
      "[900]\ttraining's rmse: 5.14138\tvalid_1's rmse: 49.52\n",
      "[930]\ttraining's rmse: 4.84693\tvalid_1's rmse: 49.5013\n",
      "[960]\ttraining's rmse: 4.57691\tvalid_1's rmse: 49.4925\n",
      "[990]\ttraining's rmse: 4.32551\tvalid_1's rmse: 49.4803\n",
      "[1020]\ttraining's rmse: 4.0923\tvalid_1's rmse: 49.4478\n",
      "[1050]\ttraining's rmse: 3.87213\tvalid_1's rmse: 49.4352\n",
      "[1080]\ttraining's rmse: 3.66509\tvalid_1's rmse: 49.4189\n",
      "[1110]\ttraining's rmse: 3.47271\tvalid_1's rmse: 49.4098\n",
      "[1140]\ttraining's rmse: 3.28453\tvalid_1's rmse: 49.389\n",
      "[1170]\ttraining's rmse: 3.1086\tvalid_1's rmse: 49.3762\n",
      "[1200]\ttraining's rmse: 2.94746\tvalid_1's rmse: 49.3639\n",
      "[1230]\ttraining's rmse: 2.7924\tvalid_1's rmse: 49.3537\n",
      "[1260]\ttraining's rmse: 2.64578\tvalid_1's rmse: 49.3433\n",
      "[1290]\ttraining's rmse: 2.50671\tvalid_1's rmse: 49.3412\n",
      "[1320]\ttraining's rmse: 2.37443\tvalid_1's rmse: 49.3333\n",
      "[1350]\ttraining's rmse: 2.25309\tvalid_1's rmse: 49.328\n",
      "[1380]\ttraining's rmse: 2.14136\tvalid_1's rmse: 49.3224\n",
      "[1410]\ttraining's rmse: 2.03056\tvalid_1's rmse: 49.3152\n",
      "[1440]\ttraining's rmse: 1.92948\tvalid_1's rmse: 49.3128\n",
      "[1470]\ttraining's rmse: 1.83171\tvalid_1's rmse: 49.308\n",
      "[1500]\ttraining's rmse: 1.7411\tvalid_1's rmse: 49.3026\n",
      "[1530]\ttraining's rmse: 1.65478\tvalid_1's rmse: 49.2983\n",
      "[1560]\ttraining's rmse: 1.57226\tvalid_1's rmse: 49.2918\n",
      "[1590]\ttraining's rmse: 1.4941\tvalid_1's rmse: 49.288\n",
      "[1620]\ttraining's rmse: 1.4201\tvalid_1's rmse: 49.2834\n",
      "[1650]\ttraining's rmse: 1.34927\tvalid_1's rmse: 49.28\n",
      "[1680]\ttraining's rmse: 1.28424\tvalid_1's rmse: 49.2751\n",
      "[1710]\ttraining's rmse: 1.22182\tvalid_1's rmse: 49.2732\n",
      "[1740]\ttraining's rmse: 1.16319\tvalid_1's rmse: 49.2711\n",
      "[1770]\ttraining's rmse: 1.10636\tvalid_1's rmse: 49.2705\n",
      "[1800]\ttraining's rmse: 1.05122\tvalid_1's rmse: 49.2669\n",
      "[1830]\ttraining's rmse: 0.999355\tvalid_1's rmse: 49.2639\n",
      "[1860]\ttraining's rmse: 0.950764\tvalid_1's rmse: 49.2608\n",
      "[1890]\ttraining's rmse: 0.905236\tvalid_1's rmse: 49.2582\n",
      "[1920]\ttraining's rmse: 0.860932\tvalid_1's rmse: 49.2573\n",
      "[1950]\ttraining's rmse: 0.820127\tvalid_1's rmse: 49.2588\n",
      "[1980]\ttraining's rmse: 0.780714\tvalid_1's rmse: 49.2585\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's rmse: 0.755904\tvalid_1's rmse: 49.2581\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002626 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 20022\n",
      "[LightGBM] [Info] Number of data points in the train set: 9219, number of used features: 79\n",
      "[LightGBM] [Info] Start training from score 369.295247\n",
      "Training until validation scores don't improve for 125 rounds\n",
      "[30]\ttraining's rmse: 151.955\tvalid_1's rmse: 157.417\n",
      "[60]\ttraining's rmse: 95.0882\tvalid_1's rmse: 107.753\n",
      "[90]\ttraining's rmse: 64.4912\tvalid_1's rmse: 83.4001\n",
      "[120]\ttraining's rmse: 47.746\tvalid_1's rmse: 71.9332\n",
      "[150]\ttraining's rmse: 38.3517\tvalid_1's rmse: 66.3151\n",
      "[180]\ttraining's rmse: 32.5685\tvalid_1's rmse: 63.4409\n",
      "[210]\ttraining's rmse: 28.5017\tvalid_1's rmse: 61.873\n",
      "[240]\ttraining's rmse: 25.4019\tvalid_1's rmse: 60.5868\n",
      "[270]\ttraining's rmse: 22.9191\tvalid_1's rmse: 59.8671\n",
      "[300]\ttraining's rmse: 20.8488\tvalid_1's rmse: 59.3958\n",
      "[330]\ttraining's rmse: 19.0704\tvalid_1's rmse: 58.9059\n",
      "[360]\ttraining's rmse: 17.5691\tvalid_1's rmse: 58.6544\n",
      "[390]\ttraining's rmse: 16.2279\tvalid_1's rmse: 58.3955\n",
      "[420]\ttraining's rmse: 15.0382\tvalid_1's rmse: 58.1646\n",
      "[450]\ttraining's rmse: 13.9515\tvalid_1's rmse: 57.9933\n",
      "[480]\ttraining's rmse: 12.9842\tvalid_1's rmse: 57.8509\n",
      "[510]\ttraining's rmse: 12.0622\tvalid_1's rmse: 57.7579\n",
      "[540]\ttraining's rmse: 11.2509\tvalid_1's rmse: 57.6422\n",
      "[570]\ttraining's rmse: 10.5243\tvalid_1's rmse: 57.5385\n",
      "[600]\ttraining's rmse: 9.84547\tvalid_1's rmse: 57.4734\n",
      "[630]\ttraining's rmse: 9.22453\tvalid_1's rmse: 57.4081\n",
      "[660]\ttraining's rmse: 8.64912\tvalid_1's rmse: 57.3635\n",
      "[690]\ttraining's rmse: 8.12105\tvalid_1's rmse: 57.3134\n",
      "[720]\ttraining's rmse: 7.62528\tvalid_1's rmse: 57.2466\n",
      "[750]\ttraining's rmse: 7.16854\tvalid_1's rmse: 57.2135\n",
      "[780]\ttraining's rmse: 6.74961\tvalid_1's rmse: 57.1956\n",
      "[810]\ttraining's rmse: 6.35327\tvalid_1's rmse: 57.1642\n",
      "[840]\ttraining's rmse: 5.99103\tvalid_1's rmse: 57.1455\n",
      "[870]\ttraining's rmse: 5.64641\tvalid_1's rmse: 57.1326\n",
      "[900]\ttraining's rmse: 5.32401\tvalid_1's rmse: 57.114\n",
      "[930]\ttraining's rmse: 5.01903\tvalid_1's rmse: 57.0943\n",
      "[960]\ttraining's rmse: 4.73122\tvalid_1's rmse: 57.0702\n",
      "[990]\ttraining's rmse: 4.46566\tvalid_1's rmse: 57.0678\n",
      "[1020]\ttraining's rmse: 4.21427\tvalid_1's rmse: 57.0487\n",
      "[1050]\ttraining's rmse: 3.9816\tvalid_1's rmse: 57.0426\n",
      "[1080]\ttraining's rmse: 3.76267\tvalid_1's rmse: 57.032\n",
      "[1110]\ttraining's rmse: 3.55783\tvalid_1's rmse: 57.0194\n",
      "[1140]\ttraining's rmse: 3.36526\tvalid_1's rmse: 57.0099\n",
      "[1170]\ttraining's rmse: 3.18561\tvalid_1's rmse: 57.009\n",
      "[1200]\ttraining's rmse: 3.01483\tvalid_1's rmse: 56.9967\n",
      "[1230]\ttraining's rmse: 2.85254\tvalid_1's rmse: 56.991\n",
      "[1260]\ttraining's rmse: 2.70282\tvalid_1's rmse: 56.9798\n",
      "[1290]\ttraining's rmse: 2.55872\tvalid_1's rmse: 56.9785\n",
      "[1320]\ttraining's rmse: 2.42683\tvalid_1's rmse: 56.977\n",
      "[1350]\ttraining's rmse: 2.30044\tvalid_1's rmse: 56.9661\n",
      "[1380]\ttraining's rmse: 2.18402\tvalid_1's rmse: 56.9645\n",
      "[1410]\ttraining's rmse: 2.07168\tvalid_1's rmse: 56.9622\n",
      "[1440]\ttraining's rmse: 1.96264\tvalid_1's rmse: 56.9604\n",
      "[1470]\ttraining's rmse: 1.86399\tvalid_1's rmse: 56.9566\n",
      "[1500]\ttraining's rmse: 1.76862\tvalid_1's rmse: 56.9514\n",
      "[1530]\ttraining's rmse: 1.67901\tvalid_1's rmse: 56.951\n",
      "[1560]\ttraining's rmse: 1.59317\tvalid_1's rmse: 56.9466\n",
      "[1590]\ttraining's rmse: 1.51445\tvalid_1's rmse: 56.9437\n",
      "[1620]\ttraining's rmse: 1.43743\tvalid_1's rmse: 56.9437\n",
      "[1650]\ttraining's rmse: 1.36707\tvalid_1's rmse: 56.9418\n",
      "[1680]\ttraining's rmse: 1.29879\tvalid_1's rmse: 56.9401\n",
      "[1710]\ttraining's rmse: 1.23382\tvalid_1's rmse: 56.9395\n",
      "[1740]\ttraining's rmse: 1.17298\tvalid_1's rmse: 56.9376\n",
      "[1770]\ttraining's rmse: 1.11381\tvalid_1's rmse: 56.9341\n",
      "[1800]\ttraining's rmse: 1.05833\tvalid_1's rmse: 56.9346\n",
      "[1830]\ttraining's rmse: 1.00498\tvalid_1's rmse: 56.9344\n",
      "[1860]\ttraining's rmse: 0.955983\tvalid_1's rmse: 56.9328\n",
      "[1890]\ttraining's rmse: 0.908531\tvalid_1's rmse: 56.9312\n",
      "[1920]\ttraining's rmse: 0.86521\tvalid_1's rmse: 56.9301\n",
      "[1950]\ttraining's rmse: 0.823129\tvalid_1's rmse: 56.9285\n",
      "[1980]\ttraining's rmse: 0.782548\tvalid_1's rmse: 56.9273\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's rmse: 0.75691\tvalid_1's rmse: 56.9262\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002363 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 20022\n",
      "[LightGBM] [Info] Number of data points in the train set: 9219, number of used features: 79\n",
      "[LightGBM] [Info] Start training from score 370.680730\n",
      "Training until validation scores don't improve for 125 rounds\n",
      "[30]\ttraining's rmse: 153.291\tvalid_1's rmse: 154.643\n",
      "[60]\ttraining's rmse: 96.2858\tvalid_1's rmse: 104.622\n",
      "[90]\ttraining's rmse: 64.9447\tvalid_1's rmse: 79.7053\n",
      "[120]\ttraining's rmse: 48.0209\tvalid_1's rmse: 67.9403\n",
      "[150]\ttraining's rmse: 38.6671\tvalid_1's rmse: 62.339\n",
      "[180]\ttraining's rmse: 32.9128\tvalid_1's rmse: 59.4373\n",
      "[210]\ttraining's rmse: 28.8417\tvalid_1's rmse: 57.7426\n",
      "[240]\ttraining's rmse: 25.713\tvalid_1's rmse: 56.693\n",
      "[270]\ttraining's rmse: 23.1675\tvalid_1's rmse: 55.8922\n",
      "[300]\ttraining's rmse: 21.0333\tvalid_1's rmse: 55.4021\n",
      "[330]\ttraining's rmse: 19.2113\tvalid_1's rmse: 55.0293\n",
      "[360]\ttraining's rmse: 17.6787\tvalid_1's rmse: 54.8005\n",
      "[390]\ttraining's rmse: 16.307\tvalid_1's rmse: 54.5935\n",
      "[420]\ttraining's rmse: 15.0875\tvalid_1's rmse: 54.3972\n",
      "[450]\ttraining's rmse: 13.9926\tvalid_1's rmse: 54.2203\n",
      "[480]\ttraining's rmse: 12.983\tvalid_1's rmse: 54.1076\n",
      "[510]\ttraining's rmse: 12.0828\tvalid_1's rmse: 53.9852\n",
      "[540]\ttraining's rmse: 11.275\tvalid_1's rmse: 53.9296\n",
      "[570]\ttraining's rmse: 10.5219\tvalid_1's rmse: 53.851\n",
      "[600]\ttraining's rmse: 9.82439\tvalid_1's rmse: 53.8074\n",
      "[630]\ttraining's rmse: 9.20463\tvalid_1's rmse: 53.7459\n",
      "[660]\ttraining's rmse: 8.6286\tvalid_1's rmse: 53.6757\n",
      "[690]\ttraining's rmse: 8.1062\tvalid_1's rmse: 53.6245\n",
      "[720]\ttraining's rmse: 7.60765\tvalid_1's rmse: 53.5607\n",
      "[750]\ttraining's rmse: 7.13659\tvalid_1's rmse: 53.5229\n",
      "[780]\ttraining's rmse: 6.72392\tvalid_1's rmse: 53.5093\n",
      "[810]\ttraining's rmse: 6.33238\tvalid_1's rmse: 53.4723\n",
      "[840]\ttraining's rmse: 5.96591\tvalid_1's rmse: 53.4496\n",
      "[870]\ttraining's rmse: 5.62415\tvalid_1's rmse: 53.4304\n",
      "[900]\ttraining's rmse: 5.30534\tvalid_1's rmse: 53.4023\n",
      "[930]\ttraining's rmse: 5.00586\tvalid_1's rmse: 53.3945\n",
      "[960]\ttraining's rmse: 4.72757\tvalid_1's rmse: 53.3869\n",
      "[990]\ttraining's rmse: 4.46863\tvalid_1's rmse: 53.3747\n",
      "[1020]\ttraining's rmse: 4.22491\tvalid_1's rmse: 53.3678\n",
      "[1050]\ttraining's rmse: 3.99352\tvalid_1's rmse: 53.3529\n",
      "[1080]\ttraining's rmse: 3.77771\tvalid_1's rmse: 53.3445\n",
      "[1110]\ttraining's rmse: 3.57331\tvalid_1's rmse: 53.3433\n",
      "[1140]\ttraining's rmse: 3.38017\tvalid_1's rmse: 53.3266\n",
      "[1170]\ttraining's rmse: 3.20207\tvalid_1's rmse: 53.3099\n",
      "[1200]\ttraining's rmse: 3.03297\tvalid_1's rmse: 53.3013\n",
      "[1230]\ttraining's rmse: 2.87432\tvalid_1's rmse: 53.2943\n",
      "[1260]\ttraining's rmse: 2.72241\tvalid_1's rmse: 53.29\n",
      "[1290]\ttraining's rmse: 2.5822\tvalid_1's rmse: 53.2849\n",
      "[1320]\ttraining's rmse: 2.4477\tvalid_1's rmse: 53.2849\n",
      "[1350]\ttraining's rmse: 2.32551\tvalid_1's rmse: 53.2772\n",
      "[1380]\ttraining's rmse: 2.20365\tvalid_1's rmse: 53.2722\n",
      "[1410]\ttraining's rmse: 2.09086\tvalid_1's rmse: 53.2718\n",
      "[1440]\ttraining's rmse: 1.98625\tvalid_1's rmse: 53.2689\n",
      "[1470]\ttraining's rmse: 1.88596\tvalid_1's rmse: 53.2679\n",
      "[1500]\ttraining's rmse: 1.79251\tvalid_1's rmse: 53.2661\n",
      "[1530]\ttraining's rmse: 1.70354\tvalid_1's rmse: 53.2643\n",
      "[1560]\ttraining's rmse: 1.6207\tvalid_1's rmse: 53.2592\n",
      "[1590]\ttraining's rmse: 1.54119\tvalid_1's rmse: 53.2565\n",
      "[1620]\ttraining's rmse: 1.46676\tvalid_1's rmse: 53.2528\n",
      "[1650]\ttraining's rmse: 1.39614\tvalid_1's rmse: 53.2517\n",
      "[1680]\ttraining's rmse: 1.32763\tvalid_1's rmse: 53.2488\n",
      "[1710]\ttraining's rmse: 1.26277\tvalid_1's rmse: 53.2481\n",
      "[1740]\ttraining's rmse: 1.20139\tvalid_1's rmse: 53.251\n",
      "[1770]\ttraining's rmse: 1.14359\tvalid_1's rmse: 53.2495\n",
      "[1800]\ttraining's rmse: 1.09052\tvalid_1's rmse: 53.2471\n",
      "[1830]\ttraining's rmse: 1.0372\tvalid_1's rmse: 53.2458\n",
      "[1860]\ttraining's rmse: 0.986541\tvalid_1's rmse: 53.2446\n",
      "[1890]\ttraining's rmse: 0.938721\tvalid_1's rmse: 53.2454\n",
      "[1920]\ttraining's rmse: 0.894495\tvalid_1's rmse: 53.2436\n",
      "[1950]\ttraining's rmse: 0.851732\tvalid_1's rmse: 53.2426\n",
      "[1980]\ttraining's rmse: 0.811218\tvalid_1's rmse: 53.2427\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's rmse: 0.786137\tvalid_1's rmse: 53.2425\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003344 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 20022\n",
      "[LightGBM] [Info] Number of data points in the train set: 9219, number of used features: 79\n",
      "[LightGBM] [Info] Start training from score 367.729997\n",
      "Training until validation scores don't improve for 125 rounds\n",
      "[30]\ttraining's rmse: 153.756\tvalid_1's rmse: 159.051\n",
      "[60]\ttraining's rmse: 96.6959\tvalid_1's rmse: 108.962\n",
      "[90]\ttraining's rmse: 66.0254\tvalid_1's rmse: 84.5797\n",
      "[120]\ttraining's rmse: 49.4516\tvalid_1's rmse: 72.8882\n",
      "[150]\ttraining's rmse: 40.0178\tvalid_1's rmse: 67.0892\n",
      "[180]\ttraining's rmse: 34.1472\tvalid_1's rmse: 63.7232\n",
      "[210]\ttraining's rmse: 30.0038\tvalid_1's rmse: 61.6543\n",
      "[240]\ttraining's rmse: 26.8091\tvalid_1's rmse: 60.2683\n",
      "[270]\ttraining's rmse: 24.2448\tvalid_1's rmse: 59.474\n",
      "[300]\ttraining's rmse: 22.0474\tvalid_1's rmse: 58.883\n",
      "[330]\ttraining's rmse: 20.184\tvalid_1's rmse: 58.5141\n",
      "[360]\ttraining's rmse: 18.5767\tvalid_1's rmse: 58.1659\n",
      "[390]\ttraining's rmse: 17.1548\tvalid_1's rmse: 57.9173\n",
      "[420]\ttraining's rmse: 15.8964\tvalid_1's rmse: 57.7683\n",
      "[450]\ttraining's rmse: 14.7576\tvalid_1's rmse: 57.5952\n",
      "[480]\ttraining's rmse: 13.7232\tvalid_1's rmse: 57.4476\n",
      "[510]\ttraining's rmse: 12.7835\tvalid_1's rmse: 57.3163\n",
      "[540]\ttraining's rmse: 11.9349\tvalid_1's rmse: 57.2131\n",
      "[570]\ttraining's rmse: 11.1488\tvalid_1's rmse: 57.1125\n",
      "[600]\ttraining's rmse: 10.4307\tvalid_1's rmse: 57.038\n",
      "[630]\ttraining's rmse: 9.76314\tvalid_1's rmse: 56.9634\n",
      "[660]\ttraining's rmse: 9.15948\tvalid_1's rmse: 56.8965\n",
      "[690]\ttraining's rmse: 8.59248\tvalid_1's rmse: 56.8333\n",
      "[720]\ttraining's rmse: 8.07333\tvalid_1's rmse: 56.7863\n",
      "[750]\ttraining's rmse: 7.58654\tvalid_1's rmse: 56.7449\n",
      "[780]\ttraining's rmse: 7.13914\tvalid_1's rmse: 56.7105\n",
      "[810]\ttraining's rmse: 6.72091\tvalid_1's rmse: 56.6893\n",
      "[840]\ttraining's rmse: 6.33528\tvalid_1's rmse: 56.6644\n",
      "[870]\ttraining's rmse: 5.97981\tvalid_1's rmse: 56.6376\n",
      "[900]\ttraining's rmse: 5.64183\tvalid_1's rmse: 56.6183\n",
      "[930]\ttraining's rmse: 5.33299\tvalid_1's rmse: 56.6035\n",
      "[960]\ttraining's rmse: 5.04509\tvalid_1's rmse: 56.5918\n",
      "[990]\ttraining's rmse: 4.77339\tvalid_1's rmse: 56.5775\n",
      "[1020]\ttraining's rmse: 4.5154\tvalid_1's rmse: 56.5558\n",
      "[1050]\ttraining's rmse: 4.27615\tvalid_1's rmse: 56.5402\n",
      "[1080]\ttraining's rmse: 4.05307\tvalid_1's rmse: 56.5284\n",
      "[1110]\ttraining's rmse: 3.83606\tvalid_1's rmse: 56.5094\n",
      "[1140]\ttraining's rmse: 3.63843\tvalid_1's rmse: 56.4919\n",
      "[1170]\ttraining's rmse: 3.44572\tvalid_1's rmse: 56.4791\n",
      "[1200]\ttraining's rmse: 3.26974\tvalid_1's rmse: 56.4729\n",
      "[1230]\ttraining's rmse: 3.10408\tvalid_1's rmse: 56.467\n",
      "[1260]\ttraining's rmse: 2.94597\tvalid_1's rmse: 56.46\n",
      "[1290]\ttraining's rmse: 2.7985\tvalid_1's rmse: 56.4561\n",
      "[1320]\ttraining's rmse: 2.65898\tvalid_1's rmse: 56.4531\n",
      "[1350]\ttraining's rmse: 2.52475\tvalid_1's rmse: 56.4435\n",
      "[1380]\ttraining's rmse: 2.39936\tvalid_1's rmse: 56.4404\n",
      "[1410]\ttraining's rmse: 2.28282\tvalid_1's rmse: 56.4369\n",
      "[1440]\ttraining's rmse: 2.17338\tvalid_1's rmse: 56.4309\n",
      "[1470]\ttraining's rmse: 2.06748\tvalid_1's rmse: 56.4275\n",
      "[1500]\ttraining's rmse: 1.96937\tvalid_1's rmse: 56.4225\n",
      "[1530]\ttraining's rmse: 1.87468\tvalid_1's rmse: 56.421\n",
      "[1560]\ttraining's rmse: 1.78548\tvalid_1's rmse: 56.4211\n",
      "[1590]\ttraining's rmse: 1.70186\tvalid_1's rmse: 56.4178\n",
      "[1620]\ttraining's rmse: 1.62086\tvalid_1's rmse: 56.4135\n",
      "[1650]\ttraining's rmse: 1.54528\tvalid_1's rmse: 56.4129\n",
      "[1680]\ttraining's rmse: 1.47326\tvalid_1's rmse: 56.4109\n",
      "[1710]\ttraining's rmse: 1.40346\tvalid_1's rmse: 56.4103\n",
      "[1740]\ttraining's rmse: 1.34313\tvalid_1's rmse: 56.4055\n",
      "[1770]\ttraining's rmse: 1.28088\tvalid_1's rmse: 56.4027\n",
      "[1800]\ttraining's rmse: 1.22284\tvalid_1's rmse: 56.4018\n",
      "[1830]\ttraining's rmse: 1.16561\tvalid_1's rmse: 56.4024\n",
      "[1860]\ttraining's rmse: 1.11164\tvalid_1's rmse: 56.4015\n",
      "[1890]\ttraining's rmse: 1.06123\tvalid_1's rmse: 56.399\n",
      "[1920]\ttraining's rmse: 1.01566\tvalid_1's rmse: 56.3977\n",
      "[1950]\ttraining's rmse: 0.973099\tvalid_1's rmse: 56.3952\n",
      "[1980]\ttraining's rmse: 0.930002\tvalid_1's rmse: 56.3938\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's rmse: 0.903054\tvalid_1's rmse: 56.3937\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003545 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 20022\n",
      "[LightGBM] [Info] Number of data points in the train set: 9219, number of used features: 79\n",
      "[LightGBM] [Info] Start training from score 363.655210\n",
      "Training until validation scores don't improve for 125 rounds\n",
      "[30]\ttraining's rmse: 153.445\tvalid_1's rmse: 160.362\n",
      "[60]\ttraining's rmse: 96.2637\tvalid_1's rmse: 109.28\n",
      "[90]\ttraining's rmse: 65.4279\tvalid_1's rmse: 84.9421\n",
      "[120]\ttraining's rmse: 48.6897\tvalid_1's rmse: 73.6018\n",
      "[150]\ttraining's rmse: 39.1789\tvalid_1's rmse: 68.0952\n",
      "[180]\ttraining's rmse: 33.3248\tvalid_1's rmse: 65.4247\n",
      "[210]\ttraining's rmse: 29.2934\tvalid_1's rmse: 63.7441\n",
      "[240]\ttraining's rmse: 26.1088\tvalid_1's rmse: 62.6565\n",
      "[270]\ttraining's rmse: 23.541\tvalid_1's rmse: 61.8853\n",
      "[300]\ttraining's rmse: 21.411\tvalid_1's rmse: 61.3724\n",
      "[330]\ttraining's rmse: 19.5718\tvalid_1's rmse: 60.9903\n",
      "[360]\ttraining's rmse: 17.9643\tvalid_1's rmse: 60.639\n",
      "[390]\ttraining's rmse: 16.5464\tvalid_1's rmse: 60.4243\n",
      "[420]\ttraining's rmse: 15.292\tvalid_1's rmse: 60.271\n",
      "[450]\ttraining's rmse: 14.1691\tvalid_1's rmse: 60.1171\n",
      "[480]\ttraining's rmse: 13.1619\tvalid_1's rmse: 60.0027\n",
      "[510]\ttraining's rmse: 12.2387\tvalid_1's rmse: 59.8962\n",
      "[540]\ttraining's rmse: 11.4093\tvalid_1's rmse: 59.8019\n",
      "[570]\ttraining's rmse: 10.6649\tvalid_1's rmse: 59.6945\n",
      "[600]\ttraining's rmse: 9.96612\tvalid_1's rmse: 59.6173\n",
      "[630]\ttraining's rmse: 9.32949\tvalid_1's rmse: 59.5615\n",
      "[660]\ttraining's rmse: 8.75269\tvalid_1's rmse: 59.5217\n",
      "[690]\ttraining's rmse: 8.21467\tvalid_1's rmse: 59.4632\n",
      "[720]\ttraining's rmse: 7.71184\tvalid_1's rmse: 59.4465\n",
      "[750]\ttraining's rmse: 7.25179\tvalid_1's rmse: 59.407\n",
      "[780]\ttraining's rmse: 6.81614\tvalid_1's rmse: 59.3855\n",
      "[810]\ttraining's rmse: 6.41946\tvalid_1's rmse: 59.3556\n",
      "[840]\ttraining's rmse: 6.0374\tvalid_1's rmse: 59.3249\n",
      "[870]\ttraining's rmse: 5.68372\tvalid_1's rmse: 59.3216\n",
      "[900]\ttraining's rmse: 5.36072\tvalid_1's rmse: 59.3055\n",
      "[930]\ttraining's rmse: 5.06029\tvalid_1's rmse: 59.3015\n",
      "[960]\ttraining's rmse: 4.77713\tvalid_1's rmse: 59.2854\n",
      "[990]\ttraining's rmse: 4.50496\tvalid_1's rmse: 59.2753\n",
      "[1020]\ttraining's rmse: 4.25317\tvalid_1's rmse: 59.2594\n",
      "[1050]\ttraining's rmse: 4.02014\tvalid_1's rmse: 59.2472\n",
      "[1080]\ttraining's rmse: 3.79976\tvalid_1's rmse: 59.2464\n",
      "[1110]\ttraining's rmse: 3.59286\tvalid_1's rmse: 59.2372\n",
      "[1140]\ttraining's rmse: 3.40222\tvalid_1's rmse: 59.2247\n",
      "[1170]\ttraining's rmse: 3.22669\tvalid_1's rmse: 59.2168\n",
      "[1200]\ttraining's rmse: 3.05054\tvalid_1's rmse: 59.2129\n",
      "[1230]\ttraining's rmse: 2.88904\tvalid_1's rmse: 59.2086\n",
      "[1260]\ttraining's rmse: 2.74044\tvalid_1's rmse: 59.2052\n",
      "[1290]\ttraining's rmse: 2.59661\tvalid_1's rmse: 59.2047\n",
      "[1320]\ttraining's rmse: 2.46269\tvalid_1's rmse: 59.2003\n",
      "[1350]\ttraining's rmse: 2.33688\tvalid_1's rmse: 59.1982\n",
      "[1380]\ttraining's rmse: 2.2152\tvalid_1's rmse: 59.1975\n",
      "[1410]\ttraining's rmse: 2.10184\tvalid_1's rmse: 59.1947\n",
      "[1440]\ttraining's rmse: 1.99625\tvalid_1's rmse: 59.19\n",
      "[1470]\ttraining's rmse: 1.8971\tvalid_1's rmse: 59.1859\n",
      "[1500]\ttraining's rmse: 1.80185\tvalid_1's rmse: 59.1819\n",
      "[1530]\ttraining's rmse: 1.71296\tvalid_1's rmse: 59.1796\n",
      "[1560]\ttraining's rmse: 1.62749\tvalid_1's rmse: 59.1753\n",
      "[1590]\ttraining's rmse: 1.54525\tvalid_1's rmse: 59.1729\n",
      "[1620]\ttraining's rmse: 1.46928\tvalid_1's rmse: 59.1691\n",
      "[1650]\ttraining's rmse: 1.39519\tvalid_1's rmse: 59.1682\n",
      "[1680]\ttraining's rmse: 1.32688\tvalid_1's rmse: 59.1665\n",
      "[1710]\ttraining's rmse: 1.26116\tvalid_1's rmse: 59.1672\n",
      "[1740]\ttraining's rmse: 1.19933\tvalid_1's rmse: 59.1658\n",
      "[1770]\ttraining's rmse: 1.14131\tvalid_1's rmse: 59.1625\n",
      "[1800]\ttraining's rmse: 1.0859\tvalid_1's rmse: 59.1615\n",
      "[1830]\ttraining's rmse: 1.03307\tvalid_1's rmse: 59.1609\n",
      "[1860]\ttraining's rmse: 0.982989\tvalid_1's rmse: 59.1599\n",
      "[1890]\ttraining's rmse: 0.936957\tvalid_1's rmse: 59.1603\n",
      "[1920]\ttraining's rmse: 0.89201\tvalid_1's rmse: 59.1592\n",
      "[1950]\ttraining's rmse: 0.849469\tvalid_1's rmse: 59.1576\n",
      "[1980]\ttraining's rmse: 0.809385\tvalid_1's rmse: 59.1587\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's rmse: 0.783443\tvalid_1's rmse: 59.1585\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002200 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 20022\n",
      "[LightGBM] [Info] Number of data points in the train set: 9219, number of used features: 79\n",
      "[LightGBM] [Info] Start training from score 361.183391\n",
      "Training until validation scores don't improve for 125 rounds\n",
      "[30]\ttraining's rmse: 152.452\tvalid_1's rmse: 161.86\n",
      "[60]\ttraining's rmse: 95.6638\tvalid_1's rmse: 109.164\n",
      "[90]\ttraining's rmse: 64.5647\tvalid_1's rmse: 82.5031\n",
      "[120]\ttraining's rmse: 47.7568\tvalid_1's rmse: 69.8581\n",
      "[150]\ttraining's rmse: 38.1947\tvalid_1's rmse: 63.6019\n",
      "[180]\ttraining's rmse: 32.3809\tvalid_1's rmse: 60.2255\n",
      "[210]\ttraining's rmse: 28.3771\tvalid_1's rmse: 58.3548\n",
      "[240]\ttraining's rmse: 25.2547\tvalid_1's rmse: 57.0592\n",
      "[270]\ttraining's rmse: 22.7682\tvalid_1's rmse: 56.2246\n",
      "[300]\ttraining's rmse: 20.6744\tvalid_1's rmse: 55.5733\n",
      "[330]\ttraining's rmse: 18.9572\tvalid_1's rmse: 55.1944\n",
      "[360]\ttraining's rmse: 17.44\tvalid_1's rmse: 54.9441\n",
      "[390]\ttraining's rmse: 16.1035\tvalid_1's rmse: 54.7143\n",
      "[420]\ttraining's rmse: 14.8901\tvalid_1's rmse: 54.5502\n",
      "[450]\ttraining's rmse: 13.8301\tvalid_1's rmse: 54.4123\n",
      "[480]\ttraining's rmse: 12.8433\tvalid_1's rmse: 54.2743\n",
      "[510]\ttraining's rmse: 11.9434\tvalid_1's rmse: 54.193\n",
      "[540]\ttraining's rmse: 11.1386\tvalid_1's rmse: 54.0978\n",
      "[570]\ttraining's rmse: 10.3962\tvalid_1's rmse: 54.0168\n",
      "[600]\ttraining's rmse: 9.71582\tvalid_1's rmse: 53.9453\n",
      "[630]\ttraining's rmse: 9.0931\tvalid_1's rmse: 53.872\n",
      "[660]\ttraining's rmse: 8.51339\tvalid_1's rmse: 53.8199\n",
      "[690]\ttraining's rmse: 7.99264\tvalid_1's rmse: 53.7693\n",
      "[720]\ttraining's rmse: 7.49922\tvalid_1's rmse: 53.7384\n",
      "[750]\ttraining's rmse: 7.03954\tvalid_1's rmse: 53.7104\n",
      "[780]\ttraining's rmse: 6.63264\tvalid_1's rmse: 53.6831\n",
      "[810]\ttraining's rmse: 6.23849\tvalid_1's rmse: 53.6463\n",
      "[840]\ttraining's rmse: 5.87358\tvalid_1's rmse: 53.6193\n",
      "[870]\ttraining's rmse: 5.53401\tvalid_1's rmse: 53.5958\n",
      "[900]\ttraining's rmse: 5.21372\tvalid_1's rmse: 53.5761\n",
      "[930]\ttraining's rmse: 4.91935\tvalid_1's rmse: 53.5538\n",
      "[960]\ttraining's rmse: 4.64344\tvalid_1's rmse: 53.5372\n",
      "[990]\ttraining's rmse: 4.38531\tvalid_1's rmse: 53.5199\n",
      "[1020]\ttraining's rmse: 4.1486\tvalid_1's rmse: 53.5033\n",
      "[1050]\ttraining's rmse: 3.91649\tvalid_1's rmse: 53.4909\n",
      "[1080]\ttraining's rmse: 3.69922\tvalid_1's rmse: 53.487\n",
      "[1110]\ttraining's rmse: 3.50156\tvalid_1's rmse: 53.4783\n",
      "[1140]\ttraining's rmse: 3.31035\tvalid_1's rmse: 53.4706\n",
      "[1170]\ttraining's rmse: 3.13192\tvalid_1's rmse: 53.462\n",
      "[1200]\ttraining's rmse: 2.96828\tvalid_1's rmse: 53.4609\n",
      "[1230]\ttraining's rmse: 2.80931\tvalid_1's rmse: 53.4509\n",
      "[1260]\ttraining's rmse: 2.66271\tvalid_1's rmse: 53.4502\n",
      "[1290]\ttraining's rmse: 2.52381\tvalid_1's rmse: 53.4493\n",
      "[1320]\ttraining's rmse: 2.39129\tvalid_1's rmse: 53.4417\n",
      "[1350]\ttraining's rmse: 2.26934\tvalid_1's rmse: 53.438\n",
      "[1380]\ttraining's rmse: 2.1517\tvalid_1's rmse: 53.4343\n",
      "[1410]\ttraining's rmse: 2.04153\tvalid_1's rmse: 53.4315\n",
      "[1440]\ttraining's rmse: 1.937\tvalid_1's rmse: 53.4256\n",
      "[1470]\ttraining's rmse: 1.83817\tvalid_1's rmse: 53.4228\n",
      "[1500]\ttraining's rmse: 1.74326\tvalid_1's rmse: 53.4199\n",
      "[1530]\ttraining's rmse: 1.65672\tvalid_1's rmse: 53.4175\n",
      "[1560]\ttraining's rmse: 1.5715\tvalid_1's rmse: 53.4137\n",
      "[1590]\ttraining's rmse: 1.4915\tvalid_1's rmse: 53.413\n",
      "[1620]\ttraining's rmse: 1.4183\tvalid_1's rmse: 53.4086\n",
      "[1650]\ttraining's rmse: 1.34744\tvalid_1's rmse: 53.4093\n",
      "[1680]\ttraining's rmse: 1.27838\tvalid_1's rmse: 53.4064\n",
      "[1710]\ttraining's rmse: 1.21542\tvalid_1's rmse: 53.4061\n",
      "[1740]\ttraining's rmse: 1.15406\tvalid_1's rmse: 53.406\n",
      "[1770]\ttraining's rmse: 1.09746\tvalid_1's rmse: 53.4036\n",
      "[1800]\ttraining's rmse: 1.04265\tvalid_1's rmse: 53.4021\n",
      "[1830]\ttraining's rmse: 0.992578\tvalid_1's rmse: 53.4033\n",
      "[1860]\ttraining's rmse: 0.944757\tvalid_1's rmse: 53.4036\n",
      "[1890]\ttraining's rmse: 0.898142\tvalid_1's rmse: 53.4038\n",
      "[1920]\ttraining's rmse: 0.8541\tvalid_1's rmse: 53.403\n",
      "Early stopping, best iteration is:\n",
      "[1803]\ttraining's rmse: 1.03747\tvalid_1's rmse: 53.402\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002571 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 20022\n",
      "[LightGBM] [Info] Number of data points in the train set: 9219, number of used features: 79\n",
      "[LightGBM] [Info] Start training from score 370.159354\n",
      "Training until validation scores don't improve for 125 rounds\n",
      "[30]\ttraining's rmse: 159.997\tvalid_1's rmse: 159.369\n",
      "[60]\ttraining's rmse: 100.442\tvalid_1's rmse: 106.772\n",
      "[90]\ttraining's rmse: 67.778\tvalid_1's rmse: 80.2474\n",
      "[120]\ttraining's rmse: 50.1656\tvalid_1's rmse: 67.7334\n",
      "[150]\ttraining's rmse: 40.2499\tvalid_1's rmse: 61.7323\n",
      "[180]\ttraining's rmse: 34.237\tvalid_1's rmse: 58.6524\n",
      "[210]\ttraining's rmse: 30.012\tvalid_1's rmse: 56.9323\n",
      "[240]\ttraining's rmse: 26.8241\tvalid_1's rmse: 55.878\n",
      "[270]\ttraining's rmse: 24.2332\tvalid_1's rmse: 55.2042\n",
      "[300]\ttraining's rmse: 22.0304\tvalid_1's rmse: 54.823\n",
      "[330]\ttraining's rmse: 20.2061\tvalid_1's rmse: 54.5784\n",
      "[360]\ttraining's rmse: 18.5883\tvalid_1's rmse: 54.3537\n",
      "[390]\ttraining's rmse: 17.1817\tvalid_1's rmse: 54.2275\n",
      "[420]\ttraining's rmse: 15.9082\tvalid_1's rmse: 54.1015\n",
      "[450]\ttraining's rmse: 14.7778\tvalid_1's rmse: 53.9775\n",
      "[480]\ttraining's rmse: 13.7444\tvalid_1's rmse: 53.8767\n",
      "[510]\ttraining's rmse: 12.8136\tvalid_1's rmse: 53.8534\n",
      "[540]\ttraining's rmse: 11.9447\tvalid_1's rmse: 53.799\n",
      "[570]\ttraining's rmse: 11.1857\tvalid_1's rmse: 53.7438\n",
      "[600]\ttraining's rmse: 10.4669\tvalid_1's rmse: 53.6789\n",
      "[630]\ttraining's rmse: 9.80558\tvalid_1's rmse: 53.6501\n",
      "[660]\ttraining's rmse: 9.19562\tvalid_1's rmse: 53.6287\n",
      "[690]\ttraining's rmse: 8.63737\tvalid_1's rmse: 53.5997\n",
      "[720]\ttraining's rmse: 8.12117\tvalid_1's rmse: 53.5743\n",
      "[750]\ttraining's rmse: 7.62932\tvalid_1's rmse: 53.5531\n",
      "[780]\ttraining's rmse: 7.17761\tvalid_1's rmse: 53.5272\n",
      "[810]\ttraining's rmse: 6.75539\tvalid_1's rmse: 53.4983\n",
      "[840]\ttraining's rmse: 6.36881\tvalid_1's rmse: 53.4743\n",
      "[870]\ttraining's rmse: 6.00974\tvalid_1's rmse: 53.4516\n",
      "[900]\ttraining's rmse: 5.66895\tvalid_1's rmse: 53.4449\n",
      "[930]\ttraining's rmse: 5.35396\tvalid_1's rmse: 53.4255\n",
      "[960]\ttraining's rmse: 5.06232\tvalid_1's rmse: 53.4183\n",
      "[990]\ttraining's rmse: 4.77786\tvalid_1's rmse: 53.4055\n",
      "[1020]\ttraining's rmse: 4.52027\tvalid_1's rmse: 53.4049\n",
      "[1050]\ttraining's rmse: 4.27221\tvalid_1's rmse: 53.3979\n",
      "[1080]\ttraining's rmse: 4.04111\tvalid_1's rmse: 53.3885\n",
      "[1110]\ttraining's rmse: 3.82816\tvalid_1's rmse: 53.3888\n",
      "[1140]\ttraining's rmse: 3.62938\tvalid_1's rmse: 53.3885\n",
      "[1170]\ttraining's rmse: 3.44049\tvalid_1's rmse: 53.3835\n",
      "[1200]\ttraining's rmse: 3.26112\tvalid_1's rmse: 53.3781\n",
      "[1230]\ttraining's rmse: 3.09217\tvalid_1's rmse: 53.374\n",
      "[1260]\ttraining's rmse: 2.93451\tvalid_1's rmse: 53.3733\n",
      "[1290]\ttraining's rmse: 2.78267\tvalid_1's rmse: 53.3757\n",
      "[1320]\ttraining's rmse: 2.64305\tvalid_1's rmse: 53.3703\n",
      "[1350]\ttraining's rmse: 2.509\tvalid_1's rmse: 53.3604\n",
      "[1380]\ttraining's rmse: 2.38101\tvalid_1's rmse: 53.3588\n",
      "[1410]\ttraining's rmse: 2.2615\tvalid_1's rmse: 53.3561\n",
      "[1440]\ttraining's rmse: 2.14812\tvalid_1's rmse: 53.3533\n",
      "[1470]\ttraining's rmse: 2.04187\tvalid_1's rmse: 53.3523\n",
      "[1500]\ttraining's rmse: 1.94162\tvalid_1's rmse: 53.3515\n",
      "[1530]\ttraining's rmse: 1.84859\tvalid_1's rmse: 53.3479\n",
      "[1560]\ttraining's rmse: 1.75944\tvalid_1's rmse: 53.346\n",
      "[1590]\ttraining's rmse: 1.67456\tvalid_1's rmse: 53.3454\n",
      "[1620]\ttraining's rmse: 1.59402\tvalid_1's rmse: 53.3436\n",
      "[1650]\ttraining's rmse: 1.51627\tvalid_1's rmse: 53.3421\n",
      "[1680]\ttraining's rmse: 1.44206\tvalid_1's rmse: 53.341\n",
      "[1710]\ttraining's rmse: 1.37323\tvalid_1's rmse: 53.3363\n",
      "[1740]\ttraining's rmse: 1.30791\tvalid_1's rmse: 53.3351\n",
      "[1770]\ttraining's rmse: 1.24616\tvalid_1's rmse: 53.3322\n",
      "[1800]\ttraining's rmse: 1.18944\tvalid_1's rmse: 53.3341\n",
      "[1830]\ttraining's rmse: 1.13243\tvalid_1's rmse: 53.332\n",
      "[1860]\ttraining's rmse: 1.0793\tvalid_1's rmse: 53.3322\n",
      "[1890]\ttraining's rmse: 1.02786\tvalid_1's rmse: 53.3297\n",
      "[1920]\ttraining's rmse: 0.979461\tvalid_1's rmse: 53.33\n",
      "[1950]\ttraining's rmse: 0.935004\tvalid_1's rmse: 53.331\n",
      "[1980]\ttraining's rmse: 0.892973\tvalid_1's rmse: 53.3298\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's rmse: 0.865046\tvalid_1's rmse: 53.3292\n",
      "19\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002334 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 20024\n",
      "[LightGBM] [Info] Number of data points in the train set: 9219, number of used features: 79\n",
      "[LightGBM] [Info] Start training from score 364.555425\n",
      "Training until validation scores don't improve for 125 rounds\n",
      "[30]\ttraining's rmse: 152.624\tvalid_1's rmse: 152.056\n",
      "[60]\ttraining's rmse: 94.8223\tvalid_1's rmse: 101.392\n",
      "[90]\ttraining's rmse: 63.7475\tvalid_1's rmse: 76.6586\n",
      "[120]\ttraining's rmse: 46.7692\tvalid_1's rmse: 65.1124\n",
      "[150]\ttraining's rmse: 37.4261\tvalid_1's rmse: 59.7459\n",
      "[180]\ttraining's rmse: 31.7331\tvalid_1's rmse: 57.0035\n",
      "[210]\ttraining's rmse: 27.8225\tvalid_1's rmse: 55.5716\n",
      "[240]\ttraining's rmse: 24.7739\tvalid_1's rmse: 54.553\n",
      "[270]\ttraining's rmse: 22.3231\tvalid_1's rmse: 53.8405\n",
      "[300]\ttraining's rmse: 20.3154\tvalid_1's rmse: 53.3378\n",
      "[330]\ttraining's rmse: 18.5926\tvalid_1's rmse: 53.0446\n",
      "[360]\ttraining's rmse: 17.1198\tvalid_1's rmse: 52.7678\n",
      "[390]\ttraining's rmse: 15.8178\tvalid_1's rmse: 52.5459\n",
      "[420]\ttraining's rmse: 14.6588\tvalid_1's rmse: 52.3867\n",
      "[450]\ttraining's rmse: 13.6074\tvalid_1's rmse: 52.2245\n",
      "[480]\ttraining's rmse: 12.6741\tvalid_1's rmse: 52.1185\n",
      "[510]\ttraining's rmse: 11.8148\tvalid_1's rmse: 52.021\n",
      "[540]\ttraining's rmse: 11.0197\tvalid_1's rmse: 51.974\n",
      "[570]\ttraining's rmse: 10.3006\tvalid_1's rmse: 51.907\n",
      "[600]\ttraining's rmse: 9.64839\tvalid_1's rmse: 51.8547\n",
      "[630]\ttraining's rmse: 9.05146\tvalid_1's rmse: 51.8154\n",
      "[660]\ttraining's rmse: 8.4933\tvalid_1's rmse: 51.7891\n",
      "[690]\ttraining's rmse: 7.97732\tvalid_1's rmse: 51.7475\n",
      "[720]\ttraining's rmse: 7.50813\tvalid_1's rmse: 51.7387\n",
      "[750]\ttraining's rmse: 7.06766\tvalid_1's rmse: 51.7016\n",
      "[780]\ttraining's rmse: 6.65354\tvalid_1's rmse: 51.6843\n",
      "[810]\ttraining's rmse: 6.27247\tvalid_1's rmse: 51.6572\n",
      "[840]\ttraining's rmse: 5.91296\tvalid_1's rmse: 51.6416\n",
      "[870]\ttraining's rmse: 5.58432\tvalid_1's rmse: 51.6234\n",
      "[900]\ttraining's rmse: 5.27627\tvalid_1's rmse: 51.6139\n",
      "[930]\ttraining's rmse: 4.98644\tvalid_1's rmse: 51.6099\n",
      "[960]\ttraining's rmse: 4.71436\tvalid_1's rmse: 51.6002\n",
      "[990]\ttraining's rmse: 4.45619\tvalid_1's rmse: 51.591\n",
      "[1020]\ttraining's rmse: 4.2166\tvalid_1's rmse: 51.5855\n",
      "[1050]\ttraining's rmse: 3.99518\tvalid_1's rmse: 51.5707\n",
      "[1080]\ttraining's rmse: 3.78591\tvalid_1's rmse: 51.5524\n",
      "[1110]\ttraining's rmse: 3.58992\tvalid_1's rmse: 51.5559\n",
      "[1140]\ttraining's rmse: 3.40286\tvalid_1's rmse: 51.5513\n",
      "[1170]\ttraining's rmse: 3.22668\tvalid_1's rmse: 51.5529\n",
      "[1200]\ttraining's rmse: 3.0591\tvalid_1's rmse: 51.5443\n",
      "[1230]\ttraining's rmse: 2.90056\tvalid_1's rmse: 51.5437\n",
      "[1260]\ttraining's rmse: 2.75457\tvalid_1's rmse: 51.5505\n",
      "[1290]\ttraining's rmse: 2.61602\tvalid_1's rmse: 51.5406\n",
      "[1320]\ttraining's rmse: 2.48492\tvalid_1's rmse: 51.5393\n",
      "[1350]\ttraining's rmse: 2.36238\tvalid_1's rmse: 51.5349\n",
      "[1380]\ttraining's rmse: 2.24606\tvalid_1's rmse: 51.5276\n",
      "[1410]\ttraining's rmse: 2.13572\tvalid_1's rmse: 51.5269\n",
      "[1440]\ttraining's rmse: 2.03135\tvalid_1's rmse: 51.522\n",
      "[1470]\ttraining's rmse: 1.93303\tvalid_1's rmse: 51.52\n",
      "[1500]\ttraining's rmse: 1.83939\tvalid_1's rmse: 51.5226\n",
      "[1530]\ttraining's rmse: 1.74932\tvalid_1's rmse: 51.5247\n",
      "[1560]\ttraining's rmse: 1.66643\tvalid_1's rmse: 51.5238\n",
      "Early stopping, best iteration is:\n",
      "[1458]\ttraining's rmse: 1.97237\tvalid_1's rmse: 51.5185\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003573 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 20024\n",
      "[LightGBM] [Info] Number of data points in the train set: 9219, number of used features: 79\n",
      "[LightGBM] [Info] Start training from score 367.822387\n",
      "Training until validation scores don't improve for 125 rounds\n",
      "[30]\ttraining's rmse: 153.088\tvalid_1's rmse: 154.461\n",
      "[60]\ttraining's rmse: 96.0364\tvalid_1's rmse: 104.684\n",
      "[90]\ttraining's rmse: 65.2532\tvalid_1's rmse: 80.1247\n",
      "[120]\ttraining's rmse: 48.3624\tvalid_1's rmse: 68.2073\n",
      "[150]\ttraining's rmse: 38.9429\tvalid_1's rmse: 62.4244\n",
      "[180]\ttraining's rmse: 33.0689\tvalid_1's rmse: 59.299\n",
      "[210]\ttraining's rmse: 29.0268\tvalid_1's rmse: 57.4842\n",
      "[240]\ttraining's rmse: 25.8417\tvalid_1's rmse: 56.3068\n",
      "[270]\ttraining's rmse: 23.287\tvalid_1's rmse: 55.543\n",
      "[300]\ttraining's rmse: 21.1254\tvalid_1's rmse: 54.9845\n",
      "[330]\ttraining's rmse: 19.3106\tvalid_1's rmse: 54.5256\n",
      "[360]\ttraining's rmse: 17.7346\tvalid_1's rmse: 54.2041\n",
      "[390]\ttraining's rmse: 16.3897\tvalid_1's rmse: 53.9574\n",
      "[420]\ttraining's rmse: 15.1697\tvalid_1's rmse: 53.7046\n",
      "[450]\ttraining's rmse: 14.0995\tvalid_1's rmse: 53.5151\n",
      "[480]\ttraining's rmse: 13.1114\tvalid_1's rmse: 53.3914\n",
      "[510]\ttraining's rmse: 12.2074\tvalid_1's rmse: 53.2842\n",
      "[540]\ttraining's rmse: 11.3744\tvalid_1's rmse: 53.2\n",
      "[570]\ttraining's rmse: 10.6326\tvalid_1's rmse: 53.1199\n",
      "[600]\ttraining's rmse: 9.94097\tvalid_1's rmse: 53.0378\n",
      "[630]\ttraining's rmse: 9.30951\tvalid_1's rmse: 52.9807\n",
      "[660]\ttraining's rmse: 8.72673\tvalid_1's rmse: 52.9304\n",
      "[690]\ttraining's rmse: 8.19033\tvalid_1's rmse: 52.8733\n",
      "[720]\ttraining's rmse: 7.67993\tvalid_1's rmse: 52.813\n",
      "[750]\ttraining's rmse: 7.22648\tvalid_1's rmse: 52.7732\n",
      "[780]\ttraining's rmse: 6.80198\tvalid_1's rmse: 52.7285\n",
      "[810]\ttraining's rmse: 6.39643\tvalid_1's rmse: 52.7051\n",
      "[840]\ttraining's rmse: 6.03188\tvalid_1's rmse: 52.6692\n",
      "[870]\ttraining's rmse: 5.68697\tvalid_1's rmse: 52.649\n",
      "[900]\ttraining's rmse: 5.36355\tvalid_1's rmse: 52.6237\n",
      "[930]\ttraining's rmse: 5.06315\tvalid_1's rmse: 52.6037\n",
      "[960]\ttraining's rmse: 4.77586\tvalid_1's rmse: 52.5828\n",
      "[990]\ttraining's rmse: 4.50538\tvalid_1's rmse: 52.5694\n",
      "[1020]\ttraining's rmse: 4.25393\tvalid_1's rmse: 52.5495\n",
      "[1050]\ttraining's rmse: 4.02138\tvalid_1's rmse: 52.5341\n",
      "[1080]\ttraining's rmse: 3.80153\tvalid_1's rmse: 52.5202\n",
      "[1110]\ttraining's rmse: 3.59658\tvalid_1's rmse: 52.4989\n",
      "[1140]\ttraining's rmse: 3.40195\tvalid_1's rmse: 52.4882\n",
      "[1170]\ttraining's rmse: 3.22153\tvalid_1's rmse: 52.4749\n",
      "[1200]\ttraining's rmse: 3.04747\tvalid_1's rmse: 52.4577\n",
      "[1230]\ttraining's rmse: 2.88455\tvalid_1's rmse: 52.4453\n",
      "[1260]\ttraining's rmse: 2.73363\tvalid_1's rmse: 52.4415\n",
      "[1290]\ttraining's rmse: 2.58618\tvalid_1's rmse: 52.4348\n",
      "[1320]\ttraining's rmse: 2.45167\tvalid_1's rmse: 52.4251\n",
      "[1350]\ttraining's rmse: 2.32222\tvalid_1's rmse: 52.4184\n",
      "[1380]\ttraining's rmse: 2.2044\tvalid_1's rmse: 52.4117\n",
      "[1410]\ttraining's rmse: 2.08843\tvalid_1's rmse: 52.4086\n",
      "[1440]\ttraining's rmse: 1.98141\tvalid_1's rmse: 52.4027\n",
      "[1470]\ttraining's rmse: 1.87878\tvalid_1's rmse: 52.3973\n",
      "[1500]\ttraining's rmse: 1.78186\tvalid_1's rmse: 52.3951\n",
      "[1530]\ttraining's rmse: 1.69238\tvalid_1's rmse: 52.3939\n",
      "[1560]\ttraining's rmse: 1.6072\tvalid_1's rmse: 52.3907\n",
      "[1590]\ttraining's rmse: 1.52618\tvalid_1's rmse: 52.3879\n",
      "[1620]\ttraining's rmse: 1.45122\tvalid_1's rmse: 52.3812\n",
      "[1650]\ttraining's rmse: 1.3798\tvalid_1's rmse: 52.3817\n",
      "[1680]\ttraining's rmse: 1.31163\tvalid_1's rmse: 52.3791\n",
      "[1710]\ttraining's rmse: 1.2464\tvalid_1's rmse: 52.377\n",
      "[1740]\ttraining's rmse: 1.1862\tvalid_1's rmse: 52.3757\n",
      "[1770]\ttraining's rmse: 1.12833\tvalid_1's rmse: 52.3752\n",
      "[1800]\ttraining's rmse: 1.07284\tvalid_1's rmse: 52.3722\n",
      "[1830]\ttraining's rmse: 1.02032\tvalid_1's rmse: 52.3691\n",
      "[1860]\ttraining's rmse: 0.970255\tvalid_1's rmse: 52.3673\n",
      "[1890]\ttraining's rmse: 0.922999\tvalid_1's rmse: 52.3667\n",
      "[1920]\ttraining's rmse: 0.87824\tvalid_1's rmse: 52.3664\n",
      "[1950]\ttraining's rmse: 0.835559\tvalid_1's rmse: 52.3649\n",
      "[1980]\ttraining's rmse: 0.794557\tvalid_1's rmse: 52.3647\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's rmse: 0.769005\tvalid_1's rmse: 52.364\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003335 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 20024\n",
      "[LightGBM] [Info] Number of data points in the train set: 9219, number of used features: 79\n",
      "[LightGBM] [Info] Start training from score 369.976424\n",
      "Training until validation scores don't improve for 125 rounds\n",
      "[30]\ttraining's rmse: 153.182\tvalid_1's rmse: 155.29\n",
      "[60]\ttraining's rmse: 96.2788\tvalid_1's rmse: 104.544\n",
      "[90]\ttraining's rmse: 65.3654\tvalid_1's rmse: 79.5351\n",
      "[120]\ttraining's rmse: 48.4274\tvalid_1's rmse: 67.3799\n",
      "[150]\ttraining's rmse: 38.9404\tvalid_1's rmse: 61.8199\n",
      "[180]\ttraining's rmse: 33.1319\tvalid_1's rmse: 59.0439\n",
      "[210]\ttraining's rmse: 29.045\tvalid_1's rmse: 57.4681\n",
      "[240]\ttraining's rmse: 25.8877\tvalid_1's rmse: 56.4782\n",
      "[270]\ttraining's rmse: 23.3535\tvalid_1's rmse: 55.6983\n",
      "[300]\ttraining's rmse: 21.2702\tvalid_1's rmse: 55.1429\n",
      "[330]\ttraining's rmse: 19.4711\tvalid_1's rmse: 54.5986\n",
      "[360]\ttraining's rmse: 17.9144\tvalid_1's rmse: 54.2326\n",
      "[390]\ttraining's rmse: 16.5386\tvalid_1's rmse: 53.9264\n",
      "[420]\ttraining's rmse: 15.3218\tvalid_1's rmse: 53.7452\n",
      "[450]\ttraining's rmse: 14.2322\tvalid_1's rmse: 53.597\n",
      "[480]\ttraining's rmse: 13.2383\tvalid_1's rmse: 53.4726\n",
      "[510]\ttraining's rmse: 12.3497\tvalid_1's rmse: 53.3531\n",
      "[540]\ttraining's rmse: 11.5223\tvalid_1's rmse: 53.2702\n",
      "[570]\ttraining's rmse: 10.7734\tvalid_1's rmse: 53.1493\n",
      "[600]\ttraining's rmse: 10.0918\tvalid_1's rmse: 53.06\n",
      "[630]\ttraining's rmse: 9.47203\tvalid_1's rmse: 53.0326\n",
      "[660]\ttraining's rmse: 8.88992\tvalid_1's rmse: 52.9818\n",
      "[690]\ttraining's rmse: 8.33828\tvalid_1's rmse: 52.9344\n",
      "[720]\ttraining's rmse: 7.84481\tvalid_1's rmse: 52.8994\n",
      "[750]\ttraining's rmse: 7.37475\tvalid_1's rmse: 52.8684\n",
      "[780]\ttraining's rmse: 6.94326\tvalid_1's rmse: 52.821\n",
      "[810]\ttraining's rmse: 6.5463\tvalid_1's rmse: 52.8072\n",
      "[840]\ttraining's rmse: 6.17556\tvalid_1's rmse: 52.7777\n",
      "[870]\ttraining's rmse: 5.8255\tvalid_1's rmse: 52.7754\n",
      "[900]\ttraining's rmse: 5.50801\tvalid_1's rmse: 52.7434\n",
      "[930]\ttraining's rmse: 5.20549\tvalid_1's rmse: 52.7289\n",
      "[960]\ttraining's rmse: 4.91436\tvalid_1's rmse: 52.7086\n",
      "[990]\ttraining's rmse: 4.65114\tvalid_1's rmse: 52.6763\n",
      "[1020]\ttraining's rmse: 4.40815\tvalid_1's rmse: 52.6523\n",
      "[1050]\ttraining's rmse: 4.17928\tvalid_1's rmse: 52.6425\n",
      "[1080]\ttraining's rmse: 3.95704\tvalid_1's rmse: 52.6349\n",
      "[1110]\ttraining's rmse: 3.75349\tvalid_1's rmse: 52.6257\n",
      "[1140]\ttraining's rmse: 3.55588\tvalid_1's rmse: 52.61\n",
      "[1170]\ttraining's rmse: 3.37039\tvalid_1's rmse: 52.5919\n",
      "[1200]\ttraining's rmse: 3.19636\tvalid_1's rmse: 52.5838\n",
      "[1230]\ttraining's rmse: 3.03163\tvalid_1's rmse: 52.5737\n",
      "[1260]\ttraining's rmse: 2.8774\tvalid_1's rmse: 52.5533\n",
      "[1290]\ttraining's rmse: 2.73186\tvalid_1's rmse: 52.5469\n",
      "[1320]\ttraining's rmse: 2.59219\tvalid_1's rmse: 52.5352\n",
      "[1350]\ttraining's rmse: 2.46375\tvalid_1's rmse: 52.531\n",
      "[1380]\ttraining's rmse: 2.34198\tvalid_1's rmse: 52.5217\n",
      "[1410]\ttraining's rmse: 2.22694\tvalid_1's rmse: 52.5133\n",
      "[1440]\ttraining's rmse: 2.11925\tvalid_1's rmse: 52.508\n",
      "[1470]\ttraining's rmse: 2.01701\tvalid_1's rmse: 52.5015\n",
      "[1500]\ttraining's rmse: 1.92053\tvalid_1's rmse: 52.4928\n",
      "[1530]\ttraining's rmse: 1.82769\tvalid_1's rmse: 52.4912\n",
      "[1560]\ttraining's rmse: 1.74058\tvalid_1's rmse: 52.4861\n",
      "[1590]\ttraining's rmse: 1.65708\tvalid_1's rmse: 52.4761\n",
      "[1620]\ttraining's rmse: 1.57709\tvalid_1's rmse: 52.4696\n",
      "[1650]\ttraining's rmse: 1.50226\tvalid_1's rmse: 52.4633\n",
      "[1680]\ttraining's rmse: 1.43104\tvalid_1's rmse: 52.46\n",
      "[1710]\ttraining's rmse: 1.36337\tvalid_1's rmse: 52.455\n",
      "[1740]\ttraining's rmse: 1.30174\tvalid_1's rmse: 52.4514\n",
      "[1770]\ttraining's rmse: 1.24113\tvalid_1's rmse: 52.4469\n",
      "[1800]\ttraining's rmse: 1.18118\tvalid_1's rmse: 52.441\n",
      "[1830]\ttraining's rmse: 1.12515\tvalid_1's rmse: 52.4407\n",
      "[1860]\ttraining's rmse: 1.07198\tvalid_1's rmse: 52.4381\n",
      "[1890]\ttraining's rmse: 1.02369\tvalid_1's rmse: 52.4355\n",
      "[1920]\ttraining's rmse: 0.976349\tvalid_1's rmse: 52.4328\n",
      "[1950]\ttraining's rmse: 0.931654\tvalid_1's rmse: 52.4271\n",
      "[1980]\ttraining's rmse: 0.889066\tvalid_1's rmse: 52.4245\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's rmse: 0.862371\tvalid_1's rmse: 52.4233\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003186 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 20024\n",
      "[LightGBM] [Info] Number of data points in the train set: 9219, number of used features: 79\n",
      "[LightGBM] [Info] Start training from score 369.295247\n",
      "Training until validation scores don't improve for 125 rounds\n",
      "[30]\ttraining's rmse: 152.743\tvalid_1's rmse: 158.032\n",
      "[60]\ttraining's rmse: 95.9132\tvalid_1's rmse: 107.864\n",
      "[90]\ttraining's rmse: 65.0608\tvalid_1's rmse: 83.1874\n",
      "[120]\ttraining's rmse: 48.3923\tvalid_1's rmse: 71.7518\n",
      "[150]\ttraining's rmse: 38.9361\tvalid_1's rmse: 66.2812\n",
      "[180]\ttraining's rmse: 33.0964\tvalid_1's rmse: 63.4946\n",
      "[210]\ttraining's rmse: 28.9677\tvalid_1's rmse: 61.7146\n",
      "[240]\ttraining's rmse: 25.797\tvalid_1's rmse: 60.5649\n",
      "[270]\ttraining's rmse: 23.2895\tvalid_1's rmse: 59.6936\n",
      "[300]\ttraining's rmse: 21.1988\tvalid_1's rmse: 59.196\n",
      "[330]\ttraining's rmse: 19.3794\tvalid_1's rmse: 58.7854\n",
      "[360]\ttraining's rmse: 17.8222\tvalid_1's rmse: 58.4765\n",
      "[390]\ttraining's rmse: 16.4296\tvalid_1's rmse: 58.2091\n",
      "[420]\ttraining's rmse: 15.2381\tvalid_1's rmse: 58.0605\n",
      "[450]\ttraining's rmse: 14.13\tvalid_1's rmse: 57.9086\n",
      "[480]\ttraining's rmse: 13.1487\tvalid_1's rmse: 57.7966\n",
      "[510]\ttraining's rmse: 12.2466\tvalid_1's rmse: 57.6888\n",
      "[540]\ttraining's rmse: 11.4358\tvalid_1's rmse: 57.6117\n",
      "[570]\ttraining's rmse: 10.7037\tvalid_1's rmse: 57.5438\n",
      "[600]\ttraining's rmse: 10.0187\tvalid_1's rmse: 57.469\n",
      "[630]\ttraining's rmse: 9.3784\tvalid_1's rmse: 57.4165\n",
      "[660]\ttraining's rmse: 8.79887\tvalid_1's rmse: 57.3672\n",
      "[690]\ttraining's rmse: 8.25031\tvalid_1's rmse: 57.3202\n",
      "[720]\ttraining's rmse: 7.74947\tvalid_1's rmse: 57.2636\n",
      "[750]\ttraining's rmse: 7.2878\tvalid_1's rmse: 57.2158\n",
      "[780]\ttraining's rmse: 6.85885\tvalid_1's rmse: 57.1871\n",
      "[810]\ttraining's rmse: 6.45995\tvalid_1's rmse: 57.156\n",
      "[840]\ttraining's rmse: 6.08231\tvalid_1's rmse: 57.1341\n",
      "[870]\ttraining's rmse: 5.73562\tvalid_1's rmse: 57.1209\n",
      "[900]\ttraining's rmse: 5.41054\tvalid_1's rmse: 57.1073\n",
      "[930]\ttraining's rmse: 5.10626\tvalid_1's rmse: 57.0865\n",
      "[960]\ttraining's rmse: 4.81972\tvalid_1's rmse: 57.0735\n",
      "[990]\ttraining's rmse: 4.55749\tvalid_1's rmse: 57.0793\n",
      "[1020]\ttraining's rmse: 4.30787\tvalid_1's rmse: 57.0475\n",
      "[1050]\ttraining's rmse: 4.07426\tvalid_1's rmse: 57.0413\n",
      "[1080]\ttraining's rmse: 3.8509\tvalid_1's rmse: 57.0293\n",
      "[1110]\ttraining's rmse: 3.6456\tvalid_1's rmse: 57.006\n",
      "[1140]\ttraining's rmse: 3.45175\tvalid_1's rmse: 57.0011\n",
      "[1170]\ttraining's rmse: 3.27272\tvalid_1's rmse: 56.9962\n",
      "[1200]\ttraining's rmse: 3.10186\tvalid_1's rmse: 56.9883\n",
      "[1230]\ttraining's rmse: 2.9385\tvalid_1's rmse: 56.978\n",
      "[1260]\ttraining's rmse: 2.78498\tvalid_1's rmse: 56.9737\n",
      "[1290]\ttraining's rmse: 2.6421\tvalid_1's rmse: 56.9748\n",
      "[1320]\ttraining's rmse: 2.50637\tvalid_1's rmse: 56.971\n",
      "[1350]\ttraining's rmse: 2.37671\tvalid_1's rmse: 56.9621\n",
      "[1380]\ttraining's rmse: 2.25427\tvalid_1's rmse: 56.9532\n",
      "[1410]\ttraining's rmse: 2.13833\tvalid_1's rmse: 56.9454\n",
      "[1440]\ttraining's rmse: 2.03081\tvalid_1's rmse: 56.9423\n",
      "[1470]\ttraining's rmse: 1.92951\tvalid_1's rmse: 56.9359\n",
      "[1500]\ttraining's rmse: 1.83353\tvalid_1's rmse: 56.9326\n",
      "[1530]\ttraining's rmse: 1.74412\tvalid_1's rmse: 56.9294\n",
      "[1560]\ttraining's rmse: 1.65744\tvalid_1's rmse: 56.9239\n",
      "[1590]\ttraining's rmse: 1.57576\tvalid_1's rmse: 56.9203\n",
      "[1620]\ttraining's rmse: 1.49954\tvalid_1's rmse: 56.9136\n",
      "[1650]\ttraining's rmse: 1.42713\tvalid_1's rmse: 56.9099\n",
      "[1680]\ttraining's rmse: 1.35695\tvalid_1's rmse: 56.9098\n",
      "[1710]\ttraining's rmse: 1.29177\tvalid_1's rmse: 56.9053\n",
      "[1740]\ttraining's rmse: 1.2306\tvalid_1's rmse: 56.8988\n",
      "[1770]\ttraining's rmse: 1.17029\tvalid_1's rmse: 56.8951\n",
      "[1800]\ttraining's rmse: 1.11393\tvalid_1's rmse: 56.8956\n",
      "[1830]\ttraining's rmse: 1.05973\tvalid_1's rmse: 56.895\n",
      "[1860]\ttraining's rmse: 1.00884\tvalid_1's rmse: 56.8934\n",
      "[1890]\ttraining's rmse: 0.960607\tvalid_1's rmse: 56.8938\n",
      "[1920]\ttraining's rmse: 0.915259\tvalid_1's rmse: 56.8916\n",
      "[1950]\ttraining's rmse: 0.87196\tvalid_1's rmse: 56.8894\n",
      "[1980]\ttraining's rmse: 0.830891\tvalid_1's rmse: 56.8873\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's rmse: 0.804753\tvalid_1's rmse: 56.8863\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003606 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 20024\n",
      "[LightGBM] [Info] Number of data points in the train set: 9219, number of used features: 79\n",
      "[LightGBM] [Info] Start training from score 370.680730\n",
      "Training until validation scores don't improve for 125 rounds\n",
      "[30]\ttraining's rmse: 153.334\tvalid_1's rmse: 153.577\n",
      "[60]\ttraining's rmse: 96.5463\tvalid_1's rmse: 103.246\n",
      "[90]\ttraining's rmse: 65.6801\tvalid_1's rmse: 77.9709\n",
      "[120]\ttraining's rmse: 48.8494\tvalid_1's rmse: 65.815\n",
      "[150]\ttraining's rmse: 39.2825\tvalid_1's rmse: 59.9242\n",
      "[180]\ttraining's rmse: 33.5355\tvalid_1's rmse: 56.921\n",
      "[210]\ttraining's rmse: 29.4065\tvalid_1's rmse: 55.0291\n",
      "[240]\ttraining's rmse: 26.2269\tvalid_1's rmse: 53.902\n",
      "[270]\ttraining's rmse: 23.6718\tvalid_1's rmse: 53.1578\n",
      "[300]\ttraining's rmse: 21.5108\tvalid_1's rmse: 52.5718\n",
      "[330]\ttraining's rmse: 19.6478\tvalid_1's rmse: 52.1171\n",
      "[360]\ttraining's rmse: 18.0501\tvalid_1's rmse: 51.8564\n",
      "[390]\ttraining's rmse: 16.638\tvalid_1's rmse: 51.6323\n",
      "[420]\ttraining's rmse: 15.3822\tvalid_1's rmse: 51.4585\n",
      "[450]\ttraining's rmse: 14.27\tvalid_1's rmse: 51.3076\n",
      "[480]\ttraining's rmse: 13.257\tvalid_1's rmse: 51.1948\n",
      "[510]\ttraining's rmse: 12.3464\tvalid_1's rmse: 51.05\n",
      "[540]\ttraining's rmse: 11.5312\tvalid_1's rmse: 50.9887\n",
      "[570]\ttraining's rmse: 10.7661\tvalid_1's rmse: 50.9036\n",
      "[600]\ttraining's rmse: 10.0813\tvalid_1's rmse: 50.844\n",
      "[630]\ttraining's rmse: 9.43686\tvalid_1's rmse: 50.7943\n",
      "[660]\ttraining's rmse: 8.84404\tvalid_1's rmse: 50.734\n",
      "[690]\ttraining's rmse: 8.30922\tvalid_1's rmse: 50.6826\n",
      "[720]\ttraining's rmse: 7.80994\tvalid_1's rmse: 50.6376\n",
      "[750]\ttraining's rmse: 7.33944\tvalid_1's rmse: 50.6048\n",
      "[780]\ttraining's rmse: 6.90682\tvalid_1's rmse: 50.5902\n",
      "[810]\ttraining's rmse: 6.50326\tvalid_1's rmse: 50.5564\n",
      "[840]\ttraining's rmse: 6.13495\tvalid_1's rmse: 50.5404\n",
      "[870]\ttraining's rmse: 5.78744\tvalid_1's rmse: 50.515\n",
      "[900]\ttraining's rmse: 5.4595\tvalid_1's rmse: 50.504\n",
      "[930]\ttraining's rmse: 5.15796\tvalid_1's rmse: 50.4818\n",
      "[960]\ttraining's rmse: 4.87703\tvalid_1's rmse: 50.4687\n",
      "[990]\ttraining's rmse: 4.60595\tvalid_1's rmse: 50.4606\n",
      "[1020]\ttraining's rmse: 4.35918\tvalid_1's rmse: 50.4493\n",
      "[1050]\ttraining's rmse: 4.12145\tvalid_1's rmse: 50.4396\n",
      "[1080]\ttraining's rmse: 3.90623\tvalid_1's rmse: 50.4258\n",
      "[1110]\ttraining's rmse: 3.6969\tvalid_1's rmse: 50.4137\n",
      "[1140]\ttraining's rmse: 3.50016\tvalid_1's rmse: 50.4073\n",
      "[1170]\ttraining's rmse: 3.31557\tvalid_1's rmse: 50.3997\n",
      "[1200]\ttraining's rmse: 3.13747\tvalid_1's rmse: 50.388\n",
      "[1230]\ttraining's rmse: 2.97897\tvalid_1's rmse: 50.3846\n",
      "[1260]\ttraining's rmse: 2.82541\tvalid_1's rmse: 50.3801\n",
      "[1290]\ttraining's rmse: 2.68187\tvalid_1's rmse: 50.3733\n",
      "[1320]\ttraining's rmse: 2.54588\tvalid_1's rmse: 50.3644\n",
      "[1350]\ttraining's rmse: 2.41586\tvalid_1's rmse: 50.3614\n",
      "[1380]\ttraining's rmse: 2.29743\tvalid_1's rmse: 50.3573\n",
      "[1410]\ttraining's rmse: 2.18185\tvalid_1's rmse: 50.3532\n",
      "[1440]\ttraining's rmse: 2.07368\tvalid_1's rmse: 50.3481\n",
      "[1470]\ttraining's rmse: 1.97282\tvalid_1's rmse: 50.3471\n",
      "[1500]\ttraining's rmse: 1.87753\tvalid_1's rmse: 50.343\n",
      "[1530]\ttraining's rmse: 1.78439\tvalid_1's rmse: 50.3402\n",
      "[1560]\ttraining's rmse: 1.69769\tvalid_1's rmse: 50.332\n",
      "[1590]\ttraining's rmse: 1.61607\tvalid_1's rmse: 50.3299\n",
      "[1620]\ttraining's rmse: 1.53767\tvalid_1's rmse: 50.3256\n",
      "[1650]\ttraining's rmse: 1.46262\tvalid_1's rmse: 50.3219\n",
      "[1680]\ttraining's rmse: 1.39315\tvalid_1's rmse: 50.3212\n",
      "[1710]\ttraining's rmse: 1.32581\tvalid_1's rmse: 50.3197\n",
      "[1740]\ttraining's rmse: 1.2629\tvalid_1's rmse: 50.3198\n",
      "[1770]\ttraining's rmse: 1.20183\tvalid_1's rmse: 50.3195\n",
      "[1800]\ttraining's rmse: 1.14595\tvalid_1's rmse: 50.3184\n",
      "[1830]\ttraining's rmse: 1.09253\tvalid_1's rmse: 50.3179\n",
      "[1860]\ttraining's rmse: 1.04274\tvalid_1's rmse: 50.3159\n",
      "[1890]\ttraining's rmse: 0.993355\tvalid_1's rmse: 50.3158\n",
      "[1920]\ttraining's rmse: 0.949326\tvalid_1's rmse: 50.315\n",
      "[1950]\ttraining's rmse: 0.905756\tvalid_1's rmse: 50.3149\n",
      "[1980]\ttraining's rmse: 0.864248\tvalid_1's rmse: 50.3142\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's rmse: 0.838413\tvalid_1's rmse: 50.3129\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002262 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 20024\n",
      "[LightGBM] [Info] Number of data points in the train set: 9219, number of used features: 79\n",
      "[LightGBM] [Info] Start training from score 367.729997\n",
      "Training until validation scores don't improve for 125 rounds\n",
      "[30]\ttraining's rmse: 153.954\tvalid_1's rmse: 159.3\n",
      "[60]\ttraining's rmse: 96.8432\tvalid_1's rmse: 108.89\n",
      "[90]\ttraining's rmse: 65.6645\tvalid_1's rmse: 83.212\n",
      "[120]\ttraining's rmse: 48.9983\tvalid_1's rmse: 71.1641\n",
      "[150]\ttraining's rmse: 39.5102\tvalid_1's rmse: 64.723\n",
      "[180]\ttraining's rmse: 33.5673\tvalid_1's rmse: 61.3567\n",
      "[210]\ttraining's rmse: 29.3089\tvalid_1's rmse: 59.2003\n",
      "[240]\ttraining's rmse: 26.1477\tvalid_1's rmse: 57.7343\n",
      "[270]\ttraining's rmse: 23.6077\tvalid_1's rmse: 56.9478\n",
      "[300]\ttraining's rmse: 21.4744\tvalid_1's rmse: 56.3446\n",
      "[330]\ttraining's rmse: 19.6414\tvalid_1's rmse: 55.8559\n",
      "[360]\ttraining's rmse: 18.07\tvalid_1's rmse: 55.5526\n",
      "[390]\ttraining's rmse: 16.6816\tvalid_1's rmse: 55.2834\n",
      "[420]\ttraining's rmse: 15.4574\tvalid_1's rmse: 55.0594\n",
      "[450]\ttraining's rmse: 14.3529\tvalid_1's rmse: 54.8794\n",
      "[480]\ttraining's rmse: 13.3472\tvalid_1's rmse: 54.7148\n",
      "[510]\ttraining's rmse: 12.4222\tvalid_1's rmse: 54.61\n",
      "[540]\ttraining's rmse: 11.5875\tvalid_1's rmse: 54.4988\n",
      "[570]\ttraining's rmse: 10.8416\tvalid_1's rmse: 54.4296\n",
      "[600]\ttraining's rmse: 10.1281\tvalid_1's rmse: 54.3541\n",
      "[630]\ttraining's rmse: 9.48618\tvalid_1's rmse: 54.282\n",
      "[660]\ttraining's rmse: 8.88885\tvalid_1's rmse: 54.2288\n",
      "[690]\ttraining's rmse: 8.33269\tvalid_1's rmse: 54.1897\n",
      "[720]\ttraining's rmse: 7.82833\tvalid_1's rmse: 54.1386\n",
      "[750]\ttraining's rmse: 7.35313\tvalid_1's rmse: 54.1084\n",
      "[780]\ttraining's rmse: 6.92596\tvalid_1's rmse: 54.0826\n",
      "[810]\ttraining's rmse: 6.53063\tvalid_1's rmse: 54.038\n",
      "[840]\ttraining's rmse: 6.15842\tvalid_1's rmse: 54.0248\n",
      "[870]\ttraining's rmse: 5.80987\tvalid_1's rmse: 53.9956\n",
      "[900]\ttraining's rmse: 5.47348\tvalid_1's rmse: 53.9851\n",
      "[930]\ttraining's rmse: 5.1657\tvalid_1's rmse: 53.9717\n",
      "[960]\ttraining's rmse: 4.88191\tvalid_1's rmse: 53.9561\n",
      "[990]\ttraining's rmse: 4.61169\tvalid_1's rmse: 53.9329\n",
      "[1020]\ttraining's rmse: 4.36139\tvalid_1's rmse: 53.9097\n",
      "[1050]\ttraining's rmse: 4.12387\tvalid_1's rmse: 53.9082\n",
      "[1080]\ttraining's rmse: 3.90267\tvalid_1's rmse: 53.9029\n",
      "[1110]\ttraining's rmse: 3.69205\tvalid_1's rmse: 53.8948\n",
      "[1140]\ttraining's rmse: 3.50175\tvalid_1's rmse: 53.8881\n",
      "[1170]\ttraining's rmse: 3.31751\tvalid_1's rmse: 53.8809\n",
      "[1200]\ttraining's rmse: 3.14636\tvalid_1's rmse: 53.8693\n",
      "[1230]\ttraining's rmse: 2.98548\tvalid_1's rmse: 53.8613\n",
      "[1260]\ttraining's rmse: 2.82978\tvalid_1's rmse: 53.8578\n",
      "[1290]\ttraining's rmse: 2.68266\tvalid_1's rmse: 53.8522\n",
      "[1320]\ttraining's rmse: 2.54584\tvalid_1's rmse: 53.8484\n",
      "[1350]\ttraining's rmse: 2.41723\tvalid_1's rmse: 53.8444\n",
      "[1380]\ttraining's rmse: 2.29268\tvalid_1's rmse: 53.8401\n",
      "[1410]\ttraining's rmse: 2.1772\tvalid_1's rmse: 53.8361\n",
      "[1440]\ttraining's rmse: 2.06893\tvalid_1's rmse: 53.8321\n",
      "[1470]\ttraining's rmse: 1.9661\tvalid_1's rmse: 53.8281\n",
      "[1500]\ttraining's rmse: 1.86698\tvalid_1's rmse: 53.8239\n",
      "[1530]\ttraining's rmse: 1.77548\tvalid_1's rmse: 53.8177\n",
      "[1560]\ttraining's rmse: 1.68863\tvalid_1's rmse: 53.8159\n",
      "[1590]\ttraining's rmse: 1.60911\tvalid_1's rmse: 53.8118\n",
      "[1620]\ttraining's rmse: 1.53199\tvalid_1's rmse: 53.8089\n",
      "[1650]\ttraining's rmse: 1.45977\tvalid_1's rmse: 53.8074\n",
      "[1680]\ttraining's rmse: 1.39172\tvalid_1's rmse: 53.8058\n",
      "[1710]\ttraining's rmse: 1.32586\tvalid_1's rmse: 53.8033\n",
      "[1740]\ttraining's rmse: 1.2642\tvalid_1's rmse: 53.8004\n",
      "[1770]\ttraining's rmse: 1.2032\tvalid_1's rmse: 53.7993\n",
      "[1800]\ttraining's rmse: 1.14744\tvalid_1's rmse: 53.7963\n",
      "[1830]\ttraining's rmse: 1.0956\tvalid_1's rmse: 53.7953\n",
      "[1860]\ttraining's rmse: 1.04426\tvalid_1's rmse: 53.7925\n",
      "[1890]\ttraining's rmse: 0.995273\tvalid_1's rmse: 53.7924\n",
      "[1920]\ttraining's rmse: 0.951265\tvalid_1's rmse: 53.791\n",
      "[1950]\ttraining's rmse: 0.908608\tvalid_1's rmse: 53.7889\n",
      "[1980]\ttraining's rmse: 0.8677\tvalid_1's rmse: 53.7866\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's rmse: 0.842466\tvalid_1's rmse: 53.7878\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002236 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 20024\n",
      "[LightGBM] [Info] Number of data points in the train set: 9219, number of used features: 79\n",
      "[LightGBM] [Info] Start training from score 363.655210\n",
      "Training until validation scores don't improve for 125 rounds\n",
      "[30]\ttraining's rmse: 153.665\tvalid_1's rmse: 159.858\n",
      "[60]\ttraining's rmse: 96.2478\tvalid_1's rmse: 107.655\n",
      "[90]\ttraining's rmse: 64.9808\tvalid_1's rmse: 82.5538\n",
      "[120]\ttraining's rmse: 48.1945\tvalid_1's rmse: 71.106\n",
      "[150]\ttraining's rmse: 38.7612\tvalid_1's rmse: 65.7949\n",
      "[180]\ttraining's rmse: 32.9799\tvalid_1's rmse: 62.9089\n",
      "[210]\ttraining's rmse: 28.9246\tvalid_1's rmse: 61.2047\n",
      "[240]\ttraining's rmse: 25.8906\tvalid_1's rmse: 60.139\n",
      "[270]\ttraining's rmse: 23.3955\tvalid_1's rmse: 59.4028\n",
      "[300]\ttraining's rmse: 21.316\tvalid_1's rmse: 58.7897\n",
      "[330]\ttraining's rmse: 19.5523\tvalid_1's rmse: 58.4005\n",
      "[360]\ttraining's rmse: 18.0063\tvalid_1's rmse: 58.1286\n",
      "[390]\ttraining's rmse: 16.654\tvalid_1's rmse: 57.8672\n",
      "[420]\ttraining's rmse: 15.4543\tvalid_1's rmse: 57.7013\n",
      "[450]\ttraining's rmse: 14.3653\tvalid_1's rmse: 57.5682\n",
      "[480]\ttraining's rmse: 13.3741\tvalid_1's rmse: 57.4633\n",
      "[510]\ttraining's rmse: 12.4536\tvalid_1's rmse: 57.3737\n",
      "[540]\ttraining's rmse: 11.6291\tvalid_1's rmse: 57.307\n",
      "[570]\ttraining's rmse: 10.8707\tvalid_1's rmse: 57.2041\n",
      "[600]\ttraining's rmse: 10.1777\tvalid_1's rmse: 57.172\n",
      "[630]\ttraining's rmse: 9.52381\tvalid_1's rmse: 57.1246\n",
      "[660]\ttraining's rmse: 8.92522\tvalid_1's rmse: 57.0985\n",
      "[690]\ttraining's rmse: 8.37523\tvalid_1's rmse: 57.0629\n",
      "[720]\ttraining's rmse: 7.87143\tvalid_1's rmse: 57.0361\n",
      "[750]\ttraining's rmse: 7.39796\tvalid_1's rmse: 57.0125\n",
      "[780]\ttraining's rmse: 6.96518\tvalid_1's rmse: 56.9866\n",
      "[810]\ttraining's rmse: 6.55455\tvalid_1's rmse: 56.9545\n",
      "[840]\ttraining's rmse: 6.17922\tvalid_1's rmse: 56.938\n",
      "[870]\ttraining's rmse: 5.81926\tvalid_1's rmse: 56.9194\n",
      "[900]\ttraining's rmse: 5.48791\tvalid_1's rmse: 56.8908\n",
      "[930]\ttraining's rmse: 5.17655\tvalid_1's rmse: 56.8844\n",
      "[960]\ttraining's rmse: 4.88989\tvalid_1's rmse: 56.8697\n",
      "[990]\ttraining's rmse: 4.6192\tvalid_1's rmse: 56.8655\n",
      "[1020]\ttraining's rmse: 4.36811\tvalid_1's rmse: 56.8597\n",
      "[1050]\ttraining's rmse: 4.13595\tvalid_1's rmse: 56.8394\n",
      "[1080]\ttraining's rmse: 3.9136\tvalid_1's rmse: 56.8398\n",
      "[1110]\ttraining's rmse: 3.7054\tvalid_1's rmse: 56.8405\n",
      "[1140]\ttraining's rmse: 3.51045\tvalid_1's rmse: 56.8412\n",
      "[1170]\ttraining's rmse: 3.32921\tvalid_1's rmse: 56.8331\n",
      "[1200]\ttraining's rmse: 3.15332\tvalid_1's rmse: 56.8283\n",
      "[1230]\ttraining's rmse: 2.98772\tvalid_1's rmse: 56.8257\n",
      "[1260]\ttraining's rmse: 2.8307\tvalid_1's rmse: 56.8205\n",
      "[1290]\ttraining's rmse: 2.68603\tvalid_1's rmse: 56.8138\n",
      "[1320]\ttraining's rmse: 2.54744\tvalid_1's rmse: 56.8112\n",
      "[1350]\ttraining's rmse: 2.41809\tvalid_1's rmse: 56.8025\n",
      "[1380]\ttraining's rmse: 2.29643\tvalid_1's rmse: 56.7985\n",
      "[1410]\ttraining's rmse: 2.18143\tvalid_1's rmse: 56.7977\n",
      "[1440]\ttraining's rmse: 2.07037\tvalid_1's rmse: 56.7985\n",
      "[1470]\ttraining's rmse: 1.96728\tvalid_1's rmse: 56.7975\n",
      "[1500]\ttraining's rmse: 1.86928\tvalid_1's rmse: 56.7979\n",
      "[1530]\ttraining's rmse: 1.77649\tvalid_1's rmse: 56.7953\n",
      "[1560]\ttraining's rmse: 1.69125\tvalid_1's rmse: 56.7956\n",
      "[1590]\ttraining's rmse: 1.61022\tvalid_1's rmse: 56.7916\n",
      "[1620]\ttraining's rmse: 1.53223\tvalid_1's rmse: 56.7916\n",
      "[1650]\ttraining's rmse: 1.45782\tvalid_1's rmse: 56.7884\n",
      "[1680]\ttraining's rmse: 1.38813\tvalid_1's rmse: 56.7863\n",
      "[1710]\ttraining's rmse: 1.32183\tvalid_1's rmse: 56.7842\n",
      "[1740]\ttraining's rmse: 1.25956\tvalid_1's rmse: 56.7831\n",
      "[1770]\ttraining's rmse: 1.19946\tvalid_1's rmse: 56.7822\n",
      "[1800]\ttraining's rmse: 1.1435\tvalid_1's rmse: 56.7836\n",
      "[1830]\ttraining's rmse: 1.08995\tvalid_1's rmse: 56.7848\n",
      "Early stopping, best iteration is:\n",
      "[1727]\ttraining's rmse: 1.28595\tvalid_1's rmse: 56.7811\n",
      "20\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003248 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 20024\n",
      "[LightGBM] [Info] Number of data points in the train set: 9219, number of used features: 79\n",
      "[LightGBM] [Info] Start training from score 356.933281\n",
      "Training until validation scores don't improve for 125 rounds\n",
      "[30]\ttraining's rmse: 153.241\tvalid_1's rmse: 154.071\n",
      "[60]\ttraining's rmse: 95.0278\tvalid_1's rmse: 101.134\n",
      "[90]\ttraining's rmse: 63.8275\tvalid_1's rmse: 75.8036\n",
      "[120]\ttraining's rmse: 46.8541\tvalid_1's rmse: 63.6865\n",
      "[150]\ttraining's rmse: 37.4923\tvalid_1's rmse: 57.9453\n",
      "[180]\ttraining's rmse: 31.8454\tvalid_1's rmse: 55.1284\n",
      "[210]\ttraining's rmse: 27.9628\tvalid_1's rmse: 53.5089\n",
      "[240]\ttraining's rmse: 24.8319\tvalid_1's rmse: 52.2974\n",
      "[270]\ttraining's rmse: 22.3594\tvalid_1's rmse: 51.453\n",
      "[300]\ttraining's rmse: 20.2969\tvalid_1's rmse: 50.8805\n",
      "[330]\ttraining's rmse: 18.6059\tvalid_1's rmse: 50.5737\n",
      "[360]\ttraining's rmse: 17.075\tvalid_1's rmse: 50.3575\n",
      "[390]\ttraining's rmse: 15.7593\tvalid_1's rmse: 50.1479\n",
      "[420]\ttraining's rmse: 14.5884\tvalid_1's rmse: 49.9736\n",
      "[450]\ttraining's rmse: 13.529\tvalid_1's rmse: 49.8784\n",
      "[480]\ttraining's rmse: 12.5648\tvalid_1's rmse: 49.8053\n",
      "[510]\ttraining's rmse: 11.6961\tvalid_1's rmse: 49.6923\n",
      "[540]\ttraining's rmse: 10.9117\tvalid_1's rmse: 49.57\n",
      "[570]\ttraining's rmse: 10.1839\tvalid_1's rmse: 49.5249\n",
      "[600]\ttraining's rmse: 9.51502\tvalid_1's rmse: 49.4278\n",
      "[630]\ttraining's rmse: 8.91511\tvalid_1's rmse: 49.3838\n",
      "[660]\ttraining's rmse: 8.35006\tvalid_1's rmse: 49.3448\n",
      "[690]\ttraining's rmse: 7.83087\tvalid_1's rmse: 49.2812\n",
      "[720]\ttraining's rmse: 7.35372\tvalid_1's rmse: 49.2479\n",
      "[750]\ttraining's rmse: 6.91935\tvalid_1's rmse: 49.2305\n",
      "[780]\ttraining's rmse: 6.51983\tvalid_1's rmse: 49.187\n",
      "[810]\ttraining's rmse: 6.13234\tvalid_1's rmse: 49.1655\n",
      "[840]\ttraining's rmse: 5.78345\tvalid_1's rmse: 49.1514\n",
      "[870]\ttraining's rmse: 5.45498\tvalid_1's rmse: 49.1399\n",
      "[900]\ttraining's rmse: 5.14063\tvalid_1's rmse: 49.12\n",
      "[930]\ttraining's rmse: 4.85633\tvalid_1's rmse: 49.1086\n",
      "[960]\ttraining's rmse: 4.58166\tvalid_1's rmse: 49.1023\n",
      "[990]\ttraining's rmse: 4.33479\tvalid_1's rmse: 49.0978\n",
      "[1020]\ttraining's rmse: 4.09677\tvalid_1's rmse: 49.0813\n",
      "[1050]\ttraining's rmse: 3.87662\tvalid_1's rmse: 49.0713\n",
      "[1080]\ttraining's rmse: 3.66253\tvalid_1's rmse: 49.0629\n",
      "[1110]\ttraining's rmse: 3.46439\tvalid_1's rmse: 49.0581\n",
      "[1140]\ttraining's rmse: 3.27764\tvalid_1's rmse: 49.0577\n",
      "[1170]\ttraining's rmse: 3.10416\tvalid_1's rmse: 49.0477\n",
      "[1200]\ttraining's rmse: 2.94041\tvalid_1's rmse: 49.0422\n",
      "[1230]\ttraining's rmse: 2.78832\tvalid_1's rmse: 49.0347\n",
      "[1260]\ttraining's rmse: 2.64277\tvalid_1's rmse: 49.0294\n",
      "[1290]\ttraining's rmse: 2.50401\tvalid_1's rmse: 49.0215\n",
      "[1320]\ttraining's rmse: 2.37719\tvalid_1's rmse: 49.0174\n",
      "[1350]\ttraining's rmse: 2.25547\tvalid_1's rmse: 49.0125\n",
      "[1380]\ttraining's rmse: 2.14022\tvalid_1's rmse: 49.0093\n",
      "[1410]\ttraining's rmse: 2.02938\tvalid_1's rmse: 49.0095\n",
      "[1440]\ttraining's rmse: 1.92682\tvalid_1's rmse: 49.0059\n",
      "[1470]\ttraining's rmse: 1.83007\tvalid_1's rmse: 49.0024\n",
      "[1500]\ttraining's rmse: 1.73934\tvalid_1's rmse: 48.9997\n",
      "[1530]\ttraining's rmse: 1.65242\tvalid_1's rmse: 49\n",
      "[1560]\ttraining's rmse: 1.57227\tvalid_1's rmse: 48.9999\n",
      "[1590]\ttraining's rmse: 1.49449\tvalid_1's rmse: 48.997\n",
      "[1620]\ttraining's rmse: 1.42068\tvalid_1's rmse: 48.996\n",
      "[1650]\ttraining's rmse: 1.35076\tvalid_1's rmse: 48.995\n",
      "[1680]\ttraining's rmse: 1.28428\tvalid_1's rmse: 48.994\n",
      "[1710]\ttraining's rmse: 1.22204\tvalid_1's rmse: 48.9944\n",
      "[1740]\ttraining's rmse: 1.16392\tvalid_1's rmse: 48.9958\n",
      "[1770]\ttraining's rmse: 1.10807\tvalid_1's rmse: 48.9935\n",
      "[1800]\ttraining's rmse: 1.05499\tvalid_1's rmse: 48.9928\n",
      "[1830]\ttraining's rmse: 1.00531\tvalid_1's rmse: 48.9932\n",
      "[1860]\ttraining's rmse: 0.95735\tvalid_1's rmse: 48.9938\n",
      "[1890]\ttraining's rmse: 0.911603\tvalid_1's rmse: 48.9942\n",
      "[1920]\ttraining's rmse: 0.867317\tvalid_1's rmse: 48.9951\n",
      "Early stopping, best iteration is:\n",
      "[1808]\ttraining's rmse: 1.04133\tvalid_1's rmse: 48.9918\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003284 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 20024\n",
      "[LightGBM] [Info] Number of data points in the train set: 9219, number of used features: 79\n",
      "[LightGBM] [Info] Start training from score 364.236337\n",
      "Training until validation scores don't improve for 125 rounds\n",
      "[30]\ttraining's rmse: 154.901\tvalid_1's rmse: 151.813\n",
      "[60]\ttraining's rmse: 97.5863\tvalid_1's rmse: 101.028\n",
      "[90]\ttraining's rmse: 66.5622\tvalid_1's rmse: 75.1433\n",
      "[120]\ttraining's rmse: 49.6173\tvalid_1's rmse: 62.5138\n",
      "[150]\ttraining's rmse: 39.8906\tvalid_1's rmse: 56.1441\n",
      "[180]\ttraining's rmse: 33.9652\tvalid_1's rmse: 52.844\n",
      "[210]\ttraining's rmse: 29.859\tvalid_1's rmse: 51.0634\n",
      "[240]\ttraining's rmse: 26.548\tvalid_1's rmse: 49.9019\n",
      "[270]\ttraining's rmse: 23.8586\tvalid_1's rmse: 48.9182\n",
      "[300]\ttraining's rmse: 21.6338\tvalid_1's rmse: 48.2415\n",
      "[330]\ttraining's rmse: 19.7914\tvalid_1's rmse: 47.7668\n",
      "[360]\ttraining's rmse: 18.1878\tvalid_1's rmse: 47.4479\n",
      "[390]\ttraining's rmse: 16.7659\tvalid_1's rmse: 47.1777\n",
      "[420]\ttraining's rmse: 15.5116\tvalid_1's rmse: 46.9511\n",
      "[450]\ttraining's rmse: 14.3941\tvalid_1's rmse: 46.8137\n",
      "[480]\ttraining's rmse: 13.3702\tvalid_1's rmse: 46.706\n",
      "[510]\ttraining's rmse: 12.4462\tvalid_1's rmse: 46.6193\n",
      "[540]\ttraining's rmse: 11.6037\tvalid_1's rmse: 46.5039\n",
      "[570]\ttraining's rmse: 10.8299\tvalid_1's rmse: 46.4115\n",
      "[600]\ttraining's rmse: 10.1216\tvalid_1's rmse: 46.3606\n",
      "[630]\ttraining's rmse: 9.4828\tvalid_1's rmse: 46.3304\n",
      "[660]\ttraining's rmse: 8.87545\tvalid_1's rmse: 46.2457\n",
      "[690]\ttraining's rmse: 8.31157\tvalid_1's rmse: 46.1875\n",
      "[720]\ttraining's rmse: 7.81392\tvalid_1's rmse: 46.1544\n",
      "[750]\ttraining's rmse: 7.33817\tvalid_1's rmse: 46.1416\n",
      "[780]\ttraining's rmse: 6.90025\tvalid_1's rmse: 46.1212\n",
      "[810]\ttraining's rmse: 6.48652\tvalid_1's rmse: 46.0818\n",
      "[840]\ttraining's rmse: 6.10917\tvalid_1's rmse: 46.0705\n",
      "[870]\ttraining's rmse: 5.75642\tvalid_1's rmse: 46.066\n",
      "[900]\ttraining's rmse: 5.42437\tvalid_1's rmse: 46.0463\n",
      "[930]\ttraining's rmse: 5.11391\tvalid_1's rmse: 46.0297\n",
      "[960]\ttraining's rmse: 4.82844\tvalid_1's rmse: 46.0185\n",
      "[990]\ttraining's rmse: 4.55731\tvalid_1's rmse: 46.0136\n",
      "[1020]\ttraining's rmse: 4.3069\tvalid_1's rmse: 45.9978\n",
      "[1050]\ttraining's rmse: 4.07529\tvalid_1's rmse: 45.9961\n",
      "[1080]\ttraining's rmse: 3.85823\tvalid_1's rmse: 45.9885\n",
      "[1110]\ttraining's rmse: 3.65021\tvalid_1's rmse: 45.9809\n",
      "[1140]\ttraining's rmse: 3.45589\tvalid_1's rmse: 45.9745\n",
      "[1170]\ttraining's rmse: 3.27687\tvalid_1's rmse: 45.973\n",
      "[1200]\ttraining's rmse: 3.10115\tvalid_1's rmse: 45.9686\n",
      "[1230]\ttraining's rmse: 2.93706\tvalid_1's rmse: 45.9621\n",
      "[1260]\ttraining's rmse: 2.78504\tvalid_1's rmse: 45.9593\n",
      "[1290]\ttraining's rmse: 2.63854\tvalid_1's rmse: 45.9519\n",
      "[1320]\ttraining's rmse: 2.50148\tvalid_1's rmse: 45.9448\n",
      "[1350]\ttraining's rmse: 2.37064\tvalid_1's rmse: 45.9436\n",
      "[1380]\ttraining's rmse: 2.25041\tvalid_1's rmse: 45.9391\n",
      "[1410]\ttraining's rmse: 2.13449\tvalid_1's rmse: 45.937\n",
      "[1440]\ttraining's rmse: 2.02529\tvalid_1's rmse: 45.9378\n",
      "[1470]\ttraining's rmse: 1.9218\tvalid_1's rmse: 45.932\n",
      "[1500]\ttraining's rmse: 1.8243\tvalid_1's rmse: 45.9304\n",
      "[1530]\ttraining's rmse: 1.73399\tvalid_1's rmse: 45.9253\n",
      "[1560]\ttraining's rmse: 1.64749\tvalid_1's rmse: 45.9233\n",
      "[1590]\ttraining's rmse: 1.56491\tvalid_1's rmse: 45.9216\n",
      "[1620]\ttraining's rmse: 1.48637\tvalid_1's rmse: 45.9198\n",
      "[1650]\ttraining's rmse: 1.41416\tvalid_1's rmse: 45.9179\n",
      "[1680]\ttraining's rmse: 1.344\tvalid_1's rmse: 45.9131\n",
      "[1710]\ttraining's rmse: 1.2781\tvalid_1's rmse: 45.9113\n",
      "[1740]\ttraining's rmse: 1.21737\tvalid_1's rmse: 45.9085\n",
      "[1770]\ttraining's rmse: 1.15722\tvalid_1's rmse: 45.91\n",
      "[1800]\ttraining's rmse: 1.10192\tvalid_1's rmse: 45.9101\n",
      "[1830]\ttraining's rmse: 1.04835\tvalid_1's rmse: 45.9104\n",
      "[1860]\ttraining's rmse: 0.997726\tvalid_1's rmse: 45.9089\n",
      "Early stopping, best iteration is:\n",
      "[1738]\ttraining's rmse: 1.22143\tvalid_1's rmse: 45.9081\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003704 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 20024\n",
      "[LightGBM] [Info] Number of data points in the train set: 9219, number of used features: 79\n",
      "[LightGBM] [Info] Start training from score 364.555425\n",
      "Training until validation scores don't improve for 125 rounds\n",
      "[30]\ttraining's rmse: 154.631\tvalid_1's rmse: 154.08\n",
      "[60]\ttraining's rmse: 97.2928\tvalid_1's rmse: 104.147\n",
      "[90]\ttraining's rmse: 65.6626\tvalid_1's rmse: 78.8834\n",
      "[120]\ttraining's rmse: 48.5701\tvalid_1's rmse: 67.2751\n",
      "[150]\ttraining's rmse: 39.1174\tvalid_1's rmse: 61.914\n",
      "[180]\ttraining's rmse: 33.254\tvalid_1's rmse: 59.2153\n",
      "[210]\ttraining's rmse: 29.1413\tvalid_1's rmse: 57.7176\n",
      "[240]\ttraining's rmse: 25.9419\tvalid_1's rmse: 56.7302\n",
      "[270]\ttraining's rmse: 23.359\tvalid_1's rmse: 55.9146\n",
      "[300]\ttraining's rmse: 21.1606\tvalid_1's rmse: 55.3824\n",
      "[330]\ttraining's rmse: 19.3412\tvalid_1's rmse: 55.0314\n",
      "[360]\ttraining's rmse: 17.7549\tvalid_1's rmse: 54.7619\n",
      "[390]\ttraining's rmse: 16.3705\tvalid_1's rmse: 54.4417\n",
      "[420]\ttraining's rmse: 15.1325\tvalid_1's rmse: 54.2327\n",
      "[450]\ttraining's rmse: 14.0378\tvalid_1's rmse: 54.0946\n",
      "[480]\ttraining's rmse: 13.0338\tvalid_1's rmse: 53.944\n",
      "[510]\ttraining's rmse: 12.1304\tvalid_1's rmse: 53.8006\n",
      "[540]\ttraining's rmse: 11.3141\tvalid_1's rmse: 53.7184\n",
      "[570]\ttraining's rmse: 10.576\tvalid_1's rmse: 53.6588\n",
      "[600]\ttraining's rmse: 9.89439\tvalid_1's rmse: 53.5986\n",
      "[630]\ttraining's rmse: 9.26047\tvalid_1's rmse: 53.5372\n",
      "[660]\ttraining's rmse: 8.678\tvalid_1's rmse: 53.5043\n",
      "[690]\ttraining's rmse: 8.13808\tvalid_1's rmse: 53.4646\n",
      "[720]\ttraining's rmse: 7.64269\tvalid_1's rmse: 53.4314\n",
      "[750]\ttraining's rmse: 7.19526\tvalid_1's rmse: 53.4142\n",
      "[780]\ttraining's rmse: 6.77012\tvalid_1's rmse: 53.385\n",
      "[810]\ttraining's rmse: 6.37563\tvalid_1's rmse: 53.3486\n",
      "[840]\ttraining's rmse: 6.01021\tvalid_1's rmse: 53.3356\n",
      "[870]\ttraining's rmse: 5.66174\tvalid_1's rmse: 53.31\n",
      "[900]\ttraining's rmse: 5.33901\tvalid_1's rmse: 53.2857\n",
      "[930]\ttraining's rmse: 5.04421\tvalid_1's rmse: 53.2738\n",
      "[960]\ttraining's rmse: 4.76907\tvalid_1's rmse: 53.2627\n",
      "[990]\ttraining's rmse: 4.50905\tvalid_1's rmse: 53.2404\n",
      "[1020]\ttraining's rmse: 4.26929\tvalid_1's rmse: 53.2228\n",
      "[1050]\ttraining's rmse: 4.04296\tvalid_1's rmse: 53.2142\n",
      "[1080]\ttraining's rmse: 3.82513\tvalid_1's rmse: 53.211\n",
      "[1110]\ttraining's rmse: 3.62418\tvalid_1's rmse: 53.1997\n",
      "[1140]\ttraining's rmse: 3.42975\tvalid_1's rmse: 53.1906\n",
      "[1170]\ttraining's rmse: 3.25135\tvalid_1's rmse: 53.1873\n",
      "[1200]\ttraining's rmse: 3.08201\tvalid_1's rmse: 53.1748\n",
      "[1230]\ttraining's rmse: 2.92448\tvalid_1's rmse: 53.1737\n",
      "[1260]\ttraining's rmse: 2.7767\tvalid_1's rmse: 53.1695\n",
      "[1290]\ttraining's rmse: 2.63235\tvalid_1's rmse: 53.1637\n",
      "[1320]\ttraining's rmse: 2.49631\tvalid_1's rmse: 53.1616\n",
      "[1350]\ttraining's rmse: 2.37192\tvalid_1's rmse: 53.1572\n",
      "[1380]\ttraining's rmse: 2.25302\tvalid_1's rmse: 53.1572\n",
      "[1410]\ttraining's rmse: 2.1396\tvalid_1's rmse: 53.1524\n",
      "[1440]\ttraining's rmse: 2.03339\tvalid_1's rmse: 53.1491\n",
      "[1470]\ttraining's rmse: 1.93233\tvalid_1's rmse: 53.1433\n",
      "[1500]\ttraining's rmse: 1.83602\tvalid_1's rmse: 53.1401\n",
      "[1530]\ttraining's rmse: 1.7477\tvalid_1's rmse: 53.1391\n",
      "[1560]\ttraining's rmse: 1.66123\tvalid_1's rmse: 53.1316\n",
      "[1590]\ttraining's rmse: 1.58117\tvalid_1's rmse: 53.1276\n",
      "[1620]\ttraining's rmse: 1.50567\tvalid_1's rmse: 53.1281\n",
      "[1650]\ttraining's rmse: 1.43264\tvalid_1's rmse: 53.1243\n",
      "[1680]\ttraining's rmse: 1.36379\tvalid_1's rmse: 53.1244\n",
      "[1710]\ttraining's rmse: 1.30104\tvalid_1's rmse: 53.1256\n",
      "[1740]\ttraining's rmse: 1.23926\tvalid_1's rmse: 53.1222\n",
      "[1770]\ttraining's rmse: 1.18113\tvalid_1's rmse: 53.1217\n",
      "[1800]\ttraining's rmse: 1.12392\tvalid_1's rmse: 53.1231\n",
      "[1830]\ttraining's rmse: 1.07002\tvalid_1's rmse: 53.1205\n",
      "[1860]\ttraining's rmse: 1.02042\tvalid_1's rmse: 53.1183\n",
      "[1890]\ttraining's rmse: 0.971585\tvalid_1's rmse: 53.1154\n",
      "[1920]\ttraining's rmse: 0.926821\tvalid_1's rmse: 53.115\n",
      "[1950]\ttraining's rmse: 0.884539\tvalid_1's rmse: 53.1142\n",
      "[1980]\ttraining's rmse: 0.843853\tvalid_1's rmse: 53.1134\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's rmse: 0.817138\tvalid_1's rmse: 53.1129\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003421 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 20024\n",
      "[LightGBM] [Info] Number of data points in the train set: 9219, number of used features: 79\n",
      "[LightGBM] [Info] Start training from score 367.822387\n",
      "Training until validation scores don't improve for 125 rounds\n",
      "[30]\ttraining's rmse: 154.181\tvalid_1's rmse: 155.323\n",
      "[60]\ttraining's rmse: 97.0272\tvalid_1's rmse: 105.51\n",
      "[90]\ttraining's rmse: 65.905\tvalid_1's rmse: 81.1259\n",
      "[120]\ttraining's rmse: 49.0569\tvalid_1's rmse: 69.6493\n",
      "[150]\ttraining's rmse: 39.5719\tvalid_1's rmse: 64.0475\n",
      "[180]\ttraining's rmse: 33.6223\tvalid_1's rmse: 61.1357\n",
      "[210]\ttraining's rmse: 29.4166\tvalid_1's rmse: 59.3898\n",
      "[240]\ttraining's rmse: 26.1929\tvalid_1's rmse: 58.2525\n",
      "[270]\ttraining's rmse: 23.6101\tvalid_1's rmse: 57.3945\n",
      "[300]\ttraining's rmse: 21.4209\tvalid_1's rmse: 56.8706\n",
      "[330]\ttraining's rmse: 19.5969\tvalid_1's rmse: 56.4432\n",
      "[360]\ttraining's rmse: 17.9681\tvalid_1's rmse: 56.0806\n",
      "[390]\ttraining's rmse: 16.5596\tvalid_1's rmse: 55.8183\n",
      "[420]\ttraining's rmse: 15.3003\tvalid_1's rmse: 55.5877\n",
      "[450]\ttraining's rmse: 14.1911\tvalid_1's rmse: 55.3798\n",
      "[480]\ttraining's rmse: 13.1686\tvalid_1's rmse: 55.2323\n",
      "[510]\ttraining's rmse: 12.2571\tvalid_1's rmse: 55.117\n",
      "[540]\ttraining's rmse: 11.4324\tvalid_1's rmse: 55.0241\n",
      "[570]\ttraining's rmse: 10.6738\tvalid_1's rmse: 54.9526\n",
      "[600]\ttraining's rmse: 9.98303\tvalid_1's rmse: 54.8581\n",
      "[630]\ttraining's rmse: 9.34279\tvalid_1's rmse: 54.8032\n",
      "[660]\ttraining's rmse: 8.75004\tvalid_1's rmse: 54.7742\n",
      "[690]\ttraining's rmse: 8.19849\tvalid_1's rmse: 54.7206\n",
      "[720]\ttraining's rmse: 7.70116\tvalid_1's rmse: 54.685\n",
      "[750]\ttraining's rmse: 7.24507\tvalid_1's rmse: 54.6518\n",
      "[780]\ttraining's rmse: 6.82672\tvalid_1's rmse: 54.6285\n",
      "[810]\ttraining's rmse: 6.42011\tvalid_1's rmse: 54.5969\n",
      "[840]\ttraining's rmse: 6.054\tvalid_1's rmse: 54.5578\n",
      "[870]\ttraining's rmse: 5.70184\tvalid_1's rmse: 54.54\n",
      "[900]\ttraining's rmse: 5.3809\tvalid_1's rmse: 54.5249\n",
      "[930]\ttraining's rmse: 5.07754\tvalid_1's rmse: 54.5025\n",
      "[960]\ttraining's rmse: 4.79789\tvalid_1's rmse: 54.4818\n",
      "[990]\ttraining's rmse: 4.53131\tvalid_1's rmse: 54.4633\n",
      "[1020]\ttraining's rmse: 4.27375\tvalid_1's rmse: 54.4421\n",
      "[1050]\ttraining's rmse: 4.03181\tvalid_1's rmse: 54.4279\n",
      "[1080]\ttraining's rmse: 3.81513\tvalid_1's rmse: 54.4239\n",
      "[1110]\ttraining's rmse: 3.60868\tvalid_1's rmse: 54.4111\n",
      "[1140]\ttraining's rmse: 3.4114\tvalid_1's rmse: 54.3978\n",
      "[1170]\ttraining's rmse: 3.23246\tvalid_1's rmse: 54.392\n",
      "[1200]\ttraining's rmse: 3.05597\tvalid_1's rmse: 54.3886\n",
      "[1230]\ttraining's rmse: 2.89456\tvalid_1's rmse: 54.388\n",
      "[1260]\ttraining's rmse: 2.74381\tvalid_1's rmse: 54.381\n",
      "[1290]\ttraining's rmse: 2.60366\tvalid_1's rmse: 54.3761\n",
      "[1320]\ttraining's rmse: 2.46559\tvalid_1's rmse: 54.3698\n",
      "[1350]\ttraining's rmse: 2.33947\tvalid_1's rmse: 54.3634\n",
      "[1380]\ttraining's rmse: 2.21979\tvalid_1's rmse: 54.3576\n",
      "[1410]\ttraining's rmse: 2.10673\tvalid_1's rmse: 54.3504\n",
      "[1440]\ttraining's rmse: 1.99826\tvalid_1's rmse: 54.3452\n",
      "[1470]\ttraining's rmse: 1.89559\tvalid_1's rmse: 54.3384\n",
      "[1500]\ttraining's rmse: 1.79927\tvalid_1's rmse: 54.3375\n",
      "[1530]\ttraining's rmse: 1.70807\tvalid_1's rmse: 54.334\n",
      "[1560]\ttraining's rmse: 1.62072\tvalid_1's rmse: 54.3315\n",
      "[1590]\ttraining's rmse: 1.5386\tvalid_1's rmse: 54.3302\n",
      "[1620]\ttraining's rmse: 1.46264\tvalid_1's rmse: 54.3308\n",
      "[1650]\ttraining's rmse: 1.3883\tvalid_1's rmse: 54.3274\n",
      "[1680]\ttraining's rmse: 1.3183\tvalid_1's rmse: 54.3253\n",
      "[1710]\ttraining's rmse: 1.25314\tvalid_1's rmse: 54.3241\n",
      "[1740]\ttraining's rmse: 1.19036\tvalid_1's rmse: 54.3215\n",
      "[1770]\ttraining's rmse: 1.13317\tvalid_1's rmse: 54.3203\n",
      "[1800]\ttraining's rmse: 1.0773\tvalid_1's rmse: 54.317\n",
      "[1830]\ttraining's rmse: 1.02455\tvalid_1's rmse: 54.3174\n",
      "[1860]\ttraining's rmse: 0.975779\tvalid_1's rmse: 54.3142\n",
      "[1890]\ttraining's rmse: 0.929083\tvalid_1's rmse: 54.3139\n",
      "[1920]\ttraining's rmse: 0.88505\tvalid_1's rmse: 54.3139\n",
      "[1950]\ttraining's rmse: 0.842636\tvalid_1's rmse: 54.3125\n",
      "[1980]\ttraining's rmse: 0.801073\tvalid_1's rmse: 54.311\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's rmse: 0.775887\tvalid_1's rmse: 54.3097\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002360 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 20024\n",
      "[LightGBM] [Info] Number of data points in the train set: 9219, number of used features: 79\n",
      "[LightGBM] [Info] Start training from score 369.976424\n",
      "Training until validation scores don't improve for 125 rounds\n",
      "[30]\ttraining's rmse: 153.595\tvalid_1's rmse: 155.307\n",
      "[60]\ttraining's rmse: 96.8014\tvalid_1's rmse: 104.446\n",
      "[90]\ttraining's rmse: 66.142\tvalid_1's rmse: 79.2269\n",
      "[120]\ttraining's rmse: 49.2879\tvalid_1's rmse: 67.1134\n",
      "[150]\ttraining's rmse: 39.7193\tvalid_1's rmse: 61.3496\n",
      "[180]\ttraining's rmse: 33.703\tvalid_1's rmse: 58.3035\n",
      "[210]\ttraining's rmse: 29.5168\tvalid_1's rmse: 56.5661\n",
      "[240]\ttraining's rmse: 26.3298\tvalid_1's rmse: 55.5289\n",
      "[270]\ttraining's rmse: 23.7482\tvalid_1's rmse: 54.7884\n",
      "[300]\ttraining's rmse: 21.6273\tvalid_1's rmse: 54.2451\n",
      "[330]\ttraining's rmse: 19.7951\tvalid_1's rmse: 53.7768\n",
      "[360]\ttraining's rmse: 18.1974\tvalid_1's rmse: 53.4596\n",
      "[390]\ttraining's rmse: 16.769\tvalid_1's rmse: 53.2309\n",
      "[420]\ttraining's rmse: 15.5338\tvalid_1's rmse: 53.0614\n",
      "[450]\ttraining's rmse: 14.3967\tvalid_1's rmse: 52.9019\n",
      "[480]\ttraining's rmse: 13.3757\tvalid_1's rmse: 52.7665\n",
      "[510]\ttraining's rmse: 12.4423\tvalid_1's rmse: 52.6802\n",
      "[540]\ttraining's rmse: 11.5982\tvalid_1's rmse: 52.58\n",
      "[570]\ttraining's rmse: 10.8313\tvalid_1's rmse: 52.4858\n",
      "[600]\ttraining's rmse: 10.1254\tvalid_1's rmse: 52.4029\n",
      "[630]\ttraining's rmse: 9.47642\tvalid_1's rmse: 52.3549\n",
      "[660]\ttraining's rmse: 8.88265\tvalid_1's rmse: 52.2988\n",
      "[690]\ttraining's rmse: 8.32463\tvalid_1's rmse: 52.2435\n",
      "[720]\ttraining's rmse: 7.81144\tvalid_1's rmse: 52.2111\n",
      "[750]\ttraining's rmse: 7.35204\tvalid_1's rmse: 52.1661\n",
      "[780]\ttraining's rmse: 6.92374\tvalid_1's rmse: 52.1348\n",
      "[810]\ttraining's rmse: 6.51265\tvalid_1's rmse: 52.1012\n",
      "[840]\ttraining's rmse: 6.13224\tvalid_1's rmse: 52.0765\n",
      "[870]\ttraining's rmse: 5.77593\tvalid_1's rmse: 52.0453\n",
      "[900]\ttraining's rmse: 5.45373\tvalid_1's rmse: 52.0244\n",
      "[930]\ttraining's rmse: 5.14378\tvalid_1's rmse: 52.0105\n",
      "[960]\ttraining's rmse: 4.85553\tvalid_1's rmse: 51.9948\n",
      "[990]\ttraining's rmse: 4.58408\tvalid_1's rmse: 51.9764\n",
      "[1020]\ttraining's rmse: 4.33472\tvalid_1's rmse: 51.9611\n",
      "[1050]\ttraining's rmse: 4.10023\tvalid_1's rmse: 51.9521\n",
      "[1080]\ttraining's rmse: 3.87169\tvalid_1's rmse: 51.9389\n",
      "[1110]\ttraining's rmse: 3.66318\tvalid_1's rmse: 51.9237\n",
      "[1140]\ttraining's rmse: 3.46325\tvalid_1's rmse: 51.9103\n",
      "[1170]\ttraining's rmse: 3.28029\tvalid_1's rmse: 51.9086\n",
      "[1200]\ttraining's rmse: 3.10418\tvalid_1's rmse: 51.9015\n",
      "[1230]\ttraining's rmse: 2.9413\tvalid_1's rmse: 51.8934\n",
      "[1260]\ttraining's rmse: 2.78633\tvalid_1's rmse: 51.8869\n",
      "[1290]\ttraining's rmse: 2.63943\tvalid_1's rmse: 51.8828\n",
      "[1320]\ttraining's rmse: 2.50224\tvalid_1's rmse: 51.8749\n",
      "[1350]\ttraining's rmse: 2.37163\tvalid_1's rmse: 51.8702\n",
      "[1380]\ttraining's rmse: 2.25008\tvalid_1's rmse: 51.8642\n",
      "[1410]\ttraining's rmse: 2.13207\tvalid_1's rmse: 51.8586\n",
      "[1440]\ttraining's rmse: 2.0231\tvalid_1's rmse: 51.8558\n",
      "[1470]\ttraining's rmse: 1.91922\tvalid_1's rmse: 51.8532\n",
      "[1500]\ttraining's rmse: 1.82009\tvalid_1's rmse: 51.8475\n",
      "[1530]\ttraining's rmse: 1.72871\tvalid_1's rmse: 51.8434\n",
      "[1560]\ttraining's rmse: 1.64215\tvalid_1's rmse: 51.8433\n",
      "[1590]\ttraining's rmse: 1.56003\tvalid_1's rmse: 51.8416\n",
      "[1620]\ttraining's rmse: 1.48397\tvalid_1's rmse: 51.8394\n",
      "[1650]\ttraining's rmse: 1.4119\tvalid_1's rmse: 51.8359\n",
      "[1680]\ttraining's rmse: 1.34204\tvalid_1's rmse: 51.8352\n",
      "[1710]\ttraining's rmse: 1.27679\tvalid_1's rmse: 51.8325\n",
      "[1740]\ttraining's rmse: 1.21537\tvalid_1's rmse: 51.8299\n",
      "[1770]\ttraining's rmse: 1.15694\tvalid_1's rmse: 51.8283\n",
      "[1800]\ttraining's rmse: 1.10091\tvalid_1's rmse: 51.8258\n",
      "[1830]\ttraining's rmse: 1.04791\tvalid_1's rmse: 51.8235\n",
      "[1860]\ttraining's rmse: 0.996722\tvalid_1's rmse: 51.823\n",
      "[1890]\ttraining's rmse: 0.94928\tvalid_1's rmse: 51.8241\n",
      "[1920]\ttraining's rmse: 0.903998\tvalid_1's rmse: 51.8217\n",
      "[1950]\ttraining's rmse: 0.859969\tvalid_1's rmse: 51.8208\n",
      "[1980]\ttraining's rmse: 0.819913\tvalid_1's rmse: 51.8194\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's rmse: 0.794488\tvalid_1's rmse: 51.8193\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002875 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 20024\n",
      "[LightGBM] [Info] Number of data points in the train set: 9219, number of used features: 79\n",
      "[LightGBM] [Info] Start training from score 369.295247\n",
      "Training until validation scores don't improve for 125 rounds\n",
      "[30]\ttraining's rmse: 152.879\tvalid_1's rmse: 157.2\n",
      "[60]\ttraining's rmse: 95.5637\tvalid_1's rmse: 105.525\n",
      "[90]\ttraining's rmse: 64.5744\tvalid_1's rmse: 80.2441\n",
      "[120]\ttraining's rmse: 47.9675\tvalid_1's rmse: 68.6402\n",
      "[150]\ttraining's rmse: 38.6158\tvalid_1's rmse: 63.111\n",
      "[180]\ttraining's rmse: 32.8296\tvalid_1's rmse: 60.2358\n",
      "[210]\ttraining's rmse: 28.8172\tvalid_1's rmse: 58.552\n",
      "[240]\ttraining's rmse: 25.6729\tvalid_1's rmse: 57.2771\n",
      "[270]\ttraining's rmse: 23.155\tvalid_1's rmse: 56.4506\n",
      "[300]\ttraining's rmse: 21.0809\tvalid_1's rmse: 55.867\n",
      "[330]\ttraining's rmse: 19.2885\tvalid_1's rmse: 55.5022\n",
      "[360]\ttraining's rmse: 17.761\tvalid_1's rmse: 55.2354\n",
      "[390]\ttraining's rmse: 16.3911\tvalid_1's rmse: 55.0098\n",
      "[420]\ttraining's rmse: 15.1896\tvalid_1's rmse: 54.8401\n",
      "[450]\ttraining's rmse: 14.0801\tvalid_1's rmse: 54.7002\n",
      "[480]\ttraining's rmse: 13.0939\tvalid_1's rmse: 54.5775\n",
      "[510]\ttraining's rmse: 12.2172\tvalid_1's rmse: 54.4978\n",
      "[540]\ttraining's rmse: 11.4149\tvalid_1's rmse: 54.3786\n",
      "[570]\ttraining's rmse: 10.6667\tvalid_1's rmse: 54.2887\n",
      "[600]\ttraining's rmse: 9.99922\tvalid_1's rmse: 54.2094\n",
      "[630]\ttraining's rmse: 9.38122\tvalid_1's rmse: 54.1603\n",
      "[660]\ttraining's rmse: 8.81145\tvalid_1's rmse: 54.1178\n",
      "[690]\ttraining's rmse: 8.27464\tvalid_1's rmse: 54.0631\n",
      "[720]\ttraining's rmse: 7.77991\tvalid_1's rmse: 54.0042\n",
      "[750]\ttraining's rmse: 7.32853\tvalid_1's rmse: 53.9806\n",
      "[780]\ttraining's rmse: 6.90055\tvalid_1's rmse: 53.9483\n",
      "[810]\ttraining's rmse: 6.49695\tvalid_1's rmse: 53.9098\n",
      "[840]\ttraining's rmse: 6.12821\tvalid_1's rmse: 53.8788\n",
      "[870]\ttraining's rmse: 5.78402\tvalid_1's rmse: 53.8568\n",
      "[900]\ttraining's rmse: 5.46233\tvalid_1's rmse: 53.8214\n",
      "[930]\ttraining's rmse: 5.16107\tvalid_1's rmse: 53.7915\n",
      "[960]\ttraining's rmse: 4.88002\tvalid_1's rmse: 53.7782\n",
      "[990]\ttraining's rmse: 4.61443\tvalid_1's rmse: 53.7642\n",
      "[1020]\ttraining's rmse: 4.36279\tvalid_1's rmse: 53.7372\n",
      "[1050]\ttraining's rmse: 4.13196\tvalid_1's rmse: 53.7205\n",
      "[1080]\ttraining's rmse: 3.90667\tvalid_1's rmse: 53.703\n",
      "[1110]\ttraining's rmse: 3.69844\tvalid_1's rmse: 53.6934\n",
      "[1140]\ttraining's rmse: 3.50454\tvalid_1's rmse: 53.6913\n",
      "[1170]\ttraining's rmse: 3.31974\tvalid_1's rmse: 53.6903\n",
      "[1200]\ttraining's rmse: 3.14126\tvalid_1's rmse: 53.6801\n",
      "[1230]\ttraining's rmse: 2.9749\tvalid_1's rmse: 53.6715\n",
      "[1260]\ttraining's rmse: 2.82088\tvalid_1's rmse: 53.6638\n",
      "[1290]\ttraining's rmse: 2.67443\tvalid_1's rmse: 53.6546\n",
      "[1320]\ttraining's rmse: 2.54073\tvalid_1's rmse: 53.6491\n",
      "[1350]\ttraining's rmse: 2.41227\tvalid_1's rmse: 53.6444\n",
      "[1380]\ttraining's rmse: 2.28947\tvalid_1's rmse: 53.6407\n",
      "[1410]\ttraining's rmse: 2.17246\tvalid_1's rmse: 53.6379\n",
      "[1440]\ttraining's rmse: 2.06379\tvalid_1's rmse: 53.628\n",
      "[1470]\ttraining's rmse: 1.96009\tvalid_1's rmse: 53.6208\n",
      "[1500]\ttraining's rmse: 1.86361\tvalid_1's rmse: 53.6149\n",
      "[1530]\ttraining's rmse: 1.77561\tvalid_1's rmse: 53.6044\n",
      "[1560]\ttraining's rmse: 1.68847\tvalid_1's rmse: 53.6004\n",
      "[1590]\ttraining's rmse: 1.60749\tvalid_1's rmse: 53.5946\n",
      "[1620]\ttraining's rmse: 1.5309\tvalid_1's rmse: 53.5921\n",
      "[1650]\ttraining's rmse: 1.45844\tvalid_1's rmse: 53.5918\n",
      "[1680]\ttraining's rmse: 1.38937\tvalid_1's rmse: 53.5888\n",
      "[1710]\ttraining's rmse: 1.32279\tvalid_1's rmse: 53.5859\n",
      "[1740]\ttraining's rmse: 1.2608\tvalid_1's rmse: 53.5862\n",
      "[1770]\ttraining's rmse: 1.20082\tvalid_1's rmse: 53.5824\n",
      "[1800]\ttraining's rmse: 1.14649\tvalid_1's rmse: 53.5787\n",
      "[1830]\ttraining's rmse: 1.09195\tvalid_1's rmse: 53.5745\n",
      "[1860]\ttraining's rmse: 1.04007\tvalid_1's rmse: 53.5741\n",
      "[1890]\ttraining's rmse: 0.991177\tvalid_1's rmse: 53.5733\n",
      "[1920]\ttraining's rmse: 0.944169\tvalid_1's rmse: 53.5697\n",
      "[1950]\ttraining's rmse: 0.901983\tvalid_1's rmse: 53.5653\n",
      "[1980]\ttraining's rmse: 0.860956\tvalid_1's rmse: 53.5626\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's rmse: 0.833664\tvalid_1's rmse: 53.5622\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003533 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 20024\n",
      "[LightGBM] [Info] Number of data points in the train set: 9219, number of used features: 79\n",
      "[LightGBM] [Info] Start training from score 370.680730\n",
      "Training until validation scores don't improve for 125 rounds\n",
      "[30]\ttraining's rmse: 153.023\tvalid_1's rmse: 154.098\n",
      "[60]\ttraining's rmse: 96.3166\tvalid_1's rmse: 103.981\n",
      "[90]\ttraining's rmse: 65.0919\tvalid_1's rmse: 78.3807\n",
      "[120]\ttraining's rmse: 48.2223\tvalid_1's rmse: 66.2542\n",
      "[150]\ttraining's rmse: 38.8157\tvalid_1's rmse: 60.7018\n",
      "[180]\ttraining's rmse: 33.1724\tvalid_1's rmse: 57.8763\n",
      "[210]\ttraining's rmse: 29.0862\tvalid_1's rmse: 56.1741\n",
      "[240]\ttraining's rmse: 25.9748\tvalid_1's rmse: 55.1181\n",
      "[270]\ttraining's rmse: 23.4844\tvalid_1's rmse: 54.3362\n",
      "[300]\ttraining's rmse: 21.3926\tvalid_1's rmse: 53.8417\n",
      "[330]\ttraining's rmse: 19.5978\tvalid_1's rmse: 53.3469\n",
      "[360]\ttraining's rmse: 18.0479\tvalid_1's rmse: 53.1224\n",
      "[390]\ttraining's rmse: 16.682\tvalid_1's rmse: 52.9338\n",
      "[420]\ttraining's rmse: 15.4562\tvalid_1's rmse: 52.7042\n",
      "[450]\ttraining's rmse: 14.344\tvalid_1's rmse: 52.5823\n",
      "[480]\ttraining's rmse: 13.3665\tvalid_1's rmse: 52.5061\n",
      "[510]\ttraining's rmse: 12.4562\tvalid_1's rmse: 52.438\n",
      "[540]\ttraining's rmse: 11.6263\tvalid_1's rmse: 52.3582\n",
      "[570]\ttraining's rmse: 10.869\tvalid_1's rmse: 52.2768\n",
      "[600]\ttraining's rmse: 10.1822\tvalid_1's rmse: 52.218\n",
      "[630]\ttraining's rmse: 9.54156\tvalid_1's rmse: 52.1663\n",
      "[660]\ttraining's rmse: 8.94989\tvalid_1's rmse: 52.1127\n",
      "[690]\ttraining's rmse: 8.39786\tvalid_1's rmse: 52.0835\n",
      "[720]\ttraining's rmse: 7.8904\tvalid_1's rmse: 52.0568\n",
      "[750]\ttraining's rmse: 7.42716\tvalid_1's rmse: 52.0457\n",
      "[780]\ttraining's rmse: 6.98443\tvalid_1's rmse: 52.0337\n",
      "[810]\ttraining's rmse: 6.57254\tvalid_1's rmse: 52.0183\n",
      "[840]\ttraining's rmse: 6.20033\tvalid_1's rmse: 51.9962\n",
      "[870]\ttraining's rmse: 5.8523\tvalid_1's rmse: 51.9946\n",
      "[900]\ttraining's rmse: 5.52066\tvalid_1's rmse: 51.9786\n",
      "[930]\ttraining's rmse: 5.21004\tvalid_1's rmse: 51.9625\n",
      "[960]\ttraining's rmse: 4.9245\tvalid_1's rmse: 51.9459\n",
      "[990]\ttraining's rmse: 4.65273\tvalid_1's rmse: 51.9313\n",
      "[1020]\ttraining's rmse: 4.40432\tvalid_1's rmse: 51.9302\n",
      "[1050]\ttraining's rmse: 4.16152\tvalid_1's rmse: 51.9266\n",
      "[1080]\ttraining's rmse: 3.9402\tvalid_1's rmse: 51.9188\n",
      "[1110]\ttraining's rmse: 3.73142\tvalid_1's rmse: 51.9101\n",
      "[1140]\ttraining's rmse: 3.53132\tvalid_1's rmse: 51.9059\n",
      "[1170]\ttraining's rmse: 3.34609\tvalid_1's rmse: 51.9037\n",
      "[1200]\ttraining's rmse: 3.17343\tvalid_1's rmse: 51.8894\n",
      "[1230]\ttraining's rmse: 3.01054\tvalid_1's rmse: 51.8845\n",
      "[1260]\ttraining's rmse: 2.85914\tvalid_1's rmse: 51.881\n",
      "[1290]\ttraining's rmse: 2.71541\tvalid_1's rmse: 51.8754\n",
      "[1320]\ttraining's rmse: 2.57817\tvalid_1's rmse: 51.8764\n",
      "[1350]\ttraining's rmse: 2.45053\tvalid_1's rmse: 51.8796\n",
      "[1380]\ttraining's rmse: 2.33026\tvalid_1's rmse: 51.8724\n",
      "[1410]\ttraining's rmse: 2.21663\tvalid_1's rmse: 51.87\n",
      "[1440]\ttraining's rmse: 2.10645\tvalid_1's rmse: 51.8702\n",
      "[1470]\ttraining's rmse: 2.00703\tvalid_1's rmse: 51.8719\n",
      "[1500]\ttraining's rmse: 1.91273\tvalid_1's rmse: 51.8767\n",
      "[1530]\ttraining's rmse: 1.82055\tvalid_1's rmse: 51.8742\n",
      "Early stopping, best iteration is:\n",
      "[1412]\ttraining's rmse: 2.20827\tvalid_1's rmse: 51.8683\n",
      "21\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003025 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 20024\n",
      "[LightGBM] [Info] Number of data points in the train set: 9219, number of used features: 79\n",
      "[LightGBM] [Info] Start training from score 358.769873\n",
      "Training until validation scores don't improve for 125 rounds\n",
      "[30]\ttraining's rmse: 153.839\tvalid_1's rmse: 158.393\n",
      "[60]\ttraining's rmse: 95.2915\tvalid_1's rmse: 105.332\n",
      "[90]\ttraining's rmse: 63.7426\tvalid_1's rmse: 79.2438\n",
      "[120]\ttraining's rmse: 46.7423\tvalid_1's rmse: 66.9898\n",
      "[150]\ttraining's rmse: 37.3395\tvalid_1's rmse: 61.0598\n",
      "[180]\ttraining's rmse: 31.7486\tvalid_1's rmse: 58.0505\n",
      "[210]\ttraining's rmse: 27.8919\tvalid_1's rmse: 56.3003\n",
      "[240]\ttraining's rmse: 24.8291\tvalid_1's rmse: 55.0338\n",
      "[270]\ttraining's rmse: 22.3631\tvalid_1's rmse: 54.1104\n",
      "[300]\ttraining's rmse: 20.3239\tvalid_1's rmse: 53.4809\n",
      "[330]\ttraining's rmse: 18.6592\tvalid_1's rmse: 53.0674\n",
      "[360]\ttraining's rmse: 17.1714\tvalid_1's rmse: 52.6334\n",
      "[390]\ttraining's rmse: 15.8558\tvalid_1's rmse: 52.357\n",
      "[420]\ttraining's rmse: 14.6951\tvalid_1's rmse: 52.2349\n",
      "[450]\ttraining's rmse: 13.6795\tvalid_1's rmse: 52.0994\n",
      "[480]\ttraining's rmse: 12.7339\tvalid_1's rmse: 51.975\n",
      "[510]\ttraining's rmse: 11.8826\tvalid_1's rmse: 51.8761\n",
      "[540]\ttraining's rmse: 11.1116\tvalid_1's rmse: 51.8243\n",
      "[570]\ttraining's rmse: 10.4212\tvalid_1's rmse: 51.7444\n",
      "[600]\ttraining's rmse: 9.76236\tvalid_1's rmse: 51.6695\n",
      "[630]\ttraining's rmse: 9.1549\tvalid_1's rmse: 51.6035\n",
      "[660]\ttraining's rmse: 8.58931\tvalid_1's rmse: 51.5509\n",
      "[690]\ttraining's rmse: 8.07688\tvalid_1's rmse: 51.4872\n",
      "[720]\ttraining's rmse: 7.60848\tvalid_1's rmse: 51.4567\n",
      "[750]\ttraining's rmse: 7.15902\tvalid_1's rmse: 51.4008\n",
      "[780]\ttraining's rmse: 6.73924\tvalid_1's rmse: 51.3733\n",
      "[810]\ttraining's rmse: 6.35202\tvalid_1's rmse: 51.3504\n",
      "[840]\ttraining's rmse: 5.99685\tvalid_1's rmse: 51.349\n",
      "[870]\ttraining's rmse: 5.66368\tvalid_1's rmse: 51.3271\n",
      "[900]\ttraining's rmse: 5.3533\tvalid_1's rmse: 51.2949\n",
      "[930]\ttraining's rmse: 5.06024\tvalid_1's rmse: 51.2873\n",
      "[960]\ttraining's rmse: 4.78024\tvalid_1's rmse: 51.2809\n",
      "[990]\ttraining's rmse: 4.52672\tvalid_1's rmse: 51.2761\n",
      "[1020]\ttraining's rmse: 4.28605\tvalid_1's rmse: 51.2638\n",
      "[1050]\ttraining's rmse: 4.0602\tvalid_1's rmse: 51.2588\n",
      "[1080]\ttraining's rmse: 3.8459\tvalid_1's rmse: 51.2532\n",
      "[1110]\ttraining's rmse: 3.64122\tvalid_1's rmse: 51.2429\n",
      "[1140]\ttraining's rmse: 3.45236\tvalid_1's rmse: 51.2314\n",
      "[1170]\ttraining's rmse: 3.27898\tvalid_1's rmse: 51.2243\n",
      "[1200]\ttraining's rmse: 3.11428\tvalid_1's rmse: 51.2224\n",
      "[1230]\ttraining's rmse: 2.9572\tvalid_1's rmse: 51.2163\n",
      "[1260]\ttraining's rmse: 2.80914\tvalid_1's rmse: 51.2127\n",
      "[1290]\ttraining's rmse: 2.67015\tvalid_1's rmse: 51.2049\n",
      "[1320]\ttraining's rmse: 2.52977\tvalid_1's rmse: 51.2009\n",
      "[1350]\ttraining's rmse: 2.4006\tvalid_1's rmse: 51.1977\n",
      "[1380]\ttraining's rmse: 2.28536\tvalid_1's rmse: 51.2006\n",
      "[1410]\ttraining's rmse: 2.17437\tvalid_1's rmse: 51.2009\n",
      "[1440]\ttraining's rmse: 2.06802\tvalid_1's rmse: 51.2058\n",
      "Early stopping, best iteration is:\n",
      "[1342]\ttraining's rmse: 2.43381\tvalid_1's rmse: 51.1964\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003490 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 20024\n",
      "[LightGBM] [Info] Number of data points in the train set: 9219, number of used features: 79\n",
      "[LightGBM] [Info] Start training from score 355.004531\n",
      "Training until validation scores don't improve for 125 rounds\n",
      "[30]\ttraining's rmse: 154.319\tvalid_1's rmse: 155.266\n",
      "[60]\ttraining's rmse: 96.467\tvalid_1's rmse: 101.942\n",
      "[90]\ttraining's rmse: 65.3572\tvalid_1's rmse: 75.9572\n",
      "[120]\ttraining's rmse: 48.4065\tvalid_1's rmse: 63.9814\n",
      "[150]\ttraining's rmse: 38.9471\tvalid_1's rmse: 58.5691\n",
      "[180]\ttraining's rmse: 33.172\tvalid_1's rmse: 55.7835\n",
      "[210]\ttraining's rmse: 29.1999\tvalid_1's rmse: 54.1589\n",
      "[240]\ttraining's rmse: 26.0181\tvalid_1's rmse: 53.0906\n",
      "[270]\ttraining's rmse: 23.4724\tvalid_1's rmse: 52.4288\n",
      "[300]\ttraining's rmse: 21.3628\tvalid_1's rmse: 51.9207\n",
      "[330]\ttraining's rmse: 19.5546\tvalid_1's rmse: 51.5865\n",
      "[360]\ttraining's rmse: 18.0115\tvalid_1's rmse: 51.3012\n",
      "[390]\ttraining's rmse: 16.6378\tvalid_1's rmse: 51.1368\n",
      "[420]\ttraining's rmse: 15.3715\tvalid_1's rmse: 51.0298\n",
      "[450]\ttraining's rmse: 14.2678\tvalid_1's rmse: 50.9206\n",
      "[480]\ttraining's rmse: 13.2717\tvalid_1's rmse: 50.7988\n",
      "[510]\ttraining's rmse: 12.3859\tvalid_1's rmse: 50.6841\n",
      "[540]\ttraining's rmse: 11.5619\tvalid_1's rmse: 50.6293\n",
      "[570]\ttraining's rmse: 10.8106\tvalid_1's rmse: 50.5617\n",
      "[600]\ttraining's rmse: 10.1351\tvalid_1's rmse: 50.5164\n",
      "[630]\ttraining's rmse: 9.50122\tvalid_1's rmse: 50.4698\n",
      "[660]\ttraining's rmse: 8.91885\tvalid_1's rmse: 50.4213\n",
      "[690]\ttraining's rmse: 8.36365\tvalid_1's rmse: 50.3882\n",
      "[720]\ttraining's rmse: 7.84783\tvalid_1's rmse: 50.3581\n",
      "[750]\ttraining's rmse: 7.37792\tvalid_1's rmse: 50.3422\n",
      "[780]\ttraining's rmse: 6.94807\tvalid_1's rmse: 50.3005\n",
      "[810]\ttraining's rmse: 6.54327\tvalid_1's rmse: 50.2861\n",
      "[840]\ttraining's rmse: 6.16527\tvalid_1's rmse: 50.2545\n",
      "[870]\ttraining's rmse: 5.8127\tvalid_1's rmse: 50.2278\n",
      "[900]\ttraining's rmse: 5.48113\tvalid_1's rmse: 50.1939\n",
      "[930]\ttraining's rmse: 5.18074\tvalid_1's rmse: 50.1757\n",
      "[960]\ttraining's rmse: 4.89185\tvalid_1's rmse: 50.1553\n",
      "[990]\ttraining's rmse: 4.62203\tvalid_1's rmse: 50.1478\n",
      "[1020]\ttraining's rmse: 4.37366\tvalid_1's rmse: 50.1194\n",
      "[1050]\ttraining's rmse: 4.13534\tvalid_1's rmse: 50.1099\n",
      "[1080]\ttraining's rmse: 3.91179\tvalid_1's rmse: 50.0953\n",
      "[1110]\ttraining's rmse: 3.71008\tvalid_1's rmse: 50.0907\n",
      "[1140]\ttraining's rmse: 3.51631\tvalid_1's rmse: 50.0853\n",
      "[1170]\ttraining's rmse: 3.33375\tvalid_1's rmse: 50.0767\n",
      "[1200]\ttraining's rmse: 3.15957\tvalid_1's rmse: 50.0656\n",
      "[1230]\ttraining's rmse: 2.99636\tvalid_1's rmse: 50.0656\n",
      "[1260]\ttraining's rmse: 2.83807\tvalid_1's rmse: 50.062\n",
      "[1290]\ttraining's rmse: 2.69513\tvalid_1's rmse: 50.0532\n",
      "[1320]\ttraining's rmse: 2.554\tvalid_1's rmse: 50.0421\n",
      "[1350]\ttraining's rmse: 2.42332\tvalid_1's rmse: 50.0396\n",
      "[1380]\ttraining's rmse: 2.29795\tvalid_1's rmse: 50.029\n",
      "[1410]\ttraining's rmse: 2.18071\tvalid_1's rmse: 50.0267\n",
      "[1440]\ttraining's rmse: 2.07267\tvalid_1's rmse: 50.0238\n",
      "[1470]\ttraining's rmse: 1.96812\tvalid_1's rmse: 50.0211\n",
      "[1500]\ttraining's rmse: 1.87016\tvalid_1's rmse: 50.0247\n",
      "[1530]\ttraining's rmse: 1.77476\tvalid_1's rmse: 50.0195\n",
      "[1560]\ttraining's rmse: 1.68687\tvalid_1's rmse: 50.0143\n",
      "[1590]\ttraining's rmse: 1.60305\tvalid_1's rmse: 50.0137\n",
      "[1620]\ttraining's rmse: 1.52403\tvalid_1's rmse: 50.0092\n",
      "[1650]\ttraining's rmse: 1.45098\tvalid_1's rmse: 50.0053\n",
      "[1680]\ttraining's rmse: 1.37959\tvalid_1's rmse: 50.0039\n",
      "[1710]\ttraining's rmse: 1.31138\tvalid_1's rmse: 50.0025\n",
      "[1740]\ttraining's rmse: 1.25009\tvalid_1's rmse: 49.9987\n",
      "[1770]\ttraining's rmse: 1.18965\tvalid_1's rmse: 49.9982\n",
      "[1800]\ttraining's rmse: 1.13191\tvalid_1's rmse: 49.9957\n",
      "[1830]\ttraining's rmse: 1.07711\tvalid_1's rmse: 49.9928\n",
      "[1860]\ttraining's rmse: 1.0248\tvalid_1's rmse: 49.9914\n",
      "[1890]\ttraining's rmse: 0.974741\tvalid_1's rmse: 49.9895\n",
      "[1920]\ttraining's rmse: 0.928878\tvalid_1's rmse: 49.9869\n",
      "[1950]\ttraining's rmse: 0.886971\tvalid_1's rmse: 49.9862\n",
      "[1980]\ttraining's rmse: 0.844664\tvalid_1's rmse: 49.9866\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's rmse: 0.817849\tvalid_1's rmse: 49.9848\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002597 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 20024\n",
      "[LightGBM] [Info] Number of data points in the train set: 9219, number of used features: 79\n",
      "[LightGBM] [Info] Start training from score 356.933281\n",
      "Training until validation scores don't improve for 125 rounds\n",
      "[30]\ttraining's rmse: 155.455\tvalid_1's rmse: 157.929\n",
      "[60]\ttraining's rmse: 97.5382\tvalid_1's rmse: 106.269\n",
      "[90]\ttraining's rmse: 66.0548\tvalid_1's rmse: 79.9489\n",
      "[120]\ttraining's rmse: 49.0216\tvalid_1's rmse: 67.3664\n",
      "[150]\ttraining's rmse: 39.4202\tvalid_1's rmse: 61.1981\n",
      "[180]\ttraining's rmse: 33.5368\tvalid_1's rmse: 58.1829\n",
      "[210]\ttraining's rmse: 29.537\tvalid_1's rmse: 56.461\n",
      "[240]\ttraining's rmse: 26.3123\tvalid_1's rmse: 55.4484\n",
      "[270]\ttraining's rmse: 23.7317\tvalid_1's rmse: 54.7372\n",
      "[300]\ttraining's rmse: 21.5884\tvalid_1's rmse: 54.1884\n",
      "[330]\ttraining's rmse: 19.7673\tvalid_1's rmse: 53.8351\n",
      "[360]\ttraining's rmse: 18.1433\tvalid_1's rmse: 53.5362\n",
      "[390]\ttraining's rmse: 16.7381\tvalid_1's rmse: 53.3158\n",
      "[420]\ttraining's rmse: 15.4826\tvalid_1's rmse: 53.1731\n",
      "[450]\ttraining's rmse: 14.3764\tvalid_1's rmse: 53.0297\n",
      "[480]\ttraining's rmse: 13.3597\tvalid_1's rmse: 52.8806\n",
      "[510]\ttraining's rmse: 12.4423\tvalid_1's rmse: 52.7921\n",
      "[540]\ttraining's rmse: 11.6155\tvalid_1's rmse: 52.6967\n",
      "[570]\ttraining's rmse: 10.8584\tvalid_1's rmse: 52.6244\n",
      "[600]\ttraining's rmse: 10.152\tvalid_1's rmse: 52.5757\n",
      "[630]\ttraining's rmse: 9.49895\tvalid_1's rmse: 52.5193\n",
      "[660]\ttraining's rmse: 8.90197\tvalid_1's rmse: 52.4895\n",
      "[690]\ttraining's rmse: 8.35841\tvalid_1's rmse: 52.4443\n",
      "[720]\ttraining's rmse: 7.84372\tvalid_1's rmse: 52.4084\n",
      "[750]\ttraining's rmse: 7.37229\tvalid_1's rmse: 52.3761\n",
      "[780]\ttraining's rmse: 6.94497\tvalid_1's rmse: 52.3386\n",
      "[810]\ttraining's rmse: 6.53734\tvalid_1's rmse: 52.3014\n",
      "[840]\ttraining's rmse: 6.162\tvalid_1's rmse: 52.2849\n",
      "[870]\ttraining's rmse: 5.809\tvalid_1's rmse: 52.2648\n",
      "[900]\ttraining's rmse: 5.48393\tvalid_1's rmse: 52.2515\n",
      "[930]\ttraining's rmse: 5.17396\tvalid_1's rmse: 52.2345\n",
      "[960]\ttraining's rmse: 4.88144\tvalid_1's rmse: 52.2201\n",
      "[990]\ttraining's rmse: 4.61477\tvalid_1's rmse: 52.2127\n",
      "[1020]\ttraining's rmse: 4.36048\tvalid_1's rmse: 52.1983\n",
      "[1050]\ttraining's rmse: 4.12619\tvalid_1's rmse: 52.1873\n",
      "[1080]\ttraining's rmse: 3.90684\tvalid_1's rmse: 52.1857\n",
      "[1110]\ttraining's rmse: 3.69599\tvalid_1's rmse: 52.1794\n",
      "[1140]\ttraining's rmse: 3.50242\tvalid_1's rmse: 52.1706\n",
      "[1170]\ttraining's rmse: 3.31786\tvalid_1's rmse: 52.1693\n",
      "[1200]\ttraining's rmse: 3.14493\tvalid_1's rmse: 52.168\n",
      "[1230]\ttraining's rmse: 2.98112\tvalid_1's rmse: 52.1642\n",
      "[1260]\ttraining's rmse: 2.82614\tvalid_1's rmse: 52.1519\n",
      "[1290]\ttraining's rmse: 2.68057\tvalid_1's rmse: 52.149\n",
      "[1320]\ttraining's rmse: 2.54215\tvalid_1's rmse: 52.148\n",
      "[1350]\ttraining's rmse: 2.40998\tvalid_1's rmse: 52.1429\n",
      "[1380]\ttraining's rmse: 2.28902\tvalid_1's rmse: 52.1443\n",
      "[1410]\ttraining's rmse: 2.17225\tvalid_1's rmse: 52.1387\n",
      "[1440]\ttraining's rmse: 2.06338\tvalid_1's rmse: 52.1353\n",
      "[1470]\ttraining's rmse: 1.96021\tvalid_1's rmse: 52.1299\n",
      "[1500]\ttraining's rmse: 1.8627\tvalid_1's rmse: 52.131\n",
      "[1530]\ttraining's rmse: 1.7716\tvalid_1's rmse: 52.1254\n",
      "[1560]\ttraining's rmse: 1.68319\tvalid_1's rmse: 52.1244\n",
      "[1590]\ttraining's rmse: 1.60285\tvalid_1's rmse: 52.122\n",
      "[1620]\ttraining's rmse: 1.52362\tvalid_1's rmse: 52.1188\n",
      "[1650]\ttraining's rmse: 1.45045\tvalid_1's rmse: 52.1143\n",
      "[1680]\ttraining's rmse: 1.38324\tvalid_1's rmse: 52.1123\n",
      "[1710]\ttraining's rmse: 1.31753\tvalid_1's rmse: 52.1124\n",
      "[1740]\ttraining's rmse: 1.25529\tvalid_1's rmse: 52.1121\n",
      "[1770]\ttraining's rmse: 1.19589\tvalid_1's rmse: 52.112\n",
      "[1800]\ttraining's rmse: 1.14028\tvalid_1's rmse: 52.1098\n",
      "[1830]\ttraining's rmse: 1.08719\tvalid_1's rmse: 52.1086\n",
      "[1860]\ttraining's rmse: 1.03665\tvalid_1's rmse: 52.1082\n",
      "[1890]\ttraining's rmse: 0.988071\tvalid_1's rmse: 52.1058\n",
      "[1920]\ttraining's rmse: 0.941877\tvalid_1's rmse: 52.1039\n",
      "[1950]\ttraining's rmse: 0.898977\tvalid_1's rmse: 52.1037\n",
      "[1980]\ttraining's rmse: 0.857537\tvalid_1's rmse: 52.103\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's rmse: 0.830445\tvalid_1's rmse: 52.1015\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003263 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 20024\n",
      "[LightGBM] [Info] Number of data points in the train set: 9219, number of used features: 79\n",
      "[LightGBM] [Info] Start training from score 364.236337\n",
      "Training until validation scores don't improve for 125 rounds\n",
      "[30]\ttraining's rmse: 155.774\tvalid_1's rmse: 152.067\n",
      "[60]\ttraining's rmse: 98.3638\tvalid_1's rmse: 100.812\n",
      "[90]\ttraining's rmse: 67.4335\tvalid_1's rmse: 75.4347\n",
      "[120]\ttraining's rmse: 50.4493\tvalid_1's rmse: 62.9729\n",
      "[150]\ttraining's rmse: 40.5467\tvalid_1's rmse: 56.8231\n",
      "[180]\ttraining's rmse: 34.3496\tvalid_1's rmse: 53.5838\n",
      "[210]\ttraining's rmse: 30.0855\tvalid_1's rmse: 51.8541\n",
      "[240]\ttraining's rmse: 26.768\tvalid_1's rmse: 50.75\n",
      "[270]\ttraining's rmse: 24.086\tvalid_1's rmse: 49.8614\n",
      "[300]\ttraining's rmse: 21.8409\tvalid_1's rmse: 49.169\n",
      "[330]\ttraining's rmse: 19.9475\tvalid_1's rmse: 48.7103\n",
      "[360]\ttraining's rmse: 18.3163\tvalid_1's rmse: 48.3862\n",
      "[390]\ttraining's rmse: 16.8739\tvalid_1's rmse: 48.1838\n",
      "[420]\ttraining's rmse: 15.5716\tvalid_1's rmse: 48.006\n",
      "[450]\ttraining's rmse: 14.4187\tvalid_1's rmse: 47.8256\n",
      "[480]\ttraining's rmse: 13.3814\tvalid_1's rmse: 47.7015\n",
      "[510]\ttraining's rmse: 12.4518\tvalid_1's rmse: 47.5707\n",
      "[540]\ttraining's rmse: 11.5948\tvalid_1's rmse: 47.4988\n",
      "[570]\ttraining's rmse: 10.8215\tvalid_1's rmse: 47.4247\n",
      "[600]\ttraining's rmse: 10.1055\tvalid_1's rmse: 47.3508\n",
      "[630]\ttraining's rmse: 9.45617\tvalid_1's rmse: 47.2926\n",
      "[660]\ttraining's rmse: 8.86124\tvalid_1's rmse: 47.2559\n",
      "[690]\ttraining's rmse: 8.32145\tvalid_1's rmse: 47.2069\n",
      "[720]\ttraining's rmse: 7.81805\tvalid_1's rmse: 47.1727\n",
      "[750]\ttraining's rmse: 7.34299\tvalid_1's rmse: 47.1374\n",
      "[780]\ttraining's rmse: 6.9035\tvalid_1's rmse: 47.1156\n",
      "[810]\ttraining's rmse: 6.49431\tvalid_1's rmse: 47.0941\n",
      "[840]\ttraining's rmse: 6.11021\tvalid_1's rmse: 47.0764\n",
      "[870]\ttraining's rmse: 5.75545\tvalid_1's rmse: 47.0675\n",
      "[900]\ttraining's rmse: 5.42691\tvalid_1's rmse: 47.0458\n",
      "[930]\ttraining's rmse: 5.12221\tvalid_1's rmse: 47.0264\n",
      "[960]\ttraining's rmse: 4.82919\tvalid_1's rmse: 47.0154\n",
      "[990]\ttraining's rmse: 4.56362\tvalid_1's rmse: 47.0068\n",
      "[1020]\ttraining's rmse: 4.31861\tvalid_1's rmse: 47.0061\n",
      "[1050]\ttraining's rmse: 4.08517\tvalid_1's rmse: 46.9977\n",
      "[1080]\ttraining's rmse: 3.86394\tvalid_1's rmse: 46.9858\n",
      "[1110]\ttraining's rmse: 3.6546\tvalid_1's rmse: 46.9782\n",
      "[1140]\ttraining's rmse: 3.46169\tvalid_1's rmse: 46.9624\n",
      "[1170]\ttraining's rmse: 3.27963\tvalid_1's rmse: 46.9576\n",
      "[1200]\ttraining's rmse: 3.1065\tvalid_1's rmse: 46.9554\n",
      "[1230]\ttraining's rmse: 2.94658\tvalid_1's rmse: 46.9501\n",
      "[1260]\ttraining's rmse: 2.79576\tvalid_1's rmse: 46.9467\n",
      "[1290]\ttraining's rmse: 2.64986\tvalid_1's rmse: 46.938\n",
      "[1320]\ttraining's rmse: 2.51157\tvalid_1's rmse: 46.9312\n",
      "[1350]\ttraining's rmse: 2.3805\tvalid_1's rmse: 46.9283\n",
      "[1380]\ttraining's rmse: 2.25721\tvalid_1's rmse: 46.9252\n",
      "[1410]\ttraining's rmse: 2.14157\tvalid_1's rmse: 46.9214\n",
      "[1440]\ttraining's rmse: 2.03239\tvalid_1's rmse: 46.9158\n",
      "[1470]\ttraining's rmse: 1.92946\tvalid_1's rmse: 46.9112\n",
      "[1500]\ttraining's rmse: 1.83074\tvalid_1's rmse: 46.9055\n",
      "[1530]\ttraining's rmse: 1.73955\tvalid_1's rmse: 46.9022\n",
      "[1560]\ttraining's rmse: 1.65391\tvalid_1's rmse: 46.9002\n",
      "[1590]\ttraining's rmse: 1.56951\tvalid_1's rmse: 46.8962\n",
      "[1620]\ttraining's rmse: 1.49096\tvalid_1's rmse: 46.8932\n",
      "[1650]\ttraining's rmse: 1.4188\tvalid_1's rmse: 46.8897\n",
      "[1680]\ttraining's rmse: 1.34947\tvalid_1's rmse: 46.8859\n",
      "[1710]\ttraining's rmse: 1.28329\tvalid_1's rmse: 46.8821\n",
      "[1740]\ttraining's rmse: 1.22174\tvalid_1's rmse: 46.8799\n",
      "[1770]\ttraining's rmse: 1.16297\tvalid_1's rmse: 46.8762\n",
      "[1800]\ttraining's rmse: 1.10817\tvalid_1's rmse: 46.8747\n",
      "[1830]\ttraining's rmse: 1.05446\tvalid_1's rmse: 46.8751\n",
      "[1860]\ttraining's rmse: 1.00393\tvalid_1's rmse: 46.8732\n",
      "[1890]\ttraining's rmse: 0.955257\tvalid_1's rmse: 46.873\n",
      "[1920]\ttraining's rmse: 0.909556\tvalid_1's rmse: 46.8717\n",
      "[1950]\ttraining's rmse: 0.866133\tvalid_1's rmse: 46.8702\n",
      "[1980]\ttraining's rmse: 0.825001\tvalid_1's rmse: 46.8687\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's rmse: 0.799041\tvalid_1's rmse: 46.8679\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003385 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 20024\n",
      "[LightGBM] [Info] Number of data points in the train set: 9219, number of used features: 79\n",
      "[LightGBM] [Info] Start training from score 364.555425\n",
      "Training until validation scores don't improve for 125 rounds\n",
      "[30]\ttraining's rmse: 154.548\tvalid_1's rmse: 154.04\n",
      "[60]\ttraining's rmse: 97.4267\tvalid_1's rmse: 104.598\n",
      "[90]\ttraining's rmse: 66.4085\tvalid_1's rmse: 80.457\n",
      "[120]\ttraining's rmse: 49.383\tvalid_1's rmse: 69.0843\n",
      "[150]\ttraining's rmse: 39.7576\tvalid_1's rmse: 63.5635\n",
      "[180]\ttraining's rmse: 33.7424\tvalid_1's rmse: 60.891\n",
      "[210]\ttraining's rmse: 29.5838\tvalid_1's rmse: 59.3323\n",
      "[240]\ttraining's rmse: 26.398\tvalid_1's rmse: 58.2851\n",
      "[270]\ttraining's rmse: 23.7743\tvalid_1's rmse: 57.4633\n",
      "[300]\ttraining's rmse: 21.656\tvalid_1's rmse: 56.9484\n",
      "[330]\ttraining's rmse: 19.8153\tvalid_1's rmse: 56.5499\n",
      "[360]\ttraining's rmse: 18.221\tvalid_1's rmse: 56.2343\n",
      "[390]\ttraining's rmse: 16.7945\tvalid_1's rmse: 55.9768\n",
      "[420]\ttraining's rmse: 15.546\tvalid_1's rmse: 55.7808\n",
      "[450]\ttraining's rmse: 14.4284\tvalid_1's rmse: 55.6191\n",
      "[480]\ttraining's rmse: 13.409\tvalid_1's rmse: 55.4522\n",
      "[510]\ttraining's rmse: 12.483\tvalid_1's rmse: 55.3436\n",
      "[540]\ttraining's rmse: 11.6363\tvalid_1's rmse: 55.2633\n",
      "[570]\ttraining's rmse: 10.8781\tvalid_1's rmse: 55.1883\n",
      "[600]\ttraining's rmse: 10.188\tvalid_1's rmse: 55.1205\n",
      "[630]\ttraining's rmse: 9.53855\tvalid_1's rmse: 55.0636\n",
      "[660]\ttraining's rmse: 8.94652\tvalid_1's rmse: 55.0125\n",
      "[690]\ttraining's rmse: 8.38578\tvalid_1's rmse: 54.978\n",
      "[720]\ttraining's rmse: 7.8801\tvalid_1's rmse: 54.9507\n",
      "[750]\ttraining's rmse: 7.41601\tvalid_1's rmse: 54.9214\n",
      "[780]\ttraining's rmse: 6.9891\tvalid_1's rmse: 54.8932\n",
      "[810]\ttraining's rmse: 6.58255\tvalid_1's rmse: 54.8609\n",
      "[840]\ttraining's rmse: 6.1971\tvalid_1's rmse: 54.8487\n",
      "[870]\ttraining's rmse: 5.84308\tvalid_1's rmse: 54.8257\n",
      "[900]\ttraining's rmse: 5.50945\tvalid_1's rmse: 54.7969\n",
      "[930]\ttraining's rmse: 5.20764\tvalid_1's rmse: 54.7788\n",
      "[960]\ttraining's rmse: 4.92229\tvalid_1's rmse: 54.7707\n",
      "[990]\ttraining's rmse: 4.65115\tvalid_1's rmse: 54.7494\n",
      "[1020]\ttraining's rmse: 4.40223\tvalid_1's rmse: 54.7476\n",
      "[1050]\ttraining's rmse: 4.16286\tvalid_1's rmse: 54.7352\n",
      "[1080]\ttraining's rmse: 3.93635\tvalid_1's rmse: 54.7249\n",
      "[1110]\ttraining's rmse: 3.7301\tvalid_1's rmse: 54.7239\n",
      "[1140]\ttraining's rmse: 3.5334\tvalid_1's rmse: 54.7213\n",
      "[1170]\ttraining's rmse: 3.3478\tvalid_1's rmse: 54.7199\n",
      "[1200]\ttraining's rmse: 3.17538\tvalid_1's rmse: 54.7075\n",
      "[1230]\ttraining's rmse: 3.01367\tvalid_1's rmse: 54.7055\n",
      "[1260]\ttraining's rmse: 2.86229\tvalid_1's rmse: 54.6989\n",
      "[1290]\ttraining's rmse: 2.71772\tvalid_1's rmse: 54.6937\n",
      "[1320]\ttraining's rmse: 2.58011\tvalid_1's rmse: 54.6956\n",
      "[1350]\ttraining's rmse: 2.4474\tvalid_1's rmse: 54.6918\n",
      "[1380]\ttraining's rmse: 2.32452\tvalid_1's rmse: 54.6871\n",
      "[1410]\ttraining's rmse: 2.21077\tvalid_1's rmse: 54.6834\n",
      "[1440]\ttraining's rmse: 2.1002\tvalid_1's rmse: 54.6817\n",
      "[1470]\ttraining's rmse: 1.99634\tvalid_1's rmse: 54.6761\n",
      "[1500]\ttraining's rmse: 1.89551\tvalid_1's rmse: 54.6766\n",
      "[1530]\ttraining's rmse: 1.80183\tvalid_1's rmse: 54.6707\n",
      "[1560]\ttraining's rmse: 1.7132\tvalid_1's rmse: 54.6693\n",
      "[1590]\ttraining's rmse: 1.6296\tvalid_1's rmse: 54.6683\n",
      "[1620]\ttraining's rmse: 1.54884\tvalid_1's rmse: 54.6678\n",
      "[1650]\ttraining's rmse: 1.47381\tvalid_1's rmse: 54.6648\n",
      "[1680]\ttraining's rmse: 1.40115\tvalid_1's rmse: 54.6628\n",
      "[1710]\ttraining's rmse: 1.33244\tvalid_1's rmse: 54.6625\n",
      "[1740]\ttraining's rmse: 1.27039\tvalid_1's rmse: 54.6599\n",
      "[1770]\ttraining's rmse: 1.21007\tvalid_1's rmse: 54.6578\n",
      "[1800]\ttraining's rmse: 1.15167\tvalid_1's rmse: 54.6574\n",
      "[1830]\ttraining's rmse: 1.09603\tvalid_1's rmse: 54.6564\n",
      "[1860]\ttraining's rmse: 1.04384\tvalid_1's rmse: 54.6537\n",
      "[1890]\ttraining's rmse: 0.994566\tvalid_1's rmse: 54.6517\n",
      "[1920]\ttraining's rmse: 0.947142\tvalid_1's rmse: 54.6508\n",
      "[1950]\ttraining's rmse: 0.902803\tvalid_1's rmse: 54.6494\n",
      "[1980]\ttraining's rmse: 0.859668\tvalid_1's rmse: 54.6484\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's rmse: 0.832586\tvalid_1's rmse: 54.6475\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002466 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 20024\n",
      "[LightGBM] [Info] Number of data points in the train set: 9219, number of used features: 79\n",
      "[LightGBM] [Info] Start training from score 367.822387\n",
      "Training until validation scores don't improve for 125 rounds\n",
      "[30]\ttraining's rmse: 153.464\tvalid_1's rmse: 153.66\n",
      "[60]\ttraining's rmse: 95.8162\tvalid_1's rmse: 102.813\n",
      "[90]\ttraining's rmse: 64.5005\tvalid_1's rmse: 77.8395\n",
      "[120]\ttraining's rmse: 47.6638\tvalid_1's rmse: 66.3005\n",
      "[150]\ttraining's rmse: 38.1507\tvalid_1's rmse: 60.6375\n",
      "[180]\ttraining's rmse: 32.306\tvalid_1's rmse: 57.813\n",
      "[210]\ttraining's rmse: 28.2612\tvalid_1's rmse: 56.1335\n",
      "[240]\ttraining's rmse: 25.1425\tvalid_1's rmse: 54.9876\n",
      "[270]\ttraining's rmse: 22.6989\tvalid_1's rmse: 54.2797\n",
      "[300]\ttraining's rmse: 20.6547\tvalid_1's rmse: 53.8075\n",
      "[330]\ttraining's rmse: 18.9156\tvalid_1's rmse: 53.4763\n",
      "[360]\ttraining's rmse: 17.3841\tvalid_1's rmse: 53.2214\n",
      "[390]\ttraining's rmse: 16.0585\tvalid_1's rmse: 53.0272\n",
      "[420]\ttraining's rmse: 14.8651\tvalid_1's rmse: 52.8661\n",
      "[450]\ttraining's rmse: 13.7825\tvalid_1's rmse: 52.7121\n",
      "[480]\ttraining's rmse: 12.8056\tvalid_1's rmse: 52.6011\n",
      "[510]\ttraining's rmse: 11.9489\tvalid_1's rmse: 52.4993\n",
      "[540]\ttraining's rmse: 11.1468\tvalid_1's rmse: 52.3859\n",
      "[570]\ttraining's rmse: 10.4176\tvalid_1's rmse: 52.3011\n",
      "[600]\ttraining's rmse: 9.74803\tvalid_1's rmse: 52.241\n",
      "[630]\ttraining's rmse: 9.12646\tvalid_1's rmse: 52.2055\n",
      "[660]\ttraining's rmse: 8.561\tvalid_1's rmse: 52.1597\n",
      "[690]\ttraining's rmse: 8.03669\tvalid_1's rmse: 52.1223\n",
      "[720]\ttraining's rmse: 7.54386\tvalid_1's rmse: 52.077\n",
      "[750]\ttraining's rmse: 7.09013\tvalid_1's rmse: 52.0521\n",
      "[780]\ttraining's rmse: 6.66697\tvalid_1's rmse: 52.0152\n",
      "[810]\ttraining's rmse: 6.28296\tvalid_1's rmse: 51.9857\n",
      "[840]\ttraining's rmse: 5.92163\tvalid_1's rmse: 51.9495\n",
      "[870]\ttraining's rmse: 5.57807\tvalid_1's rmse: 51.9243\n",
      "[900]\ttraining's rmse: 5.26999\tvalid_1's rmse: 51.9055\n",
      "[930]\ttraining's rmse: 4.97694\tvalid_1's rmse: 51.8918\n",
      "[960]\ttraining's rmse: 4.69452\tvalid_1's rmse: 51.8834\n",
      "[990]\ttraining's rmse: 4.43691\tvalid_1's rmse: 51.8709\n",
      "[1020]\ttraining's rmse: 4.19303\tvalid_1's rmse: 51.8446\n",
      "[1050]\ttraining's rmse: 3.962\tvalid_1's rmse: 51.835\n",
      "[1080]\ttraining's rmse: 3.75026\tvalid_1's rmse: 51.8251\n",
      "[1110]\ttraining's rmse: 3.55022\tvalid_1's rmse: 51.8171\n",
      "[1140]\ttraining's rmse: 3.36258\tvalid_1's rmse: 51.8056\n",
      "[1170]\ttraining's rmse: 3.1874\tvalid_1's rmse: 51.8025\n",
      "[1200]\ttraining's rmse: 3.01797\tvalid_1's rmse: 51.7973\n",
      "[1230]\ttraining's rmse: 2.86092\tvalid_1's rmse: 51.792\n",
      "[1260]\ttraining's rmse: 2.71493\tvalid_1's rmse: 51.7859\n",
      "[1290]\ttraining's rmse: 2.57447\tvalid_1's rmse: 51.7767\n",
      "[1320]\ttraining's rmse: 2.44242\tvalid_1's rmse: 51.7714\n",
      "[1350]\ttraining's rmse: 2.31869\tvalid_1's rmse: 51.7693\n",
      "[1380]\ttraining's rmse: 2.20066\tvalid_1's rmse: 51.7641\n",
      "[1410]\ttraining's rmse: 2.08847\tvalid_1's rmse: 51.7615\n",
      "[1440]\ttraining's rmse: 1.98517\tvalid_1's rmse: 51.751\n",
      "[1470]\ttraining's rmse: 1.88558\tvalid_1's rmse: 51.7486\n",
      "[1500]\ttraining's rmse: 1.79243\tvalid_1's rmse: 51.7444\n",
      "[1530]\ttraining's rmse: 1.70507\tvalid_1's rmse: 51.7403\n",
      "[1560]\ttraining's rmse: 1.61831\tvalid_1's rmse: 51.7372\n",
      "[1590]\ttraining's rmse: 1.53788\tvalid_1's rmse: 51.7356\n",
      "[1620]\ttraining's rmse: 1.46287\tvalid_1's rmse: 51.7339\n",
      "[1650]\ttraining's rmse: 1.39201\tvalid_1's rmse: 51.7307\n",
      "[1680]\ttraining's rmse: 1.32384\tvalid_1's rmse: 51.7279\n",
      "[1710]\ttraining's rmse: 1.25952\tvalid_1's rmse: 51.7238\n",
      "[1740]\ttraining's rmse: 1.19856\tvalid_1's rmse: 51.7213\n",
      "[1770]\ttraining's rmse: 1.14256\tvalid_1's rmse: 51.721\n",
      "[1800]\ttraining's rmse: 1.08814\tvalid_1's rmse: 51.7207\n",
      "[1830]\ttraining's rmse: 1.03567\tvalid_1's rmse: 51.7206\n",
      "[1860]\ttraining's rmse: 0.986971\tvalid_1's rmse: 51.7193\n",
      "[1890]\ttraining's rmse: 0.93987\tvalid_1's rmse: 51.7182\n",
      "[1920]\ttraining's rmse: 0.896828\tvalid_1's rmse: 51.7175\n",
      "[1950]\ttraining's rmse: 0.853944\tvalid_1's rmse: 51.7157\n",
      "[1980]\ttraining's rmse: 0.813796\tvalid_1's rmse: 51.7153\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's rmse: 0.789167\tvalid_1's rmse: 51.7151\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003490 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 20024\n",
      "[LightGBM] [Info] Number of data points in the train set: 9219, number of used features: 79\n",
      "[LightGBM] [Info] Start training from score 369.976424\n",
      "Training until validation scores don't improve for 125 rounds\n",
      "[30]\ttraining's rmse: 153.52\tvalid_1's rmse: 155.048\n",
      "[60]\ttraining's rmse: 96.2069\tvalid_1's rmse: 103.379\n",
      "[90]\ttraining's rmse: 65.1905\tvalid_1's rmse: 77.6351\n",
      "[120]\ttraining's rmse: 48.4263\tvalid_1's rmse: 65.5209\n",
      "[150]\ttraining's rmse: 38.9058\tvalid_1's rmse: 59.7035\n",
      "[180]\ttraining's rmse: 33.0305\tvalid_1's rmse: 56.7066\n",
      "[210]\ttraining's rmse: 28.9559\tvalid_1's rmse: 54.9917\n",
      "[240]\ttraining's rmse: 25.8425\tvalid_1's rmse: 53.8098\n",
      "[270]\ttraining's rmse: 23.3596\tvalid_1's rmse: 53.0534\n",
      "[300]\ttraining's rmse: 21.3079\tvalid_1's rmse: 52.5928\n",
      "[330]\ttraining's rmse: 19.5736\tvalid_1's rmse: 52.1677\n",
      "[360]\ttraining's rmse: 18.0428\tvalid_1's rmse: 51.8571\n",
      "[390]\ttraining's rmse: 16.7005\tvalid_1's rmse: 51.6599\n",
      "[420]\ttraining's rmse: 15.4782\tvalid_1's rmse: 51.5129\n",
      "[450]\ttraining's rmse: 14.383\tvalid_1's rmse: 51.3579\n",
      "[480]\ttraining's rmse: 13.391\tvalid_1's rmse: 51.2754\n",
      "[510]\ttraining's rmse: 12.511\tvalid_1's rmse: 51.1596\n",
      "[540]\ttraining's rmse: 11.6707\tvalid_1's rmse: 51.0745\n",
      "[570]\ttraining's rmse: 10.9176\tvalid_1's rmse: 50.9832\n",
      "[600]\ttraining's rmse: 10.2292\tvalid_1's rmse: 50.9161\n",
      "[630]\ttraining's rmse: 9.60064\tvalid_1's rmse: 50.8483\n",
      "[660]\ttraining's rmse: 9.02073\tvalid_1's rmse: 50.8067\n",
      "[690]\ttraining's rmse: 8.46594\tvalid_1's rmse: 50.783\n",
      "[720]\ttraining's rmse: 7.96046\tvalid_1's rmse: 50.7448\n",
      "[750]\ttraining's rmse: 7.49567\tvalid_1's rmse: 50.7116\n",
      "[780]\ttraining's rmse: 7.05785\tvalid_1's rmse: 50.6806\n",
      "[810]\ttraining's rmse: 6.65572\tvalid_1's rmse: 50.6617\n",
      "[840]\ttraining's rmse: 6.28326\tvalid_1's rmse: 50.6242\n",
      "[870]\ttraining's rmse: 5.92646\tvalid_1's rmse: 50.6028\n",
      "[900]\ttraining's rmse: 5.60063\tvalid_1's rmse: 50.5823\n",
      "[930]\ttraining's rmse: 5.28977\tvalid_1's rmse: 50.5702\n",
      "[960]\ttraining's rmse: 5.00386\tvalid_1's rmse: 50.5663\n",
      "[990]\ttraining's rmse: 4.73636\tvalid_1's rmse: 50.5442\n",
      "[1020]\ttraining's rmse: 4.48683\tvalid_1's rmse: 50.5206\n",
      "[1050]\ttraining's rmse: 4.25311\tvalid_1's rmse: 50.4954\n",
      "[1080]\ttraining's rmse: 4.0312\tvalid_1's rmse: 50.4897\n",
      "[1110]\ttraining's rmse: 3.82596\tvalid_1's rmse: 50.4805\n",
      "[1140]\ttraining's rmse: 3.62972\tvalid_1's rmse: 50.4689\n",
      "[1170]\ttraining's rmse: 3.44177\tvalid_1's rmse: 50.4673\n",
      "[1200]\ttraining's rmse: 3.26416\tvalid_1's rmse: 50.4607\n",
      "[1230]\ttraining's rmse: 3.10176\tvalid_1's rmse: 50.453\n",
      "[1260]\ttraining's rmse: 2.94838\tvalid_1's rmse: 50.448\n",
      "[1290]\ttraining's rmse: 2.80259\tvalid_1's rmse: 50.4474\n",
      "[1320]\ttraining's rmse: 2.66335\tvalid_1's rmse: 50.4412\n",
      "[1350]\ttraining's rmse: 2.53332\tvalid_1's rmse: 50.4402\n",
      "[1380]\ttraining's rmse: 2.41236\tvalid_1's rmse: 50.4388\n",
      "[1410]\ttraining's rmse: 2.2926\tvalid_1's rmse: 50.4324\n",
      "[1440]\ttraining's rmse: 2.18077\tvalid_1's rmse: 50.429\n",
      "[1470]\ttraining's rmse: 2.07947\tvalid_1's rmse: 50.4288\n",
      "[1500]\ttraining's rmse: 1.9806\tvalid_1's rmse: 50.4275\n",
      "[1530]\ttraining's rmse: 1.88592\tvalid_1's rmse: 50.4191\n",
      "[1560]\ttraining's rmse: 1.7971\tvalid_1's rmse: 50.4159\n",
      "[1590]\ttraining's rmse: 1.71284\tvalid_1's rmse: 50.4179\n",
      "[1620]\ttraining's rmse: 1.63518\tvalid_1's rmse: 50.4184\n",
      "[1650]\ttraining's rmse: 1.56134\tvalid_1's rmse: 50.415\n",
      "[1680]\ttraining's rmse: 1.49178\tvalid_1's rmse: 50.4141\n",
      "[1710]\ttraining's rmse: 1.42503\tvalid_1's rmse: 50.4147\n",
      "[1740]\ttraining's rmse: 1.36333\tvalid_1's rmse: 50.4148\n",
      "[1770]\ttraining's rmse: 1.30074\tvalid_1's rmse: 50.4132\n",
      "[1800]\ttraining's rmse: 1.24597\tvalid_1's rmse: 50.4105\n",
      "[1830]\ttraining's rmse: 1.18956\tvalid_1's rmse: 50.4119\n",
      "[1860]\ttraining's rmse: 1.13694\tvalid_1's rmse: 50.41\n",
      "[1890]\ttraining's rmse: 1.08904\tvalid_1's rmse: 50.4095\n",
      "[1920]\ttraining's rmse: 1.04194\tvalid_1's rmse: 50.4079\n",
      "[1950]\ttraining's rmse: 0.997594\tvalid_1's rmse: 50.4071\n",
      "[1980]\ttraining's rmse: 0.955135\tvalid_1's rmse: 50.4058\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's rmse: 0.927794\tvalid_1's rmse: 50.4062\n",
      "22\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003308 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 20024\n",
      "[LightGBM] [Info] Number of data points in the train set: 9219, number of used features: 79\n",
      "[LightGBM] [Info] Start training from score 360.971773\n",
      "Training until validation scores don't improve for 125 rounds\n",
      "[30]\ttraining's rmse: 154.02\tvalid_1's rmse: 157.617\n",
      "[60]\ttraining's rmse: 95.4549\tvalid_1's rmse: 102.413\n",
      "[90]\ttraining's rmse: 63.934\tvalid_1's rmse: 74.7883\n",
      "[120]\ttraining's rmse: 46.9049\tvalid_1's rmse: 61.2886\n",
      "[150]\ttraining's rmse: 37.421\tvalid_1's rmse: 54.8503\n",
      "[180]\ttraining's rmse: 31.6591\tvalid_1's rmse: 51.5174\n",
      "[210]\ttraining's rmse: 27.7909\tvalid_1's rmse: 49.6585\n",
      "[240]\ttraining's rmse: 24.7096\tvalid_1's rmse: 48.3375\n",
      "[270]\ttraining's rmse: 22.2645\tvalid_1's rmse: 47.4469\n",
      "[300]\ttraining's rmse: 20.21\tvalid_1's rmse: 46.8817\n",
      "[330]\ttraining's rmse: 18.4876\tvalid_1's rmse: 46.4522\n",
      "[360]\ttraining's rmse: 17.0167\tvalid_1's rmse: 46.1656\n",
      "[390]\ttraining's rmse: 15.7233\tvalid_1's rmse: 45.964\n",
      "[420]\ttraining's rmse: 14.5589\tvalid_1's rmse: 45.7958\n",
      "[450]\ttraining's rmse: 13.5109\tvalid_1's rmse: 45.6423\n",
      "[480]\ttraining's rmse: 12.5498\tvalid_1's rmse: 45.5055\n",
      "[510]\ttraining's rmse: 11.688\tvalid_1's rmse: 45.3767\n",
      "[540]\ttraining's rmse: 10.9079\tvalid_1's rmse: 45.3033\n",
      "[570]\ttraining's rmse: 10.2115\tvalid_1's rmse: 45.2405\n",
      "[600]\ttraining's rmse: 9.56542\tvalid_1's rmse: 45.2113\n",
      "[630]\ttraining's rmse: 8.95435\tvalid_1's rmse: 45.151\n",
      "[660]\ttraining's rmse: 8.40947\tvalid_1's rmse: 45.1078\n",
      "[690]\ttraining's rmse: 7.89405\tvalid_1's rmse: 45.0706\n",
      "[720]\ttraining's rmse: 7.41059\tvalid_1's rmse: 45.0348\n",
      "[750]\ttraining's rmse: 6.97168\tvalid_1's rmse: 45.0014\n",
      "[780]\ttraining's rmse: 6.5599\tvalid_1's rmse: 44.966\n",
      "[810]\ttraining's rmse: 6.16944\tvalid_1's rmse: 44.9418\n",
      "[840]\ttraining's rmse: 5.81387\tvalid_1's rmse: 44.9253\n",
      "[870]\ttraining's rmse: 5.47937\tvalid_1's rmse: 44.8945\n",
      "[900]\ttraining's rmse: 5.16844\tvalid_1's rmse: 44.8674\n",
      "[930]\ttraining's rmse: 4.87786\tvalid_1's rmse: 44.8531\n",
      "[960]\ttraining's rmse: 4.60096\tvalid_1's rmse: 44.8342\n",
      "[990]\ttraining's rmse: 4.34737\tvalid_1's rmse: 44.8218\n",
      "[1020]\ttraining's rmse: 4.10852\tvalid_1's rmse: 44.807\n",
      "[1050]\ttraining's rmse: 3.88807\tvalid_1's rmse: 44.7881\n",
      "[1080]\ttraining's rmse: 3.67488\tvalid_1's rmse: 44.7824\n",
      "[1110]\ttraining's rmse: 3.47673\tvalid_1's rmse: 44.7749\n",
      "[1140]\ttraining's rmse: 3.29333\tvalid_1's rmse: 44.7652\n",
      "[1170]\ttraining's rmse: 3.12257\tvalid_1's rmse: 44.7612\n",
      "[1200]\ttraining's rmse: 2.9563\tvalid_1's rmse: 44.7556\n",
      "[1230]\ttraining's rmse: 2.799\tvalid_1's rmse: 44.7511\n",
      "[1260]\ttraining's rmse: 2.65216\tvalid_1's rmse: 44.7444\n",
      "[1290]\ttraining's rmse: 2.51371\tvalid_1's rmse: 44.741\n",
      "[1320]\ttraining's rmse: 2.38211\tvalid_1's rmse: 44.7376\n",
      "[1350]\ttraining's rmse: 2.26102\tvalid_1's rmse: 44.7357\n",
      "[1380]\ttraining's rmse: 2.14403\tvalid_1's rmse: 44.7344\n",
      "[1410]\ttraining's rmse: 2.03421\tvalid_1's rmse: 44.7267\n",
      "[1440]\ttraining's rmse: 1.93145\tvalid_1's rmse: 44.7251\n",
      "[1470]\ttraining's rmse: 1.83518\tvalid_1's rmse: 44.724\n",
      "[1500]\ttraining's rmse: 1.74388\tvalid_1's rmse: 44.7186\n",
      "[1530]\ttraining's rmse: 1.65671\tvalid_1's rmse: 44.7157\n",
      "[1560]\ttraining's rmse: 1.57178\tvalid_1's rmse: 44.7106\n",
      "[1590]\ttraining's rmse: 1.49349\tvalid_1's rmse: 44.7077\n",
      "[1620]\ttraining's rmse: 1.42094\tvalid_1's rmse: 44.7063\n",
      "[1650]\ttraining's rmse: 1.35209\tvalid_1's rmse: 44.7059\n",
      "[1680]\ttraining's rmse: 1.2854\tvalid_1's rmse: 44.7049\n",
      "[1710]\ttraining's rmse: 1.22181\tvalid_1's rmse: 44.7034\n",
      "[1740]\ttraining's rmse: 1.16259\tvalid_1's rmse: 44.702\n",
      "[1770]\ttraining's rmse: 1.10625\tvalid_1's rmse: 44.6999\n",
      "[1800]\ttraining's rmse: 1.05168\tvalid_1's rmse: 44.6983\n",
      "[1830]\ttraining's rmse: 1.00077\tvalid_1's rmse: 44.6964\n",
      "[1860]\ttraining's rmse: 0.952552\tvalid_1's rmse: 44.6959\n",
      "[1890]\ttraining's rmse: 0.905127\tvalid_1's rmse: 44.6934\n",
      "[1920]\ttraining's rmse: 0.860785\tvalid_1's rmse: 44.6925\n",
      "[1950]\ttraining's rmse: 0.819247\tvalid_1's rmse: 44.6918\n",
      "[1980]\ttraining's rmse: 0.780411\tvalid_1's rmse: 44.6905\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's rmse: 0.755487\tvalid_1's rmse: 44.69\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003265 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 20024\n",
      "[LightGBM] [Info] Number of data points in the train set: 9219, number of used features: 79\n",
      "[LightGBM] [Info] Start training from score 359.814089\n",
      "Training until validation scores don't improve for 125 rounds\n",
      "[30]\ttraining's rmse: 155.048\tvalid_1's rmse: 159.074\n",
      "[60]\ttraining's rmse: 96.7039\tvalid_1's rmse: 105.947\n",
      "[90]\ttraining's rmse: 65.3768\tvalid_1's rmse: 79.6456\n",
      "[120]\ttraining's rmse: 48.3786\tvalid_1's rmse: 66.8807\n",
      "[150]\ttraining's rmse: 38.8582\tvalid_1's rmse: 60.702\n",
      "[180]\ttraining's rmse: 32.9404\tvalid_1's rmse: 57.552\n",
      "[210]\ttraining's rmse: 28.8806\tvalid_1's rmse: 55.5542\n",
      "[240]\ttraining's rmse: 25.6819\tvalid_1's rmse: 54.2965\n",
      "[270]\ttraining's rmse: 23.15\tvalid_1's rmse: 53.4508\n",
      "[300]\ttraining's rmse: 21.0427\tvalid_1's rmse: 52.8775\n",
      "[330]\ttraining's rmse: 19.2501\tvalid_1's rmse: 52.5267\n",
      "[360]\ttraining's rmse: 17.7118\tvalid_1's rmse: 52.2755\n",
      "[390]\ttraining's rmse: 16.3389\tvalid_1's rmse: 52.0815\n",
      "[420]\ttraining's rmse: 15.1119\tvalid_1's rmse: 51.9036\n",
      "[450]\ttraining's rmse: 14.0419\tvalid_1's rmse: 51.7556\n",
      "[480]\ttraining's rmse: 13.0546\tvalid_1's rmse: 51.6579\n",
      "[510]\ttraining's rmse: 12.176\tvalid_1's rmse: 51.5553\n",
      "[540]\ttraining's rmse: 11.3668\tvalid_1's rmse: 51.4511\n",
      "[570]\ttraining's rmse: 10.6297\tvalid_1's rmse: 51.3723\n",
      "[600]\ttraining's rmse: 9.94807\tvalid_1's rmse: 51.2977\n",
      "[630]\ttraining's rmse: 9.32053\tvalid_1's rmse: 51.2295\n",
      "[660]\ttraining's rmse: 8.7366\tvalid_1's rmse: 51.1644\n",
      "[690]\ttraining's rmse: 8.19299\tvalid_1's rmse: 51.1205\n",
      "[720]\ttraining's rmse: 7.68875\tvalid_1's rmse: 51.0782\n",
      "[750]\ttraining's rmse: 7.22641\tvalid_1's rmse: 51.0334\n",
      "[780]\ttraining's rmse: 6.78715\tvalid_1's rmse: 50.9999\n",
      "[810]\ttraining's rmse: 6.39094\tvalid_1's rmse: 50.9634\n",
      "[840]\ttraining's rmse: 6.01953\tvalid_1's rmse: 50.9371\n",
      "[870]\ttraining's rmse: 5.6772\tvalid_1's rmse: 50.9169\n",
      "[900]\ttraining's rmse: 5.35666\tvalid_1's rmse: 50.8956\n",
      "[930]\ttraining's rmse: 5.05704\tvalid_1's rmse: 50.8795\n",
      "[960]\ttraining's rmse: 4.7693\tvalid_1's rmse: 50.8566\n",
      "[990]\ttraining's rmse: 4.50536\tvalid_1's rmse: 50.8422\n",
      "[1020]\ttraining's rmse: 4.25937\tvalid_1's rmse: 50.8314\n",
      "[1050]\ttraining's rmse: 4.02623\tvalid_1's rmse: 50.8208\n",
      "[1080]\ttraining's rmse: 3.80872\tvalid_1's rmse: 50.81\n",
      "[1110]\ttraining's rmse: 3.60652\tvalid_1's rmse: 50.8004\n",
      "[1140]\ttraining's rmse: 3.41451\tvalid_1's rmse: 50.7952\n",
      "[1170]\ttraining's rmse: 3.2296\tvalid_1's rmse: 50.7859\n",
      "[1200]\ttraining's rmse: 3.05401\tvalid_1's rmse: 50.7803\n",
      "[1230]\ttraining's rmse: 2.89372\tvalid_1's rmse: 50.7741\n",
      "[1260]\ttraining's rmse: 2.74051\tvalid_1's rmse: 50.764\n",
      "[1290]\ttraining's rmse: 2.59567\tvalid_1's rmse: 50.7547\n",
      "[1320]\ttraining's rmse: 2.46058\tvalid_1's rmse: 50.746\n",
      "[1350]\ttraining's rmse: 2.33356\tvalid_1's rmse: 50.7392\n",
      "[1380]\ttraining's rmse: 2.21686\tvalid_1's rmse: 50.7365\n",
      "[1410]\ttraining's rmse: 2.09833\tvalid_1's rmse: 50.736\n",
      "[1440]\ttraining's rmse: 1.99214\tvalid_1's rmse: 50.7287\n",
      "[1470]\ttraining's rmse: 1.89094\tvalid_1's rmse: 50.7261\n",
      "[1500]\ttraining's rmse: 1.79465\tvalid_1's rmse: 50.7184\n",
      "[1530]\ttraining's rmse: 1.70359\tvalid_1's rmse: 50.71\n",
      "[1560]\ttraining's rmse: 1.61817\tvalid_1's rmse: 50.7081\n",
      "[1590]\ttraining's rmse: 1.53718\tvalid_1's rmse: 50.7049\n",
      "[1620]\ttraining's rmse: 1.45905\tvalid_1's rmse: 50.7021\n",
      "[1650]\ttraining's rmse: 1.38499\tvalid_1's rmse: 50.6998\n",
      "[1680]\ttraining's rmse: 1.31562\tvalid_1's rmse: 50.6978\n",
      "[1710]\ttraining's rmse: 1.24831\tvalid_1's rmse: 50.695\n",
      "[1740]\ttraining's rmse: 1.18622\tvalid_1's rmse: 50.6946\n",
      "[1770]\ttraining's rmse: 1.12874\tvalid_1's rmse: 50.6943\n",
      "[1800]\ttraining's rmse: 1.07395\tvalid_1's rmse: 50.6942\n",
      "[1830]\ttraining's rmse: 1.02102\tvalid_1's rmse: 50.693\n",
      "[1860]\ttraining's rmse: 0.97094\tvalid_1's rmse: 50.6919\n",
      "[1890]\ttraining's rmse: 0.923568\tvalid_1's rmse: 50.689\n",
      "[1920]\ttraining's rmse: 0.880335\tvalid_1's rmse: 50.6867\n",
      "[1950]\ttraining's rmse: 0.838347\tvalid_1's rmse: 50.6849\n",
      "[1980]\ttraining's rmse: 0.798954\tvalid_1's rmse: 50.6828\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's rmse: 0.774042\tvalid_1's rmse: 50.6834\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002542 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 20024\n",
      "[LightGBM] [Info] Number of data points in the train set: 9219, number of used features: 79\n",
      "[LightGBM] [Info] Start training from score 358.769873\n",
      "Training until validation scores don't improve for 125 rounds\n",
      "[30]\ttraining's rmse: 155.978\tvalid_1's rmse: 161.751\n",
      "[60]\ttraining's rmse: 97.6845\tvalid_1's rmse: 109.504\n",
      "[90]\ttraining's rmse: 66.0146\tvalid_1's rmse: 83.6765\n",
      "[120]\ttraining's rmse: 48.9121\tvalid_1's rmse: 71.295\n",
      "[150]\ttraining's rmse: 39.5226\tvalid_1's rmse: 65.4011\n",
      "[180]\ttraining's rmse: 33.7284\tvalid_1's rmse: 62.4221\n",
      "[210]\ttraining's rmse: 29.6931\tvalid_1's rmse: 60.5305\n",
      "[240]\ttraining's rmse: 26.5041\tvalid_1's rmse: 59.4741\n",
      "[270]\ttraining's rmse: 23.9335\tvalid_1's rmse: 58.6893\n",
      "[300]\ttraining's rmse: 21.7643\tvalid_1's rmse: 58.1544\n",
      "[330]\ttraining's rmse: 19.9153\tvalid_1's rmse: 57.7215\n",
      "[360]\ttraining's rmse: 18.2768\tvalid_1's rmse: 57.5011\n",
      "[390]\ttraining's rmse: 16.8602\tvalid_1's rmse: 57.2913\n",
      "[420]\ttraining's rmse: 15.627\tvalid_1's rmse: 57.1354\n",
      "[450]\ttraining's rmse: 14.4982\tvalid_1's rmse: 56.9856\n",
      "[480]\ttraining's rmse: 13.4651\tvalid_1's rmse: 56.8516\n",
      "[510]\ttraining's rmse: 12.5418\tvalid_1's rmse: 56.7403\n",
      "[540]\ttraining's rmse: 11.7151\tvalid_1's rmse: 56.6426\n",
      "[570]\ttraining's rmse: 10.9463\tvalid_1's rmse: 56.5486\n",
      "[600]\ttraining's rmse: 10.2419\tvalid_1's rmse: 56.4802\n",
      "[630]\ttraining's rmse: 9.58477\tvalid_1's rmse: 56.3902\n",
      "[660]\ttraining's rmse: 8.99307\tvalid_1's rmse: 56.3297\n",
      "[690]\ttraining's rmse: 8.44114\tvalid_1's rmse: 56.2924\n",
      "[720]\ttraining's rmse: 7.93328\tvalid_1's rmse: 56.2634\n",
      "[750]\ttraining's rmse: 7.45257\tvalid_1's rmse: 56.2439\n",
      "[780]\ttraining's rmse: 7.01232\tvalid_1's rmse: 56.2197\n",
      "[810]\ttraining's rmse: 6.61482\tvalid_1's rmse: 56.1707\n",
      "[840]\ttraining's rmse: 6.23002\tvalid_1's rmse: 56.1559\n",
      "[870]\ttraining's rmse: 5.87173\tvalid_1's rmse: 56.1298\n",
      "[900]\ttraining's rmse: 5.53605\tvalid_1's rmse: 56.1061\n",
      "[930]\ttraining's rmse: 5.22347\tvalid_1's rmse: 56.0901\n",
      "[960]\ttraining's rmse: 4.9409\tvalid_1's rmse: 56.068\n",
      "[990]\ttraining's rmse: 4.67037\tvalid_1's rmse: 56.0568\n",
      "[1020]\ttraining's rmse: 4.40955\tvalid_1's rmse: 56.036\n",
      "[1050]\ttraining's rmse: 4.17153\tvalid_1's rmse: 56.0319\n",
      "[1080]\ttraining's rmse: 3.94748\tvalid_1's rmse: 56.0222\n",
      "[1110]\ttraining's rmse: 3.7349\tvalid_1's rmse: 56.0107\n",
      "[1140]\ttraining's rmse: 3.54258\tvalid_1's rmse: 55.9942\n",
      "[1170]\ttraining's rmse: 3.35969\tvalid_1's rmse: 55.9796\n",
      "[1200]\ttraining's rmse: 3.18431\tvalid_1's rmse: 55.975\n",
      "[1230]\ttraining's rmse: 3.01849\tvalid_1's rmse: 55.9681\n",
      "[1260]\ttraining's rmse: 2.86467\tvalid_1's rmse: 55.9671\n",
      "[1290]\ttraining's rmse: 2.71609\tvalid_1's rmse: 55.9646\n",
      "[1320]\ttraining's rmse: 2.57623\tvalid_1's rmse: 55.9543\n",
      "[1350]\ttraining's rmse: 2.44635\tvalid_1's rmse: 55.9503\n",
      "[1380]\ttraining's rmse: 2.32418\tvalid_1's rmse: 55.9519\n",
      "[1410]\ttraining's rmse: 2.21131\tvalid_1's rmse: 55.9503\n",
      "[1440]\ttraining's rmse: 2.10089\tvalid_1's rmse: 55.9452\n",
      "[1470]\ttraining's rmse: 1.99596\tvalid_1's rmse: 55.9435\n",
      "[1500]\ttraining's rmse: 1.89777\tvalid_1's rmse: 55.9393\n",
      "[1530]\ttraining's rmse: 1.8048\tvalid_1's rmse: 55.9368\n",
      "[1560]\ttraining's rmse: 1.71925\tvalid_1's rmse: 55.9335\n",
      "[1590]\ttraining's rmse: 1.63724\tvalid_1's rmse: 55.9278\n",
      "[1620]\ttraining's rmse: 1.55831\tvalid_1's rmse: 55.926\n",
      "[1650]\ttraining's rmse: 1.48344\tvalid_1's rmse: 55.9259\n",
      "[1680]\ttraining's rmse: 1.41186\tvalid_1's rmse: 55.9228\n",
      "[1710]\ttraining's rmse: 1.34318\tvalid_1's rmse: 55.9209\n",
      "[1740]\ttraining's rmse: 1.28059\tvalid_1's rmse: 55.9185\n",
      "[1770]\ttraining's rmse: 1.22124\tvalid_1's rmse: 55.9173\n",
      "[1800]\ttraining's rmse: 1.16396\tvalid_1's rmse: 55.9176\n",
      "[1830]\ttraining's rmse: 1.1092\tvalid_1's rmse: 55.9177\n",
      "[1860]\ttraining's rmse: 1.05728\tvalid_1's rmse: 55.9151\n",
      "[1890]\ttraining's rmse: 1.00933\tvalid_1's rmse: 55.915\n",
      "[1920]\ttraining's rmse: 0.9618\tvalid_1's rmse: 55.9147\n",
      "[1950]\ttraining's rmse: 0.917011\tvalid_1's rmse: 55.9151\n",
      "[1980]\ttraining's rmse: 0.875207\tvalid_1's rmse: 55.9155\n",
      "Early stopping, best iteration is:\n",
      "[1872]\ttraining's rmse: 1.0376\tvalid_1's rmse: 55.9141\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003578 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 20024\n",
      "[LightGBM] [Info] Number of data points in the train set: 9219, number of used features: 79\n",
      "[LightGBM] [Info] Start training from score 355.004531\n",
      "Training until validation scores don't improve for 125 rounds\n",
      "[30]\ttraining's rmse: 154.917\tvalid_1's rmse: 157.282\n",
      "[60]\ttraining's rmse: 97.064\tvalid_1's rmse: 104.551\n",
      "[90]\ttraining's rmse: 65.9002\tvalid_1's rmse: 79.185\n",
      "[120]\ttraining's rmse: 48.9626\tvalid_1's rmse: 67.6326\n",
      "[150]\ttraining's rmse: 39.3445\tvalid_1's rmse: 62.4796\n",
      "[180]\ttraining's rmse: 33.5047\tvalid_1's rmse: 59.7353\n",
      "[210]\ttraining's rmse: 29.4322\tvalid_1's rmse: 58.2266\n",
      "[240]\ttraining's rmse: 26.287\tvalid_1's rmse: 57.2204\n",
      "[270]\ttraining's rmse: 23.7326\tvalid_1's rmse: 56.4851\n",
      "[300]\ttraining's rmse: 21.5627\tvalid_1's rmse: 55.9531\n",
      "[330]\ttraining's rmse: 19.7403\tvalid_1's rmse: 55.5427\n",
      "[360]\ttraining's rmse: 18.1692\tvalid_1's rmse: 55.2151\n",
      "[390]\ttraining's rmse: 16.7532\tvalid_1's rmse: 54.9738\n",
      "[420]\ttraining's rmse: 15.4782\tvalid_1's rmse: 54.837\n",
      "[450]\ttraining's rmse: 14.3468\tvalid_1's rmse: 54.7075\n",
      "[480]\ttraining's rmse: 13.3212\tvalid_1's rmse: 54.5959\n",
      "[510]\ttraining's rmse: 12.419\tvalid_1's rmse: 54.5032\n",
      "[540]\ttraining's rmse: 11.584\tvalid_1's rmse: 54.4178\n",
      "[570]\ttraining's rmse: 10.839\tvalid_1's rmse: 54.325\n",
      "[600]\ttraining's rmse: 10.1458\tvalid_1's rmse: 54.2633\n",
      "[630]\ttraining's rmse: 9.49539\tvalid_1's rmse: 54.209\n",
      "[660]\ttraining's rmse: 8.90315\tvalid_1's rmse: 54.1517\n",
      "[690]\ttraining's rmse: 8.3467\tvalid_1's rmse: 54.0949\n",
      "[720]\ttraining's rmse: 7.83627\tvalid_1's rmse: 54.0445\n",
      "[750]\ttraining's rmse: 7.36748\tvalid_1's rmse: 54.011\n",
      "[780]\ttraining's rmse: 6.9339\tvalid_1's rmse: 53.958\n",
      "[810]\ttraining's rmse: 6.53124\tvalid_1's rmse: 53.9189\n",
      "[840]\ttraining's rmse: 6.15256\tvalid_1's rmse: 53.8913\n",
      "[870]\ttraining's rmse: 5.79703\tvalid_1's rmse: 53.8819\n",
      "[900]\ttraining's rmse: 5.47116\tvalid_1's rmse: 53.8702\n",
      "[930]\ttraining's rmse: 5.17101\tvalid_1's rmse: 53.8442\n",
      "[960]\ttraining's rmse: 4.87978\tvalid_1's rmse: 53.8096\n",
      "[990]\ttraining's rmse: 4.6097\tvalid_1's rmse: 53.7932\n",
      "[1020]\ttraining's rmse: 4.35626\tvalid_1's rmse: 53.7771\n",
      "[1050]\ttraining's rmse: 4.12093\tvalid_1's rmse: 53.7669\n",
      "[1080]\ttraining's rmse: 3.89829\tvalid_1's rmse: 53.7589\n",
      "[1110]\ttraining's rmse: 3.69219\tvalid_1's rmse: 53.75\n",
      "[1140]\ttraining's rmse: 3.49648\tvalid_1's rmse: 53.7352\n",
      "[1170]\ttraining's rmse: 3.3114\tvalid_1's rmse: 53.7215\n",
      "[1200]\ttraining's rmse: 3.13643\tvalid_1's rmse: 53.7164\n",
      "[1230]\ttraining's rmse: 2.97081\tvalid_1's rmse: 53.7146\n",
      "[1260]\ttraining's rmse: 2.81409\tvalid_1's rmse: 53.7129\n",
      "[1290]\ttraining's rmse: 2.66793\tvalid_1's rmse: 53.6985\n",
      "[1320]\ttraining's rmse: 2.53004\tvalid_1's rmse: 53.6907\n",
      "[1350]\ttraining's rmse: 2.4022\tvalid_1's rmse: 53.6867\n",
      "[1380]\ttraining's rmse: 2.28299\tvalid_1's rmse: 53.6772\n",
      "[1410]\ttraining's rmse: 2.16879\tvalid_1's rmse: 53.6741\n",
      "[1440]\ttraining's rmse: 2.06029\tvalid_1's rmse: 53.6726\n",
      "[1470]\ttraining's rmse: 1.95764\tvalid_1's rmse: 53.6665\n",
      "[1500]\ttraining's rmse: 1.86071\tvalid_1's rmse: 53.6573\n",
      "[1530]\ttraining's rmse: 1.76559\tvalid_1's rmse: 53.6539\n",
      "[1560]\ttraining's rmse: 1.6795\tvalid_1's rmse: 53.6496\n",
      "[1590]\ttraining's rmse: 1.59575\tvalid_1's rmse: 53.6445\n",
      "[1620]\ttraining's rmse: 1.5185\tvalid_1's rmse: 53.6415\n",
      "[1650]\ttraining's rmse: 1.44568\tvalid_1's rmse: 53.6384\n",
      "[1680]\ttraining's rmse: 1.37599\tvalid_1's rmse: 53.6334\n",
      "[1710]\ttraining's rmse: 1.30846\tvalid_1's rmse: 53.634\n",
      "[1740]\ttraining's rmse: 1.24872\tvalid_1's rmse: 53.6318\n",
      "[1770]\ttraining's rmse: 1.18826\tvalid_1's rmse: 53.6274\n",
      "[1800]\ttraining's rmse: 1.1317\tvalid_1's rmse: 53.6258\n",
      "[1830]\ttraining's rmse: 1.07709\tvalid_1's rmse: 53.6242\n",
      "[1860]\ttraining's rmse: 1.02532\tvalid_1's rmse: 53.6229\n",
      "[1890]\ttraining's rmse: 0.976622\tvalid_1's rmse: 53.6202\n",
      "[1920]\ttraining's rmse: 0.93105\tvalid_1's rmse: 53.6186\n",
      "[1950]\ttraining's rmse: 0.88695\tvalid_1's rmse: 53.6181\n",
      "[1980]\ttraining's rmse: 0.845526\tvalid_1's rmse: 53.6166\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's rmse: 0.82044\tvalid_1's rmse: 53.6165\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002506 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 20024\n",
      "[LightGBM] [Info] Number of data points in the train set: 9219, number of used features: 79\n",
      "[LightGBM] [Info] Start training from score 356.933281\n",
      "Training until validation scores don't improve for 125 rounds\n",
      "[30]\ttraining's rmse: 155.096\tvalid_1's rmse: 157.624\n",
      "[60]\ttraining's rmse: 97.2146\tvalid_1's rmse: 106.617\n",
      "[90]\ttraining's rmse: 66.1199\tvalid_1's rmse: 81.3351\n",
      "[120]\ttraining's rmse: 49.2986\tvalid_1's rmse: 69.3714\n",
      "[150]\ttraining's rmse: 39.6595\tvalid_1's rmse: 63.4647\n",
      "[180]\ttraining's rmse: 33.7965\tvalid_1's rmse: 60.4345\n",
      "[210]\ttraining's rmse: 29.6935\tvalid_1's rmse: 58.6494\n",
      "[240]\ttraining's rmse: 26.5054\tvalid_1's rmse: 57.5684\n",
      "[270]\ttraining's rmse: 23.8839\tvalid_1's rmse: 56.8383\n",
      "[300]\ttraining's rmse: 21.7289\tvalid_1's rmse: 56.3511\n",
      "[330]\ttraining's rmse: 19.9019\tvalid_1's rmse: 55.9419\n",
      "[360]\ttraining's rmse: 18.3019\tvalid_1's rmse: 55.619\n",
      "[390]\ttraining's rmse: 16.8938\tvalid_1's rmse: 55.3946\n",
      "[420]\ttraining's rmse: 15.6358\tvalid_1's rmse: 55.1694\n",
      "[450]\ttraining's rmse: 14.5166\tvalid_1's rmse: 55.0139\n",
      "[480]\ttraining's rmse: 13.4636\tvalid_1's rmse: 54.8254\n",
      "[510]\ttraining's rmse: 12.5497\tvalid_1's rmse: 54.6984\n",
      "[540]\ttraining's rmse: 11.6897\tvalid_1's rmse: 54.6459\n",
      "[570]\ttraining's rmse: 10.9117\tvalid_1's rmse: 54.5677\n",
      "[600]\ttraining's rmse: 10.199\tvalid_1's rmse: 54.5056\n",
      "[630]\ttraining's rmse: 9.53968\tvalid_1's rmse: 54.4513\n",
      "[660]\ttraining's rmse: 8.93115\tvalid_1's rmse: 54.3995\n",
      "[690]\ttraining's rmse: 8.37796\tvalid_1's rmse: 54.3468\n",
      "[720]\ttraining's rmse: 7.86277\tvalid_1's rmse: 54.2961\n",
      "[750]\ttraining's rmse: 7.38862\tvalid_1's rmse: 54.2735\n",
      "[780]\ttraining's rmse: 6.96348\tvalid_1's rmse: 54.2358\n",
      "[810]\ttraining's rmse: 6.54584\tvalid_1's rmse: 54.2163\n",
      "[840]\ttraining's rmse: 6.16991\tvalid_1's rmse: 54.1995\n",
      "[870]\ttraining's rmse: 5.81211\tvalid_1's rmse: 54.1711\n",
      "[900]\ttraining's rmse: 5.4818\tvalid_1's rmse: 54.1702\n",
      "[930]\ttraining's rmse: 5.17466\tvalid_1's rmse: 54.1471\n",
      "[960]\ttraining's rmse: 4.88518\tvalid_1's rmse: 54.1271\n",
      "[990]\ttraining's rmse: 4.61283\tvalid_1's rmse: 54.1188\n",
      "[1020]\ttraining's rmse: 4.3627\tvalid_1's rmse: 54.1109\n",
      "[1050]\ttraining's rmse: 4.13013\tvalid_1's rmse: 54.1047\n",
      "[1080]\ttraining's rmse: 3.90433\tvalid_1's rmse: 54.0864\n",
      "[1110]\ttraining's rmse: 3.69264\tvalid_1's rmse: 54.0751\n",
      "[1140]\ttraining's rmse: 3.49353\tvalid_1's rmse: 54.0722\n",
      "[1170]\ttraining's rmse: 3.30623\tvalid_1's rmse: 54.0538\n",
      "[1200]\ttraining's rmse: 3.1335\tvalid_1's rmse: 54.0493\n",
      "[1230]\ttraining's rmse: 2.97169\tvalid_1's rmse: 54.0445\n",
      "[1260]\ttraining's rmse: 2.81592\tvalid_1's rmse: 54.0422\n",
      "[1290]\ttraining's rmse: 2.67349\tvalid_1's rmse: 54.035\n",
      "[1320]\ttraining's rmse: 2.53616\tvalid_1's rmse: 54.0271\n",
      "[1350]\ttraining's rmse: 2.40623\tvalid_1's rmse: 54.0218\n",
      "[1380]\ttraining's rmse: 2.28226\tvalid_1's rmse: 54.0195\n",
      "[1410]\ttraining's rmse: 2.16413\tvalid_1's rmse: 54.0167\n",
      "[1440]\ttraining's rmse: 2.05582\tvalid_1's rmse: 54.011\n",
      "[1470]\ttraining's rmse: 1.95222\tvalid_1's rmse: 54.01\n",
      "[1500]\ttraining's rmse: 1.85602\tvalid_1's rmse: 54.0072\n",
      "[1530]\ttraining's rmse: 1.76301\tvalid_1's rmse: 54.0058\n",
      "[1560]\ttraining's rmse: 1.67492\tvalid_1's rmse: 54.0029\n",
      "[1590]\ttraining's rmse: 1.58922\tvalid_1's rmse: 54.0001\n",
      "[1620]\ttraining's rmse: 1.51198\tvalid_1's rmse: 53.9973\n",
      "[1650]\ttraining's rmse: 1.43833\tvalid_1's rmse: 53.9967\n",
      "[1680]\ttraining's rmse: 1.36855\tvalid_1's rmse: 53.9931\n",
      "[1710]\ttraining's rmse: 1.30134\tvalid_1's rmse: 53.9914\n",
      "[1740]\ttraining's rmse: 1.23765\tvalid_1's rmse: 53.9905\n",
      "[1770]\ttraining's rmse: 1.17697\tvalid_1's rmse: 53.9889\n",
      "[1800]\ttraining's rmse: 1.12085\tvalid_1's rmse: 53.9872\n",
      "[1830]\ttraining's rmse: 1.06745\tvalid_1's rmse: 53.9868\n",
      "[1860]\ttraining's rmse: 1.017\tvalid_1's rmse: 53.9856\n",
      "[1890]\ttraining's rmse: 0.969364\tvalid_1's rmse: 53.9848\n",
      "[1920]\ttraining's rmse: 0.923868\tvalid_1's rmse: 53.9855\n",
      "[1950]\ttraining's rmse: 0.879416\tvalid_1's rmse: 53.9849\n",
      "[1980]\ttraining's rmse: 0.837161\tvalid_1's rmse: 53.9848\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's rmse: 0.810063\tvalid_1's rmse: 53.9834\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003656 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 20024\n",
      "[LightGBM] [Info] Number of data points in the train set: 9219, number of used features: 79\n",
      "[LightGBM] [Info] Start training from score 364.236337\n",
      "Training until validation scores don't improve for 125 rounds\n",
      "[30]\ttraining's rmse: 154.925\tvalid_1's rmse: 151.777\n",
      "[60]\ttraining's rmse: 97.0959\tvalid_1's rmse: 100.076\n",
      "[90]\ttraining's rmse: 65.9253\tvalid_1's rmse: 74.1251\n",
      "[120]\ttraining's rmse: 49.1056\tvalid_1's rmse: 61.6465\n",
      "[150]\ttraining's rmse: 39.4501\tvalid_1's rmse: 55.544\n",
      "[180]\ttraining's rmse: 33.4506\tvalid_1's rmse: 52.3883\n",
      "[210]\ttraining's rmse: 29.3842\tvalid_1's rmse: 50.4891\n",
      "[240]\ttraining's rmse: 26.188\tvalid_1's rmse: 49.3083\n",
      "[270]\ttraining's rmse: 23.5891\tvalid_1's rmse: 48.4322\n",
      "[300]\ttraining's rmse: 21.4572\tvalid_1's rmse: 47.8532\n",
      "[330]\ttraining's rmse: 19.6377\tvalid_1's rmse: 47.4965\n",
      "[360]\ttraining's rmse: 18.0608\tvalid_1's rmse: 47.2445\n",
      "[390]\ttraining's rmse: 16.6758\tvalid_1's rmse: 47.0075\n",
      "[420]\ttraining's rmse: 15.4147\tvalid_1's rmse: 46.8301\n",
      "[450]\ttraining's rmse: 14.2797\tvalid_1's rmse: 46.6714\n",
      "[480]\ttraining's rmse: 13.2598\tvalid_1's rmse: 46.5402\n",
      "[510]\ttraining's rmse: 12.35\tvalid_1's rmse: 46.4315\n",
      "[540]\ttraining's rmse: 11.5123\tvalid_1's rmse: 46.3288\n",
      "[570]\ttraining's rmse: 10.7559\tvalid_1's rmse: 46.2895\n",
      "[600]\ttraining's rmse: 10.0557\tvalid_1's rmse: 46.229\n",
      "[630]\ttraining's rmse: 9.41033\tvalid_1's rmse: 46.1585\n",
      "[660]\ttraining's rmse: 8.80927\tvalid_1's rmse: 46.1187\n",
      "[690]\ttraining's rmse: 8.2608\tvalid_1's rmse: 46.0863\n",
      "[720]\ttraining's rmse: 7.76282\tvalid_1's rmse: 46.051\n",
      "[750]\ttraining's rmse: 7.29377\tvalid_1's rmse: 45.9966\n",
      "[780]\ttraining's rmse: 6.86481\tvalid_1's rmse: 45.9764\n",
      "[810]\ttraining's rmse: 6.45265\tvalid_1's rmse: 45.9552\n",
      "[840]\ttraining's rmse: 6.08409\tvalid_1's rmse: 45.9394\n",
      "[870]\ttraining's rmse: 5.73476\tvalid_1's rmse: 45.9188\n",
      "[900]\ttraining's rmse: 5.40802\tvalid_1's rmse: 45.9126\n",
      "[930]\ttraining's rmse: 5.1075\tvalid_1's rmse: 45.8902\n",
      "[960]\ttraining's rmse: 4.81498\tvalid_1's rmse: 45.8767\n",
      "[990]\ttraining's rmse: 4.55325\tvalid_1's rmse: 45.8709\n",
      "[1020]\ttraining's rmse: 4.30626\tvalid_1's rmse: 45.8601\n",
      "[1050]\ttraining's rmse: 4.07393\tvalid_1's rmse: 45.8464\n",
      "[1080]\ttraining's rmse: 3.85403\tvalid_1's rmse: 45.8395\n",
      "[1110]\ttraining's rmse: 3.64999\tvalid_1's rmse: 45.8255\n",
      "[1140]\ttraining's rmse: 3.4532\tvalid_1's rmse: 45.821\n",
      "[1170]\ttraining's rmse: 3.27384\tvalid_1's rmse: 45.8102\n",
      "[1200]\ttraining's rmse: 3.10159\tvalid_1's rmse: 45.8023\n",
      "[1230]\ttraining's rmse: 2.93993\tvalid_1's rmse: 45.7963\n",
      "[1260]\ttraining's rmse: 2.79115\tvalid_1's rmse: 45.7846\n",
      "[1290]\ttraining's rmse: 2.64484\tvalid_1's rmse: 45.7827\n",
      "[1320]\ttraining's rmse: 2.50793\tvalid_1's rmse: 45.7774\n",
      "[1350]\ttraining's rmse: 2.37958\tvalid_1's rmse: 45.7683\n",
      "[1380]\ttraining's rmse: 2.26075\tvalid_1's rmse: 45.7648\n",
      "[1410]\ttraining's rmse: 2.1457\tvalid_1's rmse: 45.7561\n",
      "[1440]\ttraining's rmse: 2.03626\tvalid_1's rmse: 45.7535\n",
      "[1470]\ttraining's rmse: 1.93334\tvalid_1's rmse: 45.7516\n",
      "[1500]\ttraining's rmse: 1.83706\tvalid_1's rmse: 45.7505\n",
      "[1530]\ttraining's rmse: 1.74695\tvalid_1's rmse: 45.7494\n",
      "[1560]\ttraining's rmse: 1.66034\tvalid_1's rmse: 45.7449\n",
      "[1590]\ttraining's rmse: 1.57829\tvalid_1's rmse: 45.7408\n",
      "[1620]\ttraining's rmse: 1.50195\tvalid_1's rmse: 45.7384\n",
      "[1650]\ttraining's rmse: 1.42885\tvalid_1's rmse: 45.7347\n",
      "[1680]\ttraining's rmse: 1.35994\tvalid_1's rmse: 45.7328\n",
      "[1710]\ttraining's rmse: 1.29337\tvalid_1's rmse: 45.7339\n",
      "[1740]\ttraining's rmse: 1.23093\tvalid_1's rmse: 45.7297\n",
      "[1770]\ttraining's rmse: 1.17181\tvalid_1's rmse: 45.7263\n",
      "[1800]\ttraining's rmse: 1.11617\tvalid_1's rmse: 45.7227\n",
      "[1830]\ttraining's rmse: 1.06272\tvalid_1's rmse: 45.7218\n",
      "[1860]\ttraining's rmse: 1.01255\tvalid_1's rmse: 45.7218\n",
      "[1890]\ttraining's rmse: 0.964908\tvalid_1's rmse: 45.7201\n",
      "[1920]\ttraining's rmse: 0.918864\tvalid_1's rmse: 45.7188\n",
      "[1950]\ttraining's rmse: 0.87595\tvalid_1's rmse: 45.7175\n",
      "[1980]\ttraining's rmse: 0.83574\tvalid_1's rmse: 45.7167\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's rmse: 0.810301\tvalid_1's rmse: 45.7155\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003274 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 20024\n",
      "[LightGBM] [Info] Number of data points in the train set: 9219, number of used features: 79\n",
      "[LightGBM] [Info] Start training from score 364.555425\n",
      "Training until validation scores don't improve for 125 rounds\n",
      "[30]\ttraining's rmse: 154.365\tvalid_1's rmse: 154.72\n",
      "[60]\ttraining's rmse: 96.5686\tvalid_1's rmse: 104.775\n",
      "[90]\ttraining's rmse: 65.2385\tvalid_1's rmse: 79.896\n",
      "[120]\ttraining's rmse: 48.0101\tvalid_1's rmse: 68.1021\n",
      "[150]\ttraining's rmse: 38.5205\tvalid_1's rmse: 62.6119\n",
      "[180]\ttraining's rmse: 32.675\tvalid_1's rmse: 59.7921\n",
      "[210]\ttraining's rmse: 28.6496\tvalid_1's rmse: 58.3132\n",
      "[240]\ttraining's rmse: 25.6294\tvalid_1's rmse: 57.3709\n",
      "[270]\ttraining's rmse: 23.1499\tvalid_1's rmse: 56.6716\n",
      "[300]\ttraining's rmse: 21.0695\tvalid_1's rmse: 56.1743\n",
      "[330]\ttraining's rmse: 19.2969\tvalid_1's rmse: 55.8098\n",
      "[360]\ttraining's rmse: 17.7595\tvalid_1's rmse: 55.5799\n",
      "[390]\ttraining's rmse: 16.4447\tvalid_1's rmse: 55.3709\n",
      "[420]\ttraining's rmse: 15.2535\tvalid_1's rmse: 55.1783\n",
      "[450]\ttraining's rmse: 14.1664\tvalid_1's rmse: 55.0245\n",
      "[480]\ttraining's rmse: 13.1822\tvalid_1's rmse: 54.911\n",
      "[510]\ttraining's rmse: 12.2906\tvalid_1's rmse: 54.8216\n",
      "[540]\ttraining's rmse: 11.474\tvalid_1's rmse: 54.7524\n",
      "[570]\ttraining's rmse: 10.7203\tvalid_1's rmse: 54.6881\n",
      "[600]\ttraining's rmse: 10.0486\tvalid_1's rmse: 54.6099\n",
      "[630]\ttraining's rmse: 9.42639\tvalid_1's rmse: 54.5473\n",
      "[660]\ttraining's rmse: 8.85533\tvalid_1's rmse: 54.5013\n",
      "[690]\ttraining's rmse: 8.3082\tvalid_1's rmse: 54.4371\n",
      "[720]\ttraining's rmse: 7.80341\tvalid_1's rmse: 54.4218\n",
      "[750]\ttraining's rmse: 7.33401\tvalid_1's rmse: 54.3926\n",
      "[780]\ttraining's rmse: 6.89931\tvalid_1's rmse: 54.3857\n",
      "[810]\ttraining's rmse: 6.49284\tvalid_1's rmse: 54.3576\n",
      "[840]\ttraining's rmse: 6.1225\tvalid_1's rmse: 54.3273\n",
      "[870]\ttraining's rmse: 5.77677\tvalid_1's rmse: 54.3111\n",
      "[900]\ttraining's rmse: 5.44164\tvalid_1's rmse: 54.2921\n",
      "[930]\ttraining's rmse: 5.14133\tvalid_1's rmse: 54.2771\n",
      "[960]\ttraining's rmse: 4.85615\tvalid_1's rmse: 54.2662\n",
      "[990]\ttraining's rmse: 4.58523\tvalid_1's rmse: 54.2465\n",
      "[1020]\ttraining's rmse: 4.33925\tvalid_1's rmse: 54.235\n",
      "[1050]\ttraining's rmse: 4.10846\tvalid_1's rmse: 54.228\n",
      "[1080]\ttraining's rmse: 3.88527\tvalid_1's rmse: 54.2063\n",
      "[1110]\ttraining's rmse: 3.67662\tvalid_1's rmse: 54.1984\n",
      "[1140]\ttraining's rmse: 3.48009\tvalid_1's rmse: 54.1902\n",
      "[1170]\ttraining's rmse: 3.29912\tvalid_1's rmse: 54.1837\n",
      "[1200]\ttraining's rmse: 3.12605\tvalid_1's rmse: 54.1807\n",
      "[1230]\ttraining's rmse: 2.9644\tvalid_1's rmse: 54.1741\n",
      "[1260]\ttraining's rmse: 2.80994\tvalid_1's rmse: 54.1627\n",
      "[1290]\ttraining's rmse: 2.66704\tvalid_1's rmse: 54.1617\n",
      "[1320]\ttraining's rmse: 2.52635\tvalid_1's rmse: 54.1605\n",
      "[1350]\ttraining's rmse: 2.39578\tvalid_1's rmse: 54.1577\n",
      "[1380]\ttraining's rmse: 2.27096\tvalid_1's rmse: 54.1561\n",
      "[1410]\ttraining's rmse: 2.15288\tvalid_1's rmse: 54.1539\n",
      "[1440]\ttraining's rmse: 2.04224\tvalid_1's rmse: 54.1464\n",
      "[1470]\ttraining's rmse: 1.94216\tvalid_1's rmse: 54.146\n",
      "[1500]\ttraining's rmse: 1.84498\tvalid_1's rmse: 54.1429\n",
      "[1530]\ttraining's rmse: 1.7535\tvalid_1's rmse: 54.1421\n",
      "[1560]\ttraining's rmse: 1.66645\tvalid_1's rmse: 54.1419\n",
      "[1590]\ttraining's rmse: 1.58162\tvalid_1's rmse: 54.1415\n",
      "[1620]\ttraining's rmse: 1.50499\tvalid_1's rmse: 54.1407\n",
      "[1650]\ttraining's rmse: 1.4315\tvalid_1's rmse: 54.1393\n",
      "[1680]\ttraining's rmse: 1.36272\tvalid_1's rmse: 54.1382\n",
      "[1710]\ttraining's rmse: 1.29684\tvalid_1's rmse: 54.1388\n",
      "[1740]\ttraining's rmse: 1.23543\tvalid_1's rmse: 54.1378\n",
      "[1770]\ttraining's rmse: 1.17631\tvalid_1's rmse: 54.1339\n",
      "[1800]\ttraining's rmse: 1.1199\tvalid_1's rmse: 54.1322\n",
      "[1830]\ttraining's rmse: 1.06496\tvalid_1's rmse: 54.1328\n",
      "[1860]\ttraining's rmse: 1.01371\tvalid_1's rmse: 54.1312\n",
      "[1890]\ttraining's rmse: 0.966915\tvalid_1's rmse: 54.1296\n",
      "[1920]\ttraining's rmse: 0.920391\tvalid_1's rmse: 54.128\n",
      "[1950]\ttraining's rmse: 0.877972\tvalid_1's rmse: 54.1264\n",
      "[1980]\ttraining's rmse: 0.836711\tvalid_1's rmse: 54.1285\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's rmse: 0.809908\tvalid_1's rmse: 54.1267\n",
      "23\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003643 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 20024\n",
      "[LightGBM] [Info] Number of data points in the train set: 9219, number of used features: 79\n",
      "[LightGBM] [Info] Start training from score 365.545418\n",
      "Training until validation scores don't improve for 125 rounds\n",
      "[30]\ttraining's rmse: 154.237\tvalid_1's rmse: 154.457\n",
      "[60]\ttraining's rmse: 95.4891\tvalid_1's rmse: 102.783\n",
      "[90]\ttraining's rmse: 63.8678\tvalid_1's rmse: 78.0272\n",
      "[120]\ttraining's rmse: 46.7881\tvalid_1's rmse: 66.7435\n",
      "[150]\ttraining's rmse: 37.3011\tvalid_1's rmse: 61.6208\n",
      "[180]\ttraining's rmse: 31.5392\tvalid_1's rmse: 58.9018\n",
      "[210]\ttraining's rmse: 27.6858\tvalid_1's rmse: 57.425\n",
      "[240]\ttraining's rmse: 24.6904\tvalid_1's rmse: 56.3724\n",
      "[270]\ttraining's rmse: 22.2174\tvalid_1's rmse: 55.5972\n",
      "[300]\ttraining's rmse: 20.2026\tvalid_1's rmse: 55.0693\n",
      "[330]\ttraining's rmse: 18.496\tvalid_1's rmse: 54.6041\n",
      "[360]\ttraining's rmse: 16.9995\tvalid_1's rmse: 54.3072\n",
      "[390]\ttraining's rmse: 15.6765\tvalid_1's rmse: 54.012\n",
      "[420]\ttraining's rmse: 14.5298\tvalid_1's rmse: 53.8735\n",
      "[450]\ttraining's rmse: 13.5025\tvalid_1's rmse: 53.7395\n",
      "[480]\ttraining's rmse: 12.5574\tvalid_1's rmse: 53.6331\n",
      "[510]\ttraining's rmse: 11.6951\tvalid_1's rmse: 53.5459\n",
      "[540]\ttraining's rmse: 10.9284\tvalid_1's rmse: 53.4896\n",
      "[570]\ttraining's rmse: 10.2331\tvalid_1's rmse: 53.3994\n",
      "[600]\ttraining's rmse: 9.57662\tvalid_1's rmse: 53.3587\n",
      "[630]\ttraining's rmse: 8.98147\tvalid_1's rmse: 53.3173\n",
      "[660]\ttraining's rmse: 8.4093\tvalid_1's rmse: 53.2777\n",
      "[690]\ttraining's rmse: 7.89572\tvalid_1's rmse: 53.2407\n",
      "[720]\ttraining's rmse: 7.41869\tvalid_1's rmse: 53.1883\n",
      "[750]\ttraining's rmse: 6.96635\tvalid_1's rmse: 53.1573\n",
      "[780]\ttraining's rmse: 6.55892\tvalid_1's rmse: 53.1454\n",
      "[810]\ttraining's rmse: 6.18071\tvalid_1's rmse: 53.1297\n",
      "[840]\ttraining's rmse: 5.83035\tvalid_1's rmse: 53.1136\n",
      "[870]\ttraining's rmse: 5.49352\tvalid_1's rmse: 53.0993\n",
      "[900]\ttraining's rmse: 5.19213\tvalid_1's rmse: 53.0766\n",
      "[930]\ttraining's rmse: 4.90537\tvalid_1's rmse: 53.0604\n",
      "[960]\ttraining's rmse: 4.62844\tvalid_1's rmse: 53.0434\n",
      "[990]\ttraining's rmse: 4.37593\tvalid_1's rmse: 53.0183\n",
      "[1020]\ttraining's rmse: 4.14184\tvalid_1's rmse: 53.0034\n",
      "[1050]\ttraining's rmse: 3.92061\tvalid_1's rmse: 52.987\n",
      "[1080]\ttraining's rmse: 3.70466\tvalid_1's rmse: 52.9815\n",
      "[1110]\ttraining's rmse: 3.51164\tvalid_1's rmse: 52.9794\n",
      "[1140]\ttraining's rmse: 3.32382\tvalid_1's rmse: 52.9783\n",
      "[1170]\ttraining's rmse: 3.14869\tvalid_1's rmse: 52.9749\n",
      "[1200]\ttraining's rmse: 2.98585\tvalid_1's rmse: 52.9644\n",
      "[1230]\ttraining's rmse: 2.83145\tvalid_1's rmse: 52.9646\n",
      "[1260]\ttraining's rmse: 2.68797\tvalid_1's rmse: 52.9526\n",
      "[1290]\ttraining's rmse: 2.55183\tvalid_1's rmse: 52.9473\n",
      "[1320]\ttraining's rmse: 2.4223\tvalid_1's rmse: 52.9414\n",
      "[1350]\ttraining's rmse: 2.29963\tvalid_1's rmse: 52.9351\n",
      "[1380]\ttraining's rmse: 2.18372\tvalid_1's rmse: 52.9314\n",
      "[1410]\ttraining's rmse: 2.07475\tvalid_1's rmse: 52.9296\n",
      "[1440]\ttraining's rmse: 1.96873\tvalid_1's rmse: 52.9298\n",
      "[1470]\ttraining's rmse: 1.87038\tvalid_1's rmse: 52.9266\n",
      "[1500]\ttraining's rmse: 1.77723\tvalid_1's rmse: 52.924\n",
      "[1530]\ttraining's rmse: 1.68861\tvalid_1's rmse: 52.9245\n",
      "[1560]\ttraining's rmse: 1.60408\tvalid_1's rmse: 52.9222\n",
      "[1590]\ttraining's rmse: 1.52581\tvalid_1's rmse: 52.9213\n",
      "[1620]\ttraining's rmse: 1.45077\tvalid_1's rmse: 52.9187\n",
      "[1650]\ttraining's rmse: 1.38037\tvalid_1's rmse: 52.9195\n",
      "[1680]\ttraining's rmse: 1.31313\tvalid_1's rmse: 52.9171\n",
      "[1710]\ttraining's rmse: 1.24905\tvalid_1's rmse: 52.9163\n",
      "[1740]\ttraining's rmse: 1.19094\tvalid_1's rmse: 52.9171\n",
      "[1770]\ttraining's rmse: 1.13405\tvalid_1's rmse: 52.9165\n",
      "[1800]\ttraining's rmse: 1.08149\tvalid_1's rmse: 52.9149\n",
      "[1830]\ttraining's rmse: 1.0315\tvalid_1's rmse: 52.9151\n",
      "[1860]\ttraining's rmse: 0.983493\tvalid_1's rmse: 52.9123\n",
      "[1890]\ttraining's rmse: 0.938017\tvalid_1's rmse: 52.9103\n",
      "[1920]\ttraining's rmse: 0.894862\tvalid_1's rmse: 52.9104\n",
      "[1950]\ttraining's rmse: 0.853544\tvalid_1's rmse: 52.9104\n",
      "[1980]\ttraining's rmse: 0.813613\tvalid_1's rmse: 52.9114\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's rmse: 0.788573\tvalid_1's rmse: 52.9101\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002449 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 20024\n",
      "[LightGBM] [Info] Number of data points in the train set: 9219, number of used features: 79\n",
      "[LightGBM] [Info] Start training from score 365.785320\n",
      "Training until validation scores don't improve for 125 rounds\n",
      "[30]\ttraining's rmse: 154.743\tvalid_1's rmse: 156.24\n",
      "[60]\ttraining's rmse: 96.5336\tvalid_1's rmse: 105.425\n",
      "[90]\ttraining's rmse: 65.3702\tvalid_1's rmse: 81.053\n",
      "[120]\ttraining's rmse: 48.4436\tvalid_1's rmse: 69.6985\n",
      "[150]\ttraining's rmse: 39.0007\tvalid_1's rmse: 64.0292\n",
      "[180]\ttraining's rmse: 33.1604\tvalid_1's rmse: 61.0421\n",
      "[210]\ttraining's rmse: 29.0996\tvalid_1's rmse: 59.3196\n",
      "[240]\ttraining's rmse: 25.9148\tvalid_1's rmse: 58.2341\n",
      "[270]\ttraining's rmse: 23.355\tvalid_1's rmse: 57.5008\n",
      "[300]\ttraining's rmse: 21.2141\tvalid_1's rmse: 56.9543\n",
      "[330]\ttraining's rmse: 19.3813\tvalid_1's rmse: 56.5745\n",
      "[360]\ttraining's rmse: 17.7851\tvalid_1's rmse: 56.3355\n",
      "[390]\ttraining's rmse: 16.4278\tvalid_1's rmse: 56.1337\n",
      "[420]\ttraining's rmse: 15.197\tvalid_1's rmse: 55.9434\n",
      "[450]\ttraining's rmse: 14.1028\tvalid_1's rmse: 55.8086\n",
      "[480]\ttraining's rmse: 13.1137\tvalid_1's rmse: 55.7316\n",
      "[510]\ttraining's rmse: 12.2223\tvalid_1's rmse: 55.6486\n",
      "[540]\ttraining's rmse: 11.4056\tvalid_1's rmse: 55.5504\n",
      "[570]\ttraining's rmse: 10.6572\tvalid_1's rmse: 55.475\n",
      "[600]\ttraining's rmse: 9.97099\tvalid_1's rmse: 55.4168\n",
      "[630]\ttraining's rmse: 9.34376\tvalid_1's rmse: 55.3733\n",
      "[660]\ttraining's rmse: 8.76239\tvalid_1's rmse: 55.3333\n",
      "[690]\ttraining's rmse: 8.22748\tvalid_1's rmse: 55.3075\n",
      "[720]\ttraining's rmse: 7.73412\tvalid_1's rmse: 55.2641\n",
      "[750]\ttraining's rmse: 7.27949\tvalid_1's rmse: 55.2482\n",
      "[780]\ttraining's rmse: 6.84776\tvalid_1's rmse: 55.2345\n",
      "[810]\ttraining's rmse: 6.44454\tvalid_1's rmse: 55.2368\n",
      "[840]\ttraining's rmse: 6.08451\tvalid_1's rmse: 55.2208\n",
      "[870]\ttraining's rmse: 5.73816\tvalid_1's rmse: 55.2091\n",
      "[900]\ttraining's rmse: 5.42008\tvalid_1's rmse: 55.1904\n",
      "[930]\ttraining's rmse: 5.11505\tvalid_1's rmse: 55.17\n",
      "[960]\ttraining's rmse: 4.83556\tvalid_1's rmse: 55.1598\n",
      "[990]\ttraining's rmse: 4.56936\tvalid_1's rmse: 55.1525\n",
      "[1020]\ttraining's rmse: 4.31773\tvalid_1's rmse: 55.1508\n",
      "[1050]\ttraining's rmse: 4.08321\tvalid_1's rmse: 55.1393\n",
      "[1080]\ttraining's rmse: 3.86547\tvalid_1's rmse: 55.1272\n",
      "[1110]\ttraining's rmse: 3.65724\tvalid_1's rmse: 55.124\n",
      "[1140]\ttraining's rmse: 3.46136\tvalid_1's rmse: 55.1149\n",
      "[1170]\ttraining's rmse: 3.27826\tvalid_1's rmse: 55.106\n",
      "[1200]\ttraining's rmse: 3.10823\tvalid_1's rmse: 55.1022\n",
      "[1230]\ttraining's rmse: 2.94746\tvalid_1's rmse: 55.097\n",
      "[1260]\ttraining's rmse: 2.79696\tvalid_1's rmse: 55.0941\n",
      "[1290]\ttraining's rmse: 2.6535\tvalid_1's rmse: 55.0899\n",
      "[1320]\ttraining's rmse: 2.51996\tvalid_1's rmse: 55.0861\n",
      "[1350]\ttraining's rmse: 2.39211\tvalid_1's rmse: 55.0856\n",
      "[1380]\ttraining's rmse: 2.27231\tvalid_1's rmse: 55.0821\n",
      "[1410]\ttraining's rmse: 2.15658\tvalid_1's rmse: 55.0782\n",
      "[1440]\ttraining's rmse: 2.04868\tvalid_1's rmse: 55.0782\n",
      "[1470]\ttraining's rmse: 1.94712\tvalid_1's rmse: 55.0742\n",
      "[1500]\ttraining's rmse: 1.84983\tvalid_1's rmse: 55.0708\n",
      "[1530]\ttraining's rmse: 1.75913\tvalid_1's rmse: 55.0691\n",
      "[1560]\ttraining's rmse: 1.67136\tvalid_1's rmse: 55.0668\n",
      "[1590]\ttraining's rmse: 1.58876\tvalid_1's rmse: 55.0643\n",
      "[1620]\ttraining's rmse: 1.51168\tvalid_1's rmse: 55.0616\n",
      "[1650]\ttraining's rmse: 1.43635\tvalid_1's rmse: 55.0614\n",
      "[1680]\ttraining's rmse: 1.3664\tvalid_1's rmse: 55.0609\n",
      "[1710]\ttraining's rmse: 1.30001\tvalid_1's rmse: 55.0572\n",
      "[1740]\ttraining's rmse: 1.23738\tvalid_1's rmse: 55.0551\n",
      "[1770]\ttraining's rmse: 1.17705\tvalid_1's rmse: 55.0567\n",
      "[1800]\ttraining's rmse: 1.12063\tvalid_1's rmse: 55.0561\n",
      "[1830]\ttraining's rmse: 1.06755\tvalid_1's rmse: 55.0557\n",
      "[1860]\ttraining's rmse: 1.01676\tvalid_1's rmse: 55.0543\n",
      "[1890]\ttraining's rmse: 0.968119\tvalid_1's rmse: 55.0538\n",
      "[1920]\ttraining's rmse: 0.922424\tvalid_1's rmse: 55.0526\n",
      "[1950]\ttraining's rmse: 0.878463\tvalid_1's rmse: 55.0508\n",
      "[1980]\ttraining's rmse: 0.836811\tvalid_1's rmse: 55.0513\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's rmse: 0.811443\tvalid_1's rmse: 55.0513\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003275 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 20024\n",
      "[LightGBM] [Info] Number of data points in the train set: 9219, number of used features: 79\n",
      "[LightGBM] [Info] Start training from score 360.971773\n",
      "Training until validation scores don't improve for 125 rounds\n",
      "[30]\ttraining's rmse: 155.82\tvalid_1's rmse: 161.388\n",
      "[60]\ttraining's rmse: 97.6278\tvalid_1's rmse: 108.162\n",
      "[90]\ttraining's rmse: 65.9478\tvalid_1's rmse: 80.9572\n",
      "[120]\ttraining's rmse: 48.882\tvalid_1's rmse: 67.9933\n",
      "[150]\ttraining's rmse: 39.3458\tvalid_1's rmse: 61.8243\n",
      "[180]\ttraining's rmse: 33.4696\tvalid_1's rmse: 58.5555\n",
      "[210]\ttraining's rmse: 29.4469\tvalid_1's rmse: 56.6635\n",
      "[240]\ttraining's rmse: 26.301\tvalid_1's rmse: 55.351\n",
      "[270]\ttraining's rmse: 23.7044\tvalid_1's rmse: 54.471\n",
      "[300]\ttraining's rmse: 21.5216\tvalid_1's rmse: 53.8308\n",
      "[330]\ttraining's rmse: 19.6786\tvalid_1's rmse: 53.3652\n",
      "[360]\ttraining's rmse: 18.0606\tvalid_1's rmse: 53.0654\n",
      "[390]\ttraining's rmse: 16.6386\tvalid_1's rmse: 52.7855\n",
      "[420]\ttraining's rmse: 15.3925\tvalid_1's rmse: 52.5981\n",
      "[450]\ttraining's rmse: 14.2631\tvalid_1's rmse: 52.399\n",
      "[480]\ttraining's rmse: 13.2419\tvalid_1's rmse: 52.2758\n",
      "[510]\ttraining's rmse: 12.3328\tvalid_1's rmse: 52.1282\n",
      "[540]\ttraining's rmse: 11.5014\tvalid_1's rmse: 52.0084\n",
      "[570]\ttraining's rmse: 10.7323\tvalid_1's rmse: 51.9293\n",
      "[600]\ttraining's rmse: 10.0655\tvalid_1's rmse: 51.8656\n",
      "[630]\ttraining's rmse: 9.41376\tvalid_1's rmse: 51.8043\n",
      "[660]\ttraining's rmse: 8.82718\tvalid_1's rmse: 51.7352\n",
      "[690]\ttraining's rmse: 8.2741\tvalid_1's rmse: 51.6932\n",
      "[720]\ttraining's rmse: 7.76914\tvalid_1's rmse: 51.6499\n",
      "[750]\ttraining's rmse: 7.29186\tvalid_1's rmse: 51.6133\n",
      "[780]\ttraining's rmse: 6.8604\tvalid_1's rmse: 51.5878\n",
      "[810]\ttraining's rmse: 6.4485\tvalid_1's rmse: 51.546\n",
      "[840]\ttraining's rmse: 6.06961\tvalid_1's rmse: 51.5189\n",
      "[870]\ttraining's rmse: 5.72473\tvalid_1's rmse: 51.4894\n",
      "[900]\ttraining's rmse: 5.39045\tvalid_1's rmse: 51.4599\n",
      "[930]\ttraining's rmse: 5.08977\tvalid_1's rmse: 51.4441\n",
      "[960]\ttraining's rmse: 4.80743\tvalid_1's rmse: 51.4236\n",
      "[990]\ttraining's rmse: 4.54184\tvalid_1's rmse: 51.3982\n",
      "[1020]\ttraining's rmse: 4.2977\tvalid_1's rmse: 51.3886\n",
      "[1050]\ttraining's rmse: 4.06515\tvalid_1's rmse: 51.3726\n",
      "[1080]\ttraining's rmse: 3.84262\tvalid_1's rmse: 51.3631\n",
      "[1110]\ttraining's rmse: 3.63656\tvalid_1's rmse: 51.3552\n",
      "[1140]\ttraining's rmse: 3.44811\tvalid_1's rmse: 51.3463\n",
      "[1170]\ttraining's rmse: 3.26485\tvalid_1's rmse: 51.3349\n",
      "[1200]\ttraining's rmse: 3.09155\tvalid_1's rmse: 51.3265\n",
      "[1230]\ttraining's rmse: 2.93095\tvalid_1's rmse: 51.327\n",
      "[1260]\ttraining's rmse: 2.78116\tvalid_1's rmse: 51.3142\n",
      "[1290]\ttraining's rmse: 2.6358\tvalid_1's rmse: 51.3091\n",
      "[1320]\ttraining's rmse: 2.49959\tvalid_1's rmse: 51.3021\n",
      "[1350]\ttraining's rmse: 2.36685\tvalid_1's rmse: 51.2965\n",
      "[1380]\ttraining's rmse: 2.24663\tvalid_1's rmse: 51.2968\n",
      "[1410]\ttraining's rmse: 2.13296\tvalid_1's rmse: 51.2937\n",
      "[1440]\ttraining's rmse: 2.02465\tvalid_1's rmse: 51.2904\n",
      "[1470]\ttraining's rmse: 1.92194\tvalid_1's rmse: 51.2872\n",
      "[1500]\ttraining's rmse: 1.82553\tvalid_1's rmse: 51.2828\n",
      "[1530]\ttraining's rmse: 1.73475\tvalid_1's rmse: 51.2798\n",
      "[1560]\ttraining's rmse: 1.64856\tvalid_1's rmse: 51.276\n",
      "[1590]\ttraining's rmse: 1.56879\tvalid_1's rmse: 51.2723\n",
      "[1620]\ttraining's rmse: 1.49112\tvalid_1's rmse: 51.2698\n",
      "[1650]\ttraining's rmse: 1.41736\tvalid_1's rmse: 51.2653\n",
      "[1680]\ttraining's rmse: 1.34619\tvalid_1's rmse: 51.2631\n",
      "[1710]\ttraining's rmse: 1.28075\tvalid_1's rmse: 51.2607\n",
      "[1740]\ttraining's rmse: 1.21939\tvalid_1's rmse: 51.2579\n",
      "[1770]\ttraining's rmse: 1.16116\tvalid_1's rmse: 51.2567\n",
      "[1800]\ttraining's rmse: 1.10637\tvalid_1's rmse: 51.2548\n",
      "[1830]\ttraining's rmse: 1.05321\tvalid_1's rmse: 51.2527\n",
      "[1860]\ttraining's rmse: 1.00256\tvalid_1's rmse: 51.2518\n",
      "[1890]\ttraining's rmse: 0.953702\tvalid_1's rmse: 51.2515\n",
      "[1920]\ttraining's rmse: 0.90809\tvalid_1's rmse: 51.2501\n",
      "[1950]\ttraining's rmse: 0.86508\tvalid_1's rmse: 51.2499\n",
      "[1980]\ttraining's rmse: 0.823815\tvalid_1's rmse: 51.2488\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's rmse: 0.797855\tvalid_1's rmse: 51.2484\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003264 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 20024\n",
      "[LightGBM] [Info] Number of data points in the train set: 9219, number of used features: 79\n",
      "[LightGBM] [Info] Start training from score 359.814089\n",
      "Training until validation scores don't improve for 125 rounds\n",
      "[30]\ttraining's rmse: 156.444\tvalid_1's rmse: 160.708\n",
      "[60]\ttraining's rmse: 98.0405\tvalid_1's rmse: 107.172\n",
      "[90]\ttraining's rmse: 66.4881\tvalid_1's rmse: 80.5111\n",
      "[120]\ttraining's rmse: 49.4224\tvalid_1's rmse: 67.549\n",
      "[150]\ttraining's rmse: 39.7272\tvalid_1's rmse: 61.3064\n",
      "[180]\ttraining's rmse: 33.7403\tvalid_1's rmse: 58.0608\n",
      "[210]\ttraining's rmse: 29.5681\tvalid_1's rmse: 56.1006\n",
      "[240]\ttraining's rmse: 26.3257\tvalid_1's rmse: 54.8688\n",
      "[270]\ttraining's rmse: 23.7529\tvalid_1's rmse: 54.0387\n",
      "[300]\ttraining's rmse: 21.6055\tvalid_1's rmse: 53.4473\n",
      "[330]\ttraining's rmse: 19.7609\tvalid_1's rmse: 53.0646\n",
      "[360]\ttraining's rmse: 18.1702\tvalid_1's rmse: 52.7505\n",
      "[390]\ttraining's rmse: 16.7412\tvalid_1's rmse: 52.5059\n",
      "[420]\ttraining's rmse: 15.4672\tvalid_1's rmse: 52.2852\n",
      "[450]\ttraining's rmse: 14.3515\tvalid_1's rmse: 52.1136\n",
      "[480]\ttraining's rmse: 13.3165\tvalid_1's rmse: 51.9534\n",
      "[510]\ttraining's rmse: 12.4206\tvalid_1's rmse: 51.8218\n",
      "[540]\ttraining's rmse: 11.5658\tvalid_1's rmse: 51.705\n",
      "[570]\ttraining's rmse: 10.818\tvalid_1's rmse: 51.6218\n",
      "[600]\ttraining's rmse: 10.1262\tvalid_1's rmse: 51.5539\n",
      "[630]\ttraining's rmse: 9.48359\tvalid_1's rmse: 51.51\n",
      "[660]\ttraining's rmse: 8.88889\tvalid_1's rmse: 51.4619\n",
      "[690]\ttraining's rmse: 8.33724\tvalid_1's rmse: 51.4134\n",
      "[720]\ttraining's rmse: 7.82202\tvalid_1's rmse: 51.3553\n",
      "[750]\ttraining's rmse: 7.36015\tvalid_1's rmse: 51.3259\n",
      "[780]\ttraining's rmse: 6.91647\tvalid_1's rmse: 51.2988\n",
      "[810]\ttraining's rmse: 6.52009\tvalid_1's rmse: 51.2732\n",
      "[840]\ttraining's rmse: 6.14626\tvalid_1's rmse: 51.2664\n",
      "[870]\ttraining's rmse: 5.80063\tvalid_1's rmse: 51.2407\n",
      "[900]\ttraining's rmse: 5.46687\tvalid_1's rmse: 51.2173\n",
      "[930]\ttraining's rmse: 5.16078\tvalid_1's rmse: 51.2013\n",
      "[960]\ttraining's rmse: 4.86796\tvalid_1's rmse: 51.1801\n",
      "[990]\ttraining's rmse: 4.60508\tvalid_1's rmse: 51.1561\n",
      "[1020]\ttraining's rmse: 4.35751\tvalid_1's rmse: 51.1433\n",
      "[1050]\ttraining's rmse: 4.11989\tvalid_1's rmse: 51.1306\n",
      "[1080]\ttraining's rmse: 3.89579\tvalid_1's rmse: 51.1204\n",
      "[1110]\ttraining's rmse: 3.68437\tvalid_1's rmse: 51.1083\n",
      "[1140]\ttraining's rmse: 3.49067\tvalid_1's rmse: 51.0924\n",
      "[1170]\ttraining's rmse: 3.3063\tvalid_1's rmse: 51.0807\n",
      "[1200]\ttraining's rmse: 3.13642\tvalid_1's rmse: 51.0801\n",
      "[1230]\ttraining's rmse: 2.97447\tvalid_1's rmse: 51.0659\n",
      "[1260]\ttraining's rmse: 2.82288\tvalid_1's rmse: 51.0587\n",
      "[1290]\ttraining's rmse: 2.67973\tvalid_1's rmse: 51.0509\n",
      "[1320]\ttraining's rmse: 2.54556\tvalid_1's rmse: 51.0472\n",
      "[1350]\ttraining's rmse: 2.41764\tvalid_1's rmse: 51.0383\n",
      "[1380]\ttraining's rmse: 2.29501\tvalid_1's rmse: 51.0304\n",
      "[1410]\ttraining's rmse: 2.17718\tvalid_1's rmse: 51.0229\n",
      "[1440]\ttraining's rmse: 2.06745\tvalid_1's rmse: 51.019\n",
      "[1470]\ttraining's rmse: 1.96625\tvalid_1's rmse: 51.0167\n",
      "[1500]\ttraining's rmse: 1.86993\tvalid_1's rmse: 51.0124\n",
      "[1530]\ttraining's rmse: 1.77803\tvalid_1's rmse: 51.0087\n",
      "[1560]\ttraining's rmse: 1.68932\tvalid_1's rmse: 51.0051\n",
      "[1590]\ttraining's rmse: 1.60506\tvalid_1's rmse: 51.0018\n",
      "[1620]\ttraining's rmse: 1.52677\tvalid_1's rmse: 51.0009\n",
      "[1650]\ttraining's rmse: 1.45422\tvalid_1's rmse: 50.9998\n",
      "[1680]\ttraining's rmse: 1.38473\tvalid_1's rmse: 51.0005\n",
      "[1710]\ttraining's rmse: 1.31745\tvalid_1's rmse: 50.9964\n",
      "[1740]\ttraining's rmse: 1.25421\tvalid_1's rmse: 50.9913\n",
      "[1770]\ttraining's rmse: 1.19522\tvalid_1's rmse: 50.9887\n",
      "[1800]\ttraining's rmse: 1.14023\tvalid_1's rmse: 50.986\n",
      "[1830]\ttraining's rmse: 1.08529\tvalid_1's rmse: 50.9866\n",
      "[1860]\ttraining's rmse: 1.03397\tvalid_1's rmse: 50.986\n",
      "[1890]\ttraining's rmse: 0.987366\tvalid_1's rmse: 50.985\n",
      "[1920]\ttraining's rmse: 0.942344\tvalid_1's rmse: 50.9829\n",
      "[1950]\ttraining's rmse: 0.897405\tvalid_1's rmse: 50.9811\n",
      "[1980]\ttraining's rmse: 0.854368\tvalid_1's rmse: 50.979\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's rmse: 0.827332\tvalid_1's rmse: 50.9769\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003417 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 20024\n",
      "[LightGBM] [Info] Number of data points in the train set: 9219, number of used features: 79\n",
      "[LightGBM] [Info] Start training from score 358.769873\n",
      "Training until validation scores don't improve for 125 rounds\n",
      "[30]\ttraining's rmse: 155.305\tvalid_1's rmse: 160.882\n",
      "[60]\ttraining's rmse: 97.0731\tvalid_1's rmse: 108.714\n",
      "[90]\ttraining's rmse: 65.6701\tvalid_1's rmse: 82.9466\n",
      "[120]\ttraining's rmse: 48.8126\tvalid_1's rmse: 70.7002\n",
      "[150]\ttraining's rmse: 39.3992\tvalid_1's rmse: 64.7045\n",
      "[180]\ttraining's rmse: 33.6557\tvalid_1's rmse: 61.6754\n",
      "[210]\ttraining's rmse: 29.6874\tvalid_1's rmse: 59.7622\n",
      "[240]\ttraining's rmse: 26.5408\tvalid_1's rmse: 58.5266\n",
      "[270]\ttraining's rmse: 23.9793\tvalid_1's rmse: 57.7044\n",
      "[300]\ttraining's rmse: 21.835\tvalid_1's rmse: 57.1283\n",
      "[330]\ttraining's rmse: 19.9852\tvalid_1's rmse: 56.7253\n",
      "[360]\ttraining's rmse: 18.3605\tvalid_1's rmse: 56.413\n",
      "[390]\ttraining's rmse: 16.914\tvalid_1's rmse: 56.169\n",
      "[420]\ttraining's rmse: 15.6598\tvalid_1's rmse: 56.0293\n",
      "[450]\ttraining's rmse: 14.4954\tvalid_1's rmse: 55.8542\n",
      "[480]\ttraining's rmse: 13.4591\tvalid_1's rmse: 55.7377\n",
      "[510]\ttraining's rmse: 12.5286\tvalid_1's rmse: 55.6084\n",
      "[540]\ttraining's rmse: 11.6771\tvalid_1's rmse: 55.4932\n",
      "[570]\ttraining's rmse: 10.9058\tvalid_1's rmse: 55.3999\n",
      "[600]\ttraining's rmse: 10.209\tvalid_1's rmse: 55.3131\n",
      "[630]\ttraining's rmse: 9.55661\tvalid_1's rmse: 55.2519\n",
      "[660]\ttraining's rmse: 8.94791\tvalid_1's rmse: 55.1901\n",
      "[690]\ttraining's rmse: 8.38022\tvalid_1's rmse: 55.1369\n",
      "[720]\ttraining's rmse: 7.86274\tvalid_1's rmse: 55.1055\n",
      "[750]\ttraining's rmse: 7.39234\tvalid_1's rmse: 55.085\n",
      "[780]\ttraining's rmse: 6.95582\tvalid_1's rmse: 55.0611\n",
      "[810]\ttraining's rmse: 6.53511\tvalid_1's rmse: 55.0376\n",
      "[840]\ttraining's rmse: 6.15827\tvalid_1's rmse: 55.0031\n",
      "[870]\ttraining's rmse: 5.80128\tvalid_1's rmse: 54.9841\n",
      "[900]\ttraining's rmse: 5.46775\tvalid_1's rmse: 54.9591\n",
      "[930]\ttraining's rmse: 5.15962\tvalid_1's rmse: 54.9278\n",
      "[960]\ttraining's rmse: 4.87192\tvalid_1's rmse: 54.909\n",
      "[990]\ttraining's rmse: 4.60121\tvalid_1's rmse: 54.9051\n",
      "[1020]\ttraining's rmse: 4.34625\tvalid_1's rmse: 54.888\n",
      "[1050]\ttraining's rmse: 4.1111\tvalid_1's rmse: 54.8654\n",
      "[1080]\ttraining's rmse: 3.88942\tvalid_1's rmse: 54.8626\n",
      "[1110]\ttraining's rmse: 3.68421\tvalid_1's rmse: 54.8587\n",
      "[1140]\ttraining's rmse: 3.49147\tvalid_1's rmse: 54.8504\n",
      "[1170]\ttraining's rmse: 3.30917\tvalid_1's rmse: 54.8418\n",
      "[1200]\ttraining's rmse: 3.13779\tvalid_1's rmse: 54.8363\n",
      "[1230]\ttraining's rmse: 2.97235\tvalid_1's rmse: 54.8343\n",
      "[1260]\ttraining's rmse: 2.82073\tvalid_1's rmse: 54.8311\n",
      "[1290]\ttraining's rmse: 2.6763\tvalid_1's rmse: 54.8231\n",
      "[1320]\ttraining's rmse: 2.53736\tvalid_1's rmse: 54.8127\n",
      "[1350]\ttraining's rmse: 2.40969\tvalid_1's rmse: 54.8072\n",
      "[1380]\ttraining's rmse: 2.29025\tvalid_1's rmse: 54.8045\n",
      "[1410]\ttraining's rmse: 2.17377\tvalid_1's rmse: 54.8032\n",
      "[1440]\ttraining's rmse: 2.06315\tvalid_1's rmse: 54.7983\n",
      "[1470]\ttraining's rmse: 1.95958\tvalid_1's rmse: 54.7959\n",
      "[1500]\ttraining's rmse: 1.86229\tvalid_1's rmse: 54.7895\n",
      "[1530]\ttraining's rmse: 1.76892\tvalid_1's rmse: 54.7876\n",
      "[1560]\ttraining's rmse: 1.68197\tvalid_1's rmse: 54.7883\n",
      "[1590]\ttraining's rmse: 1.59841\tvalid_1's rmse: 54.7842\n",
      "[1620]\ttraining's rmse: 1.52049\tvalid_1's rmse: 54.7838\n",
      "[1650]\ttraining's rmse: 1.44878\tvalid_1's rmse: 54.7814\n",
      "[1680]\ttraining's rmse: 1.37835\tvalid_1's rmse: 54.7803\n",
      "[1710]\ttraining's rmse: 1.31343\tvalid_1's rmse: 54.7808\n",
      "[1740]\ttraining's rmse: 1.25088\tvalid_1's rmse: 54.7824\n",
      "[1770]\ttraining's rmse: 1.19108\tvalid_1's rmse: 54.7814\n",
      "[1800]\ttraining's rmse: 1.13524\tvalid_1's rmse: 54.7811\n",
      "Early stopping, best iteration is:\n",
      "[1677]\ttraining's rmse: 1.38493\tvalid_1's rmse: 54.7799\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002601 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 20024\n",
      "[LightGBM] [Info] Number of data points in the train set: 9219, number of used features: 79\n",
      "[LightGBM] [Info] Start training from score 355.004531\n",
      "Training until validation scores don't improve for 125 rounds\n",
      "[30]\ttraining's rmse: 154.979\tvalid_1's rmse: 158.533\n",
      "[60]\ttraining's rmse: 96.9862\tvalid_1's rmse: 106.222\n",
      "[90]\ttraining's rmse: 65.6043\tvalid_1's rmse: 80.5894\n",
      "[120]\ttraining's rmse: 48.5392\tvalid_1's rmse: 68.4229\n",
      "[150]\ttraining's rmse: 39.0065\tvalid_1's rmse: 62.7121\n",
      "[180]\ttraining's rmse: 33.156\tvalid_1's rmse: 59.7293\n",
      "[210]\ttraining's rmse: 29.1509\tvalid_1's rmse: 57.9566\n",
      "[240]\ttraining's rmse: 26.0755\tvalid_1's rmse: 56.9383\n",
      "[270]\ttraining's rmse: 23.6143\tvalid_1's rmse: 56.2658\n",
      "[300]\ttraining's rmse: 21.4731\tvalid_1's rmse: 55.741\n",
      "[330]\ttraining's rmse: 19.6926\tvalid_1's rmse: 55.3425\n",
      "[360]\ttraining's rmse: 18.1597\tvalid_1's rmse: 54.9958\n",
      "[390]\ttraining's rmse: 16.7662\tvalid_1's rmse: 54.7212\n",
      "[420]\ttraining's rmse: 15.5308\tvalid_1's rmse: 54.5893\n",
      "[450]\ttraining's rmse: 14.4369\tvalid_1's rmse: 54.4021\n",
      "[480]\ttraining's rmse: 13.4493\tvalid_1's rmse: 54.28\n",
      "[510]\ttraining's rmse: 12.56\tvalid_1's rmse: 54.1448\n",
      "[540]\ttraining's rmse: 11.7442\tvalid_1's rmse: 54.0635\n",
      "[570]\ttraining's rmse: 10.9913\tvalid_1's rmse: 53.9476\n",
      "[600]\ttraining's rmse: 10.2909\tvalid_1's rmse: 53.8599\n",
      "[630]\ttraining's rmse: 9.63664\tvalid_1's rmse: 53.7682\n",
      "[660]\ttraining's rmse: 9.04059\tvalid_1's rmse: 53.7054\n",
      "[690]\ttraining's rmse: 8.49464\tvalid_1's rmse: 53.627\n",
      "[720]\ttraining's rmse: 7.9782\tvalid_1's rmse: 53.5957\n",
      "[750]\ttraining's rmse: 7.50559\tvalid_1's rmse: 53.5476\n",
      "[780]\ttraining's rmse: 7.07293\tvalid_1's rmse: 53.5154\n",
      "[810]\ttraining's rmse: 6.65146\tvalid_1's rmse: 53.4807\n",
      "[840]\ttraining's rmse: 6.26623\tvalid_1's rmse: 53.4313\n",
      "[870]\ttraining's rmse: 5.91521\tvalid_1's rmse: 53.3991\n",
      "[900]\ttraining's rmse: 5.58178\tvalid_1's rmse: 53.3747\n",
      "[930]\ttraining's rmse: 5.27383\tvalid_1's rmse: 53.3696\n",
      "[960]\ttraining's rmse: 4.98478\tvalid_1's rmse: 53.3615\n",
      "[990]\ttraining's rmse: 4.71308\tvalid_1's rmse: 53.3496\n",
      "[1020]\ttraining's rmse: 4.46288\tvalid_1's rmse: 53.3274\n",
      "[1050]\ttraining's rmse: 4.22646\tvalid_1's rmse: 53.3106\n",
      "[1080]\ttraining's rmse: 4.00512\tvalid_1's rmse: 53.2972\n",
      "[1110]\ttraining's rmse: 3.7945\tvalid_1's rmse: 53.2918\n",
      "[1140]\ttraining's rmse: 3.59522\tvalid_1's rmse: 53.2789\n",
      "[1170]\ttraining's rmse: 3.40713\tvalid_1's rmse: 53.2629\n",
      "[1200]\ttraining's rmse: 3.23321\tvalid_1's rmse: 53.2552\n",
      "[1230]\ttraining's rmse: 3.06576\tvalid_1's rmse: 53.2494\n",
      "[1260]\ttraining's rmse: 2.91313\tvalid_1's rmse: 53.2398\n",
      "[1290]\ttraining's rmse: 2.76574\tvalid_1's rmse: 53.2282\n",
      "[1320]\ttraining's rmse: 2.62681\tvalid_1's rmse: 53.2195\n",
      "[1350]\ttraining's rmse: 2.49367\tvalid_1's rmse: 53.2132\n",
      "[1380]\ttraining's rmse: 2.3661\tvalid_1's rmse: 53.2088\n",
      "[1410]\ttraining's rmse: 2.24897\tvalid_1's rmse: 53.2088\n",
      "[1440]\ttraining's rmse: 2.1399\tvalid_1's rmse: 53.2009\n",
      "[1470]\ttraining's rmse: 2.03368\tvalid_1's rmse: 53.1982\n",
      "[1500]\ttraining's rmse: 1.93629\tvalid_1's rmse: 53.1927\n",
      "[1530]\ttraining's rmse: 1.84261\tvalid_1's rmse: 53.1889\n",
      "[1560]\ttraining's rmse: 1.75581\tvalid_1's rmse: 53.1833\n",
      "[1590]\ttraining's rmse: 1.67087\tvalid_1's rmse: 53.1806\n",
      "[1620]\ttraining's rmse: 1.59268\tvalid_1's rmse: 53.1773\n",
      "[1650]\ttraining's rmse: 1.51914\tvalid_1's rmse: 53.1702\n",
      "[1680]\ttraining's rmse: 1.44648\tvalid_1's rmse: 53.1628\n",
      "[1710]\ttraining's rmse: 1.37559\tvalid_1's rmse: 53.1608\n",
      "[1740]\ttraining's rmse: 1.31247\tvalid_1's rmse: 53.1589\n",
      "[1770]\ttraining's rmse: 1.25054\tvalid_1's rmse: 53.1562\n",
      "[1800]\ttraining's rmse: 1.19304\tvalid_1's rmse: 53.1511\n",
      "[1830]\ttraining's rmse: 1.13483\tvalid_1's rmse: 53.149\n",
      "[1860]\ttraining's rmse: 1.08165\tvalid_1's rmse: 53.1457\n",
      "[1890]\ttraining's rmse: 1.03192\tvalid_1's rmse: 53.1442\n",
      "[1920]\ttraining's rmse: 0.985861\tvalid_1's rmse: 53.1419\n",
      "[1950]\ttraining's rmse: 0.941906\tvalid_1's rmse: 53.1405\n",
      "[1980]\ttraining's rmse: 0.898271\tvalid_1's rmse: 53.1372\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's rmse: 0.871847\tvalid_1's rmse: 53.1361\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003383 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 20024\n",
      "[LightGBM] [Info] Number of data points in the train set: 9219, number of used features: 79\n",
      "[LightGBM] [Info] Start training from score 356.933281\n",
      "Training until validation scores don't improve for 125 rounds\n",
      "[30]\ttraining's rmse: 155.224\tvalid_1's rmse: 158.842\n",
      "[60]\ttraining's rmse: 97.0351\tvalid_1's rmse: 107.397\n",
      "[90]\ttraining's rmse: 65.6477\tvalid_1's rmse: 81.8395\n",
      "[120]\ttraining's rmse: 48.526\tvalid_1's rmse: 69.2771\n",
      "[150]\ttraining's rmse: 38.941\tvalid_1's rmse: 63.1209\n",
      "[180]\ttraining's rmse: 33.0923\tvalid_1's rmse: 60.0797\n",
      "[210]\ttraining's rmse: 29.0121\tvalid_1's rmse: 58.2708\n",
      "[240]\ttraining's rmse: 25.9417\tvalid_1's rmse: 57.1422\n",
      "[270]\ttraining's rmse: 23.4746\tvalid_1's rmse: 56.3216\n",
      "[300]\ttraining's rmse: 21.3319\tvalid_1's rmse: 55.7105\n",
      "[330]\ttraining's rmse: 19.5863\tvalid_1's rmse: 55.322\n",
      "[360]\ttraining's rmse: 18.0223\tvalid_1's rmse: 55.0022\n",
      "[390]\ttraining's rmse: 16.6843\tvalid_1's rmse: 54.8055\n",
      "[420]\ttraining's rmse: 15.4492\tvalid_1's rmse: 54.5952\n",
      "[450]\ttraining's rmse: 14.3336\tvalid_1's rmse: 54.4522\n",
      "[480]\ttraining's rmse: 13.3377\tvalid_1's rmse: 54.2896\n",
      "[510]\ttraining's rmse: 12.4353\tvalid_1's rmse: 54.1642\n",
      "[540]\ttraining's rmse: 11.6181\tvalid_1's rmse: 54.1193\n",
      "[570]\ttraining's rmse: 10.8778\tvalid_1's rmse: 54.049\n",
      "[600]\ttraining's rmse: 10.179\tvalid_1's rmse: 53.9919\n",
      "[630]\ttraining's rmse: 9.53098\tvalid_1's rmse: 53.9345\n",
      "[660]\ttraining's rmse: 8.94947\tvalid_1's rmse: 53.8878\n",
      "[690]\ttraining's rmse: 8.4078\tvalid_1's rmse: 53.8467\n",
      "[720]\ttraining's rmse: 7.89328\tvalid_1's rmse: 53.804\n",
      "[750]\ttraining's rmse: 7.4359\tvalid_1's rmse: 53.7851\n",
      "[780]\ttraining's rmse: 7.00592\tvalid_1's rmse: 53.7392\n",
      "[810]\ttraining's rmse: 6.60444\tvalid_1's rmse: 53.7246\n",
      "[840]\ttraining's rmse: 6.22521\tvalid_1's rmse: 53.7041\n",
      "[870]\ttraining's rmse: 5.87436\tvalid_1's rmse: 53.6782\n",
      "[900]\ttraining's rmse: 5.54559\tvalid_1's rmse: 53.6614\n",
      "[930]\ttraining's rmse: 5.23988\tvalid_1's rmse: 53.6386\n",
      "[960]\ttraining's rmse: 4.94751\tvalid_1's rmse: 53.6327\n",
      "[990]\ttraining's rmse: 4.67737\tvalid_1's rmse: 53.6268\n",
      "[1020]\ttraining's rmse: 4.42067\tvalid_1's rmse: 53.6163\n",
      "[1050]\ttraining's rmse: 4.18265\tvalid_1's rmse: 53.6096\n",
      "[1080]\ttraining's rmse: 3.95827\tvalid_1's rmse: 53.5992\n",
      "[1110]\ttraining's rmse: 3.74967\tvalid_1's rmse: 53.5915\n",
      "[1140]\ttraining's rmse: 3.55246\tvalid_1's rmse: 53.5803\n",
      "[1170]\ttraining's rmse: 3.37181\tvalid_1's rmse: 53.5697\n",
      "[1200]\ttraining's rmse: 3.19336\tvalid_1's rmse: 53.5569\n",
      "[1230]\ttraining's rmse: 3.02996\tvalid_1's rmse: 53.5585\n",
      "[1260]\ttraining's rmse: 2.87312\tvalid_1's rmse: 53.5557\n",
      "[1290]\ttraining's rmse: 2.72908\tvalid_1's rmse: 53.5493\n",
      "[1320]\ttraining's rmse: 2.58847\tvalid_1's rmse: 53.5404\n",
      "[1350]\ttraining's rmse: 2.45972\tvalid_1's rmse: 53.5324\n",
      "[1380]\ttraining's rmse: 2.34028\tvalid_1's rmse: 53.5294\n",
      "[1410]\ttraining's rmse: 2.22395\tvalid_1's rmse: 53.528\n",
      "[1440]\ttraining's rmse: 2.11578\tvalid_1's rmse: 53.5278\n",
      "[1470]\ttraining's rmse: 2.01323\tvalid_1's rmse: 53.5239\n",
      "[1500]\ttraining's rmse: 1.91593\tvalid_1's rmse: 53.5201\n",
      "[1530]\ttraining's rmse: 1.82359\tvalid_1's rmse: 53.5158\n",
      "[1560]\ttraining's rmse: 1.73588\tvalid_1's rmse: 53.5147\n",
      "[1590]\ttraining's rmse: 1.65412\tvalid_1's rmse: 53.513\n",
      "[1620]\ttraining's rmse: 1.57653\tvalid_1's rmse: 53.513\n",
      "[1650]\ttraining's rmse: 1.50123\tvalid_1's rmse: 53.5088\n",
      "[1680]\ttraining's rmse: 1.42966\tvalid_1's rmse: 53.5067\n",
      "[1710]\ttraining's rmse: 1.36265\tvalid_1's rmse: 53.5076\n",
      "[1740]\ttraining's rmse: 1.3003\tvalid_1's rmse: 53.5067\n",
      "[1770]\ttraining's rmse: 1.24027\tvalid_1's rmse: 53.5062\n",
      "[1800]\ttraining's rmse: 1.18705\tvalid_1's rmse: 53.5043\n",
      "[1830]\ttraining's rmse: 1.13211\tvalid_1's rmse: 53.5041\n",
      "[1860]\ttraining's rmse: 1.0806\tvalid_1's rmse: 53.5035\n",
      "[1890]\ttraining's rmse: 1.03075\tvalid_1's rmse: 53.5009\n",
      "[1920]\ttraining's rmse: 0.984795\tvalid_1's rmse: 53.5013\n",
      "[1950]\ttraining's rmse: 0.940396\tvalid_1's rmse: 53.5004\n",
      "[1980]\ttraining's rmse: 0.898259\tvalid_1's rmse: 53.4978\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's rmse: 0.869507\tvalid_1's rmse: 53.4969\n",
      "24\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002190 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 20024\n",
      "[LightGBM] [Info] Number of data points in the train set: 9219, number of used features: 79\n",
      "[LightGBM] [Info] Start training from score 360.131644\n",
      "Training until validation scores don't improve for 125 rounds\n",
      "[30]\ttraining's rmse: 153.912\tvalid_1's rmse: 162.415\n",
      "[60]\ttraining's rmse: 95.4302\tvalid_1's rmse: 106.654\n",
      "[90]\ttraining's rmse: 63.9912\tvalid_1's rmse: 78.9817\n",
      "[120]\ttraining's rmse: 47.0455\tvalid_1's rmse: 66.2419\n",
      "[150]\ttraining's rmse: 37.4903\tvalid_1's rmse: 60.1111\n",
      "[180]\ttraining's rmse: 31.6685\tvalid_1's rmse: 57.1908\n",
      "[210]\ttraining's rmse: 27.6834\tvalid_1's rmse: 55.5089\n",
      "[240]\ttraining's rmse: 24.6441\tvalid_1's rmse: 54.4018\n",
      "[270]\ttraining's rmse: 22.167\tvalid_1's rmse: 53.6715\n",
      "[300]\ttraining's rmse: 20.1566\tvalid_1's rmse: 53.1296\n",
      "[330]\ttraining's rmse: 18.4487\tvalid_1's rmse: 52.808\n",
      "[360]\ttraining's rmse: 16.9566\tvalid_1's rmse: 52.4865\n",
      "[390]\ttraining's rmse: 15.6563\tvalid_1's rmse: 52.2953\n",
      "[420]\ttraining's rmse: 14.5208\tvalid_1's rmse: 52.0798\n",
      "[450]\ttraining's rmse: 13.469\tvalid_1's rmse: 51.9119\n",
      "[480]\ttraining's rmse: 12.536\tvalid_1's rmse: 51.7934\n",
      "[510]\ttraining's rmse: 11.7041\tvalid_1's rmse: 51.6572\n",
      "[540]\ttraining's rmse: 10.928\tvalid_1's rmse: 51.5331\n",
      "[570]\ttraining's rmse: 10.2113\tvalid_1's rmse: 51.4779\n",
      "[600]\ttraining's rmse: 9.56275\tvalid_1's rmse: 51.4334\n",
      "[630]\ttraining's rmse: 8.9506\tvalid_1's rmse: 51.4004\n",
      "[660]\ttraining's rmse: 8.39884\tvalid_1's rmse: 51.3705\n",
      "[690]\ttraining's rmse: 7.88446\tvalid_1's rmse: 51.3354\n",
      "[720]\ttraining's rmse: 7.39887\tvalid_1's rmse: 51.2917\n",
      "[750]\ttraining's rmse: 6.95429\tvalid_1's rmse: 51.2552\n",
      "[780]\ttraining's rmse: 6.55039\tvalid_1's rmse: 51.2277\n",
      "[810]\ttraining's rmse: 6.17235\tvalid_1's rmse: 51.1991\n",
      "[840]\ttraining's rmse: 5.81535\tvalid_1's rmse: 51.1807\n",
      "[870]\ttraining's rmse: 5.48882\tvalid_1's rmse: 51.1717\n",
      "[900]\ttraining's rmse: 5.18278\tvalid_1's rmse: 51.1575\n",
      "[930]\ttraining's rmse: 4.89816\tvalid_1's rmse: 51.1489\n",
      "[960]\ttraining's rmse: 4.62339\tvalid_1's rmse: 51.1283\n",
      "[990]\ttraining's rmse: 4.37519\tvalid_1's rmse: 51.1153\n",
      "[1020]\ttraining's rmse: 4.13726\tvalid_1's rmse: 51.1063\n",
      "[1050]\ttraining's rmse: 3.91437\tvalid_1's rmse: 51.099\n",
      "[1080]\ttraining's rmse: 3.70745\tvalid_1's rmse: 51.0842\n",
      "[1110]\ttraining's rmse: 3.51168\tvalid_1's rmse: 51.0814\n",
      "[1140]\ttraining's rmse: 3.32568\tvalid_1's rmse: 51.075\n",
      "[1170]\ttraining's rmse: 3.15593\tvalid_1's rmse: 51.0666\n",
      "[1200]\ttraining's rmse: 2.98851\tvalid_1's rmse: 51.065\n",
      "[1230]\ttraining's rmse: 2.82859\tvalid_1's rmse: 51.0568\n",
      "[1260]\ttraining's rmse: 2.68533\tvalid_1's rmse: 51.0455\n",
      "[1290]\ttraining's rmse: 2.54393\tvalid_1's rmse: 51.0384\n",
      "[1320]\ttraining's rmse: 2.41127\tvalid_1's rmse: 51.0352\n",
      "[1350]\ttraining's rmse: 2.2861\tvalid_1's rmse: 51.0299\n",
      "[1380]\ttraining's rmse: 2.16942\tvalid_1's rmse: 51.0265\n",
      "[1410]\ttraining's rmse: 2.05856\tvalid_1's rmse: 51.0237\n",
      "[1440]\ttraining's rmse: 1.9561\tvalid_1's rmse: 51.0231\n",
      "[1470]\ttraining's rmse: 1.85945\tvalid_1's rmse: 51.0145\n",
      "[1500]\ttraining's rmse: 1.76353\tvalid_1's rmse: 51.0118\n",
      "[1530]\ttraining's rmse: 1.67464\tvalid_1's rmse: 51.0095\n",
      "[1560]\ttraining's rmse: 1.58972\tvalid_1's rmse: 51.0086\n",
      "[1590]\ttraining's rmse: 1.5115\tvalid_1's rmse: 51.0047\n",
      "[1620]\ttraining's rmse: 1.4363\tvalid_1's rmse: 51.0031\n",
      "[1650]\ttraining's rmse: 1.36517\tvalid_1's rmse: 51.0002\n",
      "[1680]\ttraining's rmse: 1.2989\tvalid_1's rmse: 50.9969\n",
      "[1710]\ttraining's rmse: 1.23601\tvalid_1's rmse: 50.997\n",
      "[1740]\ttraining's rmse: 1.17753\tvalid_1's rmse: 50.9955\n",
      "[1770]\ttraining's rmse: 1.11997\tvalid_1's rmse: 50.9926\n",
      "[1800]\ttraining's rmse: 1.06675\tvalid_1's rmse: 50.989\n",
      "[1830]\ttraining's rmse: 1.01679\tvalid_1's rmse: 50.9892\n",
      "[1860]\ttraining's rmse: 0.968033\tvalid_1's rmse: 50.9879\n",
      "[1890]\ttraining's rmse: 0.922189\tvalid_1's rmse: 50.9855\n",
      "[1920]\ttraining's rmse: 0.878773\tvalid_1's rmse: 50.9855\n",
      "[1950]\ttraining's rmse: 0.83786\tvalid_1's rmse: 50.9849\n",
      "[1980]\ttraining's rmse: 0.798484\tvalid_1's rmse: 50.9839\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's rmse: 0.773084\tvalid_1's rmse: 50.9845\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002345 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 20024\n",
      "[LightGBM] [Info] Number of data points in the train set: 9219, number of used features: 79\n",
      "[LightGBM] [Info] Start training from score 360.035562\n",
      "Training until validation scores don't improve for 125 rounds\n",
      "[30]\ttraining's rmse: 154.989\tvalid_1's rmse: 161.024\n",
      "[60]\ttraining's rmse: 96.4421\tvalid_1's rmse: 107.842\n",
      "[90]\ttraining's rmse: 65.2449\tvalid_1's rmse: 82.2489\n",
      "[120]\ttraining's rmse: 48.2888\tvalid_1's rmse: 69.934\n",
      "[150]\ttraining's rmse: 38.7116\tvalid_1's rmse: 64.1435\n",
      "[180]\ttraining's rmse: 32.7379\tvalid_1's rmse: 61.1027\n",
      "[210]\ttraining's rmse: 28.6347\tvalid_1's rmse: 59.1603\n",
      "[240]\ttraining's rmse: 25.5369\tvalid_1's rmse: 57.9605\n",
      "[270]\ttraining's rmse: 23.0095\tvalid_1's rmse: 57.123\n",
      "[300]\ttraining's rmse: 20.9478\tvalid_1's rmse: 56.5141\n",
      "[330]\ttraining's rmse: 19.2046\tvalid_1's rmse: 56.0557\n",
      "[360]\ttraining's rmse: 17.6621\tvalid_1's rmse: 55.7034\n",
      "[390]\ttraining's rmse: 16.2762\tvalid_1's rmse: 55.4115\n",
      "[420]\ttraining's rmse: 15.0685\tvalid_1's rmse: 55.1608\n",
      "[450]\ttraining's rmse: 13.9885\tvalid_1's rmse: 54.9764\n",
      "[480]\ttraining's rmse: 13.0083\tvalid_1's rmse: 54.792\n",
      "[510]\ttraining's rmse: 12.1151\tvalid_1's rmse: 54.6563\n",
      "[540]\ttraining's rmse: 11.3093\tvalid_1's rmse: 54.5966\n",
      "[570]\ttraining's rmse: 10.5845\tvalid_1's rmse: 54.4951\n",
      "[600]\ttraining's rmse: 9.90961\tvalid_1's rmse: 54.4102\n",
      "[630]\ttraining's rmse: 9.28682\tvalid_1's rmse: 54.3159\n",
      "[660]\ttraining's rmse: 8.69584\tvalid_1's rmse: 54.2686\n",
      "[690]\ttraining's rmse: 8.17347\tvalid_1's rmse: 54.2016\n",
      "[720]\ttraining's rmse: 7.69376\tvalid_1's rmse: 54.1673\n",
      "[750]\ttraining's rmse: 7.23135\tvalid_1's rmse: 54.1122\n",
      "[780]\ttraining's rmse: 6.80306\tvalid_1's rmse: 54.0851\n",
      "[810]\ttraining's rmse: 6.40946\tvalid_1's rmse: 54.0575\n",
      "[840]\ttraining's rmse: 6.0316\tvalid_1's rmse: 54.017\n",
      "[870]\ttraining's rmse: 5.67955\tvalid_1's rmse: 53.9879\n",
      "[900]\ttraining's rmse: 5.35809\tvalid_1's rmse: 53.9594\n",
      "[930]\ttraining's rmse: 5.06351\tvalid_1's rmse: 53.9421\n",
      "[960]\ttraining's rmse: 4.78309\tvalid_1's rmse: 53.9204\n",
      "[990]\ttraining's rmse: 4.51901\tvalid_1's rmse: 53.8879\n",
      "[1020]\ttraining's rmse: 4.27461\tvalid_1's rmse: 53.8777\n",
      "[1050]\ttraining's rmse: 4.0441\tvalid_1's rmse: 53.8633\n",
      "[1080]\ttraining's rmse: 3.8212\tvalid_1's rmse: 53.8425\n",
      "[1110]\ttraining's rmse: 3.61716\tvalid_1's rmse: 53.8275\n",
      "[1140]\ttraining's rmse: 3.4182\tvalid_1's rmse: 53.81\n",
      "[1170]\ttraining's rmse: 3.23723\tvalid_1's rmse: 53.7966\n",
      "[1200]\ttraining's rmse: 3.06877\tvalid_1's rmse: 53.784\n",
      "[1230]\ttraining's rmse: 2.9094\tvalid_1's rmse: 53.7732\n",
      "[1260]\ttraining's rmse: 2.75323\tvalid_1's rmse: 53.7649\n",
      "[1290]\ttraining's rmse: 2.60872\tvalid_1's rmse: 53.7608\n",
      "[1320]\ttraining's rmse: 2.47091\tvalid_1's rmse: 53.7499\n",
      "[1350]\ttraining's rmse: 2.34175\tvalid_1's rmse: 53.7449\n",
      "[1380]\ttraining's rmse: 2.22403\tvalid_1's rmse: 53.7432\n",
      "[1410]\ttraining's rmse: 2.11106\tvalid_1's rmse: 53.7379\n",
      "[1440]\ttraining's rmse: 2.00438\tvalid_1's rmse: 53.7335\n",
      "[1470]\ttraining's rmse: 1.90105\tvalid_1's rmse: 53.731\n",
      "[1500]\ttraining's rmse: 1.80444\tvalid_1's rmse: 53.7282\n",
      "[1530]\ttraining's rmse: 1.71418\tvalid_1's rmse: 53.7232\n",
      "[1560]\ttraining's rmse: 1.62882\tvalid_1's rmse: 53.7197\n",
      "[1590]\ttraining's rmse: 1.54636\tvalid_1's rmse: 53.716\n",
      "[1620]\ttraining's rmse: 1.47016\tvalid_1's rmse: 53.7148\n",
      "[1650]\ttraining's rmse: 1.39629\tvalid_1's rmse: 53.7126\n",
      "[1680]\ttraining's rmse: 1.32659\tvalid_1's rmse: 53.7101\n",
      "[1710]\ttraining's rmse: 1.26058\tvalid_1's rmse: 53.7083\n",
      "[1740]\ttraining's rmse: 1.19906\tvalid_1's rmse: 53.7068\n",
      "[1770]\ttraining's rmse: 1.14081\tvalid_1's rmse: 53.7041\n",
      "[1800]\ttraining's rmse: 1.08438\tvalid_1's rmse: 53.7031\n",
      "[1830]\ttraining's rmse: 1.031\tvalid_1's rmse: 53.7001\n",
      "[1860]\ttraining's rmse: 0.980233\tvalid_1's rmse: 53.698\n",
      "[1890]\ttraining's rmse: 0.931719\tvalid_1's rmse: 53.6978\n",
      "[1920]\ttraining's rmse: 0.886631\tvalid_1's rmse: 53.697\n",
      "[1950]\ttraining's rmse: 0.844258\tvalid_1's rmse: 53.6968\n",
      "[1980]\ttraining's rmse: 0.803656\tvalid_1's rmse: 53.6946\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's rmse: 0.77826\tvalid_1's rmse: 53.6931\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002320 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 20024\n",
      "[LightGBM] [Info] Number of data points in the train set: 9219, number of used features: 79\n",
      "[LightGBM] [Info] Start training from score 365.545418\n",
      "Training until validation scores don't improve for 125 rounds\n",
      "[30]\ttraining's rmse: 156.164\tvalid_1's rmse: 159.1\n",
      "[60]\ttraining's rmse: 97.6963\tvalid_1's rmse: 108.408\n",
      "[90]\ttraining's rmse: 66.1846\tvalid_1's rmse: 83.4151\n",
      "[120]\ttraining's rmse: 48.9514\tvalid_1's rmse: 71.2121\n",
      "[150]\ttraining's rmse: 39.3598\tvalid_1's rmse: 65.4408\n",
      "[180]\ttraining's rmse: 33.3276\tvalid_1's rmse: 62.3457\n",
      "[210]\ttraining's rmse: 29.1558\tvalid_1's rmse: 60.5186\n",
      "[240]\ttraining's rmse: 26.0523\tvalid_1's rmse: 59.3725\n",
      "[270]\ttraining's rmse: 23.4855\tvalid_1's rmse: 58.496\n",
      "[300]\ttraining's rmse: 21.3315\tvalid_1's rmse: 57.8332\n",
      "[330]\ttraining's rmse: 19.4923\tvalid_1's rmse: 57.3236\n",
      "[360]\ttraining's rmse: 17.918\tvalid_1's rmse: 56.9161\n",
      "[390]\ttraining's rmse: 16.5116\tvalid_1's rmse: 56.6737\n",
      "[420]\ttraining's rmse: 15.2787\tvalid_1's rmse: 56.4746\n",
      "[450]\ttraining's rmse: 14.1792\tvalid_1's rmse: 56.2957\n",
      "[480]\ttraining's rmse: 13.187\tvalid_1's rmse: 56.115\n",
      "[510]\ttraining's rmse: 12.2852\tvalid_1's rmse: 55.989\n",
      "[540]\ttraining's rmse: 11.464\tvalid_1's rmse: 55.8795\n",
      "[570]\ttraining's rmse: 10.7215\tvalid_1's rmse: 55.7594\n",
      "[600]\ttraining's rmse: 10.0339\tvalid_1's rmse: 55.6942\n",
      "[630]\ttraining's rmse: 9.40067\tvalid_1's rmse: 55.6044\n",
      "[660]\ttraining's rmse: 8.80643\tvalid_1's rmse: 55.5508\n",
      "[690]\ttraining's rmse: 8.26061\tvalid_1's rmse: 55.4844\n",
      "[720]\ttraining's rmse: 7.76012\tvalid_1's rmse: 55.4434\n",
      "[750]\ttraining's rmse: 7.29576\tvalid_1's rmse: 55.4065\n",
      "[780]\ttraining's rmse: 6.86375\tvalid_1's rmse: 55.3705\n",
      "[810]\ttraining's rmse: 6.45386\tvalid_1's rmse: 55.3559\n",
      "[840]\ttraining's rmse: 6.07445\tvalid_1's rmse: 55.3323\n",
      "[870]\ttraining's rmse: 5.72759\tvalid_1's rmse: 55.3252\n",
      "[900]\ttraining's rmse: 5.40098\tvalid_1's rmse: 55.3005\n",
      "[930]\ttraining's rmse: 5.09878\tvalid_1's rmse: 55.2885\n",
      "[960]\ttraining's rmse: 4.81555\tvalid_1's rmse: 55.2768\n",
      "[990]\ttraining's rmse: 4.55065\tvalid_1's rmse: 55.2628\n",
      "[1020]\ttraining's rmse: 4.30099\tvalid_1's rmse: 55.2573\n",
      "[1050]\ttraining's rmse: 4.07026\tvalid_1's rmse: 55.2512\n",
      "[1080]\ttraining's rmse: 3.85587\tvalid_1's rmse: 55.2394\n",
      "[1110]\ttraining's rmse: 3.65026\tvalid_1's rmse: 55.2412\n",
      "[1140]\ttraining's rmse: 3.45302\tvalid_1's rmse: 55.2257\n",
      "[1170]\ttraining's rmse: 3.26601\tvalid_1's rmse: 55.217\n",
      "[1200]\ttraining's rmse: 3.09834\tvalid_1's rmse: 55.2098\n",
      "[1230]\ttraining's rmse: 2.93513\tvalid_1's rmse: 55.2084\n",
      "[1260]\ttraining's rmse: 2.77947\tvalid_1's rmse: 55.2049\n",
      "[1290]\ttraining's rmse: 2.63649\tvalid_1's rmse: 55.1988\n",
      "[1320]\ttraining's rmse: 2.49895\tvalid_1's rmse: 55.1942\n",
      "[1350]\ttraining's rmse: 2.37224\tvalid_1's rmse: 55.1887\n",
      "[1380]\ttraining's rmse: 2.25391\tvalid_1's rmse: 55.1842\n",
      "[1410]\ttraining's rmse: 2.13693\tvalid_1's rmse: 55.186\n",
      "[1440]\ttraining's rmse: 2.03101\tvalid_1's rmse: 55.1854\n",
      "[1470]\ttraining's rmse: 1.93023\tvalid_1's rmse: 55.1814\n",
      "[1500]\ttraining's rmse: 1.83616\tvalid_1's rmse: 55.1805\n",
      "[1530]\ttraining's rmse: 1.74482\tvalid_1's rmse: 55.1779\n",
      "[1560]\ttraining's rmse: 1.65875\tvalid_1's rmse: 55.1751\n",
      "[1590]\ttraining's rmse: 1.57749\tvalid_1's rmse: 55.1718\n",
      "[1620]\ttraining's rmse: 1.49981\tvalid_1's rmse: 55.1685\n",
      "[1650]\ttraining's rmse: 1.42657\tvalid_1's rmse: 55.1654\n",
      "[1680]\ttraining's rmse: 1.35728\tvalid_1's rmse: 55.1632\n",
      "[1710]\ttraining's rmse: 1.29219\tvalid_1's rmse: 55.1627\n",
      "[1740]\ttraining's rmse: 1.22928\tvalid_1's rmse: 55.161\n",
      "[1770]\ttraining's rmse: 1.17036\tvalid_1's rmse: 55.1588\n",
      "[1800]\ttraining's rmse: 1.11503\tvalid_1's rmse: 55.1599\n",
      "[1830]\ttraining's rmse: 1.06148\tvalid_1's rmse: 55.16\n",
      "[1860]\ttraining's rmse: 1.01114\tvalid_1's rmse: 55.1616\n",
      "[1890]\ttraining's rmse: 0.963072\tvalid_1's rmse: 55.1619\n",
      "Early stopping, best iteration is:\n",
      "[1770]\ttraining's rmse: 1.17036\tvalid_1's rmse: 55.1588\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002366 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 20024\n",
      "[LightGBM] [Info] Number of data points in the train set: 9219, number of used features: 79\n",
      "[LightGBM] [Info] Start training from score 365.785320\n",
      "Training until validation scores don't improve for 125 rounds\n",
      "[30]\ttraining's rmse: 155.785\tvalid_1's rmse: 157.018\n",
      "[60]\ttraining's rmse: 97.4864\tvalid_1's rmse: 105.883\n",
      "[90]\ttraining's rmse: 65.9698\tvalid_1's rmse: 80.9001\n",
      "[120]\ttraining's rmse: 49.1065\tvalid_1's rmse: 69.2623\n",
      "[150]\ttraining's rmse: 39.5426\tvalid_1's rmse: 63.4257\n",
      "[180]\ttraining's rmse: 33.5228\tvalid_1's rmse: 60.2285\n",
      "[210]\ttraining's rmse: 29.2965\tvalid_1's rmse: 58.3117\n",
      "[240]\ttraining's rmse: 26.1343\tvalid_1's rmse: 57.1983\n",
      "[270]\ttraining's rmse: 23.5482\tvalid_1's rmse: 56.3998\n",
      "[300]\ttraining's rmse: 21.4641\tvalid_1's rmse: 55.8541\n",
      "[330]\ttraining's rmse: 19.6376\tvalid_1's rmse: 55.4294\n",
      "[360]\ttraining's rmse: 18.0435\tvalid_1's rmse: 55.1187\n",
      "[390]\ttraining's rmse: 16.6425\tvalid_1's rmse: 54.8857\n",
      "[420]\ttraining's rmse: 15.3949\tvalid_1's rmse: 54.6208\n",
      "[450]\ttraining's rmse: 14.2678\tvalid_1's rmse: 54.4821\n",
      "[480]\ttraining's rmse: 13.2557\tvalid_1's rmse: 54.3992\n",
      "[510]\ttraining's rmse: 12.3415\tvalid_1's rmse: 54.2783\n",
      "[540]\ttraining's rmse: 11.511\tvalid_1's rmse: 54.1936\n",
      "[570]\ttraining's rmse: 10.7467\tvalid_1's rmse: 54.0955\n",
      "[600]\ttraining's rmse: 10.0464\tvalid_1's rmse: 54.0478\n",
      "[630]\ttraining's rmse: 9.41969\tvalid_1's rmse: 53.9878\n",
      "[660]\ttraining's rmse: 8.8284\tvalid_1's rmse: 53.9199\n",
      "[690]\ttraining's rmse: 8.28276\tvalid_1's rmse: 53.8723\n",
      "[720]\ttraining's rmse: 7.79366\tvalid_1's rmse: 53.8473\n",
      "[750]\ttraining's rmse: 7.32725\tvalid_1's rmse: 53.7929\n",
      "[780]\ttraining's rmse: 6.8855\tvalid_1's rmse: 53.7743\n",
      "[810]\ttraining's rmse: 6.48736\tvalid_1's rmse: 53.7492\n",
      "[840]\ttraining's rmse: 6.11749\tvalid_1's rmse: 53.7419\n",
      "[870]\ttraining's rmse: 5.77193\tvalid_1's rmse: 53.7186\n",
      "[900]\ttraining's rmse: 5.44809\tvalid_1's rmse: 53.7077\n",
      "[930]\ttraining's rmse: 5.14034\tvalid_1's rmse: 53.7005\n",
      "[960]\ttraining's rmse: 4.85239\tvalid_1's rmse: 53.6824\n",
      "[990]\ttraining's rmse: 4.58599\tvalid_1's rmse: 53.6725\n",
      "[1020]\ttraining's rmse: 4.3359\tvalid_1's rmse: 53.6585\n",
      "[1050]\ttraining's rmse: 4.10197\tvalid_1's rmse: 53.6402\n",
      "[1080]\ttraining's rmse: 3.88482\tvalid_1's rmse: 53.6248\n",
      "[1110]\ttraining's rmse: 3.68241\tvalid_1's rmse: 53.6179\n",
      "[1140]\ttraining's rmse: 3.48688\tvalid_1's rmse: 53.6107\n",
      "[1170]\ttraining's rmse: 3.30324\tvalid_1's rmse: 53.5977\n",
      "[1200]\ttraining's rmse: 3.13315\tvalid_1's rmse: 53.5969\n",
      "[1230]\ttraining's rmse: 2.9731\tvalid_1's rmse: 53.5888\n",
      "[1260]\ttraining's rmse: 2.82066\tvalid_1's rmse: 53.586\n",
      "[1290]\ttraining's rmse: 2.67641\tvalid_1's rmse: 53.5849\n",
      "[1320]\ttraining's rmse: 2.53964\tvalid_1's rmse: 53.5795\n",
      "[1350]\ttraining's rmse: 2.40815\tvalid_1's rmse: 53.5745\n",
      "[1380]\ttraining's rmse: 2.28837\tvalid_1's rmse: 53.5681\n",
      "[1410]\ttraining's rmse: 2.17631\tvalid_1's rmse: 53.5645\n",
      "[1440]\ttraining's rmse: 2.06957\tvalid_1's rmse: 53.5592\n",
      "[1470]\ttraining's rmse: 1.96679\tvalid_1's rmse: 53.5571\n",
      "[1500]\ttraining's rmse: 1.87157\tvalid_1's rmse: 53.5509\n",
      "[1530]\ttraining's rmse: 1.78247\tvalid_1's rmse: 53.5492\n",
      "[1560]\ttraining's rmse: 1.6962\tvalid_1's rmse: 53.5466\n",
      "[1590]\ttraining's rmse: 1.61286\tvalid_1's rmse: 53.5454\n",
      "[1620]\ttraining's rmse: 1.53476\tvalid_1's rmse: 53.5473\n",
      "[1650]\ttraining's rmse: 1.46117\tvalid_1's rmse: 53.5448\n",
      "[1680]\ttraining's rmse: 1.39297\tvalid_1's rmse: 53.5412\n",
      "[1710]\ttraining's rmse: 1.32638\tvalid_1's rmse: 53.5416\n",
      "[1740]\ttraining's rmse: 1.2638\tvalid_1's rmse: 53.5393\n",
      "[1770]\ttraining's rmse: 1.20359\tvalid_1's rmse: 53.5398\n",
      "[1800]\ttraining's rmse: 1.14652\tvalid_1's rmse: 53.5376\n",
      "[1830]\ttraining's rmse: 1.09347\tvalid_1's rmse: 53.5357\n",
      "[1860]\ttraining's rmse: 1.04221\tvalid_1's rmse: 53.5339\n",
      "[1890]\ttraining's rmse: 0.994796\tvalid_1's rmse: 53.5318\n",
      "[1920]\ttraining's rmse: 0.94925\tvalid_1's rmse: 53.5321\n",
      "[1950]\ttraining's rmse: 0.904001\tvalid_1's rmse: 53.5324\n",
      "[1980]\ttraining's rmse: 0.862318\tvalid_1's rmse: 53.5302\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's rmse: 0.83702\tvalid_1's rmse: 53.5293\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003331 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 20024\n",
      "[LightGBM] [Info] Number of data points in the train set: 9219, number of used features: 79\n",
      "[LightGBM] [Info] Start training from score 360.971773\n",
      "Training until validation scores don't improve for 125 rounds\n",
      "[30]\ttraining's rmse: 155.349\tvalid_1's rmse: 159.795\n",
      "[60]\ttraining's rmse: 97.2652\tvalid_1's rmse: 106.694\n",
      "[90]\ttraining's rmse: 65.9796\tvalid_1's rmse: 80.3136\n",
      "[120]\ttraining's rmse: 49.0611\tvalid_1's rmse: 67.9917\n",
      "[150]\ttraining's rmse: 39.5573\tvalid_1's rmse: 62.1864\n",
      "[180]\ttraining's rmse: 33.7219\tvalid_1's rmse: 59.1067\n",
      "[210]\ttraining's rmse: 29.6929\tvalid_1's rmse: 57.2857\n",
      "[240]\ttraining's rmse: 26.5833\tvalid_1's rmse: 55.9792\n",
      "[270]\ttraining's rmse: 23.9702\tvalid_1's rmse: 55.0268\n",
      "[300]\ttraining's rmse: 21.7839\tvalid_1's rmse: 54.4009\n",
      "[330]\ttraining's rmse: 19.9222\tvalid_1's rmse: 53.9289\n",
      "[360]\ttraining's rmse: 18.316\tvalid_1's rmse: 53.6571\n",
      "[390]\ttraining's rmse: 16.9204\tvalid_1's rmse: 53.4202\n",
      "[420]\ttraining's rmse: 15.6601\tvalid_1's rmse: 53.2461\n",
      "[450]\ttraining's rmse: 14.5085\tvalid_1's rmse: 53.0743\n",
      "[480]\ttraining's rmse: 13.4803\tvalid_1's rmse: 52.935\n",
      "[510]\ttraining's rmse: 12.5402\tvalid_1's rmse: 52.8482\n",
      "[540]\ttraining's rmse: 11.6875\tvalid_1's rmse: 52.7436\n",
      "[570]\ttraining's rmse: 10.903\tvalid_1's rmse: 52.6807\n",
      "[600]\ttraining's rmse: 10.1955\tvalid_1's rmse: 52.6262\n",
      "[630]\ttraining's rmse: 9.53357\tvalid_1's rmse: 52.5627\n",
      "[660]\ttraining's rmse: 8.93091\tvalid_1's rmse: 52.5214\n",
      "[690]\ttraining's rmse: 8.3659\tvalid_1's rmse: 52.4702\n",
      "[720]\ttraining's rmse: 7.86033\tvalid_1's rmse: 52.4497\n",
      "[750]\ttraining's rmse: 7.38055\tvalid_1's rmse: 52.4301\n",
      "[780]\ttraining's rmse: 6.93744\tvalid_1's rmse: 52.4116\n",
      "[810]\ttraining's rmse: 6.52998\tvalid_1's rmse: 52.3918\n",
      "[840]\ttraining's rmse: 6.15532\tvalid_1's rmse: 52.3694\n",
      "[870]\ttraining's rmse: 5.80737\tvalid_1's rmse: 52.3483\n",
      "[900]\ttraining's rmse: 5.4692\tvalid_1's rmse: 52.3352\n",
      "[930]\ttraining's rmse: 5.16395\tvalid_1's rmse: 52.3182\n",
      "[960]\ttraining's rmse: 4.87487\tvalid_1's rmse: 52.3041\n",
      "[990]\ttraining's rmse: 4.60042\tvalid_1's rmse: 52.2975\n",
      "[1020]\ttraining's rmse: 4.34192\tvalid_1's rmse: 52.2863\n",
      "[1050]\ttraining's rmse: 4.10347\tvalid_1's rmse: 52.277\n",
      "[1080]\ttraining's rmse: 3.8837\tvalid_1's rmse: 52.259\n",
      "[1110]\ttraining's rmse: 3.67705\tvalid_1's rmse: 52.2465\n",
      "[1140]\ttraining's rmse: 3.48526\tvalid_1's rmse: 52.2388\n",
      "[1170]\ttraining's rmse: 3.30091\tvalid_1's rmse: 52.233\n",
      "[1200]\ttraining's rmse: 3.13076\tvalid_1's rmse: 52.2273\n",
      "[1230]\ttraining's rmse: 2.96623\tvalid_1's rmse: 52.2219\n",
      "[1260]\ttraining's rmse: 2.81297\tvalid_1's rmse: 52.2166\n",
      "[1290]\ttraining's rmse: 2.67119\tvalid_1's rmse: 52.2133\n",
      "[1320]\ttraining's rmse: 2.53564\tvalid_1's rmse: 52.2039\n",
      "[1350]\ttraining's rmse: 2.4063\tvalid_1's rmse: 52.2001\n",
      "[1380]\ttraining's rmse: 2.28515\tvalid_1's rmse: 52.1941\n",
      "[1410]\ttraining's rmse: 2.17294\tvalid_1's rmse: 52.1871\n",
      "[1440]\ttraining's rmse: 2.06506\tvalid_1's rmse: 52.1814\n",
      "[1470]\ttraining's rmse: 1.96434\tvalid_1's rmse: 52.177\n",
      "[1500]\ttraining's rmse: 1.86865\tvalid_1's rmse: 52.1712\n",
      "[1530]\ttraining's rmse: 1.77723\tvalid_1's rmse: 52.1684\n",
      "[1560]\ttraining's rmse: 1.69165\tvalid_1's rmse: 52.1638\n",
      "[1590]\ttraining's rmse: 1.61036\tvalid_1's rmse: 52.1584\n",
      "[1620]\ttraining's rmse: 1.53239\tvalid_1's rmse: 52.1566\n",
      "[1650]\ttraining's rmse: 1.45579\tvalid_1's rmse: 52.157\n",
      "[1680]\ttraining's rmse: 1.38499\tvalid_1's rmse: 52.1551\n",
      "[1710]\ttraining's rmse: 1.32012\tvalid_1's rmse: 52.1527\n",
      "[1740]\ttraining's rmse: 1.25815\tvalid_1's rmse: 52.153\n",
      "[1770]\ttraining's rmse: 1.20029\tvalid_1's rmse: 52.1508\n",
      "[1800]\ttraining's rmse: 1.14394\tvalid_1's rmse: 52.148\n",
      "[1830]\ttraining's rmse: 1.0904\tvalid_1's rmse: 52.1476\n",
      "[1860]\ttraining's rmse: 1.03982\tvalid_1's rmse: 52.1461\n",
      "[1890]\ttraining's rmse: 0.991941\tvalid_1's rmse: 52.1447\n",
      "[1920]\ttraining's rmse: 0.945528\tvalid_1's rmse: 52.1446\n",
      "[1950]\ttraining's rmse: 0.902694\tvalid_1's rmse: 52.1432\n",
      "[1980]\ttraining's rmse: 0.860923\tvalid_1's rmse: 52.1417\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's rmse: 0.834542\tvalid_1's rmse: 52.1417\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002194 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 20024\n",
      "[LightGBM] [Info] Number of data points in the train set: 9219, number of used features: 79\n",
      "[LightGBM] [Info] Start training from score 359.814089\n",
      "Training until validation scores don't improve for 125 rounds\n",
      "[30]\ttraining's rmse: 156.349\tvalid_1's rmse: 160.639\n",
      "[60]\ttraining's rmse: 97.566\tvalid_1's rmse: 106.67\n",
      "[90]\ttraining's rmse: 65.5384\tvalid_1's rmse: 79.5128\n",
      "[120]\ttraining's rmse: 48.4925\tvalid_1's rmse: 66.8099\n",
      "[150]\ttraining's rmse: 38.818\tvalid_1's rmse: 60.3862\n",
      "[180]\ttraining's rmse: 32.8998\tvalid_1's rmse: 57.1679\n",
      "[210]\ttraining's rmse: 28.8576\tvalid_1's rmse: 55.3448\n",
      "[240]\ttraining's rmse: 25.7378\tvalid_1's rmse: 54.2078\n",
      "[270]\ttraining's rmse: 23.2767\tvalid_1's rmse: 53.472\n",
      "[300]\ttraining's rmse: 21.1576\tvalid_1's rmse: 52.9136\n",
      "[330]\ttraining's rmse: 19.3719\tvalid_1's rmse: 52.6127\n",
      "[360]\ttraining's rmse: 17.8341\tvalid_1's rmse: 52.3474\n",
      "[390]\ttraining's rmse: 16.4471\tvalid_1's rmse: 52.1379\n",
      "[420]\ttraining's rmse: 15.1964\tvalid_1's rmse: 51.9665\n",
      "[450]\ttraining's rmse: 14.113\tvalid_1's rmse: 51.7977\n",
      "[480]\ttraining's rmse: 13.1084\tvalid_1's rmse: 51.6909\n",
      "[510]\ttraining's rmse: 12.207\tvalid_1's rmse: 51.562\n",
      "[540]\ttraining's rmse: 11.388\tvalid_1's rmse: 51.474\n",
      "[570]\ttraining's rmse: 10.6465\tvalid_1's rmse: 51.3831\n",
      "[600]\ttraining's rmse: 9.96078\tvalid_1's rmse: 51.3273\n",
      "[630]\ttraining's rmse: 9.34188\tvalid_1's rmse: 51.2466\n",
      "[660]\ttraining's rmse: 8.75758\tvalid_1's rmse: 51.1945\n",
      "[690]\ttraining's rmse: 8.22056\tvalid_1's rmse: 51.1561\n",
      "[720]\ttraining's rmse: 7.73333\tvalid_1's rmse: 51.1275\n",
      "[750]\ttraining's rmse: 7.27888\tvalid_1's rmse: 51.0879\n",
      "[780]\ttraining's rmse: 6.84595\tvalid_1's rmse: 51.0658\n",
      "[810]\ttraining's rmse: 6.44956\tvalid_1's rmse: 51.0498\n",
      "[840]\ttraining's rmse: 6.0828\tvalid_1's rmse: 51.0259\n",
      "[870]\ttraining's rmse: 5.74203\tvalid_1's rmse: 51.0035\n",
      "[900]\ttraining's rmse: 5.41981\tvalid_1's rmse: 50.9853\n",
      "[930]\ttraining's rmse: 5.12003\tvalid_1's rmse: 50.9788\n",
      "[960]\ttraining's rmse: 4.83638\tvalid_1's rmse: 50.963\n",
      "[990]\ttraining's rmse: 4.57896\tvalid_1's rmse: 50.9471\n",
      "[1020]\ttraining's rmse: 4.33709\tvalid_1's rmse: 50.9344\n",
      "[1050]\ttraining's rmse: 4.10431\tvalid_1's rmse: 50.9269\n",
      "[1080]\ttraining's rmse: 3.89534\tvalid_1's rmse: 50.9189\n",
      "[1110]\ttraining's rmse: 3.69138\tvalid_1's rmse: 50.913\n",
      "[1140]\ttraining's rmse: 3.50131\tvalid_1's rmse: 50.9058\n",
      "[1170]\ttraining's rmse: 3.32292\tvalid_1's rmse: 50.9021\n",
      "[1200]\ttraining's rmse: 3.15021\tvalid_1's rmse: 50.9016\n",
      "[1230]\ttraining's rmse: 2.99131\tvalid_1's rmse: 50.8949\n",
      "[1260]\ttraining's rmse: 2.84176\tvalid_1's rmse: 50.8857\n",
      "[1290]\ttraining's rmse: 2.7012\tvalid_1's rmse: 50.8819\n",
      "[1320]\ttraining's rmse: 2.56804\tvalid_1's rmse: 50.8757\n",
      "[1350]\ttraining's rmse: 2.44337\tvalid_1's rmse: 50.8716\n",
      "[1380]\ttraining's rmse: 2.32594\tvalid_1's rmse: 50.8682\n",
      "[1410]\ttraining's rmse: 2.21099\tvalid_1's rmse: 50.8671\n",
      "[1440]\ttraining's rmse: 2.10409\tvalid_1's rmse: 50.8668\n",
      "[1470]\ttraining's rmse: 2.00267\tvalid_1's rmse: 50.862\n",
      "[1500]\ttraining's rmse: 1.9071\tvalid_1's rmse: 50.8613\n",
      "[1530]\ttraining's rmse: 1.81698\tvalid_1's rmse: 50.8593\n",
      "[1560]\ttraining's rmse: 1.73249\tvalid_1's rmse: 50.861\n",
      "[1590]\ttraining's rmse: 1.64781\tvalid_1's rmse: 50.8621\n",
      "[1620]\ttraining's rmse: 1.57148\tvalid_1's rmse: 50.8618\n",
      "Early stopping, best iteration is:\n",
      "[1519]\ttraining's rmse: 1.84982\tvalid_1's rmse: 50.8587\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003401 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 20024\n",
      "[LightGBM] [Info] Number of data points in the train set: 9219, number of used features: 79\n",
      "[LightGBM] [Info] Start training from score 358.769873\n",
      "Training until validation scores don't improve for 125 rounds\n",
      "[30]\ttraining's rmse: 155.658\tvalid_1's rmse: 162.218\n",
      "[60]\ttraining's rmse: 97.352\tvalid_1's rmse: 110.12\n",
      "[90]\ttraining's rmse: 65.5598\tvalid_1's rmse: 83.8454\n",
      "[120]\ttraining's rmse: 48.5001\tvalid_1's rmse: 71.4707\n",
      "[150]\ttraining's rmse: 39.0811\tvalid_1's rmse: 65.4308\n",
      "[180]\ttraining's rmse: 33.2879\tvalid_1's rmse: 62.1331\n",
      "[210]\ttraining's rmse: 29.2614\tvalid_1's rmse: 60.0992\n",
      "[240]\ttraining's rmse: 26.1294\tvalid_1's rmse: 58.8673\n",
      "[270]\ttraining's rmse: 23.6443\tvalid_1's rmse: 58.0666\n",
      "[300]\ttraining's rmse: 21.5425\tvalid_1's rmse: 57.5455\n",
      "[330]\ttraining's rmse: 19.7686\tvalid_1's rmse: 57.0872\n",
      "[360]\ttraining's rmse: 18.1889\tvalid_1's rmse: 56.8065\n",
      "[390]\ttraining's rmse: 16.8079\tvalid_1's rmse: 56.5702\n",
      "[420]\ttraining's rmse: 15.5569\tvalid_1's rmse: 56.4295\n",
      "[450]\ttraining's rmse: 14.4142\tvalid_1's rmse: 56.2663\n",
      "[480]\ttraining's rmse: 13.397\tvalid_1's rmse: 56.118\n",
      "[510]\ttraining's rmse: 12.4838\tvalid_1's rmse: 56.0117\n",
      "[540]\ttraining's rmse: 11.6467\tvalid_1's rmse: 55.8931\n",
      "[570]\ttraining's rmse: 10.8905\tvalid_1's rmse: 55.7948\n",
      "[600]\ttraining's rmse: 10.1963\tvalid_1's rmse: 55.6983\n",
      "[630]\ttraining's rmse: 9.55078\tvalid_1's rmse: 55.6415\n",
      "[660]\ttraining's rmse: 8.95716\tvalid_1's rmse: 55.5795\n",
      "[690]\ttraining's rmse: 8.40863\tvalid_1's rmse: 55.5432\n",
      "[720]\ttraining's rmse: 7.90412\tvalid_1's rmse: 55.4842\n",
      "[750]\ttraining's rmse: 7.43509\tvalid_1's rmse: 55.4549\n",
      "[780]\ttraining's rmse: 6.99173\tvalid_1's rmse: 55.4303\n",
      "[810]\ttraining's rmse: 6.58261\tvalid_1's rmse: 55.3947\n",
      "[840]\ttraining's rmse: 6.20707\tvalid_1's rmse: 55.3703\n",
      "[870]\ttraining's rmse: 5.85114\tvalid_1's rmse: 55.3484\n",
      "[900]\ttraining's rmse: 5.52685\tvalid_1's rmse: 55.3285\n",
      "[930]\ttraining's rmse: 5.22384\tvalid_1's rmse: 55.3058\n",
      "[960]\ttraining's rmse: 4.93637\tvalid_1's rmse: 55.2873\n",
      "[990]\ttraining's rmse: 4.66814\tvalid_1's rmse: 55.2836\n",
      "[1020]\ttraining's rmse: 4.41688\tvalid_1's rmse: 55.2769\n",
      "[1050]\ttraining's rmse: 4.18156\tvalid_1's rmse: 55.2623\n",
      "[1080]\ttraining's rmse: 3.95581\tvalid_1's rmse: 55.2585\n",
      "[1110]\ttraining's rmse: 3.74302\tvalid_1's rmse: 55.2419\n",
      "[1140]\ttraining's rmse: 3.54677\tvalid_1's rmse: 55.2334\n",
      "[1170]\ttraining's rmse: 3.36328\tvalid_1's rmse: 55.2244\n",
      "[1200]\ttraining's rmse: 3.18876\tvalid_1's rmse: 55.2217\n",
      "[1230]\ttraining's rmse: 3.02314\tvalid_1's rmse: 55.2155\n",
      "[1260]\ttraining's rmse: 2.86514\tvalid_1's rmse: 55.2151\n",
      "[1290]\ttraining's rmse: 2.72072\tvalid_1's rmse: 55.2054\n",
      "[1320]\ttraining's rmse: 2.58492\tvalid_1's rmse: 55.2024\n",
      "[1350]\ttraining's rmse: 2.45665\tvalid_1's rmse: 55.1968\n",
      "[1380]\ttraining's rmse: 2.33633\tvalid_1's rmse: 55.194\n",
      "[1410]\ttraining's rmse: 2.22041\tvalid_1's rmse: 55.1887\n",
      "[1440]\ttraining's rmse: 2.11067\tvalid_1's rmse: 55.1838\n",
      "[1470]\ttraining's rmse: 2.00619\tvalid_1's rmse: 55.1797\n",
      "[1500]\ttraining's rmse: 1.90863\tvalid_1's rmse: 55.1765\n",
      "[1530]\ttraining's rmse: 1.81637\tvalid_1's rmse: 55.1786\n",
      "[1560]\ttraining's rmse: 1.73074\tvalid_1's rmse: 55.1735\n",
      "[1590]\ttraining's rmse: 1.64488\tvalid_1's rmse: 55.1694\n",
      "[1620]\ttraining's rmse: 1.56775\tvalid_1's rmse: 55.1698\n",
      "[1650]\ttraining's rmse: 1.49583\tvalid_1's rmse: 55.1686\n",
      "[1680]\ttraining's rmse: 1.42512\tvalid_1's rmse: 55.1669\n",
      "[1710]\ttraining's rmse: 1.35833\tvalid_1's rmse: 55.1633\n",
      "[1740]\ttraining's rmse: 1.29233\tvalid_1's rmse: 55.1619\n",
      "[1770]\ttraining's rmse: 1.23181\tvalid_1's rmse: 55.1595\n",
      "[1800]\ttraining's rmse: 1.17473\tvalid_1's rmse: 55.1589\n",
      "[1830]\ttraining's rmse: 1.12113\tvalid_1's rmse: 55.1577\n",
      "[1860]\ttraining's rmse: 1.06927\tvalid_1's rmse: 55.1559\n",
      "[1890]\ttraining's rmse: 1.02112\tvalid_1's rmse: 55.1551\n",
      "[1920]\ttraining's rmse: 0.97411\tvalid_1's rmse: 55.1536\n",
      "[1950]\ttraining's rmse: 0.930016\tvalid_1's rmse: 55.1531\n",
      "[1980]\ttraining's rmse: 0.887144\tvalid_1's rmse: 55.1527\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's rmse: 0.861253\tvalid_1's rmse: 55.1524\n",
      "25\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003905 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 20024\n",
      "[LightGBM] [Info] Number of data points in the train set: 9219, number of used features: 79\n",
      "[LightGBM] [Info] Start training from score 368.804320\n",
      "Training until validation scores don't improve for 125 rounds\n",
      "[30]\ttraining's rmse: 156.135\tvalid_1's rmse: 154.605\n",
      "[60]\ttraining's rmse: 96.6984\tvalid_1's rmse: 103.618\n",
      "[90]\ttraining's rmse: 64.6932\tvalid_1's rmse: 79.1166\n",
      "[120]\ttraining's rmse: 47.5518\tvalid_1's rmse: 67.8937\n",
      "[150]\ttraining's rmse: 37.9908\tvalid_1's rmse: 62.1646\n",
      "[180]\ttraining's rmse: 32.2437\tvalid_1's rmse: 59.2519\n",
      "[210]\ttraining's rmse: 28.2977\tvalid_1's rmse: 57.4531\n",
      "[240]\ttraining's rmse: 25.223\tvalid_1's rmse: 56.1792\n",
      "[270]\ttraining's rmse: 22.702\tvalid_1's rmse: 55.2399\n",
      "[300]\ttraining's rmse: 20.7196\tvalid_1's rmse: 54.6543\n",
      "[330]\ttraining's rmse: 19.0066\tvalid_1's rmse: 54.2561\n",
      "[360]\ttraining's rmse: 17.4933\tvalid_1's rmse: 53.9716\n",
      "[390]\ttraining's rmse: 16.1598\tvalid_1's rmse: 53.7331\n",
      "[420]\ttraining's rmse: 14.9907\tvalid_1's rmse: 53.6077\n",
      "[450]\ttraining's rmse: 13.9166\tvalid_1's rmse: 53.4776\n",
      "[480]\ttraining's rmse: 12.9441\tvalid_1's rmse: 53.3455\n",
      "[510]\ttraining's rmse: 12.0577\tvalid_1's rmse: 53.2404\n",
      "[540]\ttraining's rmse: 11.2495\tvalid_1's rmse: 53.2222\n",
      "[570]\ttraining's rmse: 10.5299\tvalid_1's rmse: 53.1775\n",
      "[600]\ttraining's rmse: 9.86604\tvalid_1's rmse: 53.0965\n",
      "[630]\ttraining's rmse: 9.25039\tvalid_1's rmse: 53.0428\n",
      "[660]\ttraining's rmse: 8.68183\tvalid_1's rmse: 52.9946\n",
      "[690]\ttraining's rmse: 8.16264\tvalid_1's rmse: 52.9727\n",
      "[720]\ttraining's rmse: 7.67211\tvalid_1's rmse: 52.9462\n",
      "[750]\ttraining's rmse: 7.22379\tvalid_1's rmse: 52.9028\n",
      "[780]\ttraining's rmse: 6.7979\tvalid_1's rmse: 52.9004\n",
      "[810]\ttraining's rmse: 6.40934\tvalid_1's rmse: 52.878\n",
      "[840]\ttraining's rmse: 6.04815\tvalid_1's rmse: 52.8593\n",
      "[870]\ttraining's rmse: 5.71878\tvalid_1's rmse: 52.8229\n",
      "[900]\ttraining's rmse: 5.39497\tvalid_1's rmse: 52.8109\n",
      "[930]\ttraining's rmse: 5.10805\tvalid_1's rmse: 52.7967\n",
      "[960]\ttraining's rmse: 4.8274\tvalid_1's rmse: 52.7897\n",
      "[990]\ttraining's rmse: 4.56607\tvalid_1's rmse: 52.7777\n",
      "[1020]\ttraining's rmse: 4.32155\tvalid_1's rmse: 52.7734\n",
      "[1050]\ttraining's rmse: 4.09477\tvalid_1's rmse: 52.7592\n",
      "[1080]\ttraining's rmse: 3.87404\tvalid_1's rmse: 52.761\n",
      "[1110]\ttraining's rmse: 3.67263\tvalid_1's rmse: 52.7533\n",
      "[1140]\ttraining's rmse: 3.48062\tvalid_1's rmse: 52.7518\n",
      "[1170]\ttraining's rmse: 3.30022\tvalid_1's rmse: 52.7437\n",
      "[1200]\ttraining's rmse: 3.13072\tvalid_1's rmse: 52.7449\n",
      "[1230]\ttraining's rmse: 2.96823\tvalid_1's rmse: 52.7453\n",
      "[1260]\ttraining's rmse: 2.81936\tvalid_1's rmse: 52.7369\n",
      "[1290]\ttraining's rmse: 2.6803\tvalid_1's rmse: 52.7398\n",
      "[1320]\ttraining's rmse: 2.54703\tvalid_1's rmse: 52.7367\n",
      "[1350]\ttraining's rmse: 2.42047\tvalid_1's rmse: 52.7278\n",
      "[1380]\ttraining's rmse: 2.2972\tvalid_1's rmse: 52.7202\n",
      "[1410]\ttraining's rmse: 2.1851\tvalid_1's rmse: 52.7243\n",
      "[1440]\ttraining's rmse: 2.0798\tvalid_1's rmse: 52.7205\n",
      "[1470]\ttraining's rmse: 1.97683\tvalid_1's rmse: 52.7185\n",
      "[1500]\ttraining's rmse: 1.88212\tvalid_1's rmse: 52.714\n",
      "[1530]\ttraining's rmse: 1.79063\tvalid_1's rmse: 52.7091\n",
      "[1560]\ttraining's rmse: 1.70103\tvalid_1's rmse: 52.7055\n",
      "[1590]\ttraining's rmse: 1.6207\tvalid_1's rmse: 52.7056\n",
      "[1620]\ttraining's rmse: 1.54403\tvalid_1's rmse: 52.7004\n",
      "[1650]\ttraining's rmse: 1.47291\tvalid_1's rmse: 52.6993\n",
      "[1680]\ttraining's rmse: 1.40341\tvalid_1's rmse: 52.6968\n",
      "[1710]\ttraining's rmse: 1.33758\tvalid_1's rmse: 52.6943\n",
      "[1740]\ttraining's rmse: 1.27663\tvalid_1's rmse: 52.691\n",
      "[1770]\ttraining's rmse: 1.21789\tvalid_1's rmse: 52.6905\n",
      "[1800]\ttraining's rmse: 1.16174\tvalid_1's rmse: 52.6897\n",
      "[1830]\ttraining's rmse: 1.10797\tvalid_1's rmse: 52.6906\n",
      "[1860]\ttraining's rmse: 1.05622\tvalid_1's rmse: 52.6906\n",
      "[1890]\ttraining's rmse: 1.00785\tvalid_1's rmse: 52.6902\n",
      "[1920]\ttraining's rmse: 0.961094\tvalid_1's rmse: 52.6892\n",
      "[1950]\ttraining's rmse: 0.916768\tvalid_1's rmse: 52.69\n",
      "[1980]\ttraining's rmse: 0.876569\tvalid_1's rmse: 52.6901\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's rmse: 0.849627\tvalid_1's rmse: 52.6888\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003325 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 20024\n",
      "[LightGBM] [Info] Number of data points in the train set: 9219, number of used features: 79\n",
      "[LightGBM] [Info] Start training from score 367.769424\n",
      "Training until validation scores don't improve for 125 rounds\n",
      "[30]\ttraining's rmse: 156.465\tvalid_1's rmse: 157.274\n",
      "[60]\ttraining's rmse: 98.0706\tvalid_1's rmse: 106.289\n",
      "[90]\ttraining's rmse: 66.5819\tvalid_1's rmse: 82.0543\n",
      "[120]\ttraining's rmse: 49.4193\tvalid_1's rmse: 70.4821\n",
      "[150]\ttraining's rmse: 39.6897\tvalid_1's rmse: 64.9831\n",
      "[180]\ttraining's rmse: 33.6441\tvalid_1's rmse: 62.0003\n",
      "[210]\ttraining's rmse: 29.5353\tvalid_1's rmse: 60.1455\n",
      "[240]\ttraining's rmse: 26.3725\tvalid_1's rmse: 58.9456\n",
      "[270]\ttraining's rmse: 23.7503\tvalid_1's rmse: 57.937\n",
      "[300]\ttraining's rmse: 21.5475\tvalid_1's rmse: 57.1654\n",
      "[330]\ttraining's rmse: 19.6697\tvalid_1's rmse: 56.6269\n",
      "[360]\ttraining's rmse: 18.0697\tvalid_1's rmse: 56.2445\n",
      "[390]\ttraining's rmse: 16.6342\tvalid_1's rmse: 55.9215\n",
      "[420]\ttraining's rmse: 15.3878\tvalid_1's rmse: 55.6786\n",
      "[450]\ttraining's rmse: 14.254\tvalid_1's rmse: 55.495\n",
      "[480]\ttraining's rmse: 13.2277\tvalid_1's rmse: 55.3187\n",
      "[510]\ttraining's rmse: 12.2968\tvalid_1's rmse: 55.1577\n",
      "[540]\ttraining's rmse: 11.4567\tvalid_1's rmse: 55.0435\n",
      "[570]\ttraining's rmse: 10.6735\tvalid_1's rmse: 54.8989\n",
      "[600]\ttraining's rmse: 9.96737\tvalid_1's rmse: 54.8148\n",
      "[630]\ttraining's rmse: 9.3176\tvalid_1's rmse: 54.7248\n",
      "[660]\ttraining's rmse: 8.72635\tvalid_1's rmse: 54.6642\n",
      "[690]\ttraining's rmse: 8.18235\tvalid_1's rmse: 54.6269\n",
      "[720]\ttraining's rmse: 7.68316\tvalid_1's rmse: 54.5988\n",
      "[750]\ttraining's rmse: 7.22663\tvalid_1's rmse: 54.5487\n",
      "[780]\ttraining's rmse: 6.79541\tvalid_1's rmse: 54.5002\n",
      "[810]\ttraining's rmse: 6.3813\tvalid_1's rmse: 54.4537\n",
      "[840]\ttraining's rmse: 6.01254\tvalid_1's rmse: 54.4127\n",
      "[870]\ttraining's rmse: 5.6597\tvalid_1's rmse: 54.3719\n",
      "[900]\ttraining's rmse: 5.33358\tvalid_1's rmse: 54.3524\n",
      "[930]\ttraining's rmse: 5.03538\tvalid_1's rmse: 54.3269\n",
      "[960]\ttraining's rmse: 4.74985\tvalid_1's rmse: 54.3071\n",
      "[990]\ttraining's rmse: 4.48339\tvalid_1's rmse: 54.2851\n",
      "[1020]\ttraining's rmse: 4.24149\tvalid_1's rmse: 54.2699\n",
      "[1050]\ttraining's rmse: 4.00787\tvalid_1's rmse: 54.264\n",
      "[1080]\ttraining's rmse: 3.78598\tvalid_1's rmse: 54.2462\n",
      "[1110]\ttraining's rmse: 3.57746\tvalid_1's rmse: 54.2373\n",
      "[1140]\ttraining's rmse: 3.38669\tvalid_1's rmse: 54.2255\n",
      "[1170]\ttraining's rmse: 3.20272\tvalid_1's rmse: 54.2134\n",
      "[1200]\ttraining's rmse: 3.03302\tvalid_1's rmse: 54.2051\n",
      "[1230]\ttraining's rmse: 2.87218\tvalid_1's rmse: 54.1987\n",
      "[1260]\ttraining's rmse: 2.71997\tvalid_1's rmse: 54.1963\n",
      "[1290]\ttraining's rmse: 2.57583\tvalid_1's rmse: 54.1844\n",
      "[1320]\ttraining's rmse: 2.43971\tvalid_1's rmse: 54.1798\n",
      "[1350]\ttraining's rmse: 2.3113\tvalid_1's rmse: 54.1734\n",
      "[1380]\ttraining's rmse: 2.1902\tvalid_1's rmse: 54.1685\n",
      "[1410]\ttraining's rmse: 2.07874\tvalid_1's rmse: 54.1603\n",
      "[1440]\ttraining's rmse: 1.97376\tvalid_1's rmse: 54.1559\n",
      "[1470]\ttraining's rmse: 1.86941\tvalid_1's rmse: 54.1535\n",
      "[1500]\ttraining's rmse: 1.77531\tvalid_1's rmse: 54.1473\n",
      "[1530]\ttraining's rmse: 1.6848\tvalid_1's rmse: 54.1407\n",
      "[1560]\ttraining's rmse: 1.60008\tvalid_1's rmse: 54.1366\n",
      "[1590]\ttraining's rmse: 1.51938\tvalid_1's rmse: 54.1305\n",
      "[1620]\ttraining's rmse: 1.44391\tvalid_1's rmse: 54.1241\n",
      "[1650]\ttraining's rmse: 1.37164\tvalid_1's rmse: 54.1217\n",
      "[1680]\ttraining's rmse: 1.30369\tvalid_1's rmse: 54.119\n",
      "[1710]\ttraining's rmse: 1.239\tvalid_1's rmse: 54.1141\n",
      "[1740]\ttraining's rmse: 1.17877\tvalid_1's rmse: 54.1128\n",
      "[1770]\ttraining's rmse: 1.11875\tvalid_1's rmse: 54.1084\n",
      "[1800]\ttraining's rmse: 1.06439\tvalid_1's rmse: 54.1039\n",
      "[1830]\ttraining's rmse: 1.01129\tvalid_1's rmse: 54.0998\n",
      "[1860]\ttraining's rmse: 0.963122\tvalid_1's rmse: 54.0966\n",
      "[1890]\ttraining's rmse: 0.916229\tvalid_1's rmse: 54.093\n",
      "[1920]\ttraining's rmse: 0.871944\tvalid_1's rmse: 54.0912\n",
      "[1950]\ttraining's rmse: 0.830191\tvalid_1's rmse: 54.0906\n",
      "[1980]\ttraining's rmse: 0.790981\tvalid_1's rmse: 54.0873\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's rmse: 0.765487\tvalid_1's rmse: 54.0854\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003342 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 20024\n",
      "[LightGBM] [Info] Number of data points in the train set: 9219, number of used features: 79\n",
      "[LightGBM] [Info] Start training from score 360.131644\n",
      "Training until validation scores don't improve for 125 rounds\n",
      "[30]\ttraining's rmse: 155.363\tvalid_1's rmse: 165.1\n",
      "[60]\ttraining's rmse: 97.2474\tvalid_1's rmse: 110.524\n",
      "[90]\ttraining's rmse: 65.7455\tvalid_1's rmse: 83.7247\n",
      "[120]\ttraining's rmse: 48.7399\tvalid_1's rmse: 71.1357\n",
      "[150]\ttraining's rmse: 39.2591\tvalid_1's rmse: 65.3598\n",
      "[180]\ttraining's rmse: 33.3832\tvalid_1's rmse: 62.2692\n",
      "[210]\ttraining's rmse: 29.2433\tvalid_1's rmse: 60.5386\n",
      "[240]\ttraining's rmse: 26.129\tvalid_1's rmse: 59.4155\n",
      "[270]\ttraining's rmse: 23.583\tvalid_1's rmse: 58.5975\n",
      "[300]\ttraining's rmse: 21.4201\tvalid_1's rmse: 58.0243\n",
      "[330]\ttraining's rmse: 19.5979\tvalid_1's rmse: 57.6116\n",
      "[360]\ttraining's rmse: 18.0055\tvalid_1's rmse: 57.2768\n",
      "[390]\ttraining's rmse: 16.593\tvalid_1's rmse: 56.9871\n",
      "[420]\ttraining's rmse: 15.3607\tvalid_1's rmse: 56.7577\n",
      "[450]\ttraining's rmse: 14.2482\tvalid_1's rmse: 56.6073\n",
      "[480]\ttraining's rmse: 13.2318\tvalid_1's rmse: 56.4495\n",
      "[510]\ttraining's rmse: 12.3243\tvalid_1's rmse: 56.3349\n",
      "[540]\ttraining's rmse: 11.4823\tvalid_1's rmse: 56.2345\n",
      "[570]\ttraining's rmse: 10.7283\tvalid_1's rmse: 56.1334\n",
      "[600]\ttraining's rmse: 10.0305\tvalid_1's rmse: 56.0439\n",
      "[630]\ttraining's rmse: 9.38308\tvalid_1's rmse: 55.9684\n",
      "[660]\ttraining's rmse: 8.78894\tvalid_1's rmse: 55.916\n",
      "[690]\ttraining's rmse: 8.23041\tvalid_1's rmse: 55.865\n",
      "[720]\ttraining's rmse: 7.73315\tvalid_1's rmse: 55.8145\n",
      "[750]\ttraining's rmse: 7.27225\tvalid_1's rmse: 55.7938\n",
      "[780]\ttraining's rmse: 6.83742\tvalid_1's rmse: 55.7615\n",
      "[810]\ttraining's rmse: 6.4326\tvalid_1's rmse: 55.747\n",
      "[840]\ttraining's rmse: 6.05901\tvalid_1's rmse: 55.7214\n",
      "[870]\ttraining's rmse: 5.7083\tvalid_1's rmse: 55.6918\n",
      "[900]\ttraining's rmse: 5.38491\tvalid_1's rmse: 55.6683\n",
      "[930]\ttraining's rmse: 5.08349\tvalid_1's rmse: 55.6555\n",
      "[960]\ttraining's rmse: 4.79657\tvalid_1's rmse: 55.639\n",
      "[990]\ttraining's rmse: 4.53912\tvalid_1's rmse: 55.6303\n",
      "[1020]\ttraining's rmse: 4.29481\tvalid_1's rmse: 55.618\n",
      "[1050]\ttraining's rmse: 4.06095\tvalid_1's rmse: 55.6068\n",
      "[1080]\ttraining's rmse: 3.8381\tvalid_1's rmse: 55.591\n",
      "[1110]\ttraining's rmse: 3.62768\tvalid_1's rmse: 55.579\n",
      "[1140]\ttraining's rmse: 3.43214\tvalid_1's rmse: 55.5666\n",
      "[1170]\ttraining's rmse: 3.25146\tvalid_1's rmse: 55.5543\n",
      "[1200]\ttraining's rmse: 3.07755\tvalid_1's rmse: 55.5474\n",
      "[1230]\ttraining's rmse: 2.91408\tvalid_1's rmse: 55.5394\n",
      "[1260]\ttraining's rmse: 2.76163\tvalid_1's rmse: 55.5329\n",
      "[1290]\ttraining's rmse: 2.61639\tvalid_1's rmse: 55.5262\n",
      "[1320]\ttraining's rmse: 2.48431\tvalid_1's rmse: 55.5169\n",
      "[1350]\ttraining's rmse: 2.35492\tvalid_1's rmse: 55.5064\n",
      "[1380]\ttraining's rmse: 2.23502\tvalid_1's rmse: 55.5026\n",
      "[1410]\ttraining's rmse: 2.12205\tvalid_1's rmse: 55.502\n",
      "[1440]\ttraining's rmse: 2.0174\tvalid_1's rmse: 55.4959\n",
      "[1470]\ttraining's rmse: 1.9173\tvalid_1's rmse: 55.4907\n",
      "[1500]\ttraining's rmse: 1.81847\tvalid_1's rmse: 55.4855\n",
      "[1530]\ttraining's rmse: 1.72917\tvalid_1's rmse: 55.4835\n",
      "[1560]\ttraining's rmse: 1.64254\tvalid_1's rmse: 55.4802\n",
      "[1590]\ttraining's rmse: 1.56076\tvalid_1's rmse: 55.478\n",
      "[1620]\ttraining's rmse: 1.48478\tvalid_1's rmse: 55.4765\n",
      "[1650]\ttraining's rmse: 1.41145\tvalid_1's rmse: 55.4785\n",
      "[1680]\ttraining's rmse: 1.34123\tvalid_1's rmse: 55.4749\n",
      "[1710]\ttraining's rmse: 1.27585\tvalid_1's rmse: 55.4751\n",
      "[1740]\ttraining's rmse: 1.21393\tvalid_1's rmse: 55.4766\n",
      "[1770]\ttraining's rmse: 1.15417\tvalid_1's rmse: 55.4748\n",
      "[1800]\ttraining's rmse: 1.09882\tvalid_1's rmse: 55.4746\n",
      "[1830]\ttraining's rmse: 1.04603\tvalid_1's rmse: 55.4739\n",
      "[1860]\ttraining's rmse: 0.995718\tvalid_1's rmse: 55.4745\n",
      "[1890]\ttraining's rmse: 0.948593\tvalid_1's rmse: 55.4735\n",
      "[1920]\ttraining's rmse: 0.904198\tvalid_1's rmse: 55.4712\n",
      "[1950]\ttraining's rmse: 0.860754\tvalid_1's rmse: 55.4691\n",
      "[1980]\ttraining's rmse: 0.820553\tvalid_1's rmse: 55.4677\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's rmse: 0.794524\tvalid_1's rmse: 55.4664\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002846 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 20024\n",
      "[LightGBM] [Info] Number of data points in the train set: 9219, number of used features: 79\n",
      "[LightGBM] [Info] Start training from score 360.035562\n",
      "Training until validation scores don't improve for 125 rounds\n",
      "[30]\ttraining's rmse: 156.362\tvalid_1's rmse: 163.056\n",
      "[60]\ttraining's rmse: 97.7818\tvalid_1's rmse: 109.416\n",
      "[90]\ttraining's rmse: 66.18\tvalid_1's rmse: 82.6971\n",
      "[120]\ttraining's rmse: 49.1415\tvalid_1's rmse: 70.1699\n",
      "[150]\ttraining's rmse: 39.4834\tvalid_1's rmse: 64.0171\n",
      "[180]\ttraining's rmse: 33.45\tvalid_1's rmse: 60.8919\n",
      "[210]\ttraining's rmse: 29.3177\tvalid_1's rmse: 59.0994\n",
      "[240]\ttraining's rmse: 26.1617\tvalid_1's rmse: 57.9372\n",
      "[270]\ttraining's rmse: 23.6083\tvalid_1's rmse: 57.1521\n",
      "[300]\ttraining's rmse: 21.4452\tvalid_1's rmse: 56.5763\n",
      "[330]\ttraining's rmse: 19.5733\tvalid_1's rmse: 56.08\n",
      "[360]\ttraining's rmse: 18.0007\tvalid_1's rmse: 55.7747\n",
      "[390]\ttraining's rmse: 16.5631\tvalid_1's rmse: 55.471\n",
      "[420]\ttraining's rmse: 15.3381\tvalid_1's rmse: 55.2795\n",
      "[450]\ttraining's rmse: 14.223\tvalid_1's rmse: 55.0828\n",
      "[480]\ttraining's rmse: 13.2093\tvalid_1's rmse: 54.9153\n",
      "[510]\ttraining's rmse: 12.299\tvalid_1's rmse: 54.7649\n",
      "[540]\ttraining's rmse: 11.4613\tvalid_1's rmse: 54.6852\n",
      "[570]\ttraining's rmse: 10.7066\tvalid_1's rmse: 54.6046\n",
      "[600]\ttraining's rmse: 10.0232\tvalid_1's rmse: 54.5422\n",
      "[630]\ttraining's rmse: 9.38266\tvalid_1's rmse: 54.4899\n",
      "[660]\ttraining's rmse: 8.80118\tvalid_1's rmse: 54.4436\n",
      "[690]\ttraining's rmse: 8.26577\tvalid_1's rmse: 54.3942\n",
      "[720]\ttraining's rmse: 7.77344\tvalid_1's rmse: 54.3431\n",
      "[750]\ttraining's rmse: 7.31147\tvalid_1's rmse: 54.3102\n",
      "[780]\ttraining's rmse: 6.88261\tvalid_1's rmse: 54.2694\n",
      "[810]\ttraining's rmse: 6.48978\tvalid_1's rmse: 54.2463\n",
      "[840]\ttraining's rmse: 6.10963\tvalid_1's rmse: 54.2217\n",
      "[870]\ttraining's rmse: 5.75909\tvalid_1's rmse: 54.1875\n",
      "[900]\ttraining's rmse: 5.42597\tvalid_1's rmse: 54.1596\n",
      "[930]\ttraining's rmse: 5.12744\tvalid_1's rmse: 54.1386\n",
      "[960]\ttraining's rmse: 4.83992\tvalid_1's rmse: 54.114\n",
      "[990]\ttraining's rmse: 4.58111\tvalid_1's rmse: 54.1025\n",
      "[1020]\ttraining's rmse: 4.33164\tvalid_1's rmse: 54.0911\n",
      "[1050]\ttraining's rmse: 4.09544\tvalid_1's rmse: 54.076\n",
      "[1080]\ttraining's rmse: 3.87858\tvalid_1's rmse: 54.0631\n",
      "[1110]\ttraining's rmse: 3.66834\tvalid_1's rmse: 54.0559\n",
      "[1140]\ttraining's rmse: 3.47402\tvalid_1's rmse: 54.0453\n",
      "[1170]\ttraining's rmse: 3.29144\tvalid_1's rmse: 54.0309\n",
      "[1200]\ttraining's rmse: 3.11985\tvalid_1's rmse: 54.025\n",
      "[1230]\ttraining's rmse: 2.95999\tvalid_1's rmse: 54.0114\n",
      "[1260]\ttraining's rmse: 2.80532\tvalid_1's rmse: 54.0078\n",
      "[1290]\ttraining's rmse: 2.66056\tvalid_1's rmse: 54.0059\n",
      "[1320]\ttraining's rmse: 2.5237\tvalid_1's rmse: 54.0032\n",
      "[1350]\ttraining's rmse: 2.3945\tvalid_1's rmse: 53.9997\n",
      "[1380]\ttraining's rmse: 2.27354\tvalid_1's rmse: 53.9974\n",
      "[1410]\ttraining's rmse: 2.15983\tvalid_1's rmse: 53.9956\n",
      "[1440]\ttraining's rmse: 2.05168\tvalid_1's rmse: 53.9946\n",
      "[1470]\ttraining's rmse: 1.95042\tvalid_1's rmse: 53.9889\n",
      "[1500]\ttraining's rmse: 1.85529\tvalid_1's rmse: 53.9835\n",
      "[1530]\ttraining's rmse: 1.76463\tvalid_1's rmse: 53.9796\n",
      "[1560]\ttraining's rmse: 1.67961\tvalid_1's rmse: 53.976\n",
      "[1590]\ttraining's rmse: 1.59694\tvalid_1's rmse: 53.9728\n",
      "[1620]\ttraining's rmse: 1.51942\tvalid_1's rmse: 53.9715\n",
      "[1650]\ttraining's rmse: 1.44421\tvalid_1's rmse: 53.9723\n",
      "[1680]\ttraining's rmse: 1.37306\tvalid_1's rmse: 53.9678\n",
      "[1710]\ttraining's rmse: 1.30742\tvalid_1's rmse: 53.9667\n",
      "[1740]\ttraining's rmse: 1.24615\tvalid_1's rmse: 53.9631\n",
      "[1770]\ttraining's rmse: 1.18719\tvalid_1's rmse: 53.9585\n",
      "[1800]\ttraining's rmse: 1.13222\tvalid_1's rmse: 53.9575\n",
      "[1830]\ttraining's rmse: 1.07726\tvalid_1's rmse: 53.9565\n",
      "[1860]\ttraining's rmse: 1.02546\tvalid_1's rmse: 53.9544\n",
      "[1890]\ttraining's rmse: 0.977549\tvalid_1's rmse: 53.9518\n",
      "[1920]\ttraining's rmse: 0.930733\tvalid_1's rmse: 53.9491\n",
      "[1950]\ttraining's rmse: 0.886446\tvalid_1's rmse: 53.9498\n",
      "[1980]\ttraining's rmse: 0.845551\tvalid_1's rmse: 53.9475\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's rmse: 0.818811\tvalid_1's rmse: 53.9465\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002321 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 20024\n",
      "[LightGBM] [Info] Number of data points in the train set: 9219, number of used features: 79\n",
      "[LightGBM] [Info] Start training from score 365.545418\n",
      "Training until validation scores don't improve for 125 rounds\n",
      "[30]\ttraining's rmse: 155.578\tvalid_1's rmse: 157.383\n",
      "[60]\ttraining's rmse: 97.0828\tvalid_1's rmse: 105.905\n",
      "[90]\ttraining's rmse: 65.7308\tvalid_1's rmse: 80.9815\n",
      "[120]\ttraining's rmse: 48.9054\tvalid_1's rmse: 69.4069\n",
      "[150]\ttraining's rmse: 39.3775\tvalid_1's rmse: 63.6661\n",
      "[180]\ttraining's rmse: 33.4871\tvalid_1's rmse: 60.7206\n",
      "[210]\ttraining's rmse: 29.4183\tvalid_1's rmse: 58.9618\n",
      "[240]\ttraining's rmse: 26.2883\tvalid_1's rmse: 57.8981\n",
      "[270]\ttraining's rmse: 23.7209\tvalid_1's rmse: 57.1775\n",
      "[300]\ttraining's rmse: 21.5835\tvalid_1's rmse: 56.6915\n",
      "[330]\ttraining's rmse: 19.7477\tvalid_1's rmse: 56.265\n",
      "[360]\ttraining's rmse: 18.1689\tvalid_1's rmse: 55.8871\n",
      "[390]\ttraining's rmse: 16.7621\tvalid_1's rmse: 55.5902\n",
      "[420]\ttraining's rmse: 15.5094\tvalid_1's rmse: 55.3589\n",
      "[450]\ttraining's rmse: 14.3955\tvalid_1's rmse: 55.1879\n",
      "[480]\ttraining's rmse: 13.3873\tvalid_1's rmse: 55.0029\n",
      "[510]\ttraining's rmse: 12.4681\tvalid_1's rmse: 54.8803\n",
      "[540]\ttraining's rmse: 11.6322\tvalid_1's rmse: 54.7692\n",
      "[570]\ttraining's rmse: 10.8736\tvalid_1's rmse: 54.6827\n",
      "[600]\ttraining's rmse: 10.168\tvalid_1's rmse: 54.5917\n",
      "[630]\ttraining's rmse: 9.5344\tvalid_1's rmse: 54.5375\n",
      "[660]\ttraining's rmse: 8.93648\tvalid_1's rmse: 54.4739\n",
      "[690]\ttraining's rmse: 8.37458\tvalid_1's rmse: 54.4064\n",
      "[720]\ttraining's rmse: 7.86963\tvalid_1's rmse: 54.3678\n",
      "[750]\ttraining's rmse: 7.40001\tvalid_1's rmse: 54.3267\n",
      "[780]\ttraining's rmse: 6.9599\tvalid_1's rmse: 54.2889\n",
      "[810]\ttraining's rmse: 6.54838\tvalid_1's rmse: 54.2511\n",
      "[840]\ttraining's rmse: 6.1699\tvalid_1's rmse: 54.2215\n",
      "[870]\ttraining's rmse: 5.81387\tvalid_1's rmse: 54.2036\n",
      "[900]\ttraining's rmse: 5.48427\tvalid_1's rmse: 54.184\n",
      "[930]\ttraining's rmse: 5.17431\tvalid_1's rmse: 54.1745\n",
      "[960]\ttraining's rmse: 4.88674\tvalid_1's rmse: 54.1579\n",
      "[990]\ttraining's rmse: 4.62263\tvalid_1's rmse: 54.1361\n",
      "[1020]\ttraining's rmse: 4.3671\tvalid_1's rmse: 54.1142\n",
      "[1050]\ttraining's rmse: 4.13059\tvalid_1's rmse: 54.1003\n",
      "[1080]\ttraining's rmse: 3.90972\tvalid_1's rmse: 54.0914\n",
      "[1110]\ttraining's rmse: 3.70046\tvalid_1's rmse: 54.0779\n",
      "[1140]\ttraining's rmse: 3.49986\tvalid_1's rmse: 54.0636\n",
      "[1170]\ttraining's rmse: 3.31565\tvalid_1's rmse: 54.0519\n",
      "[1200]\ttraining's rmse: 3.1424\tvalid_1's rmse: 54.0336\n",
      "[1230]\ttraining's rmse: 2.9792\tvalid_1's rmse: 54.0223\n",
      "[1260]\ttraining's rmse: 2.82498\tvalid_1's rmse: 54.0141\n",
      "[1290]\ttraining's rmse: 2.68019\tvalid_1's rmse: 54.0033\n",
      "[1320]\ttraining's rmse: 2.54049\tvalid_1's rmse: 54.0004\n",
      "[1350]\ttraining's rmse: 2.41013\tvalid_1's rmse: 53.9903\n",
      "[1380]\ttraining's rmse: 2.28721\tvalid_1's rmse: 53.9862\n",
      "[1410]\ttraining's rmse: 2.17203\tvalid_1's rmse: 53.9793\n",
      "[1440]\ttraining's rmse: 2.06431\tvalid_1's rmse: 53.9757\n",
      "[1470]\ttraining's rmse: 1.96051\tvalid_1's rmse: 53.9723\n",
      "[1500]\ttraining's rmse: 1.86241\tvalid_1's rmse: 53.9694\n",
      "[1530]\ttraining's rmse: 1.76897\tvalid_1's rmse: 53.967\n",
      "[1560]\ttraining's rmse: 1.68284\tvalid_1's rmse: 53.9648\n",
      "[1590]\ttraining's rmse: 1.59855\tvalid_1's rmse: 53.9595\n",
      "[1620]\ttraining's rmse: 1.52058\tvalid_1's rmse: 53.9561\n",
      "[1650]\ttraining's rmse: 1.44394\tvalid_1's rmse: 53.9535\n",
      "[1680]\ttraining's rmse: 1.37317\tvalid_1's rmse: 53.9526\n",
      "[1710]\ttraining's rmse: 1.30591\tvalid_1's rmse: 53.9503\n",
      "[1740]\ttraining's rmse: 1.24242\tvalid_1's rmse: 53.9457\n",
      "[1770]\ttraining's rmse: 1.18219\tvalid_1's rmse: 53.9425\n",
      "[1800]\ttraining's rmse: 1.12564\tvalid_1's rmse: 53.941\n",
      "[1830]\ttraining's rmse: 1.07043\tvalid_1's rmse: 53.9406\n",
      "[1860]\ttraining's rmse: 1.01889\tvalid_1's rmse: 53.94\n",
      "[1890]\ttraining's rmse: 0.97024\tvalid_1's rmse: 53.9396\n",
      "[1920]\ttraining's rmse: 0.923983\tvalid_1's rmse: 53.9371\n",
      "[1950]\ttraining's rmse: 0.879954\tvalid_1's rmse: 53.9377\n",
      "[1980]\ttraining's rmse: 0.8379\tvalid_1's rmse: 53.9362\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's rmse: 0.810701\tvalid_1's rmse: 53.9353\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003733 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 20024\n",
      "[LightGBM] [Info] Number of data points in the train set: 9219, number of used features: 79\n",
      "[LightGBM] [Info] Start training from score 365.785320\n",
      "Training until validation scores don't improve for 125 rounds\n",
      "[30]\ttraining's rmse: 155.112\tvalid_1's rmse: 155.692\n",
      "[60]\ttraining's rmse: 96.3194\tvalid_1's rmse: 103.341\n",
      "[90]\ttraining's rmse: 64.7403\tvalid_1's rmse: 77.5657\n",
      "[120]\ttraining's rmse: 47.8463\tvalid_1's rmse: 65.4565\n",
      "[150]\ttraining's rmse: 38.3663\tvalid_1's rmse: 59.5466\n",
      "[180]\ttraining's rmse: 32.5703\tvalid_1's rmse: 56.2763\n",
      "[210]\ttraining's rmse: 28.6032\tvalid_1's rmse: 54.2967\n",
      "[240]\ttraining's rmse: 25.5546\tvalid_1's rmse: 53.148\n",
      "[270]\ttraining's rmse: 23.0931\tvalid_1's rmse: 52.4604\n",
      "[300]\ttraining's rmse: 21.0109\tvalid_1's rmse: 51.9159\n",
      "[330]\ttraining's rmse: 19.2486\tvalid_1's rmse: 51.5846\n",
      "[360]\ttraining's rmse: 17.7133\tvalid_1's rmse: 51.3071\n",
      "[390]\ttraining's rmse: 16.4072\tvalid_1's rmse: 51.0813\n",
      "[420]\ttraining's rmse: 15.2098\tvalid_1's rmse: 50.9191\n",
      "[450]\ttraining's rmse: 14.1187\tvalid_1's rmse: 50.7432\n",
      "[480]\ttraining's rmse: 13.1272\tvalid_1's rmse: 50.6188\n",
      "[510]\ttraining's rmse: 12.2368\tvalid_1's rmse: 50.5236\n",
      "[540]\ttraining's rmse: 11.4272\tvalid_1's rmse: 50.4558\n",
      "[570]\ttraining's rmse: 10.677\tvalid_1's rmse: 50.424\n",
      "[600]\ttraining's rmse: 9.97597\tvalid_1's rmse: 50.3881\n",
      "[630]\ttraining's rmse: 9.35127\tvalid_1's rmse: 50.3515\n",
      "[660]\ttraining's rmse: 8.76113\tvalid_1's rmse: 50.311\n",
      "[690]\ttraining's rmse: 8.21927\tvalid_1's rmse: 50.2722\n",
      "[720]\ttraining's rmse: 7.72373\tvalid_1's rmse: 50.2336\n",
      "[750]\ttraining's rmse: 7.25618\tvalid_1's rmse: 50.2123\n",
      "[780]\ttraining's rmse: 6.82599\tvalid_1's rmse: 50.1835\n",
      "[810]\ttraining's rmse: 6.43086\tvalid_1's rmse: 50.165\n",
      "[840]\ttraining's rmse: 6.05409\tvalid_1's rmse: 50.1415\n",
      "[870]\ttraining's rmse: 5.70859\tvalid_1's rmse: 50.1154\n",
      "[900]\ttraining's rmse: 5.39505\tvalid_1's rmse: 50.1004\n",
      "[930]\ttraining's rmse: 5.09944\tvalid_1's rmse: 50.082\n",
      "[960]\ttraining's rmse: 4.81693\tvalid_1's rmse: 50.0643\n",
      "[990]\ttraining's rmse: 4.55767\tvalid_1's rmse: 50.0431\n",
      "[1020]\ttraining's rmse: 4.3131\tvalid_1's rmse: 50.0363\n",
      "[1050]\ttraining's rmse: 4.08264\tvalid_1's rmse: 50.0239\n",
      "[1080]\ttraining's rmse: 3.86247\tvalid_1's rmse: 50.0172\n",
      "[1110]\ttraining's rmse: 3.65701\tvalid_1's rmse: 50.0064\n",
      "[1140]\ttraining's rmse: 3.46577\tvalid_1's rmse: 50.0002\n",
      "[1170]\ttraining's rmse: 3.28227\tvalid_1's rmse: 49.9893\n",
      "[1200]\ttraining's rmse: 3.11288\tvalid_1's rmse: 49.9858\n",
      "[1230]\ttraining's rmse: 2.95058\tvalid_1's rmse: 49.9775\n",
      "[1260]\ttraining's rmse: 2.79921\tvalid_1's rmse: 49.9724\n",
      "[1290]\ttraining's rmse: 2.66079\tvalid_1's rmse: 49.9645\n",
      "[1320]\ttraining's rmse: 2.52889\tvalid_1's rmse: 49.9618\n",
      "[1350]\ttraining's rmse: 2.40356\tvalid_1's rmse: 49.955\n",
      "[1380]\ttraining's rmse: 2.28519\tvalid_1's rmse: 49.9564\n",
      "[1410]\ttraining's rmse: 2.17129\tvalid_1's rmse: 49.9493\n",
      "[1440]\ttraining's rmse: 2.06661\tvalid_1's rmse: 49.9459\n",
      "[1470]\ttraining's rmse: 1.96436\tvalid_1's rmse: 49.9429\n",
      "[1500]\ttraining's rmse: 1.86962\tvalid_1's rmse: 49.9443\n",
      "[1530]\ttraining's rmse: 1.77947\tvalid_1's rmse: 49.9389\n",
      "[1560]\ttraining's rmse: 1.69302\tvalid_1's rmse: 49.9403\n",
      "[1590]\ttraining's rmse: 1.61134\tvalid_1's rmse: 49.9379\n",
      "[1620]\ttraining's rmse: 1.53365\tvalid_1's rmse: 49.9327\n",
      "[1650]\ttraining's rmse: 1.45831\tvalid_1's rmse: 49.9289\n",
      "[1680]\ttraining's rmse: 1.3889\tvalid_1's rmse: 49.9258\n",
      "[1710]\ttraining's rmse: 1.32163\tvalid_1's rmse: 49.923\n",
      "[1740]\ttraining's rmse: 1.25994\tvalid_1's rmse: 49.9221\n",
      "[1770]\ttraining's rmse: 1.20104\tvalid_1's rmse: 49.923\n",
      "[1800]\ttraining's rmse: 1.14599\tvalid_1's rmse: 49.9209\n",
      "[1830]\ttraining's rmse: 1.09276\tvalid_1's rmse: 49.9193\n",
      "[1860]\ttraining's rmse: 1.04288\tvalid_1's rmse: 49.9195\n",
      "[1890]\ttraining's rmse: 0.9944\tvalid_1's rmse: 49.9186\n",
      "[1920]\ttraining's rmse: 0.94985\tvalid_1's rmse: 49.9186\n",
      "[1950]\ttraining's rmse: 0.906087\tvalid_1's rmse: 49.9177\n",
      "[1980]\ttraining's rmse: 0.864475\tvalid_1's rmse: 49.9175\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's rmse: 0.839824\tvalid_1's rmse: 49.9161\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003245 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 20024\n",
      "[LightGBM] [Info] Number of data points in the train set: 9219, number of used features: 79\n",
      "[LightGBM] [Info] Start training from score 360.971773\n",
      "Training until validation scores don't improve for 125 rounds\n",
      "[30]\ttraining's rmse: 155.804\tvalid_1's rmse: 161.196\n",
      "[60]\ttraining's rmse: 97.7417\tvalid_1's rmse: 107.899\n",
      "[90]\ttraining's rmse: 65.9481\tvalid_1's rmse: 80.8209\n",
      "[120]\ttraining's rmse: 48.9448\tvalid_1's rmse: 68.0963\n",
      "[150]\ttraining's rmse: 39.3629\tvalid_1's rmse: 61.8568\n",
      "[180]\ttraining's rmse: 33.4109\tvalid_1's rmse: 58.599\n",
      "[210]\ttraining's rmse: 29.3165\tvalid_1's rmse: 56.6706\n",
      "[240]\ttraining's rmse: 26.2053\tvalid_1's rmse: 55.487\n",
      "[270]\ttraining's rmse: 23.6054\tvalid_1's rmse: 54.6981\n",
      "[300]\ttraining's rmse: 21.4558\tvalid_1's rmse: 54.1011\n",
      "[330]\ttraining's rmse: 19.6446\tvalid_1's rmse: 53.6961\n",
      "[360]\ttraining's rmse: 18.0653\tvalid_1's rmse: 53.4393\n",
      "[390]\ttraining's rmse: 16.7032\tvalid_1's rmse: 53.2359\n",
      "[420]\ttraining's rmse: 15.4644\tvalid_1's rmse: 53.0354\n",
      "[450]\ttraining's rmse: 14.3429\tvalid_1's rmse: 52.921\n",
      "[480]\ttraining's rmse: 13.334\tvalid_1's rmse: 52.8375\n",
      "[510]\ttraining's rmse: 12.411\tvalid_1's rmse: 52.7591\n",
      "[540]\ttraining's rmse: 11.5692\tvalid_1's rmse: 52.6623\n",
      "[570]\ttraining's rmse: 10.7997\tvalid_1's rmse: 52.5794\n",
      "[600]\ttraining's rmse: 10.0884\tvalid_1's rmse: 52.5319\n",
      "[630]\ttraining's rmse: 9.44832\tvalid_1's rmse: 52.4598\n",
      "[660]\ttraining's rmse: 8.85103\tvalid_1's rmse: 52.4005\n",
      "[690]\ttraining's rmse: 8.30395\tvalid_1's rmse: 52.3655\n",
      "[720]\ttraining's rmse: 7.79237\tvalid_1's rmse: 52.3191\n",
      "[750]\ttraining's rmse: 7.32556\tvalid_1's rmse: 52.3064\n",
      "[780]\ttraining's rmse: 6.88721\tvalid_1's rmse: 52.2803\n",
      "[810]\ttraining's rmse: 6.47741\tvalid_1's rmse: 52.258\n",
      "[840]\ttraining's rmse: 6.10065\tvalid_1's rmse: 52.2252\n",
      "[870]\ttraining's rmse: 5.75287\tvalid_1's rmse: 52.2084\n",
      "[900]\ttraining's rmse: 5.42301\tvalid_1's rmse: 52.1942\n",
      "[930]\ttraining's rmse: 5.115\tvalid_1's rmse: 52.1807\n",
      "[960]\ttraining's rmse: 4.8377\tvalid_1's rmse: 52.1705\n",
      "[990]\ttraining's rmse: 4.57007\tvalid_1's rmse: 52.1663\n",
      "[1020]\ttraining's rmse: 4.32408\tvalid_1's rmse: 52.1538\n",
      "[1050]\ttraining's rmse: 4.0886\tvalid_1's rmse: 52.1445\n",
      "[1080]\ttraining's rmse: 3.87037\tvalid_1's rmse: 52.1343\n",
      "[1110]\ttraining's rmse: 3.66622\tvalid_1's rmse: 52.1319\n",
      "[1140]\ttraining's rmse: 3.47437\tvalid_1's rmse: 52.12\n",
      "[1170]\ttraining's rmse: 3.29091\tvalid_1's rmse: 52.1074\n",
      "[1200]\ttraining's rmse: 3.12081\tvalid_1's rmse: 52.1005\n",
      "[1230]\ttraining's rmse: 2.95942\tvalid_1's rmse: 52.0958\n",
      "[1260]\ttraining's rmse: 2.80961\tvalid_1's rmse: 52.0936\n",
      "[1290]\ttraining's rmse: 2.6647\tvalid_1's rmse: 52.0882\n",
      "[1320]\ttraining's rmse: 2.52754\tvalid_1's rmse: 52.0835\n",
      "[1350]\ttraining's rmse: 2.3997\tvalid_1's rmse: 52.0795\n",
      "[1380]\ttraining's rmse: 2.27855\tvalid_1's rmse: 52.078\n",
      "[1410]\ttraining's rmse: 2.16486\tvalid_1's rmse: 52.0777\n",
      "[1440]\ttraining's rmse: 2.0619\tvalid_1's rmse: 52.0768\n",
      "[1470]\ttraining's rmse: 1.96025\tvalid_1's rmse: 52.0696\n",
      "[1500]\ttraining's rmse: 1.86703\tvalid_1's rmse: 52.0645\n",
      "[1530]\ttraining's rmse: 1.77445\tvalid_1's rmse: 52.0621\n",
      "[1560]\ttraining's rmse: 1.6893\tvalid_1's rmse: 52.0607\n",
      "[1590]\ttraining's rmse: 1.60804\tvalid_1's rmse: 52.06\n",
      "[1620]\ttraining's rmse: 1.53041\tvalid_1's rmse: 52.0583\n",
      "[1650]\ttraining's rmse: 1.45692\tvalid_1's rmse: 52.0561\n",
      "[1680]\ttraining's rmse: 1.38931\tvalid_1's rmse: 52.0554\n",
      "[1710]\ttraining's rmse: 1.32204\tvalid_1's rmse: 52.0544\n",
      "[1740]\ttraining's rmse: 1.26182\tvalid_1's rmse: 52.0539\n",
      "[1770]\ttraining's rmse: 1.20106\tvalid_1's rmse: 52.051\n",
      "[1800]\ttraining's rmse: 1.14786\tvalid_1's rmse: 52.0486\n",
      "[1830]\ttraining's rmse: 1.09288\tvalid_1's rmse: 52.0484\n",
      "[1860]\ttraining's rmse: 1.04204\tvalid_1's rmse: 52.047\n",
      "[1890]\ttraining's rmse: 0.994099\tvalid_1's rmse: 52.0452\n",
      "[1920]\ttraining's rmse: 0.947815\tvalid_1's rmse: 52.0449\n",
      "[1950]\ttraining's rmse: 0.90599\tvalid_1's rmse: 52.0436\n",
      "[1980]\ttraining's rmse: 0.865544\tvalid_1's rmse: 52.0441\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's rmse: 0.840133\tvalid_1's rmse: 52.0431\n",
      "26\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003414 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 20024\n",
      "[LightGBM] [Info] Number of data points in the train set: 9219, number of used features: 79\n",
      "[LightGBM] [Info] Start training from score 367.382886\n",
      "Training until validation scores don't improve for 125 rounds\n",
      "[30]\ttraining's rmse: 154.695\tvalid_1's rmse: 157.69\n",
      "[60]\ttraining's rmse: 96.1249\tvalid_1's rmse: 105.527\n",
      "[90]\ttraining's rmse: 64.4341\tvalid_1's rmse: 79.614\n",
      "[120]\ttraining's rmse: 47.3759\tvalid_1's rmse: 67.3885\n",
      "[150]\ttraining's rmse: 37.806\tvalid_1's rmse: 61.5258\n",
      "[180]\ttraining's rmse: 32.0564\tvalid_1's rmse: 58.4726\n",
      "[210]\ttraining's rmse: 28.1256\tvalid_1's rmse: 56.8146\n",
      "[240]\ttraining's rmse: 25.0746\tvalid_1's rmse: 55.5196\n",
      "[270]\ttraining's rmse: 22.6401\tvalid_1's rmse: 54.6592\n",
      "[300]\ttraining's rmse: 20.6\tvalid_1's rmse: 54.1359\n",
      "[330]\ttraining's rmse: 18.8894\tvalid_1's rmse: 53.8313\n",
      "[360]\ttraining's rmse: 17.4137\tvalid_1's rmse: 53.5291\n",
      "[390]\ttraining's rmse: 16.0795\tvalid_1's rmse: 53.3281\n",
      "[420]\ttraining's rmse: 14.905\tvalid_1's rmse: 53.1818\n",
      "[450]\ttraining's rmse: 13.8297\tvalid_1's rmse: 53.0041\n",
      "[480]\ttraining's rmse: 12.8598\tvalid_1's rmse: 52.8913\n",
      "[510]\ttraining's rmse: 11.9836\tvalid_1's rmse: 52.8042\n",
      "[540]\ttraining's rmse: 11.1727\tvalid_1's rmse: 52.7287\n",
      "[570]\ttraining's rmse: 10.4325\tvalid_1's rmse: 52.6434\n",
      "[600]\ttraining's rmse: 9.74714\tvalid_1's rmse: 52.5634\n",
      "[630]\ttraining's rmse: 9.12669\tvalid_1's rmse: 52.4985\n",
      "[660]\ttraining's rmse: 8.56009\tvalid_1's rmse: 52.4446\n",
      "[690]\ttraining's rmse: 8.03343\tvalid_1's rmse: 52.3854\n",
      "[720]\ttraining's rmse: 7.55182\tvalid_1's rmse: 52.3565\n",
      "[750]\ttraining's rmse: 7.10017\tvalid_1's rmse: 52.3152\n",
      "[780]\ttraining's rmse: 6.68175\tvalid_1's rmse: 52.2861\n",
      "[810]\ttraining's rmse: 6.28491\tvalid_1's rmse: 52.2435\n",
      "[840]\ttraining's rmse: 5.9149\tvalid_1's rmse: 52.2188\n",
      "[870]\ttraining's rmse: 5.56729\tvalid_1's rmse: 52.1861\n",
      "[900]\ttraining's rmse: 5.24942\tvalid_1's rmse: 52.1741\n",
      "[930]\ttraining's rmse: 4.95639\tvalid_1's rmse: 52.1614\n",
      "[960]\ttraining's rmse: 4.68176\tvalid_1's rmse: 52.1441\n",
      "[990]\ttraining's rmse: 4.424\tvalid_1's rmse: 52.126\n",
      "[1020]\ttraining's rmse: 4.17706\tvalid_1's rmse: 52.1183\n",
      "[1050]\ttraining's rmse: 3.95168\tvalid_1's rmse: 52.1068\n",
      "[1080]\ttraining's rmse: 3.73831\tvalid_1's rmse: 52.1004\n",
      "[1110]\ttraining's rmse: 3.54203\tvalid_1's rmse: 52.0888\n",
      "[1140]\ttraining's rmse: 3.35179\tvalid_1's rmse: 52.0783\n",
      "[1170]\ttraining's rmse: 3.17148\tvalid_1's rmse: 52.0583\n",
      "[1200]\ttraining's rmse: 3.00071\tvalid_1's rmse: 52.0499\n",
      "[1230]\ttraining's rmse: 2.84302\tvalid_1's rmse: 52.0464\n",
      "[1260]\ttraining's rmse: 2.69287\tvalid_1's rmse: 52.0359\n",
      "[1290]\ttraining's rmse: 2.55065\tvalid_1's rmse: 52.0335\n",
      "[1320]\ttraining's rmse: 2.41881\tvalid_1's rmse: 52.0232\n",
      "[1350]\ttraining's rmse: 2.29543\tvalid_1's rmse: 52.0214\n",
      "[1380]\ttraining's rmse: 2.18001\tvalid_1's rmse: 52.0188\n",
      "[1410]\ttraining's rmse: 2.06797\tvalid_1's rmse: 52.0125\n",
      "[1440]\ttraining's rmse: 1.96474\tvalid_1's rmse: 52.0099\n",
      "[1470]\ttraining's rmse: 1.86668\tvalid_1's rmse: 52.0076\n",
      "[1500]\ttraining's rmse: 1.77195\tvalid_1's rmse: 52.0003\n",
      "[1530]\ttraining's rmse: 1.68319\tvalid_1's rmse: 51.9972\n",
      "[1560]\ttraining's rmse: 1.59982\tvalid_1's rmse: 51.9977\n",
      "[1590]\ttraining's rmse: 1.52129\tvalid_1's rmse: 51.9953\n",
      "[1620]\ttraining's rmse: 1.44697\tvalid_1's rmse: 51.9917\n",
      "[1650]\ttraining's rmse: 1.37607\tvalid_1's rmse: 51.99\n",
      "[1680]\ttraining's rmse: 1.30847\tvalid_1's rmse: 51.9872\n",
      "[1710]\ttraining's rmse: 1.24471\tvalid_1's rmse: 51.9843\n",
      "[1740]\ttraining's rmse: 1.18555\tvalid_1's rmse: 51.9825\n",
      "[1770]\ttraining's rmse: 1.1287\tvalid_1's rmse: 51.9835\n",
      "[1800]\ttraining's rmse: 1.07446\tvalid_1's rmse: 51.9818\n",
      "[1830]\ttraining's rmse: 1.02288\tvalid_1's rmse: 51.9828\n",
      "[1860]\ttraining's rmse: 0.973854\tvalid_1's rmse: 51.9797\n",
      "[1890]\ttraining's rmse: 0.927386\tvalid_1's rmse: 51.976\n",
      "[1920]\ttraining's rmse: 0.883594\tvalid_1's rmse: 51.9731\n",
      "[1950]\ttraining's rmse: 0.841091\tvalid_1's rmse: 51.9713\n",
      "[1980]\ttraining's rmse: 0.801656\tvalid_1's rmse: 51.9695\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's rmse: 0.776396\tvalid_1's rmse: 51.9694\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003348 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 20024\n",
      "[LightGBM] [Info] Number of data points in the train set: 9219, number of used features: 79\n",
      "[LightGBM] [Info] Start training from score 369.350809\n",
      "Training until validation scores don't improve for 125 rounds\n",
      "[30]\ttraining's rmse: 156.033\tvalid_1's rmse: 158.907\n",
      "[60]\ttraining's rmse: 98.0193\tvalid_1's rmse: 108.487\n",
      "[90]\ttraining's rmse: 66.6843\tvalid_1's rmse: 83.7616\n",
      "[120]\ttraining's rmse: 49.5776\tvalid_1's rmse: 72.222\n",
      "[150]\ttraining's rmse: 39.6798\tvalid_1's rmse: 66.6608\n",
      "[180]\ttraining's rmse: 33.6898\tvalid_1's rmse: 63.8554\n",
      "[210]\ttraining's rmse: 29.4193\tvalid_1's rmse: 62.1753\n",
      "[240]\ttraining's rmse: 26.2237\tvalid_1's rmse: 61.1492\n",
      "[270]\ttraining's rmse: 23.5905\tvalid_1's rmse: 60.3841\n",
      "[300]\ttraining's rmse: 21.4001\tvalid_1's rmse: 59.7985\n",
      "[330]\ttraining's rmse: 19.5327\tvalid_1's rmse: 59.4961\n",
      "[360]\ttraining's rmse: 17.9406\tvalid_1's rmse: 59.0711\n",
      "[390]\ttraining's rmse: 16.5387\tvalid_1's rmse: 58.8099\n",
      "[420]\ttraining's rmse: 15.282\tvalid_1's rmse: 58.6032\n",
      "[450]\ttraining's rmse: 14.1513\tvalid_1's rmse: 58.4754\n",
      "[480]\ttraining's rmse: 13.14\tvalid_1's rmse: 58.3557\n",
      "[510]\ttraining's rmse: 12.2327\tvalid_1's rmse: 58.246\n",
      "[540]\ttraining's rmse: 11.4089\tvalid_1's rmse: 58.1702\n",
      "[570]\ttraining's rmse: 10.6408\tvalid_1's rmse: 58.0857\n",
      "[600]\ttraining's rmse: 9.95435\tvalid_1's rmse: 58.0457\n",
      "[630]\ttraining's rmse: 9.31892\tvalid_1's rmse: 58.0214\n",
      "[660]\ttraining's rmse: 8.72944\tvalid_1's rmse: 57.9745\n",
      "[690]\ttraining's rmse: 8.18407\tvalid_1's rmse: 57.9398\n",
      "[720]\ttraining's rmse: 7.68399\tvalid_1's rmse: 57.9114\n",
      "[750]\ttraining's rmse: 7.22357\tvalid_1's rmse: 57.8858\n",
      "[780]\ttraining's rmse: 6.79191\tvalid_1's rmse: 57.853\n",
      "[810]\ttraining's rmse: 6.38313\tvalid_1's rmse: 57.8165\n",
      "[840]\ttraining's rmse: 6.0042\tvalid_1's rmse: 57.8122\n",
      "[870]\ttraining's rmse: 5.65793\tvalid_1's rmse: 57.7947\n",
      "[900]\ttraining's rmse: 5.33188\tvalid_1's rmse: 57.7698\n",
      "[930]\ttraining's rmse: 5.02942\tvalid_1's rmse: 57.7552\n",
      "[960]\ttraining's rmse: 4.74511\tvalid_1's rmse: 57.7385\n",
      "[990]\ttraining's rmse: 4.47623\tvalid_1's rmse: 57.7283\n",
      "[1020]\ttraining's rmse: 4.22439\tvalid_1's rmse: 57.7206\n",
      "[1050]\ttraining's rmse: 3.99442\tvalid_1's rmse: 57.7092\n",
      "[1080]\ttraining's rmse: 3.77152\tvalid_1's rmse: 57.712\n",
      "[1110]\ttraining's rmse: 3.56776\tvalid_1's rmse: 57.6945\n",
      "[1140]\ttraining's rmse: 3.37497\tvalid_1's rmse: 57.6862\n",
      "[1170]\ttraining's rmse: 3.19302\tvalid_1's rmse: 57.6791\n",
      "[1200]\ttraining's rmse: 3.02163\tvalid_1's rmse: 57.672\n",
      "[1230]\ttraining's rmse: 2.862\tvalid_1's rmse: 57.6611\n",
      "[1260]\ttraining's rmse: 2.71192\tvalid_1's rmse: 57.6519\n",
      "[1290]\ttraining's rmse: 2.56895\tvalid_1's rmse: 57.6446\n",
      "[1320]\ttraining's rmse: 2.43449\tvalid_1's rmse: 57.6434\n",
      "[1350]\ttraining's rmse: 2.30668\tvalid_1's rmse: 57.6409\n",
      "[1380]\ttraining's rmse: 2.1844\tvalid_1's rmse: 57.633\n",
      "[1410]\ttraining's rmse: 2.06947\tvalid_1's rmse: 57.6311\n",
      "[1440]\ttraining's rmse: 1.96266\tvalid_1's rmse: 57.6265\n",
      "[1470]\ttraining's rmse: 1.86277\tvalid_1's rmse: 57.625\n",
      "[1500]\ttraining's rmse: 1.7662\tvalid_1's rmse: 57.6211\n",
      "[1530]\ttraining's rmse: 1.67733\tvalid_1's rmse: 57.6188\n",
      "[1560]\ttraining's rmse: 1.59251\tvalid_1's rmse: 57.6152\n",
      "[1590]\ttraining's rmse: 1.51271\tvalid_1's rmse: 57.6108\n",
      "[1620]\ttraining's rmse: 1.4358\tvalid_1's rmse: 57.6072\n",
      "[1650]\ttraining's rmse: 1.36393\tvalid_1's rmse: 57.6043\n",
      "[1680]\ttraining's rmse: 1.29601\tvalid_1's rmse: 57.6034\n",
      "[1710]\ttraining's rmse: 1.23192\tvalid_1's rmse: 57.6007\n",
      "[1740]\ttraining's rmse: 1.17017\tvalid_1's rmse: 57.5983\n",
      "[1770]\ttraining's rmse: 1.11414\tvalid_1's rmse: 57.597\n",
      "[1800]\ttraining's rmse: 1.06004\tvalid_1's rmse: 57.595\n",
      "[1830]\ttraining's rmse: 1.007\tvalid_1's rmse: 57.5942\n",
      "[1860]\ttraining's rmse: 0.958369\tvalid_1's rmse: 57.5923\n",
      "[1890]\ttraining's rmse: 0.911078\tvalid_1's rmse: 57.5908\n",
      "[1920]\ttraining's rmse: 0.866297\tvalid_1's rmse: 57.5888\n",
      "[1950]\ttraining's rmse: 0.823442\tvalid_1's rmse: 57.5873\n",
      "[1980]\ttraining's rmse: 0.783838\tvalid_1's rmse: 57.5876\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's rmse: 0.758164\tvalid_1's rmse: 57.5867\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002353 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 20024\n",
      "[LightGBM] [Info] Number of data points in the train set: 9219, number of used features: 79\n",
      "[LightGBM] [Info] Start training from score 368.804320\n",
      "Training until validation scores don't improve for 125 rounds\n",
      "[30]\ttraining's rmse: 157.529\tvalid_1's rmse: 156.875\n",
      "[60]\ttraining's rmse: 98.7516\tvalid_1's rmse: 107.706\n",
      "[90]\ttraining's rmse: 66.8689\tvalid_1's rmse: 83.9227\n",
      "[120]\ttraining's rmse: 49.6017\tvalid_1's rmse: 72.6881\n",
      "[150]\ttraining's rmse: 39.9053\tvalid_1's rmse: 67.2823\n",
      "[180]\ttraining's rmse: 33.935\tvalid_1's rmse: 64.4491\n",
      "[210]\ttraining's rmse: 29.6241\tvalid_1's rmse: 62.5907\n",
      "[240]\ttraining's rmse: 26.4279\tvalid_1's rmse: 61.3759\n",
      "[270]\ttraining's rmse: 23.8332\tvalid_1's rmse: 60.4359\n",
      "[300]\ttraining's rmse: 21.6825\tvalid_1's rmse: 59.8291\n",
      "[330]\ttraining's rmse: 19.8806\tvalid_1's rmse: 59.3772\n",
      "[360]\ttraining's rmse: 18.2565\tvalid_1's rmse: 59.0077\n",
      "[390]\ttraining's rmse: 16.825\tvalid_1's rmse: 58.6777\n",
      "[420]\ttraining's rmse: 15.5681\tvalid_1's rmse: 58.4349\n",
      "[450]\ttraining's rmse: 14.4385\tvalid_1's rmse: 58.2839\n",
      "[480]\ttraining's rmse: 13.4018\tvalid_1's rmse: 58.1473\n",
      "[510]\ttraining's rmse: 12.4752\tvalid_1's rmse: 58.0453\n",
      "[540]\ttraining's rmse: 11.6293\tvalid_1's rmse: 57.9405\n",
      "[570]\ttraining's rmse: 10.8642\tvalid_1's rmse: 57.8468\n",
      "[600]\ttraining's rmse: 10.1571\tvalid_1's rmse: 57.774\n",
      "[630]\ttraining's rmse: 9.5072\tvalid_1's rmse: 57.7008\n",
      "[660]\ttraining's rmse: 8.91975\tvalid_1's rmse: 57.6356\n",
      "[690]\ttraining's rmse: 8.36645\tvalid_1's rmse: 57.6026\n",
      "[720]\ttraining's rmse: 7.85814\tvalid_1's rmse: 57.5723\n",
      "[750]\ttraining's rmse: 7.40137\tvalid_1's rmse: 57.5395\n",
      "[780]\ttraining's rmse: 6.9538\tvalid_1's rmse: 57.4716\n",
      "[810]\ttraining's rmse: 6.54337\tvalid_1's rmse: 57.4403\n",
      "[840]\ttraining's rmse: 6.16233\tvalid_1's rmse: 57.4186\n",
      "[870]\ttraining's rmse: 5.80704\tvalid_1's rmse: 57.4081\n",
      "[900]\ttraining's rmse: 5.47281\tvalid_1's rmse: 57.39\n",
      "[930]\ttraining's rmse: 5.15971\tvalid_1's rmse: 57.3794\n",
      "[960]\ttraining's rmse: 4.87215\tvalid_1's rmse: 57.363\n",
      "[990]\ttraining's rmse: 4.60331\tvalid_1's rmse: 57.3386\n",
      "[1020]\ttraining's rmse: 4.34664\tvalid_1's rmse: 57.3284\n",
      "[1050]\ttraining's rmse: 4.11326\tvalid_1's rmse: 57.3144\n",
      "[1080]\ttraining's rmse: 3.88997\tvalid_1's rmse: 57.3033\n",
      "[1110]\ttraining's rmse: 3.68447\tvalid_1's rmse: 57.299\n",
      "[1140]\ttraining's rmse: 3.48758\tvalid_1's rmse: 57.2908\n",
      "[1170]\ttraining's rmse: 3.30023\tvalid_1's rmse: 57.2868\n",
      "[1200]\ttraining's rmse: 3.12533\tvalid_1's rmse: 57.2782\n",
      "[1230]\ttraining's rmse: 2.96386\tvalid_1's rmse: 57.2729\n",
      "[1260]\ttraining's rmse: 2.81074\tvalid_1's rmse: 57.2658\n",
      "[1290]\ttraining's rmse: 2.66943\tvalid_1's rmse: 57.2632\n",
      "[1320]\ttraining's rmse: 2.53072\tvalid_1's rmse: 57.2645\n",
      "[1350]\ttraining's rmse: 2.40116\tvalid_1's rmse: 57.2599\n",
      "[1380]\ttraining's rmse: 2.27628\tvalid_1's rmse: 57.2562\n",
      "[1410]\ttraining's rmse: 2.162\tvalid_1's rmse: 57.2485\n",
      "[1440]\ttraining's rmse: 2.05393\tvalid_1's rmse: 57.2419\n",
      "[1470]\ttraining's rmse: 1.95031\tvalid_1's rmse: 57.2382\n",
      "[1500]\ttraining's rmse: 1.85377\tvalid_1's rmse: 57.2331\n",
      "[1530]\ttraining's rmse: 1.76348\tvalid_1's rmse: 57.2323\n",
      "[1560]\ttraining's rmse: 1.67581\tvalid_1's rmse: 57.2293\n",
      "[1590]\ttraining's rmse: 1.59435\tvalid_1's rmse: 57.2245\n",
      "[1620]\ttraining's rmse: 1.51691\tvalid_1's rmse: 57.2229\n",
      "[1650]\ttraining's rmse: 1.44286\tvalid_1's rmse: 57.2226\n",
      "[1680]\ttraining's rmse: 1.37322\tvalid_1's rmse: 57.2202\n",
      "[1710]\ttraining's rmse: 1.30731\tvalid_1's rmse: 57.2184\n",
      "[1740]\ttraining's rmse: 1.24548\tvalid_1's rmse: 57.2167\n",
      "[1770]\ttraining's rmse: 1.1855\tvalid_1's rmse: 57.2142\n",
      "[1800]\ttraining's rmse: 1.12832\tvalid_1's rmse: 57.213\n",
      "[1830]\ttraining's rmse: 1.0736\tvalid_1's rmse: 57.2121\n",
      "[1860]\ttraining's rmse: 1.02146\tvalid_1's rmse: 57.2128\n",
      "[1890]\ttraining's rmse: 0.972352\tvalid_1's rmse: 57.2108\n",
      "[1920]\ttraining's rmse: 0.925674\tvalid_1's rmse: 57.2101\n",
      "[1950]\ttraining's rmse: 0.882167\tvalid_1's rmse: 57.2071\n",
      "[1980]\ttraining's rmse: 0.839203\tvalid_1's rmse: 57.2045\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's rmse: 0.813222\tvalid_1's rmse: 57.2045\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003686 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 20024\n",
      "[LightGBM] [Info] Number of data points in the train set: 9219, number of used features: 79\n",
      "[LightGBM] [Info] Start training from score 367.769424\n",
      "Training until validation scores don't improve for 125 rounds\n",
      "[30]\ttraining's rmse: 157.784\tvalid_1's rmse: 159.455\n",
      "[60]\ttraining's rmse: 99.0797\tvalid_1's rmse: 108.891\n",
      "[90]\ttraining's rmse: 67.4491\tvalid_1's rmse: 84.5207\n",
      "[120]\ttraining's rmse: 50.2895\tvalid_1's rmse: 73.0691\n",
      "[150]\ttraining's rmse: 40.487\tvalid_1's rmse: 67.4233\n",
      "[180]\ttraining's rmse: 34.4428\tvalid_1's rmse: 64.2173\n",
      "[210]\ttraining's rmse: 30.2795\tvalid_1's rmse: 62.2556\n",
      "[240]\ttraining's rmse: 27.0673\tvalid_1's rmse: 60.9913\n",
      "[270]\ttraining's rmse: 24.4095\tvalid_1's rmse: 60.0134\n",
      "[300]\ttraining's rmse: 22.1975\tvalid_1's rmse: 59.3086\n",
      "[330]\ttraining's rmse: 20.305\tvalid_1's rmse: 58.8232\n",
      "[360]\ttraining's rmse: 18.6478\tvalid_1's rmse: 58.4574\n",
      "[390]\ttraining's rmse: 17.1627\tvalid_1's rmse: 58.1313\n",
      "[420]\ttraining's rmse: 15.8606\tvalid_1's rmse: 57.8877\n",
      "[450]\ttraining's rmse: 14.6913\tvalid_1's rmse: 57.6792\n",
      "[480]\ttraining's rmse: 13.6461\tvalid_1's rmse: 57.4625\n",
      "[510]\ttraining's rmse: 12.7066\tvalid_1's rmse: 57.2997\n",
      "[540]\ttraining's rmse: 11.8231\tvalid_1's rmse: 57.1919\n",
      "[570]\ttraining's rmse: 11.0496\tvalid_1's rmse: 57.0875\n",
      "[600]\ttraining's rmse: 10.3249\tvalid_1's rmse: 57.0002\n",
      "[630]\ttraining's rmse: 9.6669\tvalid_1's rmse: 56.9245\n",
      "[660]\ttraining's rmse: 9.06771\tvalid_1's rmse: 56.8709\n",
      "[690]\ttraining's rmse: 8.50685\tvalid_1's rmse: 56.8268\n",
      "[720]\ttraining's rmse: 7.98875\tvalid_1's rmse: 56.764\n",
      "[750]\ttraining's rmse: 7.51608\tvalid_1's rmse: 56.7202\n",
      "[780]\ttraining's rmse: 7.07294\tvalid_1's rmse: 56.6858\n",
      "[810]\ttraining's rmse: 6.6499\tvalid_1's rmse: 56.6644\n",
      "[840]\ttraining's rmse: 6.26832\tvalid_1's rmse: 56.6198\n",
      "[870]\ttraining's rmse: 5.90849\tvalid_1's rmse: 56.5907\n",
      "[900]\ttraining's rmse: 5.58342\tvalid_1's rmse: 56.574\n",
      "[930]\ttraining's rmse: 5.27063\tvalid_1's rmse: 56.5583\n",
      "[960]\ttraining's rmse: 4.97877\tvalid_1's rmse: 56.5352\n",
      "[990]\ttraining's rmse: 4.70649\tvalid_1's rmse: 56.5209\n",
      "[1020]\ttraining's rmse: 4.45339\tvalid_1's rmse: 56.5009\n",
      "[1050]\ttraining's rmse: 4.21374\tvalid_1's rmse: 56.4818\n",
      "[1080]\ttraining's rmse: 3.99085\tvalid_1's rmse: 56.4731\n",
      "[1110]\ttraining's rmse: 3.78261\tvalid_1's rmse: 56.459\n",
      "[1140]\ttraining's rmse: 3.59191\tvalid_1's rmse: 56.444\n",
      "[1170]\ttraining's rmse: 3.40907\tvalid_1's rmse: 56.4341\n",
      "[1200]\ttraining's rmse: 3.23291\tvalid_1's rmse: 56.4257\n",
      "[1230]\ttraining's rmse: 3.07023\tvalid_1's rmse: 56.4225\n",
      "[1260]\ttraining's rmse: 2.91212\tvalid_1's rmse: 56.4175\n",
      "[1290]\ttraining's rmse: 2.76301\tvalid_1's rmse: 56.4127\n",
      "[1320]\ttraining's rmse: 2.62354\tvalid_1's rmse: 56.4024\n",
      "[1350]\ttraining's rmse: 2.49385\tvalid_1's rmse: 56.3934\n",
      "[1380]\ttraining's rmse: 2.36933\tvalid_1's rmse: 56.3932\n",
      "[1410]\ttraining's rmse: 2.25354\tvalid_1's rmse: 56.3878\n",
      "[1440]\ttraining's rmse: 2.14255\tvalid_1's rmse: 56.3883\n",
      "[1470]\ttraining's rmse: 2.03774\tvalid_1's rmse: 56.3845\n",
      "[1500]\ttraining's rmse: 1.93872\tvalid_1's rmse: 56.381\n",
      "[1530]\ttraining's rmse: 1.84451\tvalid_1's rmse: 56.3796\n",
      "[1560]\ttraining's rmse: 1.75748\tvalid_1's rmse: 56.3776\n",
      "[1590]\ttraining's rmse: 1.67526\tvalid_1's rmse: 56.3714\n",
      "[1620]\ttraining's rmse: 1.59574\tvalid_1's rmse: 56.37\n",
      "[1650]\ttraining's rmse: 1.51926\tvalid_1's rmse: 56.3666\n",
      "[1680]\ttraining's rmse: 1.44734\tvalid_1's rmse: 56.3655\n",
      "[1710]\ttraining's rmse: 1.37897\tvalid_1's rmse: 56.3634\n",
      "[1740]\ttraining's rmse: 1.31502\tvalid_1's rmse: 56.3584\n",
      "[1770]\ttraining's rmse: 1.25345\tvalid_1's rmse: 56.3544\n",
      "[1800]\ttraining's rmse: 1.19581\tvalid_1's rmse: 56.3538\n",
      "[1830]\ttraining's rmse: 1.1405\tvalid_1's rmse: 56.3503\n",
      "[1860]\ttraining's rmse: 1.08723\tvalid_1's rmse: 56.3511\n",
      "[1890]\ttraining's rmse: 1.03932\tvalid_1's rmse: 56.346\n",
      "[1920]\ttraining's rmse: 0.991811\tvalid_1's rmse: 56.345\n",
      "[1950]\ttraining's rmse: 0.94808\tvalid_1's rmse: 56.3437\n",
      "[1980]\ttraining's rmse: 0.90479\tvalid_1's rmse: 56.3419\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's rmse: 0.877959\tvalid_1's rmse: 56.3421\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002308 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 20024\n",
      "[LightGBM] [Info] Number of data points in the train set: 9219, number of used features: 79\n",
      "[LightGBM] [Info] Start training from score 360.131644\n",
      "Training until validation scores don't improve for 125 rounds\n",
      "[30]\ttraining's rmse: 155.519\tvalid_1's rmse: 164.161\n",
      "[60]\ttraining's rmse: 97.399\tvalid_1's rmse: 109.229\n",
      "[90]\ttraining's rmse: 66.2361\tvalid_1's rmse: 82.2589\n",
      "[120]\ttraining's rmse: 49.2093\tvalid_1's rmse: 69.3046\n",
      "[150]\ttraining's rmse: 39.6282\tvalid_1's rmse: 63.3271\n",
      "[180]\ttraining's rmse: 33.6763\tvalid_1's rmse: 60.32\n",
      "[210]\ttraining's rmse: 29.5995\tvalid_1's rmse: 58.6465\n",
      "[240]\ttraining's rmse: 26.4677\tvalid_1's rmse: 57.5877\n",
      "[270]\ttraining's rmse: 23.9155\tvalid_1's rmse: 56.9024\n",
      "[300]\ttraining's rmse: 21.7613\tvalid_1's rmse: 56.3944\n",
      "[330]\ttraining's rmse: 19.9272\tvalid_1's rmse: 56.0162\n",
      "[360]\ttraining's rmse: 18.3404\tvalid_1's rmse: 55.7776\n",
      "[390]\ttraining's rmse: 16.9223\tvalid_1's rmse: 55.5575\n",
      "[420]\ttraining's rmse: 15.631\tvalid_1's rmse: 55.3593\n",
      "[450]\ttraining's rmse: 14.4895\tvalid_1's rmse: 55.177\n",
      "[480]\ttraining's rmse: 13.4604\tvalid_1's rmse: 55.0305\n",
      "[510]\ttraining's rmse: 12.5428\tvalid_1's rmse: 54.9055\n",
      "[540]\ttraining's rmse: 11.6843\tvalid_1's rmse: 54.8241\n",
      "[570]\ttraining's rmse: 10.9025\tvalid_1's rmse: 54.7394\n",
      "[600]\ttraining's rmse: 10.1885\tvalid_1's rmse: 54.6595\n",
      "[630]\ttraining's rmse: 9.53476\tvalid_1's rmse: 54.6094\n",
      "[660]\ttraining's rmse: 8.93682\tvalid_1's rmse: 54.5565\n",
      "[690]\ttraining's rmse: 8.37912\tvalid_1's rmse: 54.5017\n",
      "[720]\ttraining's rmse: 7.85751\tvalid_1's rmse: 54.4517\n",
      "[750]\ttraining's rmse: 7.37795\tvalid_1's rmse: 54.4397\n",
      "[780]\ttraining's rmse: 6.9378\tvalid_1's rmse: 54.4012\n",
      "[810]\ttraining's rmse: 6.52762\tvalid_1's rmse: 54.381\n",
      "[840]\ttraining's rmse: 6.149\tvalid_1's rmse: 54.3468\n",
      "[870]\ttraining's rmse: 5.79281\tvalid_1's rmse: 54.3167\n",
      "[900]\ttraining's rmse: 5.46185\tvalid_1's rmse: 54.2759\n",
      "[930]\ttraining's rmse: 5.15274\tvalid_1's rmse: 54.2529\n",
      "[960]\ttraining's rmse: 4.85685\tvalid_1's rmse: 54.2447\n",
      "[990]\ttraining's rmse: 4.58714\tvalid_1's rmse: 54.2282\n",
      "[1020]\ttraining's rmse: 4.3357\tvalid_1's rmse: 54.2121\n",
      "[1050]\ttraining's rmse: 4.10213\tvalid_1's rmse: 54.1897\n",
      "[1080]\ttraining's rmse: 3.88046\tvalid_1's rmse: 54.1769\n",
      "[1110]\ttraining's rmse: 3.67035\tvalid_1's rmse: 54.1638\n",
      "[1140]\ttraining's rmse: 3.46985\tvalid_1's rmse: 54.1505\n",
      "[1170]\ttraining's rmse: 3.28717\tvalid_1's rmse: 54.1444\n",
      "[1200]\ttraining's rmse: 3.11129\tvalid_1's rmse: 54.1389\n",
      "[1230]\ttraining's rmse: 2.94528\tvalid_1's rmse: 54.1311\n",
      "[1260]\ttraining's rmse: 2.78588\tvalid_1's rmse: 54.1197\n",
      "[1290]\ttraining's rmse: 2.64047\tvalid_1's rmse: 54.1153\n",
      "[1320]\ttraining's rmse: 2.49745\tvalid_1's rmse: 54.1058\n",
      "[1350]\ttraining's rmse: 2.36981\tvalid_1's rmse: 54.0978\n",
      "[1380]\ttraining's rmse: 2.24538\tvalid_1's rmse: 54.0917\n",
      "[1410]\ttraining's rmse: 2.13262\tvalid_1's rmse: 54.0886\n",
      "[1440]\ttraining's rmse: 2.02414\tvalid_1's rmse: 54.0829\n",
      "[1470]\ttraining's rmse: 1.92236\tvalid_1's rmse: 54.0784\n",
      "[1500]\ttraining's rmse: 1.82374\tvalid_1's rmse: 54.0769\n",
      "[1530]\ttraining's rmse: 1.73294\tvalid_1's rmse: 54.0752\n",
      "[1560]\ttraining's rmse: 1.64755\tvalid_1's rmse: 54.0727\n",
      "[1590]\ttraining's rmse: 1.56657\tvalid_1's rmse: 54.0681\n",
      "[1620]\ttraining's rmse: 1.48893\tvalid_1's rmse: 54.0649\n",
      "[1650]\ttraining's rmse: 1.41604\tvalid_1's rmse: 54.0603\n",
      "[1680]\ttraining's rmse: 1.34514\tvalid_1's rmse: 54.0616\n",
      "[1710]\ttraining's rmse: 1.2781\tvalid_1's rmse: 54.0606\n",
      "[1740]\ttraining's rmse: 1.21546\tvalid_1's rmse: 54.0588\n",
      "[1770]\ttraining's rmse: 1.15501\tvalid_1's rmse: 54.0578\n",
      "[1800]\ttraining's rmse: 1.09934\tvalid_1's rmse: 54.055\n",
      "[1830]\ttraining's rmse: 1.04464\tvalid_1's rmse: 54.0537\n",
      "[1860]\ttraining's rmse: 0.994031\tvalid_1's rmse: 54.0502\n",
      "[1890]\ttraining's rmse: 0.946374\tvalid_1's rmse: 54.0487\n",
      "[1920]\ttraining's rmse: 0.90121\tvalid_1's rmse: 54.0468\n",
      "[1950]\ttraining's rmse: 0.857894\tvalid_1's rmse: 54.0466\n",
      "[1980]\ttraining's rmse: 0.817767\tvalid_1's rmse: 54.0461\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's rmse: 0.790855\tvalid_1's rmse: 54.0454\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002312 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 20024\n",
      "[LightGBM] [Info] Number of data points in the train set: 9219, number of used features: 79\n",
      "[LightGBM] [Info] Start training from score 360.035562\n",
      "Training until validation scores don't improve for 125 rounds\n",
      "[30]\ttraining's rmse: 155.451\tvalid_1's rmse: 161.828\n",
      "[60]\ttraining's rmse: 96.3823\tvalid_1's rmse: 107.306\n",
      "[90]\ttraining's rmse: 64.6957\tvalid_1's rmse: 80.2814\n",
      "[120]\ttraining's rmse: 47.7514\tvalid_1's rmse: 67.5993\n",
      "[150]\ttraining's rmse: 38.1322\tvalid_1's rmse: 61.5562\n",
      "[180]\ttraining's rmse: 32.2506\tvalid_1's rmse: 58.345\n",
      "[210]\ttraining's rmse: 28.2984\tvalid_1's rmse: 56.6093\n",
      "[240]\ttraining's rmse: 25.2681\tvalid_1's rmse: 55.4056\n",
      "[270]\ttraining's rmse: 22.8145\tvalid_1's rmse: 54.5598\n",
      "[300]\ttraining's rmse: 20.7418\tvalid_1's rmse: 54.061\n",
      "[330]\ttraining's rmse: 18.9611\tvalid_1's rmse: 53.6975\n",
      "[360]\ttraining's rmse: 17.3948\tvalid_1's rmse: 53.3865\n",
      "[390]\ttraining's rmse: 16.0452\tvalid_1's rmse: 53.1143\n",
      "[420]\ttraining's rmse: 14.8526\tvalid_1's rmse: 52.9835\n",
      "[450]\ttraining's rmse: 13.7723\tvalid_1's rmse: 52.8483\n",
      "[480]\ttraining's rmse: 12.7893\tvalid_1's rmse: 52.711\n",
      "[510]\ttraining's rmse: 11.8939\tvalid_1's rmse: 52.628\n",
      "[540]\ttraining's rmse: 11.0925\tvalid_1's rmse: 52.5556\n",
      "[570]\ttraining's rmse: 10.363\tvalid_1's rmse: 52.5175\n",
      "[600]\ttraining's rmse: 9.7052\tvalid_1's rmse: 52.4748\n",
      "[630]\ttraining's rmse: 9.07882\tvalid_1's rmse: 52.411\n",
      "[660]\ttraining's rmse: 8.50634\tvalid_1's rmse: 52.3533\n",
      "[690]\ttraining's rmse: 7.97292\tvalid_1's rmse: 52.299\n",
      "[720]\ttraining's rmse: 7.4858\tvalid_1's rmse: 52.256\n",
      "[750]\ttraining's rmse: 7.04152\tvalid_1's rmse: 52.2149\n",
      "[780]\ttraining's rmse: 6.61916\tvalid_1's rmse: 52.1769\n",
      "[810]\ttraining's rmse: 6.22869\tvalid_1's rmse: 52.1467\n",
      "[840]\ttraining's rmse: 5.86283\tvalid_1's rmse: 52.1382\n",
      "[870]\ttraining's rmse: 5.52154\tvalid_1's rmse: 52.1112\n",
      "[900]\ttraining's rmse: 5.20829\tvalid_1's rmse: 52.097\n",
      "[930]\ttraining's rmse: 4.91354\tvalid_1's rmse: 52.0916\n",
      "[960]\ttraining's rmse: 4.63478\tvalid_1's rmse: 52.0773\n",
      "[990]\ttraining's rmse: 4.38123\tvalid_1's rmse: 52.0659\n",
      "[1020]\ttraining's rmse: 4.13633\tvalid_1's rmse: 52.0526\n",
      "[1050]\ttraining's rmse: 3.91089\tvalid_1's rmse: 52.0429\n",
      "[1080]\ttraining's rmse: 3.6949\tvalid_1's rmse: 52.0278\n",
      "[1110]\ttraining's rmse: 3.49728\tvalid_1's rmse: 52.0183\n",
      "[1140]\ttraining's rmse: 3.30883\tvalid_1's rmse: 52.0105\n",
      "[1170]\ttraining's rmse: 3.13653\tvalid_1's rmse: 52.0039\n",
      "[1200]\ttraining's rmse: 2.97118\tvalid_1's rmse: 52.0003\n",
      "[1230]\ttraining's rmse: 2.81688\tvalid_1's rmse: 51.9912\n",
      "[1260]\ttraining's rmse: 2.66833\tvalid_1's rmse: 51.99\n",
      "[1290]\ttraining's rmse: 2.52975\tvalid_1's rmse: 51.984\n",
      "[1320]\ttraining's rmse: 2.39794\tvalid_1's rmse: 51.9801\n",
      "[1350]\ttraining's rmse: 2.27686\tvalid_1's rmse: 51.9739\n",
      "[1380]\ttraining's rmse: 2.15989\tvalid_1's rmse: 51.9682\n",
      "[1410]\ttraining's rmse: 2.05099\tvalid_1's rmse: 51.9654\n",
      "[1440]\ttraining's rmse: 1.94493\tvalid_1's rmse: 51.9605\n",
      "[1470]\ttraining's rmse: 1.84583\tvalid_1's rmse: 51.9562\n",
      "[1500]\ttraining's rmse: 1.75362\tvalid_1's rmse: 51.9543\n",
      "[1530]\ttraining's rmse: 1.66629\tvalid_1's rmse: 51.9534\n",
      "[1560]\ttraining's rmse: 1.58297\tvalid_1's rmse: 51.9512\n",
      "[1590]\ttraining's rmse: 1.50536\tvalid_1's rmse: 51.9517\n",
      "[1620]\ttraining's rmse: 1.42896\tvalid_1's rmse: 51.9476\n",
      "[1650]\ttraining's rmse: 1.35837\tvalid_1's rmse: 51.9425\n",
      "[1680]\ttraining's rmse: 1.29175\tvalid_1's rmse: 51.9398\n",
      "[1710]\ttraining's rmse: 1.22925\tvalid_1's rmse: 51.9369\n",
      "[1740]\ttraining's rmse: 1.16944\tvalid_1's rmse: 51.9352\n",
      "[1770]\ttraining's rmse: 1.11152\tvalid_1's rmse: 51.932\n",
      "[1800]\ttraining's rmse: 1.05724\tvalid_1's rmse: 51.9323\n",
      "[1830]\ttraining's rmse: 1.00597\tvalid_1's rmse: 51.9314\n",
      "[1860]\ttraining's rmse: 0.957831\tvalid_1's rmse: 51.9298\n",
      "[1890]\ttraining's rmse: 0.912156\tvalid_1's rmse: 51.9284\n",
      "[1920]\ttraining's rmse: 0.868312\tvalid_1's rmse: 51.9272\n",
      "[1950]\ttraining's rmse: 0.825989\tvalid_1's rmse: 51.9251\n",
      "[1980]\ttraining's rmse: 0.7872\tvalid_1's rmse: 51.9254\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's rmse: 0.761375\tvalid_1's rmse: 51.9245\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003529 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 20024\n",
      "[LightGBM] [Info] Number of data points in the train set: 9219, number of used features: 79\n",
      "[LightGBM] [Info] Start training from score 365.545418\n",
      "Training until validation scores don't improve for 125 rounds\n",
      "[30]\ttraining's rmse: 155.469\tvalid_1's rmse: 157.162\n",
      "[60]\ttraining's rmse: 96.722\tvalid_1's rmse: 105.384\n",
      "[90]\ttraining's rmse: 65.1376\tvalid_1's rmse: 79.9958\n",
      "[120]\ttraining's rmse: 48.1848\tvalid_1's rmse: 67.9661\n",
      "[150]\ttraining's rmse: 38.6719\tvalid_1's rmse: 62.1091\n",
      "[180]\ttraining's rmse: 32.8384\tvalid_1's rmse: 59.0563\n",
      "[210]\ttraining's rmse: 28.7898\tvalid_1's rmse: 57.354\n",
      "[240]\ttraining's rmse: 25.7508\tvalid_1's rmse: 56.328\n",
      "[270]\ttraining's rmse: 23.2497\tvalid_1's rmse: 55.6237\n",
      "[300]\ttraining's rmse: 21.2215\tvalid_1's rmse: 55.1937\n",
      "[330]\ttraining's rmse: 19.4362\tvalid_1's rmse: 54.8181\n",
      "[360]\ttraining's rmse: 17.8932\tvalid_1's rmse: 54.5354\n",
      "[390]\ttraining's rmse: 16.5314\tvalid_1's rmse: 54.3271\n",
      "[420]\ttraining's rmse: 15.307\tvalid_1's rmse: 54.1589\n",
      "[450]\ttraining's rmse: 14.2083\tvalid_1's rmse: 54.0252\n",
      "[480]\ttraining's rmse: 13.2279\tvalid_1's rmse: 53.9164\n",
      "[510]\ttraining's rmse: 12.332\tvalid_1's rmse: 53.794\n",
      "[540]\ttraining's rmse: 11.5149\tvalid_1's rmse: 53.7241\n",
      "[570]\ttraining's rmse: 10.7698\tvalid_1's rmse: 53.6387\n",
      "[600]\ttraining's rmse: 10.0946\tvalid_1's rmse: 53.5754\n",
      "[630]\ttraining's rmse: 9.47174\tvalid_1's rmse: 53.5317\n",
      "[660]\ttraining's rmse: 8.88748\tvalid_1's rmse: 53.4843\n",
      "[690]\ttraining's rmse: 8.34715\tvalid_1's rmse: 53.4467\n",
      "[720]\ttraining's rmse: 7.84173\tvalid_1's rmse: 53.4182\n",
      "[750]\ttraining's rmse: 7.37731\tvalid_1's rmse: 53.3926\n",
      "[780]\ttraining's rmse: 6.93398\tvalid_1's rmse: 53.3603\n",
      "[810]\ttraining's rmse: 6.52321\tvalid_1's rmse: 53.3453\n",
      "[840]\ttraining's rmse: 6.14551\tvalid_1's rmse: 53.3296\n",
      "[870]\ttraining's rmse: 5.79961\tvalid_1's rmse: 53.3051\n",
      "[900]\ttraining's rmse: 5.47041\tvalid_1's rmse: 53.2836\n",
      "[930]\ttraining's rmse: 5.16045\tvalid_1's rmse: 53.2673\n",
      "[960]\ttraining's rmse: 4.87541\tvalid_1's rmse: 53.2483\n",
      "[990]\ttraining's rmse: 4.61323\tvalid_1's rmse: 53.2326\n",
      "[1020]\ttraining's rmse: 4.35897\tvalid_1's rmse: 53.2114\n",
      "[1050]\ttraining's rmse: 4.1226\tvalid_1's rmse: 53.1991\n",
      "[1080]\ttraining's rmse: 3.89686\tvalid_1's rmse: 53.1889\n",
      "[1110]\ttraining's rmse: 3.68929\tvalid_1's rmse: 53.1876\n",
      "[1140]\ttraining's rmse: 3.49194\tvalid_1's rmse: 53.179\n",
      "[1170]\ttraining's rmse: 3.30637\tvalid_1's rmse: 53.1636\n",
      "[1200]\ttraining's rmse: 3.13528\tvalid_1's rmse: 53.1548\n",
      "[1230]\ttraining's rmse: 2.97389\tvalid_1's rmse: 53.1502\n",
      "[1260]\ttraining's rmse: 2.81561\tvalid_1's rmse: 53.146\n",
      "[1290]\ttraining's rmse: 2.67357\tvalid_1's rmse: 53.1419\n",
      "[1320]\ttraining's rmse: 2.5356\tvalid_1's rmse: 53.137\n",
      "[1350]\ttraining's rmse: 2.40863\tvalid_1's rmse: 53.1291\n",
      "[1380]\ttraining's rmse: 2.28564\tvalid_1's rmse: 53.1209\n",
      "[1410]\ttraining's rmse: 2.17093\tvalid_1's rmse: 53.1171\n",
      "[1440]\ttraining's rmse: 2.06354\tvalid_1's rmse: 53.1136\n",
      "[1470]\ttraining's rmse: 1.9611\tvalid_1's rmse: 53.1085\n",
      "[1500]\ttraining's rmse: 1.86145\tvalid_1's rmse: 53.1064\n",
      "[1530]\ttraining's rmse: 1.76958\tvalid_1's rmse: 53.1077\n",
      "[1560]\ttraining's rmse: 1.68288\tvalid_1's rmse: 53.1046\n",
      "[1590]\ttraining's rmse: 1.60082\tvalid_1's rmse: 53.1025\n",
      "[1620]\ttraining's rmse: 1.52225\tvalid_1's rmse: 53.0985\n",
      "[1650]\ttraining's rmse: 1.44786\tvalid_1's rmse: 53.0961\n",
      "[1680]\ttraining's rmse: 1.37712\tvalid_1's rmse: 53.0952\n",
      "[1710]\ttraining's rmse: 1.31137\tvalid_1's rmse: 53.0932\n",
      "[1740]\ttraining's rmse: 1.24774\tvalid_1's rmse: 53.0916\n",
      "[1770]\ttraining's rmse: 1.18941\tvalid_1's rmse: 53.0858\n",
      "[1800]\ttraining's rmse: 1.13403\tvalid_1's rmse: 53.0829\n",
      "[1830]\ttraining's rmse: 1.08041\tvalid_1's rmse: 53.0804\n",
      "[1860]\ttraining's rmse: 1.03115\tvalid_1's rmse: 53.0787\n",
      "[1890]\ttraining's rmse: 0.983633\tvalid_1's rmse: 53.0776\n",
      "[1920]\ttraining's rmse: 0.936695\tvalid_1's rmse: 53.0768\n",
      "[1950]\ttraining's rmse: 0.893423\tvalid_1's rmse: 53.0762\n",
      "[1980]\ttraining's rmse: 0.851954\tvalid_1's rmse: 53.0748\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's rmse: 0.82571\tvalid_1's rmse: 53.0746\n",
      "27\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003285 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 20022\n",
      "[LightGBM] [Info] Number of data points in the train set: 9219, number of used features: 79\n",
      "[LightGBM] [Info] Start training from score 352.453781\n",
      "Training until validation scores don't improve for 125 rounds\n",
      "[30]\ttraining's rmse: 150.95\tvalid_1's rmse: 156.011\n",
      "[60]\ttraining's rmse: 93.325\tvalid_1's rmse: 102.996\n",
      "[90]\ttraining's rmse: 62.2547\tvalid_1's rmse: 77.106\n",
      "[120]\ttraining's rmse: 45.6563\tvalid_1's rmse: 65.4666\n",
      "[150]\ttraining's rmse: 36.4096\tvalid_1's rmse: 60.0792\n",
      "[180]\ttraining's rmse: 30.7913\tvalid_1's rmse: 57.3058\n",
      "[210]\ttraining's rmse: 27.0219\tvalid_1's rmse: 55.89\n",
      "[240]\ttraining's rmse: 24.0384\tvalid_1's rmse: 54.7871\n",
      "[270]\ttraining's rmse: 21.6899\tvalid_1's rmse: 54.1648\n",
      "[300]\ttraining's rmse: 19.7005\tvalid_1's rmse: 53.657\n",
      "[330]\ttraining's rmse: 18.0476\tvalid_1's rmse: 53.2755\n",
      "[360]\ttraining's rmse: 16.604\tvalid_1's rmse: 52.9538\n",
      "[390]\ttraining's rmse: 15.3316\tvalid_1's rmse: 52.7625\n",
      "[420]\ttraining's rmse: 14.2299\tvalid_1's rmse: 52.6029\n",
      "[450]\ttraining's rmse: 13.1956\tvalid_1's rmse: 52.4631\n",
      "[480]\ttraining's rmse: 12.2815\tvalid_1's rmse: 52.3135\n",
      "[510]\ttraining's rmse: 11.4466\tvalid_1's rmse: 52.2181\n",
      "[540]\ttraining's rmse: 10.6816\tvalid_1's rmse: 52.1266\n",
      "[570]\ttraining's rmse: 10.0012\tvalid_1's rmse: 52.053\n",
      "[600]\ttraining's rmse: 9.37372\tvalid_1's rmse: 51.9802\n",
      "[630]\ttraining's rmse: 8.79368\tvalid_1's rmse: 51.9442\n",
      "[660]\ttraining's rmse: 8.24833\tvalid_1's rmse: 51.8886\n",
      "[690]\ttraining's rmse: 7.74972\tvalid_1's rmse: 51.8391\n",
      "[720]\ttraining's rmse: 7.27711\tvalid_1's rmse: 51.7954\n",
      "[750]\ttraining's rmse: 6.8406\tvalid_1's rmse: 51.7559\n",
      "[780]\ttraining's rmse: 6.44808\tvalid_1's rmse: 51.7153\n",
      "[810]\ttraining's rmse: 6.07196\tvalid_1's rmse: 51.6794\n",
      "[840]\ttraining's rmse: 5.7263\tvalid_1's rmse: 51.642\n",
      "[870]\ttraining's rmse: 5.40151\tvalid_1's rmse: 51.6166\n",
      "[900]\ttraining's rmse: 5.09677\tvalid_1's rmse: 51.6016\n",
      "[930]\ttraining's rmse: 4.82701\tvalid_1's rmse: 51.5791\n",
      "[960]\ttraining's rmse: 4.56199\tvalid_1's rmse: 51.5555\n",
      "[990]\ttraining's rmse: 4.31219\tvalid_1's rmse: 51.5356\n",
      "[1020]\ttraining's rmse: 4.08264\tvalid_1's rmse: 51.5279\n",
      "[1050]\ttraining's rmse: 3.86087\tvalid_1's rmse: 51.5241\n",
      "[1080]\ttraining's rmse: 3.65465\tvalid_1's rmse: 51.5132\n",
      "[1110]\ttraining's rmse: 3.45993\tvalid_1's rmse: 51.5115\n",
      "[1140]\ttraining's rmse: 3.28659\tvalid_1's rmse: 51.5009\n",
      "[1170]\ttraining's rmse: 3.11585\tvalid_1's rmse: 51.4932\n",
      "[1200]\ttraining's rmse: 2.9556\tvalid_1's rmse: 51.4881\n",
      "[1230]\ttraining's rmse: 2.80002\tvalid_1's rmse: 51.4841\n",
      "[1260]\ttraining's rmse: 2.65495\tvalid_1's rmse: 51.4747\n",
      "[1290]\ttraining's rmse: 2.5225\tvalid_1's rmse: 51.467\n",
      "[1320]\ttraining's rmse: 2.39689\tvalid_1's rmse: 51.4645\n",
      "[1350]\ttraining's rmse: 2.27653\tvalid_1's rmse: 51.4558\n",
      "[1380]\ttraining's rmse: 2.16412\tvalid_1's rmse: 51.4541\n",
      "[1410]\ttraining's rmse: 2.0611\tvalid_1's rmse: 51.4498\n",
      "[1440]\ttraining's rmse: 1.96118\tvalid_1's rmse: 51.4485\n",
      "[1470]\ttraining's rmse: 1.86483\tvalid_1's rmse: 51.4415\n",
      "[1500]\ttraining's rmse: 1.7736\tvalid_1's rmse: 51.4378\n",
      "[1530]\ttraining's rmse: 1.68816\tvalid_1's rmse: 51.4346\n",
      "[1560]\ttraining's rmse: 1.60696\tvalid_1's rmse: 51.4291\n",
      "[1590]\ttraining's rmse: 1.53115\tvalid_1's rmse: 51.4271\n",
      "[1620]\ttraining's rmse: 1.46017\tvalid_1's rmse: 51.4206\n",
      "[1650]\ttraining's rmse: 1.3935\tvalid_1's rmse: 51.4167\n",
      "[1680]\ttraining's rmse: 1.32802\tvalid_1's rmse: 51.4132\n",
      "[1710]\ttraining's rmse: 1.2655\tvalid_1's rmse: 51.4099\n",
      "[1740]\ttraining's rmse: 1.20576\tvalid_1's rmse: 51.4036\n",
      "[1770]\ttraining's rmse: 1.14864\tvalid_1's rmse: 51.4011\n",
      "[1800]\ttraining's rmse: 1.0965\tvalid_1's rmse: 51.3994\n",
      "[1830]\ttraining's rmse: 1.04512\tvalid_1's rmse: 51.3985\n",
      "[1860]\ttraining's rmse: 0.997176\tvalid_1's rmse: 51.3971\n",
      "[1890]\ttraining's rmse: 0.953025\tvalid_1's rmse: 51.3938\n",
      "[1920]\ttraining's rmse: 0.910223\tvalid_1's rmse: 51.3926\n",
      "[1950]\ttraining's rmse: 0.866751\tvalid_1's rmse: 51.3908\n",
      "[1980]\ttraining's rmse: 0.826532\tvalid_1's rmse: 51.3898\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's rmse: 0.800457\tvalid_1's rmse: 51.3881\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003542 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 20022\n",
      "[LightGBM] [Info] Number of data points in the train set: 9219, number of used features: 79\n",
      "[LightGBM] [Info] Start training from score 357.391145\n",
      "Training until validation scores don't improve for 125 rounds\n",
      "[30]\ttraining's rmse: 152.554\tvalid_1's rmse: 155.709\n",
      "[60]\ttraining's rmse: 96.0539\tvalid_1's rmse: 104.416\n",
      "[90]\ttraining's rmse: 65.5037\tvalid_1's rmse: 79.3149\n",
      "[120]\ttraining's rmse: 48.7899\tvalid_1's rmse: 67.3386\n",
      "[150]\ttraining's rmse: 39.2854\tvalid_1's rmse: 61.6351\n",
      "[180]\ttraining's rmse: 33.3288\tvalid_1's rmse: 58.5287\n",
      "[210]\ttraining's rmse: 29.1957\tvalid_1's rmse: 56.9064\n",
      "[240]\ttraining's rmse: 25.9227\tvalid_1's rmse: 55.6655\n",
      "[270]\ttraining's rmse: 23.3462\tvalid_1's rmse: 54.8274\n",
      "[300]\ttraining's rmse: 21.2362\tvalid_1's rmse: 54.2027\n",
      "[330]\ttraining's rmse: 19.3698\tvalid_1's rmse: 53.7723\n",
      "[360]\ttraining's rmse: 17.7933\tvalid_1's rmse: 53.4618\n",
      "[390]\ttraining's rmse: 16.4235\tvalid_1's rmse: 53.2203\n",
      "[420]\ttraining's rmse: 15.1931\tvalid_1's rmse: 53.0372\n",
      "[450]\ttraining's rmse: 14.0768\tvalid_1's rmse: 52.908\n",
      "[480]\ttraining's rmse: 13.0725\tvalid_1's rmse: 52.7816\n",
      "[510]\ttraining's rmse: 12.173\tvalid_1's rmse: 52.633\n",
      "[540]\ttraining's rmse: 11.3408\tvalid_1's rmse: 52.5232\n",
      "[570]\ttraining's rmse: 10.5854\tvalid_1's rmse: 52.4527\n",
      "[600]\ttraining's rmse: 9.89908\tvalid_1's rmse: 52.405\n",
      "[630]\ttraining's rmse: 9.26947\tvalid_1's rmse: 52.3391\n",
      "[660]\ttraining's rmse: 8.69126\tvalid_1's rmse: 52.275\n",
      "[690]\ttraining's rmse: 8.15585\tvalid_1's rmse: 52.2221\n",
      "[720]\ttraining's rmse: 7.65259\tvalid_1's rmse: 52.168\n",
      "[750]\ttraining's rmse: 7.19438\tvalid_1's rmse: 52.1421\n",
      "[780]\ttraining's rmse: 6.77033\tvalid_1's rmse: 52.106\n",
      "[810]\ttraining's rmse: 6.36984\tvalid_1's rmse: 52.0603\n",
      "[840]\ttraining's rmse: 6.00216\tvalid_1's rmse: 52.0548\n",
      "[870]\ttraining's rmse: 5.6512\tvalid_1's rmse: 52.0278\n",
      "[900]\ttraining's rmse: 5.33457\tvalid_1's rmse: 52.0156\n",
      "[930]\ttraining's rmse: 5.03996\tvalid_1's rmse: 51.9879\n",
      "[960]\ttraining's rmse: 4.76191\tvalid_1's rmse: 51.9793\n",
      "[990]\ttraining's rmse: 4.49406\tvalid_1's rmse: 51.9651\n",
      "[1020]\ttraining's rmse: 4.24802\tvalid_1's rmse: 51.9504\n",
      "[1050]\ttraining's rmse: 4.02243\tvalid_1's rmse: 51.9446\n",
      "[1080]\ttraining's rmse: 3.80581\tvalid_1's rmse: 51.9397\n",
      "[1110]\ttraining's rmse: 3.60173\tvalid_1's rmse: 51.9333\n",
      "[1140]\ttraining's rmse: 3.41092\tvalid_1's rmse: 51.9298\n",
      "[1170]\ttraining's rmse: 3.23295\tvalid_1's rmse: 51.9282\n",
      "[1200]\ttraining's rmse: 3.06011\tvalid_1's rmse: 51.9209\n",
      "[1230]\ttraining's rmse: 2.90079\tvalid_1's rmse: 51.9145\n",
      "[1260]\ttraining's rmse: 2.74781\tvalid_1's rmse: 51.9103\n",
      "[1290]\ttraining's rmse: 2.60565\tvalid_1's rmse: 51.9034\n",
      "[1320]\ttraining's rmse: 2.46851\tvalid_1's rmse: 51.8956\n",
      "[1350]\ttraining's rmse: 2.34369\tvalid_1's rmse: 51.892\n",
      "[1380]\ttraining's rmse: 2.22512\tvalid_1's rmse: 51.8872\n",
      "[1410]\ttraining's rmse: 2.11619\tvalid_1's rmse: 51.8838\n",
      "[1440]\ttraining's rmse: 2.01051\tvalid_1's rmse: 51.8798\n",
      "[1470]\ttraining's rmse: 1.91126\tvalid_1's rmse: 51.8793\n",
      "[1500]\ttraining's rmse: 1.81848\tvalid_1's rmse: 51.8783\n",
      "[1530]\ttraining's rmse: 1.72724\tvalid_1's rmse: 51.8745\n",
      "[1560]\ttraining's rmse: 1.64061\tvalid_1's rmse: 51.8711\n",
      "[1590]\ttraining's rmse: 1.56192\tvalid_1's rmse: 51.867\n",
      "[1620]\ttraining's rmse: 1.48702\tvalid_1's rmse: 51.8656\n",
      "[1650]\ttraining's rmse: 1.41438\tvalid_1's rmse: 51.8623\n",
      "[1680]\ttraining's rmse: 1.34547\tvalid_1's rmse: 51.865\n",
      "[1710]\ttraining's rmse: 1.27967\tvalid_1's rmse: 51.8636\n",
      "[1740]\ttraining's rmse: 1.21858\tvalid_1's rmse: 51.8632\n",
      "[1770]\ttraining's rmse: 1.15981\tvalid_1's rmse: 51.863\n",
      "Early stopping, best iteration is:\n",
      "[1651]\ttraining's rmse: 1.41204\tvalid_1's rmse: 51.8622\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003607 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 20022\n",
      "[LightGBM] [Info] Number of data points in the train set: 9219, number of used features: 79\n",
      "[LightGBM] [Info] Start training from score 367.382886\n",
      "Training until validation scores don't improve for 125 rounds\n",
      "[30]\ttraining's rmse: 156.186\tvalid_1's rmse: 159.264\n",
      "[60]\ttraining's rmse: 97.8528\tvalid_1's rmse: 108.282\n",
      "[90]\ttraining's rmse: 66.3067\tvalid_1's rmse: 83.1098\n",
      "[120]\ttraining's rmse: 49.2035\tvalid_1's rmse: 71.234\n",
      "[150]\ttraining's rmse: 39.5174\tvalid_1's rmse: 65.3236\n",
      "[180]\ttraining's rmse: 33.4823\tvalid_1's rmse: 62.281\n",
      "[210]\ttraining's rmse: 29.2704\tvalid_1's rmse: 60.4879\n",
      "[240]\ttraining's rmse: 26.1317\tvalid_1's rmse: 59.432\n",
      "[270]\ttraining's rmse: 23.5352\tvalid_1's rmse: 58.6258\n",
      "[300]\ttraining's rmse: 21.3751\tvalid_1's rmse: 58.0416\n",
      "[330]\ttraining's rmse: 19.5722\tvalid_1's rmse: 57.6238\n",
      "[360]\ttraining's rmse: 17.9893\tvalid_1's rmse: 57.2789\n",
      "[390]\ttraining's rmse: 16.5686\tvalid_1's rmse: 57.0428\n",
      "[420]\ttraining's rmse: 15.3078\tvalid_1's rmse: 56.8277\n",
      "[450]\ttraining's rmse: 14.208\tvalid_1's rmse: 56.6876\n",
      "[480]\ttraining's rmse: 13.1628\tvalid_1's rmse: 56.5309\n",
      "[510]\ttraining's rmse: 12.2702\tvalid_1's rmse: 56.4068\n",
      "[540]\ttraining's rmse: 11.414\tvalid_1's rmse: 56.2797\n",
      "[570]\ttraining's rmse: 10.6564\tvalid_1's rmse: 56.2166\n",
      "[600]\ttraining's rmse: 9.95689\tvalid_1's rmse: 56.138\n",
      "[630]\ttraining's rmse: 9.33028\tvalid_1's rmse: 56.0866\n",
      "[660]\ttraining's rmse: 8.73635\tvalid_1's rmse: 56.0267\n",
      "[690]\ttraining's rmse: 8.18825\tvalid_1's rmse: 55.9731\n",
      "[720]\ttraining's rmse: 7.69113\tvalid_1's rmse: 55.923\n",
      "[750]\ttraining's rmse: 7.22124\tvalid_1's rmse: 55.8984\n",
      "[780]\ttraining's rmse: 6.79312\tvalid_1's rmse: 55.8651\n",
      "[810]\ttraining's rmse: 6.3932\tvalid_1's rmse: 55.8277\n",
      "[840]\ttraining's rmse: 6.01321\tvalid_1's rmse: 55.8028\n",
      "[870]\ttraining's rmse: 5.66147\tvalid_1's rmse: 55.7615\n",
      "[900]\ttraining's rmse: 5.33667\tvalid_1's rmse: 55.7285\n",
      "[930]\ttraining's rmse: 5.02838\tvalid_1's rmse: 55.7082\n",
      "[960]\ttraining's rmse: 4.74434\tvalid_1's rmse: 55.6855\n",
      "[990]\ttraining's rmse: 4.47822\tvalid_1's rmse: 55.6596\n",
      "[1020]\ttraining's rmse: 4.23065\tvalid_1's rmse: 55.6431\n",
      "[1050]\ttraining's rmse: 3.99486\tvalid_1's rmse: 55.6338\n",
      "[1080]\ttraining's rmse: 3.77476\tvalid_1's rmse: 55.6137\n",
      "[1110]\ttraining's rmse: 3.57195\tvalid_1's rmse: 55.6016\n",
      "[1140]\ttraining's rmse: 3.37994\tvalid_1's rmse: 55.5946\n",
      "[1170]\ttraining's rmse: 3.19477\tvalid_1's rmse: 55.5844\n",
      "[1200]\ttraining's rmse: 3.02272\tvalid_1's rmse: 55.5651\n",
      "[1230]\ttraining's rmse: 2.85955\tvalid_1's rmse: 55.5598\n",
      "[1260]\ttraining's rmse: 2.70581\tvalid_1's rmse: 55.5492\n",
      "[1290]\ttraining's rmse: 2.56159\tvalid_1's rmse: 55.544\n",
      "[1320]\ttraining's rmse: 2.42646\tvalid_1's rmse: 55.5365\n",
      "[1350]\ttraining's rmse: 2.29901\tvalid_1's rmse: 55.5301\n",
      "[1380]\ttraining's rmse: 2.17954\tvalid_1's rmse: 55.526\n",
      "[1410]\ttraining's rmse: 2.06731\tvalid_1's rmse: 55.5227\n",
      "[1440]\ttraining's rmse: 1.95976\tvalid_1's rmse: 55.5147\n",
      "[1470]\ttraining's rmse: 1.85972\tvalid_1's rmse: 55.5079\n",
      "[1500]\ttraining's rmse: 1.76417\tvalid_1's rmse: 55.5018\n",
      "[1530]\ttraining's rmse: 1.67113\tvalid_1's rmse: 55.4966\n",
      "[1560]\ttraining's rmse: 1.58701\tvalid_1's rmse: 55.4955\n",
      "[1590]\ttraining's rmse: 1.50486\tvalid_1's rmse: 55.491\n",
      "[1620]\ttraining's rmse: 1.42645\tvalid_1's rmse: 55.4861\n",
      "[1650]\ttraining's rmse: 1.3563\tvalid_1's rmse: 55.4838\n",
      "[1680]\ttraining's rmse: 1.28774\tvalid_1's rmse: 55.4815\n",
      "[1710]\ttraining's rmse: 1.22412\tvalid_1's rmse: 55.4773\n",
      "[1740]\ttraining's rmse: 1.16424\tvalid_1's rmse: 55.4726\n",
      "[1770]\ttraining's rmse: 1.106\tvalid_1's rmse: 55.4716\n",
      "[1800]\ttraining's rmse: 1.0514\tvalid_1's rmse: 55.4694\n",
      "[1830]\ttraining's rmse: 1.00003\tvalid_1's rmse: 55.467\n",
      "[1860]\ttraining's rmse: 0.950022\tvalid_1's rmse: 55.4636\n",
      "[1890]\ttraining's rmse: 0.903975\tvalid_1's rmse: 55.4616\n",
      "[1920]\ttraining's rmse: 0.860164\tvalid_1's rmse: 55.4612\n",
      "[1950]\ttraining's rmse: 0.819213\tvalid_1's rmse: 55.4588\n",
      "[1980]\ttraining's rmse: 0.779451\tvalid_1's rmse: 55.458\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's rmse: 0.754009\tvalid_1's rmse: 55.4557\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003399 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 20022\n",
      "[LightGBM] [Info] Number of data points in the train set: 9219, number of used features: 79\n",
      "[LightGBM] [Info] Start training from score 369.350809\n",
      "Training until validation scores don't improve for 125 rounds\n",
      "[30]\ttraining's rmse: 156.998\tvalid_1's rmse: 159.553\n",
      "[60]\ttraining's rmse: 98.7985\tvalid_1's rmse: 108.868\n",
      "[90]\ttraining's rmse: 67.347\tvalid_1's rmse: 84.1246\n",
      "[120]\ttraining's rmse: 50.1303\tvalid_1's rmse: 72.6166\n",
      "[150]\ttraining's rmse: 40.2938\tvalid_1's rmse: 66.9342\n",
      "[180]\ttraining's rmse: 34.2644\tvalid_1's rmse: 63.9827\n",
      "[210]\ttraining's rmse: 30.0139\tvalid_1's rmse: 62.2366\n",
      "[240]\ttraining's rmse: 26.7876\tvalid_1's rmse: 61.0731\n",
      "[270]\ttraining's rmse: 24.1636\tvalid_1's rmse: 60.1441\n",
      "[300]\ttraining's rmse: 21.9666\tvalid_1's rmse: 59.531\n",
      "[330]\ttraining's rmse: 20.0469\tvalid_1's rmse: 59.1021\n",
      "[360]\ttraining's rmse: 18.4079\tvalid_1's rmse: 58.713\n",
      "[390]\ttraining's rmse: 16.9695\tvalid_1's rmse: 58.4655\n",
      "[420]\ttraining's rmse: 15.6566\tvalid_1's rmse: 58.26\n",
      "[450]\ttraining's rmse: 14.5055\tvalid_1's rmse: 58.0224\n",
      "[480]\ttraining's rmse: 13.4725\tvalid_1's rmse: 57.8619\n",
      "[510]\ttraining's rmse: 12.5538\tvalid_1's rmse: 57.7327\n",
      "[540]\ttraining's rmse: 11.7099\tvalid_1's rmse: 57.6318\n",
      "[570]\ttraining's rmse: 10.918\tvalid_1's rmse: 57.5464\n",
      "[600]\ttraining's rmse: 10.2109\tvalid_1's rmse: 57.4668\n",
      "[630]\ttraining's rmse: 9.56921\tvalid_1's rmse: 57.3919\n",
      "[660]\ttraining's rmse: 8.96557\tvalid_1's rmse: 57.3104\n",
      "[690]\ttraining's rmse: 8.41046\tvalid_1's rmse: 57.25\n",
      "[720]\ttraining's rmse: 7.89049\tvalid_1's rmse: 57.2009\n",
      "[750]\ttraining's rmse: 7.41188\tvalid_1's rmse: 57.1632\n",
      "[780]\ttraining's rmse: 6.96406\tvalid_1's rmse: 57.1258\n",
      "[810]\ttraining's rmse: 6.55153\tvalid_1's rmse: 57.0888\n",
      "[840]\ttraining's rmse: 6.17386\tvalid_1's rmse: 57.0735\n",
      "[870]\ttraining's rmse: 5.82483\tvalid_1's rmse: 57.0656\n",
      "[900]\ttraining's rmse: 5.50773\tvalid_1's rmse: 57.0425\n",
      "[930]\ttraining's rmse: 5.19725\tvalid_1's rmse: 57.0318\n",
      "[960]\ttraining's rmse: 4.90563\tvalid_1's rmse: 57.008\n",
      "[990]\ttraining's rmse: 4.63182\tvalid_1's rmse: 56.9952\n",
      "[1020]\ttraining's rmse: 4.37756\tvalid_1's rmse: 56.9824\n",
      "[1050]\ttraining's rmse: 4.14296\tvalid_1's rmse: 56.9638\n",
      "[1080]\ttraining's rmse: 3.92119\tvalid_1's rmse: 56.948\n",
      "[1110]\ttraining's rmse: 3.70664\tvalid_1's rmse: 56.9381\n",
      "[1140]\ttraining's rmse: 3.50894\tvalid_1's rmse: 56.9247\n",
      "[1170]\ttraining's rmse: 3.32644\tvalid_1's rmse: 56.9178\n",
      "[1200]\ttraining's rmse: 3.15037\tvalid_1's rmse: 56.909\n",
      "[1230]\ttraining's rmse: 2.98887\tvalid_1's rmse: 56.9033\n",
      "[1260]\ttraining's rmse: 2.83391\tvalid_1's rmse: 56.8987\n",
      "[1290]\ttraining's rmse: 2.68931\tvalid_1's rmse: 56.8951\n",
      "[1320]\ttraining's rmse: 2.55137\tvalid_1's rmse: 56.8833\n",
      "[1350]\ttraining's rmse: 2.42019\tvalid_1's rmse: 56.8761\n",
      "[1380]\ttraining's rmse: 2.29738\tvalid_1's rmse: 56.8725\n",
      "[1410]\ttraining's rmse: 2.18027\tvalid_1's rmse: 56.8678\n",
      "[1440]\ttraining's rmse: 2.07061\tvalid_1's rmse: 56.8655\n",
      "[1470]\ttraining's rmse: 1.96754\tvalid_1's rmse: 56.8608\n",
      "[1500]\ttraining's rmse: 1.86966\tvalid_1's rmse: 56.855\n",
      "[1530]\ttraining's rmse: 1.7783\tvalid_1's rmse: 56.8532\n",
      "[1560]\ttraining's rmse: 1.68933\tvalid_1's rmse: 56.8502\n",
      "[1590]\ttraining's rmse: 1.6069\tvalid_1's rmse: 56.8485\n",
      "[1620]\ttraining's rmse: 1.52887\tvalid_1's rmse: 56.8436\n",
      "[1650]\ttraining's rmse: 1.45552\tvalid_1's rmse: 56.8403\n",
      "[1680]\ttraining's rmse: 1.38318\tvalid_1's rmse: 56.8392\n",
      "[1710]\ttraining's rmse: 1.31486\tvalid_1's rmse: 56.8365\n",
      "[1740]\ttraining's rmse: 1.25098\tvalid_1's rmse: 56.8365\n",
      "[1770]\ttraining's rmse: 1.19185\tvalid_1's rmse: 56.8338\n",
      "[1800]\ttraining's rmse: 1.13496\tvalid_1's rmse: 56.8323\n",
      "[1830]\ttraining's rmse: 1.07969\tvalid_1's rmse: 56.8313\n",
      "[1860]\ttraining's rmse: 1.02836\tvalid_1's rmse: 56.8291\n",
      "[1890]\ttraining's rmse: 0.979331\tvalid_1's rmse: 56.8294\n",
      "[1920]\ttraining's rmse: 0.934527\tvalid_1's rmse: 56.8282\n",
      "[1950]\ttraining's rmse: 0.890566\tvalid_1's rmse: 56.8263\n",
      "[1980]\ttraining's rmse: 0.848295\tvalid_1's rmse: 56.8249\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's rmse: 0.821968\tvalid_1's rmse: 56.8247\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002539 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 20022\n",
      "[LightGBM] [Info] Number of data points in the train set: 9219, number of used features: 79\n",
      "[LightGBM] [Info] Start training from score 368.804320\n",
      "Training until validation scores don't improve for 125 rounds\n",
      "[30]\ttraining's rmse: 157.266\tvalid_1's rmse: 155.635\n",
      "[60]\ttraining's rmse: 98.4689\tvalid_1's rmse: 105.811\n",
      "[90]\ttraining's rmse: 66.7163\tvalid_1's rmse: 81.6946\n",
      "[120]\ttraining's rmse: 49.4248\tvalid_1's rmse: 70.3512\n",
      "[150]\ttraining's rmse: 39.7572\tvalid_1's rmse: 65.0638\n",
      "[180]\ttraining's rmse: 33.867\tvalid_1's rmse: 62.3069\n",
      "[210]\ttraining's rmse: 29.7548\tvalid_1's rmse: 60.7266\n",
      "[240]\ttraining's rmse: 26.5834\tvalid_1's rmse: 59.5915\n",
      "[270]\ttraining's rmse: 24.0138\tvalid_1's rmse: 58.7471\n",
      "[300]\ttraining's rmse: 21.8612\tvalid_1's rmse: 58.1557\n",
      "[330]\ttraining's rmse: 20.0217\tvalid_1's rmse: 57.7613\n",
      "[360]\ttraining's rmse: 18.3878\tvalid_1's rmse: 57.4357\n",
      "[390]\ttraining's rmse: 16.9548\tvalid_1's rmse: 57.1862\n",
      "[420]\ttraining's rmse: 15.687\tvalid_1's rmse: 56.9246\n",
      "[450]\ttraining's rmse: 14.559\tvalid_1's rmse: 56.7599\n",
      "[480]\ttraining's rmse: 13.5212\tvalid_1's rmse: 56.6291\n",
      "[510]\ttraining's rmse: 12.6097\tvalid_1's rmse: 56.5209\n",
      "[540]\ttraining's rmse: 11.7446\tvalid_1's rmse: 56.3969\n",
      "[570]\ttraining's rmse: 10.9686\tvalid_1's rmse: 56.3009\n",
      "[600]\ttraining's rmse: 10.2528\tvalid_1's rmse: 56.2145\n",
      "[630]\ttraining's rmse: 9.59311\tvalid_1's rmse: 56.1466\n",
      "[660]\ttraining's rmse: 8.99316\tvalid_1's rmse: 56.0781\n",
      "[690]\ttraining's rmse: 8.42797\tvalid_1's rmse: 55.9962\n",
      "[720]\ttraining's rmse: 7.90028\tvalid_1's rmse: 55.9313\n",
      "[750]\ttraining's rmse: 7.42855\tvalid_1's rmse: 55.8891\n",
      "[780]\ttraining's rmse: 6.96716\tvalid_1's rmse: 55.8641\n",
      "[810]\ttraining's rmse: 6.56317\tvalid_1's rmse: 55.8387\n",
      "[840]\ttraining's rmse: 6.17383\tvalid_1's rmse: 55.7905\n",
      "[870]\ttraining's rmse: 5.8237\tvalid_1's rmse: 55.7684\n",
      "[900]\ttraining's rmse: 5.48295\tvalid_1's rmse: 55.748\n",
      "[930]\ttraining's rmse: 5.17822\tvalid_1's rmse: 55.73\n",
      "[960]\ttraining's rmse: 4.88578\tvalid_1's rmse: 55.725\n",
      "[990]\ttraining's rmse: 4.61192\tvalid_1's rmse: 55.6945\n",
      "[1020]\ttraining's rmse: 4.35681\tvalid_1's rmse: 55.6811\n",
      "[1050]\ttraining's rmse: 4.11621\tvalid_1's rmse: 55.6589\n",
      "[1080]\ttraining's rmse: 3.88769\tvalid_1's rmse: 55.6438\n",
      "[1110]\ttraining's rmse: 3.68211\tvalid_1's rmse: 55.632\n",
      "[1140]\ttraining's rmse: 3.48694\tvalid_1's rmse: 55.6195\n",
      "[1170]\ttraining's rmse: 3.30162\tvalid_1's rmse: 55.6118\n",
      "[1200]\ttraining's rmse: 3.12667\tvalid_1's rmse: 55.6025\n",
      "[1230]\ttraining's rmse: 2.96279\tvalid_1's rmse: 55.5916\n",
      "[1260]\ttraining's rmse: 2.8084\tvalid_1's rmse: 55.5813\n",
      "[1290]\ttraining's rmse: 2.66496\tvalid_1's rmse: 55.5776\n",
      "[1320]\ttraining's rmse: 2.52663\tvalid_1's rmse: 55.568\n",
      "[1350]\ttraining's rmse: 2.39565\tvalid_1's rmse: 55.5632\n",
      "[1380]\ttraining's rmse: 2.27218\tvalid_1's rmse: 55.5557\n",
      "[1410]\ttraining's rmse: 2.15535\tvalid_1's rmse: 55.5551\n",
      "[1440]\ttraining's rmse: 2.04517\tvalid_1's rmse: 55.5531\n",
      "[1470]\ttraining's rmse: 1.94387\tvalid_1's rmse: 55.5534\n",
      "[1500]\ttraining's rmse: 1.84428\tvalid_1's rmse: 55.5504\n",
      "[1530]\ttraining's rmse: 1.75117\tvalid_1's rmse: 55.5454\n",
      "[1560]\ttraining's rmse: 1.66329\tvalid_1's rmse: 55.5409\n",
      "[1590]\ttraining's rmse: 1.58202\tvalid_1's rmse: 55.5385\n",
      "[1620]\ttraining's rmse: 1.5027\tvalid_1's rmse: 55.5326\n",
      "[1650]\ttraining's rmse: 1.42955\tvalid_1's rmse: 55.5285\n",
      "[1680]\ttraining's rmse: 1.3587\tvalid_1's rmse: 55.5257\n",
      "[1710]\ttraining's rmse: 1.2916\tvalid_1's rmse: 55.5236\n",
      "[1740]\ttraining's rmse: 1.2307\tvalid_1's rmse: 55.5225\n",
      "[1770]\ttraining's rmse: 1.17181\tvalid_1's rmse: 55.5188\n",
      "[1800]\ttraining's rmse: 1.11444\tvalid_1's rmse: 55.5185\n",
      "[1830]\ttraining's rmse: 1.06014\tvalid_1's rmse: 55.5178\n",
      "[1860]\ttraining's rmse: 1.00801\tvalid_1's rmse: 55.5164\n",
      "[1890]\ttraining's rmse: 0.958508\tvalid_1's rmse: 55.5139\n",
      "[1920]\ttraining's rmse: 0.911897\tvalid_1's rmse: 55.5129\n",
      "[1950]\ttraining's rmse: 0.867916\tvalid_1's rmse: 55.5123\n",
      "[1980]\ttraining's rmse: 0.826022\tvalid_1's rmse: 55.5103\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's rmse: 0.799803\tvalid_1's rmse: 55.5099\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003575 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 20022\n",
      "[LightGBM] [Info] Number of data points in the train set: 9219, number of used features: 79\n",
      "[LightGBM] [Info] Start training from score 367.769424\n",
      "Training until validation scores don't improve for 125 rounds\n",
      "[30]\ttraining's rmse: 157.011\tvalid_1's rmse: 157.729\n",
      "[60]\ttraining's rmse: 97.7311\tvalid_1's rmse: 106.24\n",
      "[90]\ttraining's rmse: 65.8783\tvalid_1's rmse: 81.0232\n",
      "[120]\ttraining's rmse: 48.8067\tvalid_1's rmse: 69.3818\n",
      "[150]\ttraining's rmse: 39.2455\tvalid_1's rmse: 63.6864\n",
      "[180]\ttraining's rmse: 33.3423\tvalid_1's rmse: 60.6907\n",
      "[210]\ttraining's rmse: 29.368\tvalid_1's rmse: 58.8852\n",
      "[240]\ttraining's rmse: 26.2148\tvalid_1's rmse: 57.6541\n",
      "[270]\ttraining's rmse: 23.6553\tvalid_1's rmse: 56.8091\n",
      "[300]\ttraining's rmse: 21.5599\tvalid_1's rmse: 56.2061\n",
      "[330]\ttraining's rmse: 19.7431\tvalid_1's rmse: 55.7305\n",
      "[360]\ttraining's rmse: 18.1615\tvalid_1's rmse: 55.4107\n",
      "[390]\ttraining's rmse: 16.7359\tvalid_1's rmse: 55.1176\n",
      "[420]\ttraining's rmse: 15.4864\tvalid_1's rmse: 54.8731\n",
      "[450]\ttraining's rmse: 14.3621\tvalid_1's rmse: 54.7229\n",
      "[480]\ttraining's rmse: 13.3294\tvalid_1's rmse: 54.5295\n",
      "[510]\ttraining's rmse: 12.3988\tvalid_1's rmse: 54.3602\n",
      "[540]\ttraining's rmse: 11.5502\tvalid_1's rmse: 54.2179\n",
      "[570]\ttraining's rmse: 10.7921\tvalid_1's rmse: 54.1108\n",
      "[600]\ttraining's rmse: 10.0717\tvalid_1's rmse: 54.0159\n",
      "[630]\ttraining's rmse: 9.42935\tvalid_1's rmse: 53.921\n",
      "[660]\ttraining's rmse: 8.83342\tvalid_1's rmse: 53.8478\n",
      "[690]\ttraining's rmse: 8.28021\tvalid_1's rmse: 53.7774\n",
      "[720]\ttraining's rmse: 7.76025\tvalid_1's rmse: 53.7085\n",
      "[750]\ttraining's rmse: 7.28924\tvalid_1's rmse: 53.6421\n",
      "[780]\ttraining's rmse: 6.84554\tvalid_1's rmse: 53.5968\n",
      "[810]\ttraining's rmse: 6.43872\tvalid_1's rmse: 53.5606\n",
      "[840]\ttraining's rmse: 6.06168\tvalid_1's rmse: 53.5181\n",
      "[870]\ttraining's rmse: 5.70864\tvalid_1's rmse: 53.4839\n",
      "[900]\ttraining's rmse: 5.38006\tvalid_1's rmse: 53.4603\n",
      "[930]\ttraining's rmse: 5.07937\tvalid_1's rmse: 53.4252\n",
      "[960]\ttraining's rmse: 4.79495\tvalid_1's rmse: 53.4006\n",
      "[990]\ttraining's rmse: 4.52796\tvalid_1's rmse: 53.3658\n",
      "[1020]\ttraining's rmse: 4.28081\tvalid_1's rmse: 53.346\n",
      "[1050]\ttraining's rmse: 4.04732\tvalid_1's rmse: 53.3334\n",
      "[1080]\ttraining's rmse: 3.82716\tvalid_1's rmse: 53.3189\n",
      "[1110]\ttraining's rmse: 3.61649\tvalid_1's rmse: 53.3033\n",
      "[1140]\ttraining's rmse: 3.4184\tvalid_1's rmse: 53.2921\n",
      "[1170]\ttraining's rmse: 3.23789\tvalid_1's rmse: 53.2873\n",
      "[1200]\ttraining's rmse: 3.06667\tvalid_1's rmse: 53.2775\n",
      "[1230]\ttraining's rmse: 2.90767\tvalid_1's rmse: 53.2717\n",
      "[1260]\ttraining's rmse: 2.75599\tvalid_1's rmse: 53.2604\n",
      "[1290]\ttraining's rmse: 2.61276\tvalid_1's rmse: 53.2513\n",
      "[1320]\ttraining's rmse: 2.47748\tvalid_1's rmse: 53.2428\n",
      "[1350]\ttraining's rmse: 2.34989\tvalid_1's rmse: 53.2327\n",
      "[1380]\ttraining's rmse: 2.22961\tvalid_1's rmse: 53.2251\n",
      "[1410]\ttraining's rmse: 2.11419\tvalid_1's rmse: 53.2193\n",
      "[1440]\ttraining's rmse: 2.00509\tvalid_1's rmse: 53.2166\n",
      "[1470]\ttraining's rmse: 1.90327\tvalid_1's rmse: 53.2098\n",
      "[1500]\ttraining's rmse: 1.80779\tvalid_1's rmse: 53.2007\n",
      "[1530]\ttraining's rmse: 1.71695\tvalid_1's rmse: 53.2006\n",
      "[1560]\ttraining's rmse: 1.63199\tvalid_1's rmse: 53.1936\n",
      "[1590]\ttraining's rmse: 1.55021\tvalid_1's rmse: 53.1922\n",
      "[1620]\ttraining's rmse: 1.47318\tvalid_1's rmse: 53.1887\n",
      "[1650]\ttraining's rmse: 1.39892\tvalid_1's rmse: 53.1844\n",
      "[1680]\ttraining's rmse: 1.32996\tvalid_1's rmse: 53.182\n",
      "[1710]\ttraining's rmse: 1.26363\tvalid_1's rmse: 53.1811\n",
      "[1740]\ttraining's rmse: 1.20188\tvalid_1's rmse: 53.1773\n",
      "[1770]\ttraining's rmse: 1.14291\tvalid_1's rmse: 53.1748\n",
      "[1800]\ttraining's rmse: 1.0867\tvalid_1's rmse: 53.1712\n",
      "[1830]\ttraining's rmse: 1.03332\tvalid_1's rmse: 53.1691\n",
      "[1860]\ttraining's rmse: 0.982586\tvalid_1's rmse: 53.1671\n",
      "[1890]\ttraining's rmse: 0.933762\tvalid_1's rmse: 53.1645\n",
      "[1920]\ttraining's rmse: 0.888918\tvalid_1's rmse: 53.1607\n",
      "[1950]\ttraining's rmse: 0.845858\tvalid_1's rmse: 53.1587\n",
      "[1980]\ttraining's rmse: 0.803686\tvalid_1's rmse: 53.1567\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's rmse: 0.778628\tvalid_1's rmse: 53.156\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002384 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 20022\n",
      "[LightGBM] [Info] Number of data points in the train set: 9219, number of used features: 79\n",
      "[LightGBM] [Info] Start training from score 360.131644\n",
      "Training until validation scores don't improve for 125 rounds\n",
      "[30]\ttraining's rmse: 155.132\tvalid_1's rmse: 164.265\n",
      "[60]\ttraining's rmse: 97.1102\tvalid_1's rmse: 109.516\n",
      "[90]\ttraining's rmse: 65.6575\tvalid_1's rmse: 82.0727\n",
      "[120]\ttraining's rmse: 48.7471\tvalid_1's rmse: 69.1258\n",
      "[150]\ttraining's rmse: 39.1835\tvalid_1's rmse: 63.0269\n",
      "[180]\ttraining's rmse: 33.1696\tvalid_1's rmse: 59.797\n",
      "[210]\ttraining's rmse: 29.1436\tvalid_1's rmse: 58.0405\n",
      "[240]\ttraining's rmse: 26.0457\tvalid_1's rmse: 56.8458\n",
      "[270]\ttraining's rmse: 23.5269\tvalid_1's rmse: 56.055\n",
      "[300]\ttraining's rmse: 21.3587\tvalid_1's rmse: 55.5812\n",
      "[330]\ttraining's rmse: 19.5776\tvalid_1's rmse: 55.2403\n",
      "[360]\ttraining's rmse: 18.0111\tvalid_1's rmse: 54.9953\n",
      "[390]\ttraining's rmse: 16.6228\tvalid_1's rmse: 54.8191\n",
      "[420]\ttraining's rmse: 15.3811\tvalid_1's rmse: 54.6802\n",
      "[450]\ttraining's rmse: 14.281\tvalid_1's rmse: 54.6042\n",
      "[480]\ttraining's rmse: 13.2694\tvalid_1's rmse: 54.4811\n",
      "[510]\ttraining's rmse: 12.3732\tvalid_1's rmse: 54.4061\n",
      "[540]\ttraining's rmse: 11.5294\tvalid_1's rmse: 54.3191\n",
      "[570]\ttraining's rmse: 10.7632\tvalid_1's rmse: 54.2604\n",
      "[600]\ttraining's rmse: 10.0632\tvalid_1's rmse: 54.2002\n",
      "[630]\ttraining's rmse: 9.4037\tvalid_1's rmse: 54.1363\n",
      "[660]\ttraining's rmse: 8.80909\tvalid_1's rmse: 54.0954\n",
      "[690]\ttraining's rmse: 8.26293\tvalid_1's rmse: 54.0573\n",
      "[720]\ttraining's rmse: 7.75883\tvalid_1's rmse: 54.0462\n",
      "[750]\ttraining's rmse: 7.29694\tvalid_1's rmse: 54.0005\n",
      "[780]\ttraining's rmse: 6.86045\tvalid_1's rmse: 53.9655\n",
      "[810]\ttraining's rmse: 6.45718\tvalid_1's rmse: 53.9471\n",
      "[840]\ttraining's rmse: 6.08648\tvalid_1's rmse: 53.9255\n",
      "[870]\ttraining's rmse: 5.73324\tvalid_1's rmse: 53.9092\n",
      "[900]\ttraining's rmse: 5.40603\tvalid_1's rmse: 53.8921\n",
      "[930]\ttraining's rmse: 5.10081\tvalid_1's rmse: 53.8839\n",
      "[960]\ttraining's rmse: 4.81167\tvalid_1's rmse: 53.8633\n",
      "[990]\ttraining's rmse: 4.54235\tvalid_1's rmse: 53.858\n",
      "[1020]\ttraining's rmse: 4.29455\tvalid_1's rmse: 53.8411\n",
      "[1050]\ttraining's rmse: 4.06357\tvalid_1's rmse: 53.8402\n",
      "[1080]\ttraining's rmse: 3.84265\tvalid_1's rmse: 53.8345\n",
      "[1110]\ttraining's rmse: 3.63786\tvalid_1's rmse: 53.8302\n",
      "[1140]\ttraining's rmse: 3.44109\tvalid_1's rmse: 53.8307\n",
      "[1170]\ttraining's rmse: 3.25615\tvalid_1's rmse: 53.8249\n",
      "[1200]\ttraining's rmse: 3.08719\tvalid_1's rmse: 53.8183\n",
      "[1230]\ttraining's rmse: 2.92524\tvalid_1's rmse: 53.8104\n",
      "[1260]\ttraining's rmse: 2.76898\tvalid_1's rmse: 53.8077\n",
      "[1290]\ttraining's rmse: 2.62606\tvalid_1's rmse: 53.805\n",
      "[1320]\ttraining's rmse: 2.49085\tvalid_1's rmse: 53.7963\n",
      "[1350]\ttraining's rmse: 2.35944\tvalid_1's rmse: 53.7894\n",
      "[1380]\ttraining's rmse: 2.23868\tvalid_1's rmse: 53.7874\n",
      "[1410]\ttraining's rmse: 2.1257\tvalid_1's rmse: 53.7845\n",
      "[1440]\ttraining's rmse: 2.01712\tvalid_1's rmse: 53.7821\n",
      "[1470]\ttraining's rmse: 1.91327\tvalid_1's rmse: 53.784\n",
      "[1500]\ttraining's rmse: 1.81656\tvalid_1's rmse: 53.7803\n",
      "[1530]\ttraining's rmse: 1.72669\tvalid_1's rmse: 53.7781\n",
      "[1560]\ttraining's rmse: 1.63973\tvalid_1's rmse: 53.7751\n",
      "[1590]\ttraining's rmse: 1.55793\tvalid_1's rmse: 53.7747\n",
      "[1620]\ttraining's rmse: 1.48217\tvalid_1's rmse: 53.7727\n",
      "[1650]\ttraining's rmse: 1.40989\tvalid_1's rmse: 53.7717\n",
      "[1680]\ttraining's rmse: 1.33888\tvalid_1's rmse: 53.7721\n",
      "[1710]\ttraining's rmse: 1.27232\tvalid_1's rmse: 53.7711\n",
      "[1740]\ttraining's rmse: 1.21148\tvalid_1's rmse: 53.7695\n",
      "[1770]\ttraining's rmse: 1.15281\tvalid_1's rmse: 53.7705\n",
      "[1800]\ttraining's rmse: 1.09694\tvalid_1's rmse: 53.7684\n",
      "[1830]\ttraining's rmse: 1.04306\tvalid_1's rmse: 53.7674\n",
      "[1860]\ttraining's rmse: 0.992395\tvalid_1's rmse: 53.7672\n",
      "[1890]\ttraining's rmse: 0.944987\tvalid_1's rmse: 53.7663\n",
      "[1920]\ttraining's rmse: 0.900922\tvalid_1's rmse: 53.7657\n",
      "[1950]\ttraining's rmse: 0.859286\tvalid_1's rmse: 53.7644\n",
      "[1980]\ttraining's rmse: 0.818343\tvalid_1's rmse: 53.7628\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's rmse: 0.792592\tvalid_1's rmse: 53.7639\n",
      "28\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002337 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 20022\n",
      "[LightGBM] [Info] Number of data points in the train set: 9219, number of used features: 79\n",
      "[LightGBM] [Info] Start training from score 357.747073\n",
      "Training until validation scores don't improve for 125 rounds\n",
      "[30]\ttraining's rmse: 149.422\tvalid_1's rmse: 155.469\n",
      "[60]\ttraining's rmse: 92.8006\tvalid_1's rmse: 101.146\n",
      "[90]\ttraining's rmse: 62.4839\tvalid_1's rmse: 74.3473\n",
      "[120]\ttraining's rmse: 46.0702\tvalid_1's rmse: 61.8556\n",
      "[150]\ttraining's rmse: 36.8206\tvalid_1's rmse: 55.8905\n",
      "[180]\ttraining's rmse: 31.0996\tvalid_1's rmse: 52.8984\n",
      "[210]\ttraining's rmse: 27.2517\tvalid_1's rmse: 51.0898\n",
      "[240]\ttraining's rmse: 24.2445\tvalid_1's rmse: 49.8565\n",
      "[270]\ttraining's rmse: 21.8526\tvalid_1's rmse: 48.9423\n",
      "[300]\ttraining's rmse: 19.8353\tvalid_1's rmse: 48.3651\n",
      "[330]\ttraining's rmse: 18.1774\tvalid_1's rmse: 47.9918\n",
      "[360]\ttraining's rmse: 16.6986\tvalid_1's rmse: 47.6554\n",
      "[390]\ttraining's rmse: 15.3872\tvalid_1's rmse: 47.4177\n",
      "[420]\ttraining's rmse: 14.2397\tvalid_1's rmse: 47.242\n",
      "[450]\ttraining's rmse: 13.2067\tvalid_1's rmse: 47.0976\n",
      "[480]\ttraining's rmse: 12.2573\tvalid_1's rmse: 46.9951\n",
      "[510]\ttraining's rmse: 11.4204\tvalid_1's rmse: 46.9365\n",
      "[540]\ttraining's rmse: 10.6515\tvalid_1's rmse: 46.8718\n",
      "[570]\ttraining's rmse: 9.95529\tvalid_1's rmse: 46.798\n",
      "[600]\ttraining's rmse: 9.32493\tvalid_1's rmse: 46.7188\n",
      "[630]\ttraining's rmse: 8.74317\tvalid_1's rmse: 46.6612\n",
      "[660]\ttraining's rmse: 8.20241\tvalid_1's rmse: 46.6157\n",
      "[690]\ttraining's rmse: 7.70586\tvalid_1's rmse: 46.5868\n",
      "[720]\ttraining's rmse: 7.23917\tvalid_1's rmse: 46.5483\n",
      "[750]\ttraining's rmse: 6.81421\tvalid_1's rmse: 46.5084\n",
      "[780]\ttraining's rmse: 6.41947\tvalid_1's rmse: 46.4788\n",
      "[810]\ttraining's rmse: 6.04825\tvalid_1's rmse: 46.4603\n",
      "[840]\ttraining's rmse: 5.70837\tvalid_1's rmse: 46.4311\n",
      "[870]\ttraining's rmse: 5.38828\tvalid_1's rmse: 46.4078\n",
      "[900]\ttraining's rmse: 5.09748\tvalid_1's rmse: 46.3899\n",
      "[930]\ttraining's rmse: 4.82011\tvalid_1's rmse: 46.3712\n",
      "[960]\ttraining's rmse: 4.55306\tvalid_1's rmse: 46.3606\n",
      "[990]\ttraining's rmse: 4.30441\tvalid_1's rmse: 46.3514\n",
      "[1020]\ttraining's rmse: 4.07262\tvalid_1's rmse: 46.3367\n",
      "[1050]\ttraining's rmse: 3.86361\tvalid_1's rmse: 46.3244\n",
      "[1080]\ttraining's rmse: 3.66237\tvalid_1's rmse: 46.318\n",
      "[1110]\ttraining's rmse: 3.46739\tvalid_1's rmse: 46.3065\n",
      "[1140]\ttraining's rmse: 3.28193\tvalid_1's rmse: 46.2993\n",
      "[1170]\ttraining's rmse: 3.11457\tvalid_1's rmse: 46.3025\n",
      "[1200]\ttraining's rmse: 2.95138\tvalid_1's rmse: 46.2976\n",
      "[1230]\ttraining's rmse: 2.80064\tvalid_1's rmse: 46.2924\n",
      "[1260]\ttraining's rmse: 2.65931\tvalid_1's rmse: 46.2855\n",
      "[1290]\ttraining's rmse: 2.52149\tvalid_1's rmse: 46.2802\n",
      "[1320]\ttraining's rmse: 2.39301\tvalid_1's rmse: 46.2822\n",
      "[1350]\ttraining's rmse: 2.27089\tvalid_1's rmse: 46.2719\n",
      "[1380]\ttraining's rmse: 2.16071\tvalid_1's rmse: 46.2669\n",
      "[1410]\ttraining's rmse: 2.05023\tvalid_1's rmse: 46.2624\n",
      "[1440]\ttraining's rmse: 1.94813\tvalid_1's rmse: 46.2589\n",
      "[1470]\ttraining's rmse: 1.85373\tvalid_1's rmse: 46.2624\n",
      "[1500]\ttraining's rmse: 1.76267\tvalid_1's rmse: 46.2566\n",
      "[1530]\ttraining's rmse: 1.67755\tvalid_1's rmse: 46.2565\n",
      "[1560]\ttraining's rmse: 1.59917\tvalid_1's rmse: 46.2549\n",
      "[1590]\ttraining's rmse: 1.51968\tvalid_1's rmse: 46.2517\n",
      "[1620]\ttraining's rmse: 1.44661\tvalid_1's rmse: 46.2523\n",
      "[1650]\ttraining's rmse: 1.37994\tvalid_1's rmse: 46.2498\n",
      "[1680]\ttraining's rmse: 1.31689\tvalid_1's rmse: 46.2468\n",
      "[1710]\ttraining's rmse: 1.25503\tvalid_1's rmse: 46.2445\n",
      "[1740]\ttraining's rmse: 1.19742\tvalid_1's rmse: 46.2401\n",
      "[1770]\ttraining's rmse: 1.14002\tvalid_1's rmse: 46.238\n",
      "[1800]\ttraining's rmse: 1.08708\tvalid_1's rmse: 46.2376\n",
      "[1830]\ttraining's rmse: 1.03891\tvalid_1's rmse: 46.2383\n",
      "[1860]\ttraining's rmse: 0.991169\tvalid_1's rmse: 46.2381\n",
      "[1890]\ttraining's rmse: 0.944673\tvalid_1's rmse: 46.237\n",
      "[1920]\ttraining's rmse: 0.90174\tvalid_1's rmse: 46.2349\n",
      "[1950]\ttraining's rmse: 0.860542\tvalid_1's rmse: 46.2335\n",
      "[1980]\ttraining's rmse: 0.821193\tvalid_1's rmse: 46.2328\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's rmse: 0.796913\tvalid_1's rmse: 46.2343\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002448 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 20022\n",
      "[LightGBM] [Info] Number of data points in the train set: 9219, number of used features: 79\n",
      "[LightGBM] [Info] Start training from score 354.939235\n",
      "Training until validation scores don't improve for 125 rounds\n",
      "[30]\ttraining's rmse: 151.26\tvalid_1's rmse: 156.202\n",
      "[60]\ttraining's rmse: 94.9481\tvalid_1's rmse: 102.881\n",
      "[90]\ttraining's rmse: 64.7864\tvalid_1's rmse: 77.1433\n",
      "[120]\ttraining's rmse: 48.1328\tvalid_1's rmse: 64.8051\n",
      "[150]\ttraining's rmse: 38.5395\tvalid_1's rmse: 58.8076\n",
      "[180]\ttraining's rmse: 32.6849\tvalid_1's rmse: 55.8412\n",
      "[210]\ttraining's rmse: 28.6148\tvalid_1's rmse: 54.2262\n",
      "[240]\ttraining's rmse: 25.4695\tvalid_1's rmse: 53.1106\n",
      "[270]\ttraining's rmse: 22.9566\tvalid_1's rmse: 52.3291\n",
      "[300]\ttraining's rmse: 20.8006\tvalid_1's rmse: 51.7518\n",
      "[330]\ttraining's rmse: 19.0057\tvalid_1's rmse: 51.3475\n",
      "[360]\ttraining's rmse: 17.4557\tvalid_1's rmse: 51.1016\n",
      "[390]\ttraining's rmse: 16.0578\tvalid_1's rmse: 50.8325\n",
      "[420]\ttraining's rmse: 14.837\tvalid_1's rmse: 50.6598\n",
      "[450]\ttraining's rmse: 13.7491\tvalid_1's rmse: 50.5118\n",
      "[480]\ttraining's rmse: 12.7568\tvalid_1's rmse: 50.3755\n",
      "[510]\ttraining's rmse: 11.8636\tvalid_1's rmse: 50.2535\n",
      "[540]\ttraining's rmse: 11.0587\tvalid_1's rmse: 50.185\n",
      "[570]\ttraining's rmse: 10.3301\tvalid_1's rmse: 50.1131\n",
      "[600]\ttraining's rmse: 9.67039\tvalid_1's rmse: 50.0588\n",
      "[630]\ttraining's rmse: 9.05642\tvalid_1's rmse: 50.014\n",
      "[660]\ttraining's rmse: 8.47425\tvalid_1's rmse: 49.9804\n",
      "[690]\ttraining's rmse: 7.93586\tvalid_1's rmse: 49.9404\n",
      "[720]\ttraining's rmse: 7.45622\tvalid_1's rmse: 49.912\n",
      "[750]\ttraining's rmse: 7.00295\tvalid_1's rmse: 49.888\n",
      "[780]\ttraining's rmse: 6.5744\tvalid_1's rmse: 49.8417\n",
      "[810]\ttraining's rmse: 6.19676\tvalid_1's rmse: 49.8257\n",
      "[840]\ttraining's rmse: 5.83315\tvalid_1's rmse: 49.7912\n",
      "[870]\ttraining's rmse: 5.49644\tvalid_1's rmse: 49.7779\n",
      "[900]\ttraining's rmse: 5.17829\tvalid_1's rmse: 49.7539\n",
      "[930]\ttraining's rmse: 4.88558\tvalid_1's rmse: 49.737\n",
      "[960]\ttraining's rmse: 4.61163\tvalid_1's rmse: 49.729\n",
      "[990]\ttraining's rmse: 4.34893\tvalid_1's rmse: 49.7208\n",
      "[1020]\ttraining's rmse: 4.10808\tvalid_1's rmse: 49.7165\n",
      "[1050]\ttraining's rmse: 3.87879\tvalid_1's rmse: 49.7082\n",
      "[1080]\ttraining's rmse: 3.66229\tvalid_1's rmse: 49.7064\n",
      "[1110]\ttraining's rmse: 3.46104\tvalid_1's rmse: 49.7024\n",
      "[1140]\ttraining's rmse: 3.27517\tvalid_1's rmse: 49.6985\n",
      "[1170]\ttraining's rmse: 3.09971\tvalid_1's rmse: 49.6928\n",
      "[1200]\ttraining's rmse: 2.93312\tvalid_1's rmse: 49.6867\n",
      "[1230]\ttraining's rmse: 2.77565\tvalid_1's rmse: 49.681\n",
      "[1260]\ttraining's rmse: 2.62775\tvalid_1's rmse: 49.6684\n",
      "[1290]\ttraining's rmse: 2.48661\tvalid_1's rmse: 49.6623\n",
      "[1320]\ttraining's rmse: 2.3545\tvalid_1's rmse: 49.6569\n",
      "[1350]\ttraining's rmse: 2.22963\tvalid_1's rmse: 49.656\n",
      "[1380]\ttraining's rmse: 2.11301\tvalid_1's rmse: 49.6502\n",
      "[1410]\ttraining's rmse: 2.00353\tvalid_1's rmse: 49.6475\n",
      "[1440]\ttraining's rmse: 1.89979\tvalid_1's rmse: 49.643\n",
      "[1470]\ttraining's rmse: 1.80232\tvalid_1's rmse: 49.6423\n",
      "[1500]\ttraining's rmse: 1.70884\tvalid_1's rmse: 49.6385\n",
      "[1530]\ttraining's rmse: 1.62077\tvalid_1's rmse: 49.6331\n",
      "[1560]\ttraining's rmse: 1.53847\tvalid_1's rmse: 49.6332\n",
      "[1590]\ttraining's rmse: 1.4596\tvalid_1's rmse: 49.6288\n",
      "[1620]\ttraining's rmse: 1.38673\tvalid_1's rmse: 49.6229\n",
      "[1650]\ttraining's rmse: 1.31535\tvalid_1's rmse: 49.6213\n",
      "[1680]\ttraining's rmse: 1.25017\tvalid_1's rmse: 49.6224\n",
      "[1710]\ttraining's rmse: 1.18692\tvalid_1's rmse: 49.6208\n",
      "[1740]\ttraining's rmse: 1.12748\tvalid_1's rmse: 49.6197\n",
      "[1770]\ttraining's rmse: 1.06981\tvalid_1's rmse: 49.6173\n",
      "[1800]\ttraining's rmse: 1.01621\tvalid_1's rmse: 49.6142\n",
      "[1830]\ttraining's rmse: 0.966804\tvalid_1's rmse: 49.6135\n",
      "[1860]\ttraining's rmse: 0.918859\tvalid_1's rmse: 49.6127\n",
      "[1890]\ttraining's rmse: 0.873661\tvalid_1's rmse: 49.6121\n",
      "[1920]\ttraining's rmse: 0.830632\tvalid_1's rmse: 49.6125\n",
      "[1950]\ttraining's rmse: 0.789546\tvalid_1's rmse: 49.6122\n",
      "[1980]\ttraining's rmse: 0.751241\tvalid_1's rmse: 49.6122\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's rmse: 0.726135\tvalid_1's rmse: 49.6116\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003429 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 20022\n",
      "[LightGBM] [Info] Number of data points in the train set: 9219, number of used features: 79\n",
      "[LightGBM] [Info] Start training from score 352.453781\n",
      "Training until validation scores don't improve for 125 rounds\n",
      "[30]\ttraining's rmse: 152.962\tvalid_1's rmse: 158.768\n",
      "[60]\ttraining's rmse: 95.9345\tvalid_1's rmse: 106.209\n",
      "[90]\ttraining's rmse: 65.0219\tvalid_1's rmse: 80.1713\n",
      "[120]\ttraining's rmse: 48.2952\tvalid_1's rmse: 67.7324\n",
      "[150]\ttraining's rmse: 38.9219\tvalid_1's rmse: 61.9755\n",
      "[180]\ttraining's rmse: 33.0528\tvalid_1's rmse: 59.1429\n",
      "[210]\ttraining's rmse: 29.025\tvalid_1's rmse: 57.4897\n",
      "[240]\ttraining's rmse: 25.9066\tvalid_1's rmse: 56.3714\n",
      "[270]\ttraining's rmse: 23.4066\tvalid_1's rmse: 55.6515\n",
      "[300]\ttraining's rmse: 21.2712\tvalid_1's rmse: 55.1333\n",
      "[330]\ttraining's rmse: 19.428\tvalid_1's rmse: 54.7187\n",
      "[360]\ttraining's rmse: 17.85\tvalid_1's rmse: 54.4376\n",
      "[390]\ttraining's rmse: 16.4504\tvalid_1's rmse: 54.2359\n",
      "[420]\ttraining's rmse: 15.2336\tvalid_1's rmse: 54.1205\n",
      "[450]\ttraining's rmse: 14.1229\tvalid_1's rmse: 53.9359\n",
      "[480]\ttraining's rmse: 13.1171\tvalid_1's rmse: 53.8081\n",
      "[510]\ttraining's rmse: 12.1927\tvalid_1's rmse: 53.6902\n",
      "[540]\ttraining's rmse: 11.3738\tvalid_1's rmse: 53.627\n",
      "[570]\ttraining's rmse: 10.631\tvalid_1's rmse: 53.5358\n",
      "[600]\ttraining's rmse: 9.93848\tvalid_1's rmse: 53.4776\n",
      "[630]\ttraining's rmse: 9.31136\tvalid_1's rmse: 53.4035\n",
      "[660]\ttraining's rmse: 8.72138\tvalid_1's rmse: 53.3481\n",
      "[690]\ttraining's rmse: 8.17905\tvalid_1's rmse: 53.2992\n",
      "[720]\ttraining's rmse: 7.67047\tvalid_1's rmse: 53.2666\n",
      "[750]\ttraining's rmse: 7.20947\tvalid_1's rmse: 53.2267\n",
      "[780]\ttraining's rmse: 6.77517\tvalid_1's rmse: 53.1892\n",
      "[810]\ttraining's rmse: 6.3773\tvalid_1's rmse: 53.1579\n",
      "[840]\ttraining's rmse: 6.00919\tvalid_1's rmse: 53.143\n",
      "[870]\ttraining's rmse: 5.6654\tvalid_1's rmse: 53.1201\n",
      "[900]\ttraining's rmse: 5.34835\tvalid_1's rmse: 53.0985\n",
      "[930]\ttraining's rmse: 5.04604\tvalid_1's rmse: 53.0747\n",
      "[960]\ttraining's rmse: 4.76275\tvalid_1's rmse: 53.0466\n",
      "[990]\ttraining's rmse: 4.48943\tvalid_1's rmse: 53.04\n",
      "[1020]\ttraining's rmse: 4.23896\tvalid_1's rmse: 53.0289\n",
      "[1050]\ttraining's rmse: 4.01152\tvalid_1's rmse: 53.0192\n",
      "[1080]\ttraining's rmse: 3.79639\tvalid_1's rmse: 53.0063\n",
      "[1110]\ttraining's rmse: 3.58919\tvalid_1's rmse: 52.9959\n",
      "[1140]\ttraining's rmse: 3.39676\tvalid_1's rmse: 52.9882\n",
      "[1170]\ttraining's rmse: 3.21504\tvalid_1's rmse: 52.9755\n",
      "[1200]\ttraining's rmse: 3.04374\tvalid_1's rmse: 52.9664\n",
      "[1230]\ttraining's rmse: 2.8848\tvalid_1's rmse: 52.9576\n",
      "[1260]\ttraining's rmse: 2.73455\tvalid_1's rmse: 52.959\n",
      "[1290]\ttraining's rmse: 2.59411\tvalid_1's rmse: 52.9521\n",
      "[1320]\ttraining's rmse: 2.46072\tvalid_1's rmse: 52.9499\n",
      "[1350]\ttraining's rmse: 2.33288\tvalid_1's rmse: 52.9467\n",
      "[1380]\ttraining's rmse: 2.21514\tvalid_1's rmse: 52.9405\n",
      "[1410]\ttraining's rmse: 2.10347\tvalid_1's rmse: 52.9326\n",
      "[1440]\ttraining's rmse: 1.99917\tvalid_1's rmse: 52.928\n",
      "[1470]\ttraining's rmse: 1.89808\tvalid_1's rmse: 52.9238\n",
      "[1500]\ttraining's rmse: 1.80523\tvalid_1's rmse: 52.9209\n",
      "[1530]\ttraining's rmse: 1.71591\tvalid_1's rmse: 52.9128\n",
      "[1560]\ttraining's rmse: 1.62963\tvalid_1's rmse: 52.9068\n",
      "[1590]\ttraining's rmse: 1.54876\tvalid_1's rmse: 52.9052\n",
      "[1620]\ttraining's rmse: 1.47258\tvalid_1's rmse: 52.9021\n",
      "[1650]\ttraining's rmse: 1.40046\tvalid_1's rmse: 52.8957\n",
      "[1680]\ttraining's rmse: 1.33219\tvalid_1's rmse: 52.8912\n",
      "[1710]\ttraining's rmse: 1.26743\tvalid_1's rmse: 52.8892\n",
      "[1740]\ttraining's rmse: 1.20643\tvalid_1's rmse: 52.8874\n",
      "[1770]\ttraining's rmse: 1.14833\tvalid_1's rmse: 52.8855\n",
      "[1800]\ttraining's rmse: 1.09503\tvalid_1's rmse: 52.882\n",
      "[1830]\ttraining's rmse: 1.04333\tvalid_1's rmse: 52.8779\n",
      "[1860]\ttraining's rmse: 0.994213\tvalid_1's rmse: 52.877\n",
      "[1890]\ttraining's rmse: 0.94862\tvalid_1's rmse: 52.875\n",
      "[1920]\ttraining's rmse: 0.904968\tvalid_1's rmse: 52.8728\n",
      "[1950]\ttraining's rmse: 0.861842\tvalid_1's rmse: 52.8714\n",
      "[1980]\ttraining's rmse: 0.821807\tvalid_1's rmse: 52.8698\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's rmse: 0.796048\tvalid_1's rmse: 52.8687\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003753 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 20022\n",
      "[LightGBM] [Info] Number of data points in the train set: 9219, number of used features: 79\n",
      "[LightGBM] [Info] Start training from score 357.391145\n",
      "Training until validation scores don't improve for 125 rounds\n",
      "[30]\ttraining's rmse: 153.829\tvalid_1's rmse: 158.363\n",
      "[60]\ttraining's rmse: 97.174\tvalid_1's rmse: 107.363\n",
      "[90]\ttraining's rmse: 66.5591\tvalid_1's rmse: 82.006\n",
      "[120]\ttraining's rmse: 49.7438\tvalid_1's rmse: 69.8313\n",
      "[150]\ttraining's rmse: 40.1613\tvalid_1's rmse: 64.051\n",
      "[180]\ttraining's rmse: 34.2001\tvalid_1's rmse: 60.9299\n",
      "[210]\ttraining's rmse: 29.9891\tvalid_1's rmse: 59.237\n",
      "[240]\ttraining's rmse: 26.7435\tvalid_1's rmse: 58.0747\n",
      "[270]\ttraining's rmse: 24.1489\tvalid_1's rmse: 57.1859\n",
      "[300]\ttraining's rmse: 21.931\tvalid_1's rmse: 56.6187\n",
      "[330]\ttraining's rmse: 20.0405\tvalid_1's rmse: 56.1218\n",
      "[360]\ttraining's rmse: 18.4164\tvalid_1's rmse: 55.7776\n",
      "[390]\ttraining's rmse: 16.9603\tvalid_1's rmse: 55.513\n",
      "[420]\ttraining's rmse: 15.7\tvalid_1's rmse: 55.303\n",
      "[450]\ttraining's rmse: 14.5397\tvalid_1's rmse: 55.1172\n",
      "[480]\ttraining's rmse: 13.5252\tvalid_1's rmse: 54.996\n",
      "[510]\ttraining's rmse: 12.5868\tvalid_1's rmse: 54.8512\n",
      "[540]\ttraining's rmse: 11.731\tvalid_1's rmse: 54.7484\n",
      "[570]\ttraining's rmse: 10.9546\tvalid_1's rmse: 54.6804\n",
      "[600]\ttraining's rmse: 10.2483\tvalid_1's rmse: 54.6276\n",
      "[630]\ttraining's rmse: 9.59889\tvalid_1's rmse: 54.5609\n",
      "[660]\ttraining's rmse: 8.99586\tvalid_1's rmse: 54.5236\n",
      "[690]\ttraining's rmse: 8.43783\tvalid_1's rmse: 54.4834\n",
      "[720]\ttraining's rmse: 7.93484\tvalid_1's rmse: 54.4352\n",
      "[750]\ttraining's rmse: 7.46655\tvalid_1's rmse: 54.3784\n",
      "[780]\ttraining's rmse: 7.02816\tvalid_1's rmse: 54.3465\n",
      "[810]\ttraining's rmse: 6.62045\tvalid_1's rmse: 54.3135\n",
      "[840]\ttraining's rmse: 6.24412\tvalid_1's rmse: 54.3005\n",
      "[870]\ttraining's rmse: 5.90217\tvalid_1's rmse: 54.2768\n",
      "[900]\ttraining's rmse: 5.57645\tvalid_1's rmse: 54.2535\n",
      "[930]\ttraining's rmse: 5.26674\tvalid_1's rmse: 54.2266\n",
      "[960]\ttraining's rmse: 4.98068\tvalid_1's rmse: 54.2088\n",
      "[990]\ttraining's rmse: 4.7086\tvalid_1's rmse: 54.1952\n",
      "[1020]\ttraining's rmse: 4.45683\tvalid_1's rmse: 54.1809\n",
      "[1050]\ttraining's rmse: 4.21698\tvalid_1's rmse: 54.1591\n",
      "[1080]\ttraining's rmse: 3.98986\tvalid_1's rmse: 54.152\n",
      "[1110]\ttraining's rmse: 3.78016\tvalid_1's rmse: 54.1346\n",
      "[1140]\ttraining's rmse: 3.58165\tvalid_1's rmse: 54.1256\n",
      "[1170]\ttraining's rmse: 3.39852\tvalid_1's rmse: 54.1175\n",
      "[1200]\ttraining's rmse: 3.22057\tvalid_1's rmse: 54.1207\n",
      "[1230]\ttraining's rmse: 3.0578\tvalid_1's rmse: 54.113\n",
      "[1260]\ttraining's rmse: 2.90339\tvalid_1's rmse: 54.1093\n",
      "[1290]\ttraining's rmse: 2.75534\tvalid_1's rmse: 54.0972\n",
      "[1320]\ttraining's rmse: 2.61397\tvalid_1's rmse: 54.0888\n",
      "[1350]\ttraining's rmse: 2.48596\tvalid_1's rmse: 54.0886\n",
      "[1380]\ttraining's rmse: 2.36292\tvalid_1's rmse: 54.0881\n",
      "[1410]\ttraining's rmse: 2.25063\tvalid_1's rmse: 54.0832\n",
      "[1440]\ttraining's rmse: 2.14186\tvalid_1's rmse: 54.0799\n",
      "[1470]\ttraining's rmse: 2.03835\tvalid_1's rmse: 54.0775\n",
      "[1500]\ttraining's rmse: 1.93765\tvalid_1's rmse: 54.0735\n",
      "[1530]\ttraining's rmse: 1.84287\tvalid_1's rmse: 54.0705\n",
      "[1560]\ttraining's rmse: 1.75419\tvalid_1's rmse: 54.065\n",
      "[1590]\ttraining's rmse: 1.67091\tvalid_1's rmse: 54.0622\n",
      "[1620]\ttraining's rmse: 1.59173\tvalid_1's rmse: 54.0617\n",
      "[1650]\ttraining's rmse: 1.51594\tvalid_1's rmse: 54.0554\n",
      "[1680]\ttraining's rmse: 1.44502\tvalid_1's rmse: 54.052\n",
      "[1710]\ttraining's rmse: 1.37708\tvalid_1's rmse: 54.0493\n",
      "[1740]\ttraining's rmse: 1.3126\tvalid_1's rmse: 54.049\n",
      "[1770]\ttraining's rmse: 1.25151\tvalid_1's rmse: 54.0487\n",
      "[1800]\ttraining's rmse: 1.19323\tvalid_1's rmse: 54.0455\n",
      "[1830]\ttraining's rmse: 1.13748\tvalid_1's rmse: 54.0449\n",
      "[1860]\ttraining's rmse: 1.08535\tvalid_1's rmse: 54.0428\n",
      "[1890]\ttraining's rmse: 1.03426\tvalid_1's rmse: 54.0423\n",
      "[1920]\ttraining's rmse: 0.98715\tvalid_1's rmse: 54.0399\n",
      "[1950]\ttraining's rmse: 0.942931\tvalid_1's rmse: 54.04\n",
      "[1980]\ttraining's rmse: 0.901007\tvalid_1's rmse: 54.0393\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's rmse: 0.874393\tvalid_1's rmse: 54.0387\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002462 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 20022\n",
      "[LightGBM] [Info] Number of data points in the train set: 9219, number of used features: 79\n",
      "[LightGBM] [Info] Start training from score 367.382886\n",
      "Training until validation scores don't improve for 125 rounds\n",
      "[30]\ttraining's rmse: 155.823\tvalid_1's rmse: 158.549\n",
      "[60]\ttraining's rmse: 97.3587\tvalid_1's rmse: 106.848\n",
      "[90]\ttraining's rmse: 65.9426\tvalid_1's rmse: 82.234\n",
      "[120]\ttraining's rmse: 48.8614\tvalid_1's rmse: 70.8044\n",
      "[150]\ttraining's rmse: 39.295\tvalid_1's rmse: 65.4918\n",
      "[180]\ttraining's rmse: 33.3545\tvalid_1's rmse: 62.8646\n",
      "[210]\ttraining's rmse: 29.2395\tvalid_1's rmse: 61.2965\n",
      "[240]\ttraining's rmse: 26.0956\tvalid_1's rmse: 60.202\n",
      "[270]\ttraining's rmse: 23.5491\tvalid_1's rmse: 59.4273\n",
      "[300]\ttraining's rmse: 21.4297\tvalid_1's rmse: 58.9088\n",
      "[330]\ttraining's rmse: 19.612\tvalid_1's rmse: 58.4766\n",
      "[360]\ttraining's rmse: 18.0559\tvalid_1's rmse: 58.0761\n",
      "[390]\ttraining's rmse: 16.6489\tvalid_1's rmse: 57.8423\n",
      "[420]\ttraining's rmse: 15.4124\tvalid_1's rmse: 57.6791\n",
      "[450]\ttraining's rmse: 14.2927\tvalid_1's rmse: 57.5286\n",
      "[480]\ttraining's rmse: 13.2828\tvalid_1's rmse: 57.4013\n",
      "[510]\ttraining's rmse: 12.3807\tvalid_1's rmse: 57.319\n",
      "[540]\ttraining's rmse: 11.5536\tvalid_1's rmse: 57.2176\n",
      "[570]\ttraining's rmse: 10.8\tvalid_1's rmse: 57.1553\n",
      "[600]\ttraining's rmse: 10.0988\tvalid_1's rmse: 57.0933\n",
      "[630]\ttraining's rmse: 9.46155\tvalid_1's rmse: 57.0281\n",
      "[660]\ttraining's rmse: 8.87144\tvalid_1's rmse: 56.9751\n",
      "[690]\ttraining's rmse: 8.3137\tvalid_1's rmse: 56.8889\n",
      "[720]\ttraining's rmse: 7.81552\tvalid_1's rmse: 56.8524\n",
      "[750]\ttraining's rmse: 7.3447\tvalid_1's rmse: 56.8127\n",
      "[780]\ttraining's rmse: 6.9013\tvalid_1's rmse: 56.7679\n",
      "[810]\ttraining's rmse: 6.49496\tvalid_1's rmse: 56.7222\n",
      "[840]\ttraining's rmse: 6.10964\tvalid_1's rmse: 56.6822\n",
      "[870]\ttraining's rmse: 5.75269\tvalid_1's rmse: 56.6531\n",
      "[900]\ttraining's rmse: 5.42455\tvalid_1's rmse: 56.6217\n",
      "[930]\ttraining's rmse: 5.11884\tvalid_1's rmse: 56.5936\n",
      "[960]\ttraining's rmse: 4.83629\tvalid_1's rmse: 56.568\n",
      "[990]\ttraining's rmse: 4.56727\tvalid_1's rmse: 56.5454\n",
      "[1020]\ttraining's rmse: 4.31816\tvalid_1's rmse: 56.5344\n",
      "[1050]\ttraining's rmse: 4.07999\tvalid_1's rmse: 56.5139\n",
      "[1080]\ttraining's rmse: 3.8615\tvalid_1's rmse: 56.4924\n",
      "[1110]\ttraining's rmse: 3.65132\tvalid_1's rmse: 56.4863\n",
      "[1140]\ttraining's rmse: 3.45334\tvalid_1's rmse: 56.4627\n",
      "[1170]\ttraining's rmse: 3.26727\tvalid_1's rmse: 56.4505\n",
      "[1200]\ttraining's rmse: 3.09238\tvalid_1's rmse: 56.4415\n",
      "[1230]\ttraining's rmse: 2.92909\tvalid_1's rmse: 56.4327\n",
      "[1260]\ttraining's rmse: 2.77268\tvalid_1's rmse: 56.4241\n",
      "[1290]\ttraining's rmse: 2.62963\tvalid_1's rmse: 56.414\n",
      "[1320]\ttraining's rmse: 2.49435\tvalid_1's rmse: 56.4084\n",
      "[1350]\ttraining's rmse: 2.36541\tvalid_1's rmse: 56.3999\n",
      "[1380]\ttraining's rmse: 2.24642\tvalid_1's rmse: 56.3948\n",
      "[1410]\ttraining's rmse: 2.13039\tvalid_1's rmse: 56.3874\n",
      "[1440]\ttraining's rmse: 2.02221\tvalid_1's rmse: 56.3819\n",
      "[1470]\ttraining's rmse: 1.91955\tvalid_1's rmse: 56.3798\n",
      "[1500]\ttraining's rmse: 1.82323\tvalid_1's rmse: 56.3749\n",
      "[1530]\ttraining's rmse: 1.7322\tvalid_1's rmse: 56.3718\n",
      "[1560]\ttraining's rmse: 1.64715\tvalid_1's rmse: 56.3707\n",
      "[1590]\ttraining's rmse: 1.56552\tvalid_1's rmse: 56.3669\n",
      "[1620]\ttraining's rmse: 1.48835\tvalid_1's rmse: 56.3618\n",
      "[1650]\ttraining's rmse: 1.41425\tvalid_1's rmse: 56.3605\n",
      "[1680]\ttraining's rmse: 1.34443\tvalid_1's rmse: 56.3573\n",
      "[1710]\ttraining's rmse: 1.27811\tvalid_1's rmse: 56.3559\n",
      "[1740]\ttraining's rmse: 1.21574\tvalid_1's rmse: 56.3538\n",
      "[1770]\ttraining's rmse: 1.15605\tvalid_1's rmse: 56.3535\n",
      "[1800]\ttraining's rmse: 1.09955\tvalid_1's rmse: 56.352\n",
      "[1830]\ttraining's rmse: 1.046\tvalid_1's rmse: 56.3501\n",
      "[1860]\ttraining's rmse: 0.995836\tvalid_1's rmse: 56.3478\n",
      "[1890]\ttraining's rmse: 0.94797\tvalid_1's rmse: 56.3432\n",
      "[1920]\ttraining's rmse: 0.902217\tvalid_1's rmse: 56.341\n",
      "[1950]\ttraining's rmse: 0.858619\tvalid_1's rmse: 56.3391\n",
      "[1980]\ttraining's rmse: 0.817699\tvalid_1's rmse: 56.3372\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's rmse: 0.791056\tvalid_1's rmse: 56.3348\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003512 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 20022\n",
      "[LightGBM] [Info] Number of data points in the train set: 9219, number of used features: 79\n",
      "[LightGBM] [Info] Start training from score 369.350809\n",
      "Training until validation scores don't improve for 125 rounds\n",
      "[30]\ttraining's rmse: 156.206\tvalid_1's rmse: 158.264\n",
      "[60]\ttraining's rmse: 97.5833\tvalid_1's rmse: 107.398\n",
      "[90]\ttraining's rmse: 65.9492\tvalid_1's rmse: 83.4097\n",
      "[120]\ttraining's rmse: 48.8464\tvalid_1's rmse: 72.2355\n",
      "[150]\ttraining's rmse: 39.1683\tvalid_1's rmse: 67.1357\n",
      "[180]\ttraining's rmse: 33.2003\tvalid_1's rmse: 64.2842\n",
      "[210]\ttraining's rmse: 29.157\tvalid_1's rmse: 62.7021\n",
      "[240]\ttraining's rmse: 26.0125\tvalid_1's rmse: 61.814\n",
      "[270]\ttraining's rmse: 23.4744\tvalid_1's rmse: 61.0542\n",
      "[300]\ttraining's rmse: 21.3857\tvalid_1's rmse: 60.5463\n",
      "[330]\ttraining's rmse: 19.5774\tvalid_1's rmse: 60.2124\n",
      "[360]\ttraining's rmse: 17.996\tvalid_1's rmse: 59.9114\n",
      "[390]\ttraining's rmse: 16.6064\tvalid_1's rmse: 59.6988\n",
      "[420]\ttraining's rmse: 15.3406\tvalid_1's rmse: 59.4991\n",
      "[450]\ttraining's rmse: 14.2366\tvalid_1's rmse: 59.3348\n",
      "[480]\ttraining's rmse: 13.2263\tvalid_1's rmse: 59.2192\n",
      "[510]\ttraining's rmse: 12.3188\tvalid_1's rmse: 59.0981\n",
      "[540]\ttraining's rmse: 11.4941\tvalid_1's rmse: 58.9957\n",
      "[570]\ttraining's rmse: 10.7417\tvalid_1's rmse: 58.963\n",
      "[600]\ttraining's rmse: 10.052\tvalid_1's rmse: 58.8893\n",
      "[630]\ttraining's rmse: 9.41548\tvalid_1's rmse: 58.8267\n",
      "[660]\ttraining's rmse: 8.83023\tvalid_1's rmse: 58.7868\n",
      "[690]\ttraining's rmse: 8.28144\tvalid_1's rmse: 58.744\n",
      "[720]\ttraining's rmse: 7.77029\tvalid_1's rmse: 58.7019\n",
      "[750]\ttraining's rmse: 7.30303\tvalid_1's rmse: 58.6514\n",
      "[780]\ttraining's rmse: 6.86845\tvalid_1's rmse: 58.6115\n",
      "[810]\ttraining's rmse: 6.46524\tvalid_1's rmse: 58.5835\n",
      "[840]\ttraining's rmse: 6.08957\tvalid_1's rmse: 58.5539\n",
      "[870]\ttraining's rmse: 5.74005\tvalid_1's rmse: 58.5312\n",
      "[900]\ttraining's rmse: 5.41762\tvalid_1's rmse: 58.5228\n",
      "[930]\ttraining's rmse: 5.11046\tvalid_1's rmse: 58.507\n",
      "[960]\ttraining's rmse: 4.82545\tvalid_1's rmse: 58.5\n",
      "[990]\ttraining's rmse: 4.55753\tvalid_1's rmse: 58.4692\n",
      "[1020]\ttraining's rmse: 4.30656\tvalid_1's rmse: 58.4424\n",
      "[1050]\ttraining's rmse: 4.07005\tvalid_1's rmse: 58.4365\n",
      "[1080]\ttraining's rmse: 3.84827\tvalid_1's rmse: 58.4208\n",
      "[1110]\ttraining's rmse: 3.64024\tvalid_1's rmse: 58.406\n",
      "[1140]\ttraining's rmse: 3.44705\tvalid_1's rmse: 58.3939\n",
      "[1170]\ttraining's rmse: 3.26307\tvalid_1's rmse: 58.3769\n",
      "[1200]\ttraining's rmse: 3.08891\tvalid_1's rmse: 58.3694\n",
      "[1230]\ttraining's rmse: 2.92678\tvalid_1's rmse: 58.3679\n",
      "[1260]\ttraining's rmse: 2.77363\tvalid_1's rmse: 58.3653\n",
      "[1290]\ttraining's rmse: 2.62767\tvalid_1's rmse: 58.3644\n",
      "[1320]\ttraining's rmse: 2.49341\tvalid_1's rmse: 58.3605\n",
      "[1350]\ttraining's rmse: 2.36719\tvalid_1's rmse: 58.3517\n",
      "[1380]\ttraining's rmse: 2.24683\tvalid_1's rmse: 58.3483\n",
      "[1410]\ttraining's rmse: 2.13285\tvalid_1's rmse: 58.3455\n",
      "[1440]\ttraining's rmse: 2.02677\tvalid_1's rmse: 58.3407\n",
      "[1470]\ttraining's rmse: 1.92307\tvalid_1's rmse: 58.3387\n",
      "[1500]\ttraining's rmse: 1.82775\tvalid_1's rmse: 58.3352\n",
      "[1530]\ttraining's rmse: 1.73528\tvalid_1's rmse: 58.3335\n",
      "[1560]\ttraining's rmse: 1.64867\tvalid_1's rmse: 58.3343\n",
      "[1590]\ttraining's rmse: 1.56745\tvalid_1's rmse: 58.3321\n",
      "[1620]\ttraining's rmse: 1.48835\tvalid_1's rmse: 58.3271\n",
      "[1650]\ttraining's rmse: 1.41605\tvalid_1's rmse: 58.3231\n",
      "[1680]\ttraining's rmse: 1.34637\tvalid_1's rmse: 58.322\n",
      "[1710]\ttraining's rmse: 1.27984\tvalid_1's rmse: 58.3214\n",
      "[1740]\ttraining's rmse: 1.21688\tvalid_1's rmse: 58.3177\n",
      "[1770]\ttraining's rmse: 1.15974\tvalid_1's rmse: 58.3166\n",
      "[1800]\ttraining's rmse: 1.10464\tvalid_1's rmse: 58.3163\n",
      "[1830]\ttraining's rmse: 1.05087\tvalid_1's rmse: 58.3142\n",
      "[1860]\ttraining's rmse: 1.00127\tvalid_1's rmse: 58.313\n",
      "[1890]\ttraining's rmse: 0.954294\tvalid_1's rmse: 58.3119\n",
      "[1920]\ttraining's rmse: 0.9085\tvalid_1's rmse: 58.3101\n",
      "[1950]\ttraining's rmse: 0.86414\tvalid_1's rmse: 58.31\n",
      "[1980]\ttraining's rmse: 0.823545\tvalid_1's rmse: 58.3087\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's rmse: 0.797333\tvalid_1's rmse: 58.3094\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003466 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 20022\n",
      "[LightGBM] [Info] Number of data points in the train set: 9219, number of used features: 79\n",
      "[LightGBM] [Info] Start training from score 368.804320\n",
      "Training until validation scores don't improve for 125 rounds\n",
      "[30]\ttraining's rmse: 157.191\tvalid_1's rmse: 155.797\n",
      "[60]\ttraining's rmse: 97.8461\tvalid_1's rmse: 105.78\n",
      "[90]\ttraining's rmse: 65.8737\tvalid_1's rmse: 81.6218\n",
      "[120]\ttraining's rmse: 48.667\tvalid_1's rmse: 70.2455\n",
      "[150]\ttraining's rmse: 39.0547\tvalid_1's rmse: 64.7683\n",
      "[180]\ttraining's rmse: 33.1768\tvalid_1's rmse: 62.0272\n",
      "[210]\ttraining's rmse: 29.1949\tvalid_1's rmse: 60.376\n",
      "[240]\ttraining's rmse: 26.1114\tvalid_1's rmse: 59.3094\n",
      "[270]\ttraining's rmse: 23.5934\tvalid_1's rmse: 58.5194\n",
      "[300]\ttraining's rmse: 21.5038\tvalid_1's rmse: 58.0555\n",
      "[330]\ttraining's rmse: 19.7089\tvalid_1's rmse: 57.621\n",
      "[360]\ttraining's rmse: 18.1362\tvalid_1's rmse: 57.3621\n",
      "[390]\ttraining's rmse: 16.7197\tvalid_1's rmse: 57.2051\n",
      "[420]\ttraining's rmse: 15.4797\tvalid_1's rmse: 57.0363\n",
      "[450]\ttraining's rmse: 14.3888\tvalid_1's rmse: 56.9074\n",
      "[480]\ttraining's rmse: 13.3741\tvalid_1's rmse: 56.7675\n",
      "[510]\ttraining's rmse: 12.4607\tvalid_1's rmse: 56.648\n",
      "[540]\ttraining's rmse: 11.6273\tvalid_1's rmse: 56.5708\n",
      "[570]\ttraining's rmse: 10.8703\tvalid_1's rmse: 56.4573\n",
      "[600]\ttraining's rmse: 10.1726\tvalid_1's rmse: 56.3912\n",
      "[630]\ttraining's rmse: 9.52915\tvalid_1's rmse: 56.3333\n",
      "[660]\ttraining's rmse: 8.94011\tvalid_1's rmse: 56.2757\n",
      "[690]\ttraining's rmse: 8.3938\tvalid_1's rmse: 56.2369\n",
      "[720]\ttraining's rmse: 7.88911\tvalid_1's rmse: 56.2128\n",
      "[750]\ttraining's rmse: 7.42424\tvalid_1's rmse: 56.1893\n",
      "[780]\ttraining's rmse: 6.98832\tvalid_1's rmse: 56.1497\n",
      "[810]\ttraining's rmse: 6.58052\tvalid_1's rmse: 56.1218\n",
      "[840]\ttraining's rmse: 6.19067\tvalid_1's rmse: 56.093\n",
      "[870]\ttraining's rmse: 5.83164\tvalid_1's rmse: 56.0843\n",
      "[900]\ttraining's rmse: 5.49783\tvalid_1's rmse: 56.062\n",
      "[930]\ttraining's rmse: 5.18892\tvalid_1's rmse: 56.0414\n",
      "[960]\ttraining's rmse: 4.89958\tvalid_1's rmse: 56.0217\n",
      "[990]\ttraining's rmse: 4.62825\tvalid_1's rmse: 56.0066\n",
      "[1020]\ttraining's rmse: 4.37573\tvalid_1's rmse: 55.9914\n",
      "[1050]\ttraining's rmse: 4.14161\tvalid_1's rmse: 55.9707\n",
      "[1080]\ttraining's rmse: 3.91501\tvalid_1's rmse: 55.9549\n",
      "[1110]\ttraining's rmse: 3.70721\tvalid_1's rmse: 55.9527\n",
      "[1140]\ttraining's rmse: 3.50988\tvalid_1's rmse: 55.9472\n",
      "[1170]\ttraining's rmse: 3.3254\tvalid_1's rmse: 55.9357\n",
      "[1200]\ttraining's rmse: 3.1537\tvalid_1's rmse: 55.9209\n",
      "[1230]\ttraining's rmse: 2.98559\tvalid_1's rmse: 55.9129\n",
      "[1260]\ttraining's rmse: 2.82899\tvalid_1's rmse: 55.9055\n",
      "[1290]\ttraining's rmse: 2.67888\tvalid_1's rmse: 55.8996\n",
      "[1320]\ttraining's rmse: 2.53794\tvalid_1's rmse: 55.8903\n",
      "[1350]\ttraining's rmse: 2.4095\tvalid_1's rmse: 55.8803\n",
      "[1380]\ttraining's rmse: 2.28573\tvalid_1's rmse: 55.8769\n",
      "[1410]\ttraining's rmse: 2.16838\tvalid_1's rmse: 55.8767\n",
      "[1440]\ttraining's rmse: 2.05869\tvalid_1's rmse: 55.8743\n",
      "[1470]\ttraining's rmse: 1.95671\tvalid_1's rmse: 55.8713\n",
      "[1500]\ttraining's rmse: 1.8582\tvalid_1's rmse: 55.8694\n",
      "[1530]\ttraining's rmse: 1.76593\tvalid_1's rmse: 55.868\n",
      "[1560]\ttraining's rmse: 1.67925\tvalid_1's rmse: 55.8623\n",
      "[1590]\ttraining's rmse: 1.59757\tvalid_1's rmse: 55.8614\n",
      "[1620]\ttraining's rmse: 1.51788\tvalid_1's rmse: 55.8575\n",
      "[1650]\ttraining's rmse: 1.44525\tvalid_1's rmse: 55.8529\n",
      "[1680]\ttraining's rmse: 1.37686\tvalid_1's rmse: 55.8503\n",
      "[1710]\ttraining's rmse: 1.30956\tvalid_1's rmse: 55.85\n",
      "[1740]\ttraining's rmse: 1.24688\tvalid_1's rmse: 55.8509\n",
      "[1770]\ttraining's rmse: 1.18774\tvalid_1's rmse: 55.8494\n",
      "[1800]\ttraining's rmse: 1.13131\tvalid_1's rmse: 55.8485\n",
      "[1830]\ttraining's rmse: 1.07757\tvalid_1's rmse: 55.8442\n",
      "[1860]\ttraining's rmse: 1.02721\tvalid_1's rmse: 55.8438\n",
      "[1890]\ttraining's rmse: 0.979483\tvalid_1's rmse: 55.8436\n",
      "[1920]\ttraining's rmse: 0.934058\tvalid_1's rmse: 55.8436\n",
      "[1950]\ttraining's rmse: 0.891469\tvalid_1's rmse: 55.8439\n",
      "[1980]\ttraining's rmse: 0.849281\tvalid_1's rmse: 55.8437\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's rmse: 0.823198\tvalid_1's rmse: 55.8444\n",
      "29\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003393 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 20020\n",
      "[LightGBM] [Info] Number of data points in the train set: 9219, number of used features: 79\n",
      "[LightGBM] [Info] Start training from score 369.377868\n",
      "Training until validation scores don't improve for 125 rounds\n",
      "[30]\ttraining's rmse: 152.443\tvalid_1's rmse: 158.924\n",
      "[60]\ttraining's rmse: 94.5954\tvalid_1's rmse: 105.558\n",
      "[90]\ttraining's rmse: 63.5748\tvalid_1's rmse: 79.6498\n",
      "[120]\ttraining's rmse: 46.9558\tvalid_1's rmse: 67.9056\n",
      "[150]\ttraining's rmse: 37.6301\tvalid_1's rmse: 62.2948\n",
      "[180]\ttraining's rmse: 31.9335\tvalid_1's rmse: 59.2684\n",
      "[210]\ttraining's rmse: 27.9959\tvalid_1's rmse: 57.4426\n",
      "[240]\ttraining's rmse: 24.915\tvalid_1's rmse: 56.2785\n",
      "[270]\ttraining's rmse: 22.478\tvalid_1's rmse: 55.5037\n",
      "[300]\ttraining's rmse: 20.4787\tvalid_1's rmse: 54.9608\n",
      "[330]\ttraining's rmse: 18.7517\tvalid_1's rmse: 54.4885\n",
      "[360]\ttraining's rmse: 17.2748\tvalid_1's rmse: 54.1662\n",
      "[390]\ttraining's rmse: 15.9508\tvalid_1's rmse: 53.9368\n",
      "[420]\ttraining's rmse: 14.7935\tvalid_1's rmse: 53.7591\n",
      "[450]\ttraining's rmse: 13.7192\tvalid_1's rmse: 53.588\n",
      "[480]\ttraining's rmse: 12.7665\tvalid_1's rmse: 53.4391\n",
      "[510]\ttraining's rmse: 11.9293\tvalid_1's rmse: 53.3625\n",
      "[540]\ttraining's rmse: 11.1468\tvalid_1's rmse: 53.2471\n",
      "[570]\ttraining's rmse: 10.4372\tvalid_1's rmse: 53.1762\n",
      "[600]\ttraining's rmse: 9.78613\tvalid_1's rmse: 53.1222\n",
      "[630]\ttraining's rmse: 9.1834\tvalid_1's rmse: 53.0579\n",
      "[660]\ttraining's rmse: 8.61538\tvalid_1's rmse: 52.9854\n",
      "[690]\ttraining's rmse: 8.094\tvalid_1's rmse: 52.9389\n",
      "[720]\ttraining's rmse: 7.60452\tvalid_1's rmse: 52.8878\n",
      "[750]\ttraining's rmse: 7.15497\tvalid_1's rmse: 52.8536\n",
      "[780]\ttraining's rmse: 6.74759\tvalid_1's rmse: 52.8271\n",
      "[810]\ttraining's rmse: 6.35404\tvalid_1's rmse: 52.7981\n",
      "[840]\ttraining's rmse: 5.98579\tvalid_1's rmse: 52.7708\n",
      "[870]\ttraining's rmse: 5.6473\tvalid_1's rmse: 52.7457\n",
      "[900]\ttraining's rmse: 5.33038\tvalid_1's rmse: 52.7167\n",
      "[930]\ttraining's rmse: 5.03611\tvalid_1's rmse: 52.6891\n",
      "[960]\ttraining's rmse: 4.76424\tvalid_1's rmse: 52.6753\n",
      "[990]\ttraining's rmse: 4.50478\tvalid_1's rmse: 52.6561\n",
      "[1020]\ttraining's rmse: 4.26355\tvalid_1's rmse: 52.6399\n",
      "[1050]\ttraining's rmse: 4.03588\tvalid_1's rmse: 52.6255\n",
      "[1080]\ttraining's rmse: 3.82235\tvalid_1's rmse: 52.6096\n",
      "[1110]\ttraining's rmse: 3.62037\tvalid_1's rmse: 52.5984\n",
      "[1140]\ttraining's rmse: 3.43594\tvalid_1's rmse: 52.5997\n",
      "[1170]\ttraining's rmse: 3.2565\tvalid_1's rmse: 52.5915\n",
      "[1200]\ttraining's rmse: 3.08794\tvalid_1's rmse: 52.5795\n",
      "[1230]\ttraining's rmse: 2.93095\tvalid_1's rmse: 52.5705\n",
      "[1260]\ttraining's rmse: 2.77842\tvalid_1's rmse: 52.565\n",
      "[1290]\ttraining's rmse: 2.6367\tvalid_1's rmse: 52.5659\n",
      "[1320]\ttraining's rmse: 2.49785\tvalid_1's rmse: 52.5637\n",
      "[1350]\ttraining's rmse: 2.37262\tvalid_1's rmse: 52.5554\n",
      "[1380]\ttraining's rmse: 2.25138\tvalid_1's rmse: 52.5522\n",
      "[1410]\ttraining's rmse: 2.13867\tvalid_1's rmse: 52.5475\n",
      "[1440]\ttraining's rmse: 2.03582\tvalid_1's rmse: 52.5417\n",
      "[1470]\ttraining's rmse: 1.93527\tvalid_1's rmse: 52.5398\n",
      "[1500]\ttraining's rmse: 1.84147\tvalid_1's rmse: 52.5316\n",
      "[1530]\ttraining's rmse: 1.75331\tvalid_1's rmse: 52.5268\n",
      "[1560]\ttraining's rmse: 1.66844\tvalid_1's rmse: 52.5207\n",
      "[1590]\ttraining's rmse: 1.5871\tvalid_1's rmse: 52.517\n",
      "[1620]\ttraining's rmse: 1.50932\tvalid_1's rmse: 52.5134\n",
      "[1650]\ttraining's rmse: 1.43993\tvalid_1's rmse: 52.5115\n",
      "[1680]\ttraining's rmse: 1.37048\tvalid_1's rmse: 52.5093\n",
      "[1710]\ttraining's rmse: 1.306\tvalid_1's rmse: 52.5074\n",
      "[1740]\ttraining's rmse: 1.24492\tvalid_1's rmse: 52.5023\n",
      "[1770]\ttraining's rmse: 1.18668\tvalid_1's rmse: 52.5011\n",
      "[1800]\ttraining's rmse: 1.12957\tvalid_1's rmse: 52.4973\n",
      "[1830]\ttraining's rmse: 1.07473\tvalid_1's rmse: 52.4954\n",
      "[1860]\ttraining's rmse: 1.02319\tvalid_1's rmse: 52.4939\n",
      "[1890]\ttraining's rmse: 0.97426\tvalid_1's rmse: 52.4929\n",
      "[1920]\ttraining's rmse: 0.93075\tvalid_1's rmse: 52.4934\n",
      "[1950]\ttraining's rmse: 0.888904\tvalid_1's rmse: 52.492\n",
      "[1980]\ttraining's rmse: 0.847856\tvalid_1's rmse: 52.4903\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's rmse: 0.822808\tvalid_1's rmse: 52.4886\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002340 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 20020\n",
      "[LightGBM] [Info] Number of data points in the train set: 9219, number of used features: 79\n",
      "[LightGBM] [Info] Start training from score 363.290863\n",
      "Training until validation scores don't improve for 125 rounds\n",
      "[30]\ttraining's rmse: 151.848\tvalid_1's rmse: 153.744\n",
      "[60]\ttraining's rmse: 95.324\tvalid_1's rmse: 104.024\n",
      "[90]\ttraining's rmse: 65.0701\tvalid_1's rmse: 79.9265\n",
      "[120]\ttraining's rmse: 48.6138\tvalid_1's rmse: 68.5624\n",
      "[150]\ttraining's rmse: 39.1396\tvalid_1's rmse: 62.8244\n",
      "[180]\ttraining's rmse: 33.3018\tvalid_1's rmse: 59.8062\n",
      "[210]\ttraining's rmse: 29.2239\tvalid_1's rmse: 58.0477\n",
      "[240]\ttraining's rmse: 26.0148\tvalid_1's rmse: 56.7353\n",
      "[270]\ttraining's rmse: 23.4971\tvalid_1's rmse: 55.8212\n",
      "[300]\ttraining's rmse: 21.3529\tvalid_1's rmse: 55.153\n",
      "[330]\ttraining's rmse: 19.5589\tvalid_1's rmse: 54.7065\n",
      "[360]\ttraining's rmse: 17.9593\tvalid_1's rmse: 54.3648\n",
      "[390]\ttraining's rmse: 16.571\tvalid_1's rmse: 54.0636\n",
      "[420]\ttraining's rmse: 15.321\tvalid_1's rmse: 53.8186\n",
      "[450]\ttraining's rmse: 14.2192\tvalid_1's rmse: 53.5933\n",
      "[480]\ttraining's rmse: 13.1973\tvalid_1's rmse: 53.4537\n",
      "[510]\ttraining's rmse: 12.3092\tvalid_1's rmse: 53.3315\n",
      "[540]\ttraining's rmse: 11.4896\tvalid_1's rmse: 53.2395\n",
      "[570]\ttraining's rmse: 10.7222\tvalid_1's rmse: 53.1149\n",
      "[600]\ttraining's rmse: 10.0412\tvalid_1's rmse: 53.0417\n",
      "[630]\ttraining's rmse: 9.42422\tvalid_1's rmse: 52.9775\n",
      "[660]\ttraining's rmse: 8.84175\tvalid_1's rmse: 52.9015\n",
      "[690]\ttraining's rmse: 8.30392\tvalid_1's rmse: 52.8574\n",
      "[720]\ttraining's rmse: 7.79603\tvalid_1's rmse: 52.822\n",
      "[750]\ttraining's rmse: 7.32814\tvalid_1's rmse: 52.7908\n",
      "[780]\ttraining's rmse: 6.89225\tvalid_1's rmse: 52.7629\n",
      "[810]\ttraining's rmse: 6.48917\tvalid_1's rmse: 52.7298\n",
      "[840]\ttraining's rmse: 6.11255\tvalid_1's rmse: 52.7023\n",
      "[870]\ttraining's rmse: 5.7581\tvalid_1's rmse: 52.6681\n",
      "[900]\ttraining's rmse: 5.43158\tvalid_1's rmse: 52.6567\n",
      "[930]\ttraining's rmse: 5.12666\tvalid_1's rmse: 52.6436\n",
      "[960]\ttraining's rmse: 4.84081\tvalid_1's rmse: 52.6399\n",
      "[990]\ttraining's rmse: 4.57222\tvalid_1's rmse: 52.6268\n",
      "[1020]\ttraining's rmse: 4.3186\tvalid_1's rmse: 52.6132\n",
      "[1050]\ttraining's rmse: 4.08081\tvalid_1's rmse: 52.5985\n",
      "[1080]\ttraining's rmse: 3.86326\tvalid_1's rmse: 52.591\n",
      "[1110]\ttraining's rmse: 3.65909\tvalid_1's rmse: 52.5787\n",
      "[1140]\ttraining's rmse: 3.45939\tvalid_1's rmse: 52.5773\n",
      "[1170]\ttraining's rmse: 3.28309\tvalid_1's rmse: 52.5721\n",
      "[1200]\ttraining's rmse: 3.1057\tvalid_1's rmse: 52.558\n",
      "[1230]\ttraining's rmse: 2.942\tvalid_1's rmse: 52.5558\n",
      "[1260]\ttraining's rmse: 2.79067\tvalid_1's rmse: 52.5537\n",
      "[1290]\ttraining's rmse: 2.6497\tvalid_1's rmse: 52.5459\n",
      "[1320]\ttraining's rmse: 2.51164\tvalid_1's rmse: 52.5418\n",
      "[1350]\ttraining's rmse: 2.38351\tvalid_1's rmse: 52.5401\n",
      "[1380]\ttraining's rmse: 2.26208\tvalid_1's rmse: 52.5382\n",
      "[1410]\ttraining's rmse: 2.14753\tvalid_1's rmse: 52.5347\n",
      "[1440]\ttraining's rmse: 2.03984\tvalid_1's rmse: 52.5335\n",
      "[1470]\ttraining's rmse: 1.93671\tvalid_1's rmse: 52.5286\n",
      "[1500]\ttraining's rmse: 1.84102\tvalid_1's rmse: 52.5285\n",
      "[1530]\ttraining's rmse: 1.74868\tvalid_1's rmse: 52.5266\n",
      "[1560]\ttraining's rmse: 1.65999\tvalid_1's rmse: 52.5256\n",
      "[1590]\ttraining's rmse: 1.57898\tvalid_1's rmse: 52.521\n",
      "[1620]\ttraining's rmse: 1.50132\tvalid_1's rmse: 52.5175\n",
      "[1650]\ttraining's rmse: 1.42704\tvalid_1's rmse: 52.5161\n",
      "[1680]\ttraining's rmse: 1.35746\tvalid_1's rmse: 52.5142\n",
      "[1710]\ttraining's rmse: 1.29243\tvalid_1's rmse: 52.513\n",
      "[1740]\ttraining's rmse: 1.23051\tvalid_1's rmse: 52.5116\n",
      "[1770]\ttraining's rmse: 1.17168\tvalid_1's rmse: 52.5111\n",
      "[1800]\ttraining's rmse: 1.11409\tvalid_1's rmse: 52.5061\n",
      "[1830]\ttraining's rmse: 1.06091\tvalid_1's rmse: 52.5062\n",
      "[1860]\ttraining's rmse: 1.00999\tvalid_1's rmse: 52.5056\n",
      "[1890]\ttraining's rmse: 0.961646\tvalid_1's rmse: 52.5051\n",
      "[1920]\ttraining's rmse: 0.916456\tvalid_1's rmse: 52.5066\n",
      "[1950]\ttraining's rmse: 0.872755\tvalid_1's rmse: 52.5049\n",
      "[1980]\ttraining's rmse: 0.831175\tvalid_1's rmse: 52.5033\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's rmse: 0.804376\tvalid_1's rmse: 52.502\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003301 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 20020\n",
      "[LightGBM] [Info] Number of data points in the train set: 9219, number of used features: 79\n",
      "[LightGBM] [Info] Start training from score 357.747073\n",
      "Training until validation scores don't improve for 125 rounds\n",
      "[30]\ttraining's rmse: 151.47\tvalid_1's rmse: 159.409\n",
      "[60]\ttraining's rmse: 95.339\tvalid_1's rmse: 107.285\n",
      "[90]\ttraining's rmse: 65.1492\tvalid_1's rmse: 81.2214\n",
      "[120]\ttraining's rmse: 48.6303\tvalid_1's rmse: 68.4622\n",
      "[150]\ttraining's rmse: 39.0838\tvalid_1's rmse: 62.3764\n",
      "[180]\ttraining's rmse: 33.2394\tvalid_1's rmse: 59.4176\n",
      "[210]\ttraining's rmse: 29.1336\tvalid_1's rmse: 57.5593\n",
      "[240]\ttraining's rmse: 26.0332\tvalid_1's rmse: 56.2601\n",
      "[270]\ttraining's rmse: 23.5037\tvalid_1's rmse: 55.4454\n",
      "[300]\ttraining's rmse: 21.3393\tvalid_1's rmse: 54.7597\n",
      "[330]\ttraining's rmse: 19.5096\tvalid_1's rmse: 54.3029\n",
      "[360]\ttraining's rmse: 17.945\tvalid_1's rmse: 54.0179\n",
      "[390]\ttraining's rmse: 16.5669\tvalid_1's rmse: 53.7959\n",
      "[420]\ttraining's rmse: 15.3041\tvalid_1's rmse: 53.5311\n",
      "[450]\ttraining's rmse: 14.1726\tvalid_1's rmse: 53.3102\n",
      "[480]\ttraining's rmse: 13.1552\tvalid_1's rmse: 53.172\n",
      "[510]\ttraining's rmse: 12.243\tvalid_1's rmse: 53.0812\n",
      "[540]\ttraining's rmse: 11.4139\tvalid_1's rmse: 52.9723\n",
      "[570]\ttraining's rmse: 10.6557\tvalid_1's rmse: 52.884\n",
      "[600]\ttraining's rmse: 9.95769\tvalid_1's rmse: 52.7834\n",
      "[630]\ttraining's rmse: 9.32294\tvalid_1's rmse: 52.6964\n",
      "[660]\ttraining's rmse: 8.72729\tvalid_1's rmse: 52.6256\n",
      "[690]\ttraining's rmse: 8.18517\tvalid_1's rmse: 52.5641\n",
      "[720]\ttraining's rmse: 7.6762\tvalid_1's rmse: 52.5179\n",
      "[750]\ttraining's rmse: 7.21667\tvalid_1's rmse: 52.4785\n",
      "[780]\ttraining's rmse: 6.78712\tvalid_1's rmse: 52.4496\n",
      "[810]\ttraining's rmse: 6.37405\tvalid_1's rmse: 52.4189\n",
      "[840]\ttraining's rmse: 6.00881\tvalid_1's rmse: 52.3826\n",
      "[870]\ttraining's rmse: 5.6622\tvalid_1's rmse: 52.3702\n",
      "[900]\ttraining's rmse: 5.34669\tvalid_1's rmse: 52.3625\n",
      "[930]\ttraining's rmse: 5.04674\tvalid_1's rmse: 52.3444\n",
      "[960]\ttraining's rmse: 4.76642\tvalid_1's rmse: 52.3215\n",
      "[990]\ttraining's rmse: 4.50688\tvalid_1's rmse: 52.3163\n",
      "[1020]\ttraining's rmse: 4.25722\tvalid_1's rmse: 52.3077\n",
      "[1050]\ttraining's rmse: 4.02364\tvalid_1's rmse: 52.2982\n",
      "[1080]\ttraining's rmse: 3.80876\tvalid_1's rmse: 52.288\n",
      "[1110]\ttraining's rmse: 3.60777\tvalid_1's rmse: 52.2808\n",
      "[1140]\ttraining's rmse: 3.4176\tvalid_1's rmse: 52.2689\n",
      "[1170]\ttraining's rmse: 3.23485\tvalid_1's rmse: 52.2586\n",
      "[1200]\ttraining's rmse: 3.0594\tvalid_1's rmse: 52.2604\n",
      "[1230]\ttraining's rmse: 2.89755\tvalid_1's rmse: 52.2631\n",
      "[1260]\ttraining's rmse: 2.74483\tvalid_1's rmse: 52.2522\n",
      "[1290]\ttraining's rmse: 2.59861\tvalid_1's rmse: 52.2442\n",
      "[1320]\ttraining's rmse: 2.45885\tvalid_1's rmse: 52.2334\n",
      "[1350]\ttraining's rmse: 2.32511\tvalid_1's rmse: 52.2324\n",
      "[1380]\ttraining's rmse: 2.20546\tvalid_1's rmse: 52.2261\n",
      "[1410]\ttraining's rmse: 2.09184\tvalid_1's rmse: 52.2225\n",
      "[1440]\ttraining's rmse: 1.98476\tvalid_1's rmse: 52.2186\n",
      "[1470]\ttraining's rmse: 1.8835\tvalid_1's rmse: 52.215\n",
      "[1500]\ttraining's rmse: 1.78862\tvalid_1's rmse: 52.2114\n",
      "[1530]\ttraining's rmse: 1.70114\tvalid_1's rmse: 52.2069\n",
      "[1560]\ttraining's rmse: 1.61531\tvalid_1's rmse: 52.2059\n",
      "[1590]\ttraining's rmse: 1.53341\tvalid_1's rmse: 52.1996\n",
      "[1620]\ttraining's rmse: 1.45615\tvalid_1's rmse: 52.1986\n",
      "[1650]\ttraining's rmse: 1.38399\tvalid_1's rmse: 52.1964\n",
      "[1680]\ttraining's rmse: 1.31624\tvalid_1's rmse: 52.1988\n",
      "[1710]\ttraining's rmse: 1.25066\tvalid_1's rmse: 52.1959\n",
      "[1740]\ttraining's rmse: 1.18979\tvalid_1's rmse: 52.1936\n",
      "[1770]\ttraining's rmse: 1.13157\tvalid_1's rmse: 52.191\n",
      "[1800]\ttraining's rmse: 1.07679\tvalid_1's rmse: 52.188\n",
      "[1830]\ttraining's rmse: 1.02444\tvalid_1's rmse: 52.189\n",
      "[1860]\ttraining's rmse: 0.97335\tvalid_1's rmse: 52.1871\n",
      "[1890]\ttraining's rmse: 0.925492\tvalid_1's rmse: 52.1863\n",
      "[1920]\ttraining's rmse: 0.881237\tvalid_1's rmse: 52.1864\n",
      "[1950]\ttraining's rmse: 0.839236\tvalid_1's rmse: 52.187\n",
      "[1980]\ttraining's rmse: 0.798727\tvalid_1's rmse: 52.1862\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's rmse: 0.7729\tvalid_1's rmse: 52.1864\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003485 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 20020\n",
      "[LightGBM] [Info] Number of data points in the train set: 9219, number of used features: 79\n",
      "[LightGBM] [Info] Start training from score 354.939235\n",
      "Training until validation scores don't improve for 125 rounds\n",
      "[30]\ttraining's rmse: 152.836\tvalid_1's rmse: 159.545\n",
      "[60]\ttraining's rmse: 96.6533\tvalid_1's rmse: 106.388\n",
      "[90]\ttraining's rmse: 66.2529\tvalid_1's rmse: 80.3392\n",
      "[120]\ttraining's rmse: 49.5442\tvalid_1's rmse: 67.8461\n",
      "[150]\ttraining's rmse: 39.9574\tvalid_1's rmse: 61.9453\n",
      "[180]\ttraining's rmse: 34.0401\tvalid_1's rmse: 58.8931\n",
      "[210]\ttraining's rmse: 29.9346\tvalid_1's rmse: 57.1066\n",
      "[240]\ttraining's rmse: 26.7313\tvalid_1's rmse: 56.0338\n",
      "[270]\ttraining's rmse: 24.133\tvalid_1's rmse: 55.3238\n",
      "[300]\ttraining's rmse: 21.9151\tvalid_1's rmse: 54.7846\n",
      "[330]\ttraining's rmse: 20.0553\tvalid_1's rmse: 54.3657\n",
      "[360]\ttraining's rmse: 18.4473\tvalid_1's rmse: 54.1305\n",
      "[390]\ttraining's rmse: 17.0424\tvalid_1's rmse: 53.9796\n",
      "[420]\ttraining's rmse: 15.7581\tvalid_1's rmse: 53.763\n",
      "[450]\ttraining's rmse: 14.6193\tvalid_1's rmse: 53.6069\n",
      "[480]\ttraining's rmse: 13.5929\tvalid_1's rmse: 53.4681\n",
      "[510]\ttraining's rmse: 12.6658\tvalid_1's rmse: 53.359\n",
      "[540]\ttraining's rmse: 11.8221\tvalid_1's rmse: 53.2766\n",
      "[570]\ttraining's rmse: 11.0508\tvalid_1's rmse: 53.2014\n",
      "[600]\ttraining's rmse: 10.3491\tvalid_1's rmse: 53.1317\n",
      "[630]\ttraining's rmse: 9.70138\tvalid_1's rmse: 53.0624\n",
      "[660]\ttraining's rmse: 9.09688\tvalid_1's rmse: 52.9948\n",
      "[690]\ttraining's rmse: 8.546\tvalid_1's rmse: 52.959\n",
      "[720]\ttraining's rmse: 8.04372\tvalid_1's rmse: 52.9216\n",
      "[750]\ttraining's rmse: 7.5513\tvalid_1's rmse: 52.8861\n",
      "[780]\ttraining's rmse: 7.11843\tvalid_1's rmse: 52.8681\n",
      "[810]\ttraining's rmse: 6.70465\tvalid_1's rmse: 52.8673\n",
      "[840]\ttraining's rmse: 6.33028\tvalid_1's rmse: 52.845\n",
      "[870]\ttraining's rmse: 5.9707\tvalid_1's rmse: 52.8174\n",
      "[900]\ttraining's rmse: 5.65323\tvalid_1's rmse: 52.7987\n",
      "[930]\ttraining's rmse: 5.34605\tvalid_1's rmse: 52.7889\n",
      "[960]\ttraining's rmse: 5.05303\tvalid_1's rmse: 52.7751\n",
      "[990]\ttraining's rmse: 4.78081\tvalid_1's rmse: 52.7574\n",
      "[1020]\ttraining's rmse: 4.5194\tvalid_1's rmse: 52.7518\n",
      "[1050]\ttraining's rmse: 4.27759\tvalid_1's rmse: 52.7351\n",
      "[1080]\ttraining's rmse: 4.04898\tvalid_1's rmse: 52.7127\n",
      "[1110]\ttraining's rmse: 3.83645\tvalid_1's rmse: 52.702\n",
      "[1140]\ttraining's rmse: 3.63235\tvalid_1's rmse: 52.6965\n",
      "[1170]\ttraining's rmse: 3.44498\tvalid_1's rmse: 52.6872\n",
      "[1200]\ttraining's rmse: 3.27027\tvalid_1's rmse: 52.6754\n",
      "[1230]\ttraining's rmse: 3.10419\tvalid_1's rmse: 52.669\n",
      "[1260]\ttraining's rmse: 2.94861\tvalid_1's rmse: 52.6631\n",
      "[1290]\ttraining's rmse: 2.80169\tvalid_1's rmse: 52.6548\n",
      "[1320]\ttraining's rmse: 2.66288\tvalid_1's rmse: 52.6495\n",
      "[1350]\ttraining's rmse: 2.53149\tvalid_1's rmse: 52.6448\n",
      "[1380]\ttraining's rmse: 2.40751\tvalid_1's rmse: 52.6407\n",
      "[1410]\ttraining's rmse: 2.28979\tvalid_1's rmse: 52.6426\n",
      "[1440]\ttraining's rmse: 2.1789\tvalid_1's rmse: 52.637\n",
      "[1470]\ttraining's rmse: 2.07717\tvalid_1's rmse: 52.6327\n",
      "[1500]\ttraining's rmse: 1.9742\tvalid_1's rmse: 52.6273\n",
      "[1530]\ttraining's rmse: 1.88072\tvalid_1's rmse: 52.6219\n",
      "[1560]\ttraining's rmse: 1.78711\tvalid_1's rmse: 52.6186\n",
      "[1590]\ttraining's rmse: 1.7018\tvalid_1's rmse: 52.6178\n",
      "[1620]\ttraining's rmse: 1.62483\tvalid_1's rmse: 52.6127\n",
      "[1650]\ttraining's rmse: 1.55006\tvalid_1's rmse: 52.606\n",
      "[1680]\ttraining's rmse: 1.47789\tvalid_1's rmse: 52.6042\n",
      "[1710]\ttraining's rmse: 1.40775\tvalid_1's rmse: 52.6031\n",
      "[1740]\ttraining's rmse: 1.3437\tvalid_1's rmse: 52.6028\n",
      "[1770]\ttraining's rmse: 1.28466\tvalid_1's rmse: 52.6012\n",
      "[1800]\ttraining's rmse: 1.22649\tvalid_1's rmse: 52.5993\n",
      "[1830]\ttraining's rmse: 1.17102\tvalid_1's rmse: 52.594\n",
      "[1860]\ttraining's rmse: 1.11865\tvalid_1's rmse: 52.5932\n",
      "[1890]\ttraining's rmse: 1.06901\tvalid_1's rmse: 52.5935\n",
      "[1920]\ttraining's rmse: 1.02114\tvalid_1's rmse: 52.5927\n",
      "[1950]\ttraining's rmse: 0.975228\tvalid_1's rmse: 52.5924\n",
      "[1980]\ttraining's rmse: 0.934041\tvalid_1's rmse: 52.5904\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's rmse: 0.906326\tvalid_1's rmse: 52.5892\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003272 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 20020\n",
      "[LightGBM] [Info] Number of data points in the train set: 9219, number of used features: 79\n",
      "[LightGBM] [Info] Start training from score 352.453781\n",
      "Training until validation scores don't improve for 125 rounds\n",
      "[30]\ttraining's rmse: 152.569\tvalid_1's rmse: 157.249\n",
      "[60]\ttraining's rmse: 95.2812\tvalid_1's rmse: 104.542\n",
      "[90]\ttraining's rmse: 64.8195\tvalid_1's rmse: 79.4516\n",
      "[120]\ttraining's rmse: 48.2631\tvalid_1's rmse: 67.9823\n",
      "[150]\ttraining's rmse: 38.8864\tvalid_1's rmse: 62.6748\n",
      "[180]\ttraining's rmse: 33.0875\tvalid_1's rmse: 60.1002\n",
      "[210]\ttraining's rmse: 29.0933\tvalid_1's rmse: 58.5553\n",
      "[240]\ttraining's rmse: 26.014\tvalid_1's rmse: 57.4557\n",
      "[270]\ttraining's rmse: 23.4801\tvalid_1's rmse: 56.734\n",
      "[300]\ttraining's rmse: 21.3568\tvalid_1's rmse: 56.1706\n",
      "[330]\ttraining's rmse: 19.5477\tvalid_1's rmse: 55.8173\n",
      "[360]\ttraining's rmse: 17.9689\tvalid_1's rmse: 55.5435\n",
      "[390]\ttraining's rmse: 16.5395\tvalid_1's rmse: 55.3058\n",
      "[420]\ttraining's rmse: 15.3112\tvalid_1's rmse: 55.1386\n",
      "[450]\ttraining's rmse: 14.1956\tvalid_1's rmse: 54.9622\n",
      "[480]\ttraining's rmse: 13.1908\tvalid_1's rmse: 54.8445\n",
      "[510]\ttraining's rmse: 12.267\tvalid_1's rmse: 54.6935\n",
      "[540]\ttraining's rmse: 11.439\tvalid_1's rmse: 54.581\n",
      "[570]\ttraining's rmse: 10.6918\tvalid_1's rmse: 54.5141\n",
      "[600]\ttraining's rmse: 9.99933\tvalid_1's rmse: 54.4335\n",
      "[630]\ttraining's rmse: 9.36396\tvalid_1's rmse: 54.3543\n",
      "[660]\ttraining's rmse: 8.77038\tvalid_1's rmse: 54.3002\n",
      "[690]\ttraining's rmse: 8.2257\tvalid_1's rmse: 54.2319\n",
      "[720]\ttraining's rmse: 7.72426\tvalid_1's rmse: 54.1904\n",
      "[750]\ttraining's rmse: 7.25438\tvalid_1's rmse: 54.1469\n",
      "[780]\ttraining's rmse: 6.823\tvalid_1's rmse: 54.1153\n",
      "[810]\ttraining's rmse: 6.42384\tvalid_1's rmse: 54.0867\n",
      "[840]\ttraining's rmse: 6.04304\tvalid_1's rmse: 54.0569\n",
      "[870]\ttraining's rmse: 5.69767\tvalid_1's rmse: 54.0379\n",
      "[900]\ttraining's rmse: 5.37698\tvalid_1's rmse: 53.9942\n",
      "[930]\ttraining's rmse: 5.07532\tvalid_1's rmse: 53.9801\n",
      "[960]\ttraining's rmse: 4.79209\tvalid_1's rmse: 53.9637\n",
      "[990]\ttraining's rmse: 4.53162\tvalid_1's rmse: 53.9445\n",
      "[1020]\ttraining's rmse: 4.28851\tvalid_1's rmse: 53.9348\n",
      "[1050]\ttraining's rmse: 4.05826\tvalid_1's rmse: 53.9264\n",
      "[1080]\ttraining's rmse: 3.84146\tvalid_1's rmse: 53.9115\n",
      "[1110]\ttraining's rmse: 3.638\tvalid_1's rmse: 53.9046\n",
      "[1140]\ttraining's rmse: 3.44756\tvalid_1's rmse: 53.8969\n",
      "[1170]\ttraining's rmse: 3.26849\tvalid_1's rmse: 53.8834\n",
      "[1200]\ttraining's rmse: 3.09892\tvalid_1's rmse: 53.874\n",
      "[1230]\ttraining's rmse: 2.93755\tvalid_1's rmse: 53.8736\n",
      "[1260]\ttraining's rmse: 2.78353\tvalid_1's rmse: 53.8665\n",
      "[1290]\ttraining's rmse: 2.6402\tvalid_1's rmse: 53.8594\n",
      "[1320]\ttraining's rmse: 2.50754\tvalid_1's rmse: 53.8534\n",
      "[1350]\ttraining's rmse: 2.38303\tvalid_1's rmse: 53.8453\n",
      "[1380]\ttraining's rmse: 2.26087\tvalid_1's rmse: 53.8427\n",
      "[1410]\ttraining's rmse: 2.14886\tvalid_1's rmse: 53.8365\n",
      "[1440]\ttraining's rmse: 2.04002\tvalid_1's rmse: 53.8297\n",
      "[1470]\ttraining's rmse: 1.93888\tvalid_1's rmse: 53.8271\n",
      "[1500]\ttraining's rmse: 1.84232\tvalid_1's rmse: 53.8233\n",
      "[1530]\ttraining's rmse: 1.75266\tvalid_1's rmse: 53.8182\n",
      "[1560]\ttraining's rmse: 1.66598\tvalid_1's rmse: 53.8167\n",
      "[1590]\ttraining's rmse: 1.58549\tvalid_1's rmse: 53.8107\n",
      "[1620]\ttraining's rmse: 1.50877\tvalid_1's rmse: 53.8094\n",
      "[1650]\ttraining's rmse: 1.43689\tvalid_1's rmse: 53.8079\n",
      "[1680]\ttraining's rmse: 1.36641\tvalid_1's rmse: 53.8047\n",
      "[1710]\ttraining's rmse: 1.30018\tvalid_1's rmse: 53.8048\n",
      "[1740]\ttraining's rmse: 1.23718\tvalid_1's rmse: 53.8039\n",
      "[1770]\ttraining's rmse: 1.17874\tvalid_1's rmse: 53.8013\n",
      "[1800]\ttraining's rmse: 1.12287\tvalid_1's rmse: 53.7979\n",
      "[1830]\ttraining's rmse: 1.0692\tvalid_1's rmse: 53.7953\n",
      "[1860]\ttraining's rmse: 1.01969\tvalid_1's rmse: 53.7944\n",
      "[1890]\ttraining's rmse: 0.972578\tvalid_1's rmse: 53.7921\n",
      "[1920]\ttraining's rmse: 0.926869\tvalid_1's rmse: 53.7918\n",
      "[1950]\ttraining's rmse: 0.88241\tvalid_1's rmse: 53.7897\n",
      "[1980]\ttraining's rmse: 0.842592\tvalid_1's rmse: 53.79\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's rmse: 0.816534\tvalid_1's rmse: 53.7896\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003771 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 20020\n",
      "[LightGBM] [Info] Number of data points in the train set: 9219, number of used features: 79\n",
      "[LightGBM] [Info] Start training from score 357.391145\n",
      "Training until validation scores don't improve for 125 rounds\n",
      "[30]\ttraining's rmse: 152.708\tvalid_1's rmse: 156.901\n",
      "[60]\ttraining's rmse: 95.1157\tvalid_1's rmse: 104.23\n",
      "[90]\ttraining's rmse: 64.1846\tvalid_1's rmse: 78.4566\n",
      "[120]\ttraining's rmse: 47.5419\tvalid_1's rmse: 66.5565\n",
      "[150]\ttraining's rmse: 38.1517\tvalid_1's rmse: 60.8498\n",
      "[180]\ttraining's rmse: 32.4094\tvalid_1's rmse: 58.1292\n",
      "[210]\ttraining's rmse: 28.4508\tvalid_1's rmse: 56.4513\n",
      "[240]\ttraining's rmse: 25.3861\tvalid_1's rmse: 55.408\n",
      "[270]\ttraining's rmse: 22.9148\tvalid_1's rmse: 54.5301\n",
      "[300]\ttraining's rmse: 20.8766\tvalid_1's rmse: 53.9509\n",
      "[330]\ttraining's rmse: 19.0884\tvalid_1's rmse: 53.4804\n",
      "[360]\ttraining's rmse: 17.5668\tvalid_1's rmse: 53.1821\n",
      "[390]\ttraining's rmse: 16.216\tvalid_1's rmse: 52.9057\n",
      "[420]\ttraining's rmse: 15.019\tvalid_1's rmse: 52.7303\n",
      "[450]\ttraining's rmse: 13.9178\tvalid_1's rmse: 52.5671\n",
      "[480]\ttraining's rmse: 12.936\tvalid_1's rmse: 52.4236\n",
      "[510]\ttraining's rmse: 12.0447\tvalid_1's rmse: 52.3484\n",
      "[540]\ttraining's rmse: 11.2492\tvalid_1's rmse: 52.2685\n",
      "[570]\ttraining's rmse: 10.4989\tvalid_1's rmse: 52.1804\n",
      "[600]\ttraining's rmse: 9.82686\tvalid_1's rmse: 52.1082\n",
      "[630]\ttraining's rmse: 9.21416\tvalid_1's rmse: 52.0493\n",
      "[660]\ttraining's rmse: 8.63582\tvalid_1's rmse: 51.987\n",
      "[690]\ttraining's rmse: 8.1049\tvalid_1's rmse: 51.949\n",
      "[720]\ttraining's rmse: 7.60215\tvalid_1's rmse: 51.9079\n",
      "[750]\ttraining's rmse: 7.14819\tvalid_1's rmse: 51.8765\n",
      "[780]\ttraining's rmse: 6.72048\tvalid_1's rmse: 51.8417\n",
      "[810]\ttraining's rmse: 6.32884\tvalid_1's rmse: 51.803\n",
      "[840]\ttraining's rmse: 5.95959\tvalid_1's rmse: 51.7822\n",
      "[870]\ttraining's rmse: 5.60936\tvalid_1's rmse: 51.7688\n",
      "[900]\ttraining's rmse: 5.28646\tvalid_1's rmse: 51.7449\n",
      "[930]\ttraining's rmse: 4.98864\tvalid_1's rmse: 51.7357\n",
      "[960]\ttraining's rmse: 4.70896\tvalid_1's rmse: 51.7142\n",
      "[990]\ttraining's rmse: 4.4443\tvalid_1's rmse: 51.7009\n",
      "[1020]\ttraining's rmse: 4.20049\tvalid_1's rmse: 51.6891\n",
      "[1050]\ttraining's rmse: 3.96466\tvalid_1's rmse: 51.6761\n",
      "[1080]\ttraining's rmse: 3.75026\tvalid_1's rmse: 51.6662\n",
      "[1110]\ttraining's rmse: 3.54505\tvalid_1's rmse: 51.6585\n",
      "[1140]\ttraining's rmse: 3.35522\tvalid_1's rmse: 51.6441\n",
      "[1170]\ttraining's rmse: 3.17766\tvalid_1's rmse: 51.633\n",
      "[1200]\ttraining's rmse: 3.00847\tvalid_1's rmse: 51.6251\n",
      "[1230]\ttraining's rmse: 2.84885\tvalid_1's rmse: 51.6144\n",
      "[1260]\ttraining's rmse: 2.69778\tvalid_1's rmse: 51.6081\n",
      "[1290]\ttraining's rmse: 2.55396\tvalid_1's rmse: 51.6003\n",
      "[1320]\ttraining's rmse: 2.42021\tvalid_1's rmse: 51.5963\n",
      "[1350]\ttraining's rmse: 2.29644\tvalid_1's rmse: 51.5906\n",
      "[1380]\ttraining's rmse: 2.18029\tvalid_1's rmse: 51.5878\n",
      "[1410]\ttraining's rmse: 2.06993\tvalid_1's rmse: 51.5783\n",
      "[1440]\ttraining's rmse: 1.96481\tvalid_1's rmse: 51.572\n",
      "[1470]\ttraining's rmse: 1.86619\tvalid_1's rmse: 51.5662\n",
      "[1500]\ttraining's rmse: 1.77319\tvalid_1's rmse: 51.5623\n",
      "[1530]\ttraining's rmse: 1.68515\tvalid_1's rmse: 51.5618\n",
      "[1560]\ttraining's rmse: 1.59844\tvalid_1's rmse: 51.5564\n",
      "[1590]\ttraining's rmse: 1.52031\tvalid_1's rmse: 51.5527\n",
      "[1620]\ttraining's rmse: 1.44475\tvalid_1's rmse: 51.5514\n",
      "[1650]\ttraining's rmse: 1.37427\tvalid_1's rmse: 51.5511\n",
      "[1680]\ttraining's rmse: 1.30586\tvalid_1's rmse: 51.548\n",
      "[1710]\ttraining's rmse: 1.2415\tvalid_1's rmse: 51.5459\n",
      "[1740]\ttraining's rmse: 1.18071\tvalid_1's rmse: 51.543\n",
      "[1770]\ttraining's rmse: 1.12203\tvalid_1's rmse: 51.5425\n",
      "[1800]\ttraining's rmse: 1.0689\tvalid_1's rmse: 51.5404\n",
      "[1830]\ttraining's rmse: 1.01639\tvalid_1's rmse: 51.5382\n",
      "[1860]\ttraining's rmse: 0.967714\tvalid_1's rmse: 51.5371\n",
      "[1890]\ttraining's rmse: 0.920708\tvalid_1's rmse: 51.5341\n",
      "[1920]\ttraining's rmse: 0.875927\tvalid_1's rmse: 51.532\n",
      "[1950]\ttraining's rmse: 0.835263\tvalid_1's rmse: 51.5305\n",
      "[1980]\ttraining's rmse: 0.795849\tvalid_1's rmse: 51.5285\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's rmse: 0.770159\tvalid_1's rmse: 51.528\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003456 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 20020\n",
      "[LightGBM] [Info] Number of data points in the train set: 9219, number of used features: 79\n",
      "[LightGBM] [Info] Start training from score 367.382886\n",
      "Training until validation scores don't improve for 125 rounds\n",
      "[30]\ttraining's rmse: 155.796\tvalid_1's rmse: 159.179\n",
      "[60]\ttraining's rmse: 97.0826\tvalid_1's rmse: 107.755\n",
      "[90]\ttraining's rmse: 65.2806\tvalid_1's rmse: 82.9061\n",
      "[120]\ttraining's rmse: 48.1843\tvalid_1's rmse: 71.3828\n",
      "[150]\ttraining's rmse: 38.6286\tvalid_1's rmse: 65.8035\n",
      "[180]\ttraining's rmse: 32.7393\tvalid_1's rmse: 62.8692\n",
      "[210]\ttraining's rmse: 28.7189\tvalid_1's rmse: 61.2414\n",
      "[240]\ttraining's rmse: 25.6753\tvalid_1's rmse: 60.0877\n",
      "[270]\ttraining's rmse: 23.1884\tvalid_1's rmse: 59.2458\n",
      "[300]\ttraining's rmse: 21.1224\tvalid_1's rmse: 58.7229\n",
      "[330]\ttraining's rmse: 19.3399\tvalid_1's rmse: 58.252\n",
      "[360]\ttraining's rmse: 17.8079\tvalid_1's rmse: 57.9268\n",
      "[390]\ttraining's rmse: 16.4397\tvalid_1's rmse: 57.7125\n",
      "[420]\ttraining's rmse: 15.218\tvalid_1's rmse: 57.4688\n",
      "[450]\ttraining's rmse: 14.1362\tvalid_1's rmse: 57.3583\n",
      "[480]\ttraining's rmse: 13.149\tvalid_1's rmse: 57.2772\n",
      "[510]\ttraining's rmse: 12.2398\tvalid_1's rmse: 57.1603\n",
      "[540]\ttraining's rmse: 11.4267\tvalid_1's rmse: 57.0618\n",
      "[570]\ttraining's rmse: 10.6738\tvalid_1's rmse: 56.9822\n",
      "[600]\ttraining's rmse: 9.97136\tvalid_1's rmse: 56.9087\n",
      "[630]\ttraining's rmse: 9.33905\tvalid_1's rmse: 56.8637\n",
      "[660]\ttraining's rmse: 8.75466\tvalid_1's rmse: 56.8166\n",
      "[690]\ttraining's rmse: 8.22023\tvalid_1's rmse: 56.7625\n",
      "[720]\ttraining's rmse: 7.71437\tvalid_1's rmse: 56.728\n",
      "[750]\ttraining's rmse: 7.24829\tvalid_1's rmse: 56.6858\n",
      "[780]\ttraining's rmse: 6.81867\tvalid_1's rmse: 56.6516\n",
      "[810]\ttraining's rmse: 6.4215\tvalid_1's rmse: 56.6354\n",
      "[840]\ttraining's rmse: 6.06282\tvalid_1's rmse: 56.5996\n",
      "[870]\ttraining's rmse: 5.71532\tvalid_1's rmse: 56.5849\n",
      "[900]\ttraining's rmse: 5.38881\tvalid_1's rmse: 56.5559\n",
      "[930]\ttraining's rmse: 5.08242\tvalid_1's rmse: 56.533\n",
      "[960]\ttraining's rmse: 4.79989\tvalid_1's rmse: 56.5072\n",
      "[990]\ttraining's rmse: 4.53612\tvalid_1's rmse: 56.4993\n",
      "[1020]\ttraining's rmse: 4.29054\tvalid_1's rmse: 56.4811\n",
      "[1050]\ttraining's rmse: 4.05674\tvalid_1's rmse: 56.4666\n",
      "[1080]\ttraining's rmse: 3.83622\tvalid_1's rmse: 56.454\n",
      "[1110]\ttraining's rmse: 3.62971\tvalid_1's rmse: 56.4391\n",
      "[1140]\ttraining's rmse: 3.43477\tvalid_1's rmse: 56.4235\n",
      "[1170]\ttraining's rmse: 3.25109\tvalid_1's rmse: 56.4149\n",
      "[1200]\ttraining's rmse: 3.07688\tvalid_1's rmse: 56.4069\n",
      "[1230]\ttraining's rmse: 2.91314\tvalid_1's rmse: 56.4015\n",
      "[1260]\ttraining's rmse: 2.75433\tvalid_1's rmse: 56.3912\n",
      "[1290]\ttraining's rmse: 2.61293\tvalid_1's rmse: 56.3828\n",
      "[1320]\ttraining's rmse: 2.47768\tvalid_1's rmse: 56.3779\n",
      "[1350]\ttraining's rmse: 2.35117\tvalid_1's rmse: 56.3665\n",
      "[1380]\ttraining's rmse: 2.23072\tvalid_1's rmse: 56.3659\n",
      "[1410]\ttraining's rmse: 2.11679\tvalid_1's rmse: 56.3607\n",
      "[1440]\ttraining's rmse: 2.01052\tvalid_1's rmse: 56.3542\n",
      "[1470]\ttraining's rmse: 1.90859\tvalid_1's rmse: 56.3489\n",
      "[1500]\ttraining's rmse: 1.81542\tvalid_1's rmse: 56.3413\n",
      "[1530]\ttraining's rmse: 1.72445\tvalid_1's rmse: 56.3375\n",
      "[1560]\ttraining's rmse: 1.63637\tvalid_1's rmse: 56.3331\n",
      "[1590]\ttraining's rmse: 1.5547\tvalid_1's rmse: 56.3308\n",
      "[1620]\ttraining's rmse: 1.47745\tvalid_1's rmse: 56.3264\n",
      "[1650]\ttraining's rmse: 1.406\tvalid_1's rmse: 56.3234\n",
      "[1680]\ttraining's rmse: 1.3379\tvalid_1's rmse: 56.3196\n",
      "[1710]\ttraining's rmse: 1.27228\tvalid_1's rmse: 56.3163\n",
      "[1740]\ttraining's rmse: 1.21104\tvalid_1's rmse: 56.314\n",
      "[1770]\ttraining's rmse: 1.15233\tvalid_1's rmse: 56.3106\n",
      "[1800]\ttraining's rmse: 1.097\tvalid_1's rmse: 56.3081\n",
      "[1830]\ttraining's rmse: 1.04519\tvalid_1's rmse: 56.3059\n",
      "[1860]\ttraining's rmse: 0.995426\tvalid_1's rmse: 56.3042\n",
      "[1890]\ttraining's rmse: 0.948147\tvalid_1's rmse: 56.3008\n",
      "[1920]\ttraining's rmse: 0.903372\tvalid_1's rmse: 56.2988\n",
      "[1950]\ttraining's rmse: 0.859594\tvalid_1's rmse: 56.2983\n",
      "[1980]\ttraining's rmse: 0.820047\tvalid_1's rmse: 56.297\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's rmse: 0.794932\tvalid_1's rmse: 56.2956\n",
      "30\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003448 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 20021\n",
      "[LightGBM] [Info] Number of data points in the train set: 9219, number of used features: 79\n",
      "[LightGBM] [Info] Start training from score 371.212692\n",
      "Training until validation scores don't improve for 125 rounds\n",
      "[30]\ttraining's rmse: 150.286\tvalid_1's rmse: 155.361\n",
      "[60]\ttraining's rmse: 93.5737\tvalid_1's rmse: 102.586\n",
      "[90]\ttraining's rmse: 63.0984\tvalid_1's rmse: 76.7469\n",
      "[120]\ttraining's rmse: 46.759\tvalid_1's rmse: 64.8439\n",
      "[150]\ttraining's rmse: 37.5566\tvalid_1's rmse: 59.11\n",
      "[180]\ttraining's rmse: 31.8225\tvalid_1's rmse: 56.1278\n",
      "[210]\ttraining's rmse: 27.8583\tvalid_1's rmse: 54.3452\n",
      "[240]\ttraining's rmse: 24.7299\tvalid_1's rmse: 53.2307\n",
      "[270]\ttraining's rmse: 22.2752\tvalid_1's rmse: 52.3918\n",
      "[300]\ttraining's rmse: 20.2335\tvalid_1's rmse: 51.737\n",
      "[330]\ttraining's rmse: 18.5172\tvalid_1's rmse: 51.3477\n",
      "[360]\ttraining's rmse: 17.0346\tvalid_1's rmse: 51.0128\n",
      "[390]\ttraining's rmse: 15.7195\tvalid_1's rmse: 50.7677\n",
      "[420]\ttraining's rmse: 14.5589\tvalid_1's rmse: 50.597\n",
      "[450]\ttraining's rmse: 13.527\tvalid_1's rmse: 50.4385\n",
      "[480]\ttraining's rmse: 12.5827\tvalid_1's rmse: 50.2961\n",
      "[510]\ttraining's rmse: 11.7422\tvalid_1's rmse: 50.1976\n",
      "[540]\ttraining's rmse: 10.9761\tvalid_1's rmse: 50.0916\n",
      "[570]\ttraining's rmse: 10.2723\tvalid_1's rmse: 50.0026\n",
      "[600]\ttraining's rmse: 9.63492\tvalid_1's rmse: 49.9231\n",
      "[630]\ttraining's rmse: 9.04518\tvalid_1's rmse: 49.8595\n",
      "[660]\ttraining's rmse: 8.49372\tvalid_1's rmse: 49.7948\n",
      "[690]\ttraining's rmse: 7.96673\tvalid_1's rmse: 49.7539\n",
      "[720]\ttraining's rmse: 7.49368\tvalid_1's rmse: 49.7171\n",
      "[750]\ttraining's rmse: 7.05157\tvalid_1's rmse: 49.6906\n",
      "[780]\ttraining's rmse: 6.64144\tvalid_1's rmse: 49.6719\n",
      "[810]\ttraining's rmse: 6.25864\tvalid_1's rmse: 49.6415\n",
      "[840]\ttraining's rmse: 5.90033\tvalid_1's rmse: 49.6285\n",
      "[870]\ttraining's rmse: 5.57184\tvalid_1's rmse: 49.6034\n",
      "[900]\ttraining's rmse: 5.26411\tvalid_1's rmse: 49.5891\n",
      "[930]\ttraining's rmse: 4.97174\tvalid_1's rmse: 49.5791\n",
      "[960]\ttraining's rmse: 4.6973\tvalid_1's rmse: 49.563\n",
      "[990]\ttraining's rmse: 4.43917\tvalid_1's rmse: 49.5496\n",
      "[1020]\ttraining's rmse: 4.19425\tvalid_1's rmse: 49.5356\n",
      "[1050]\ttraining's rmse: 3.96712\tvalid_1's rmse: 49.5282\n",
      "[1080]\ttraining's rmse: 3.75112\tvalid_1's rmse: 49.5197\n",
      "[1110]\ttraining's rmse: 3.55753\tvalid_1's rmse: 49.5117\n",
      "[1140]\ttraining's rmse: 3.37139\tvalid_1's rmse: 49.5071\n",
      "[1170]\ttraining's rmse: 3.19296\tvalid_1's rmse: 49.4998\n",
      "[1200]\ttraining's rmse: 3.02562\tvalid_1's rmse: 49.4978\n",
      "[1230]\ttraining's rmse: 2.86785\tvalid_1's rmse: 49.493\n",
      "[1260]\ttraining's rmse: 2.71693\tvalid_1's rmse: 49.485\n",
      "[1290]\ttraining's rmse: 2.5751\tvalid_1's rmse: 49.4828\n",
      "[1320]\ttraining's rmse: 2.44342\tvalid_1's rmse: 49.4833\n",
      "[1350]\ttraining's rmse: 2.32136\tvalid_1's rmse: 49.4766\n",
      "[1380]\ttraining's rmse: 2.20194\tvalid_1's rmse: 49.4702\n",
      "[1410]\ttraining's rmse: 2.09368\tvalid_1's rmse: 49.4675\n",
      "[1440]\ttraining's rmse: 1.98907\tvalid_1's rmse: 49.4653\n",
      "[1470]\ttraining's rmse: 1.88992\tvalid_1's rmse: 49.4687\n",
      "[1500]\ttraining's rmse: 1.79541\tvalid_1's rmse: 49.4658\n",
      "[1530]\ttraining's rmse: 1.70734\tvalid_1's rmse: 49.4639\n",
      "[1560]\ttraining's rmse: 1.62274\tvalid_1's rmse: 49.4628\n",
      "[1590]\ttraining's rmse: 1.54212\tvalid_1's rmse: 49.463\n",
      "[1620]\ttraining's rmse: 1.46738\tvalid_1's rmse: 49.4621\n",
      "[1650]\ttraining's rmse: 1.39631\tvalid_1's rmse: 49.4608\n",
      "[1680]\ttraining's rmse: 1.32741\tvalid_1's rmse: 49.4589\n",
      "[1710]\ttraining's rmse: 1.26326\tvalid_1's rmse: 49.4574\n",
      "[1740]\ttraining's rmse: 1.20355\tvalid_1's rmse: 49.4569\n",
      "[1770]\ttraining's rmse: 1.14619\tvalid_1's rmse: 49.4543\n",
      "[1800]\ttraining's rmse: 1.09042\tvalid_1's rmse: 49.4539\n",
      "[1830]\ttraining's rmse: 1.03734\tvalid_1's rmse: 49.4555\n",
      "[1860]\ttraining's rmse: 0.98821\tvalid_1's rmse: 49.4519\n",
      "[1890]\ttraining's rmse: 0.942077\tvalid_1's rmse: 49.4505\n",
      "[1920]\ttraining's rmse: 0.896747\tvalid_1's rmse: 49.4487\n",
      "[1950]\ttraining's rmse: 0.854568\tvalid_1's rmse: 49.4482\n",
      "[1980]\ttraining's rmse: 0.814567\tvalid_1's rmse: 49.4462\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's rmse: 0.789539\tvalid_1's rmse: 49.4451\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002320 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 20021\n",
      "[LightGBM] [Info] Number of data points in the train set: 9219, number of used features: 79\n",
      "[LightGBM] [Info] Start training from score 374.524728\n",
      "Training until validation scores don't improve for 125 rounds\n",
      "[30]\ttraining's rmse: 152.011\tvalid_1's rmse: 166.258\n",
      "[60]\ttraining's rmse: 95.6477\tvalid_1's rmse: 113.901\n",
      "[90]\ttraining's rmse: 65.2689\tvalid_1's rmse: 88.6413\n",
      "[120]\ttraining's rmse: 48.6562\tvalid_1's rmse: 76.2468\n",
      "[150]\ttraining's rmse: 39.1695\tvalid_1's rmse: 70.0847\n",
      "[180]\ttraining's rmse: 33.2465\tvalid_1's rmse: 66.7689\n",
      "[210]\ttraining's rmse: 29.1796\tvalid_1's rmse: 64.9004\n",
      "[240]\ttraining's rmse: 25.991\tvalid_1's rmse: 63.6493\n",
      "[270]\ttraining's rmse: 23.4016\tvalid_1's rmse: 62.7859\n",
      "[300]\ttraining's rmse: 21.2534\tvalid_1's rmse: 62.2179\n",
      "[330]\ttraining's rmse: 19.4339\tvalid_1's rmse: 61.7342\n",
      "[360]\ttraining's rmse: 17.8818\tvalid_1's rmse: 61.3542\n",
      "[390]\ttraining's rmse: 16.5125\tvalid_1's rmse: 61.1164\n",
      "[420]\ttraining's rmse: 15.2941\tvalid_1's rmse: 60.8842\n",
      "[450]\ttraining's rmse: 14.1728\tvalid_1's rmse: 60.6733\n",
      "[480]\ttraining's rmse: 13.1753\tvalid_1's rmse: 60.544\n",
      "[510]\ttraining's rmse: 12.2689\tvalid_1's rmse: 60.4247\n",
      "[540]\ttraining's rmse: 11.4397\tvalid_1's rmse: 60.3713\n",
      "[570]\ttraining's rmse: 10.6944\tvalid_1's rmse: 60.2697\n",
      "[600]\ttraining's rmse: 9.99329\tvalid_1's rmse: 60.157\n",
      "[630]\ttraining's rmse: 9.36814\tvalid_1's rmse: 60.1075\n",
      "[660]\ttraining's rmse: 8.77798\tvalid_1's rmse: 60.062\n",
      "[690]\ttraining's rmse: 8.23959\tvalid_1's rmse: 60.0153\n",
      "[720]\ttraining's rmse: 7.74133\tvalid_1's rmse: 59.9652\n",
      "[750]\ttraining's rmse: 7.27165\tvalid_1's rmse: 59.9312\n",
      "[780]\ttraining's rmse: 6.83751\tvalid_1's rmse: 59.8855\n",
      "[810]\ttraining's rmse: 6.43652\tvalid_1's rmse: 59.8615\n",
      "[840]\ttraining's rmse: 6.0613\tvalid_1's rmse: 59.8267\n",
      "[870]\ttraining's rmse: 5.71308\tvalid_1's rmse: 59.8103\n",
      "[900]\ttraining's rmse: 5.38615\tvalid_1's rmse: 59.7925\n",
      "[930]\ttraining's rmse: 5.0815\tvalid_1's rmse: 59.7835\n",
      "[960]\ttraining's rmse: 4.78445\tvalid_1's rmse: 59.7518\n",
      "[990]\ttraining's rmse: 4.51783\tvalid_1's rmse: 59.7449\n",
      "[1020]\ttraining's rmse: 4.27166\tvalid_1's rmse: 59.7292\n",
      "[1050]\ttraining's rmse: 4.03743\tvalid_1's rmse: 59.7124\n",
      "[1080]\ttraining's rmse: 3.81764\tvalid_1's rmse: 59.7006\n",
      "[1110]\ttraining's rmse: 3.61129\tvalid_1's rmse: 59.6894\n",
      "[1140]\ttraining's rmse: 3.42132\tvalid_1's rmse: 59.6802\n",
      "[1170]\ttraining's rmse: 3.24209\tvalid_1's rmse: 59.6628\n",
      "[1200]\ttraining's rmse: 3.07082\tvalid_1's rmse: 59.6588\n",
      "[1230]\ttraining's rmse: 2.90964\tvalid_1's rmse: 59.6547\n",
      "[1260]\ttraining's rmse: 2.75413\tvalid_1's rmse: 59.6451\n",
      "[1290]\ttraining's rmse: 2.61097\tvalid_1's rmse: 59.6392\n",
      "[1320]\ttraining's rmse: 2.47488\tvalid_1's rmse: 59.6326\n",
      "[1350]\ttraining's rmse: 2.34824\tvalid_1's rmse: 59.6316\n",
      "[1380]\ttraining's rmse: 2.23243\tvalid_1's rmse: 59.6278\n",
      "[1410]\ttraining's rmse: 2.11872\tvalid_1's rmse: 59.623\n",
      "[1440]\ttraining's rmse: 2.01258\tvalid_1's rmse: 59.6211\n",
      "[1470]\ttraining's rmse: 1.91275\tvalid_1's rmse: 59.6156\n",
      "[1500]\ttraining's rmse: 1.81798\tvalid_1's rmse: 59.6142\n",
      "[1530]\ttraining's rmse: 1.72692\tvalid_1's rmse: 59.6126\n",
      "[1560]\ttraining's rmse: 1.64083\tvalid_1's rmse: 59.6079\n",
      "[1590]\ttraining's rmse: 1.56021\tvalid_1's rmse: 59.604\n",
      "[1620]\ttraining's rmse: 1.48324\tvalid_1's rmse: 59.6013\n",
      "[1650]\ttraining's rmse: 1.41024\tvalid_1's rmse: 59.599\n",
      "[1680]\ttraining's rmse: 1.34197\tvalid_1's rmse: 59.598\n",
      "[1710]\ttraining's rmse: 1.27398\tvalid_1's rmse: 59.5954\n",
      "[1740]\ttraining's rmse: 1.21235\tvalid_1's rmse: 59.5926\n",
      "[1770]\ttraining's rmse: 1.15441\tvalid_1's rmse: 59.5911\n",
      "[1800]\ttraining's rmse: 1.09997\tvalid_1's rmse: 59.5902\n",
      "[1830]\ttraining's rmse: 1.04741\tvalid_1's rmse: 59.5881\n",
      "[1860]\ttraining's rmse: 0.997828\tvalid_1's rmse: 59.5887\n",
      "[1890]\ttraining's rmse: 0.950152\tvalid_1's rmse: 59.5879\n",
      "[1920]\ttraining's rmse: 0.904806\tvalid_1's rmse: 59.5874\n",
      "[1950]\ttraining's rmse: 0.8619\tvalid_1's rmse: 59.5864\n",
      "[1980]\ttraining's rmse: 0.820091\tvalid_1's rmse: 59.5854\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's rmse: 0.793581\tvalid_1's rmse: 59.5835\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002386 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 20021\n",
      "[LightGBM] [Info] Number of data points in the train set: 9219, number of used features: 79\n",
      "[LightGBM] [Info] Start training from score 369.377868\n",
      "Training until validation scores don't improve for 125 rounds\n",
      "[30]\ttraining's rmse: 154.765\tvalid_1's rmse: 161.509\n",
      "[60]\ttraining's rmse: 97.9428\tvalid_1's rmse: 109.303\n",
      "[90]\ttraining's rmse: 67.0282\tvalid_1's rmse: 83.0898\n",
      "[120]\ttraining's rmse: 50.0893\tvalid_1's rmse: 70.3254\n",
      "[150]\ttraining's rmse: 40.4116\tvalid_1's rmse: 63.9832\n",
      "[180]\ttraining's rmse: 34.4133\tvalid_1's rmse: 60.669\n",
      "[210]\ttraining's rmse: 30.2272\tvalid_1's rmse: 58.7342\n",
      "[240]\ttraining's rmse: 26.9705\tvalid_1's rmse: 57.598\n",
      "[270]\ttraining's rmse: 24.3026\tvalid_1's rmse: 56.8101\n",
      "[300]\ttraining's rmse: 22.0462\tvalid_1's rmse: 56.24\n",
      "[330]\ttraining's rmse: 20.1868\tvalid_1's rmse: 55.8832\n",
      "[360]\ttraining's rmse: 18.5411\tvalid_1's rmse: 55.5515\n",
      "[390]\ttraining's rmse: 17.0788\tvalid_1's rmse: 55.2773\n",
      "[420]\ttraining's rmse: 15.7973\tvalid_1's rmse: 55.0673\n",
      "[450]\ttraining's rmse: 14.6739\tvalid_1's rmse: 54.9184\n",
      "[480]\ttraining's rmse: 13.6521\tvalid_1's rmse: 54.793\n",
      "[510]\ttraining's rmse: 12.7252\tvalid_1's rmse: 54.673\n",
      "[540]\ttraining's rmse: 11.8842\tvalid_1's rmse: 54.5769\n",
      "[570]\ttraining's rmse: 11.1082\tvalid_1's rmse: 54.49\n",
      "[600]\ttraining's rmse: 10.4005\tvalid_1's rmse: 54.4198\n",
      "[630]\ttraining's rmse: 9.73607\tvalid_1's rmse: 54.3729\n",
      "[660]\ttraining's rmse: 9.12819\tvalid_1's rmse: 54.3135\n",
      "[690]\ttraining's rmse: 8.56022\tvalid_1's rmse: 54.2741\n",
      "[720]\ttraining's rmse: 8.04078\tvalid_1's rmse: 54.235\n",
      "[750]\ttraining's rmse: 7.56141\tvalid_1's rmse: 54.1862\n",
      "[780]\ttraining's rmse: 7.10856\tvalid_1's rmse: 54.1519\n",
      "[810]\ttraining's rmse: 6.68344\tvalid_1's rmse: 54.1263\n",
      "[840]\ttraining's rmse: 6.29095\tvalid_1's rmse: 54.0805\n",
      "[870]\ttraining's rmse: 5.9297\tvalid_1's rmse: 54.0551\n",
      "[900]\ttraining's rmse: 5.59146\tvalid_1's rmse: 54.0205\n",
      "[930]\ttraining's rmse: 5.2799\tvalid_1's rmse: 53.9999\n",
      "[960]\ttraining's rmse: 4.97584\tvalid_1's rmse: 53.979\n",
      "[990]\ttraining's rmse: 4.69905\tvalid_1's rmse: 53.9648\n",
      "[1020]\ttraining's rmse: 4.43375\tvalid_1's rmse: 53.9505\n",
      "[1050]\ttraining's rmse: 4.18844\tvalid_1's rmse: 53.9407\n",
      "[1080]\ttraining's rmse: 3.96561\tvalid_1's rmse: 53.9249\n",
      "[1110]\ttraining's rmse: 3.75302\tvalid_1's rmse: 53.91\n",
      "[1140]\ttraining's rmse: 3.55399\tvalid_1's rmse: 53.9035\n",
      "[1170]\ttraining's rmse: 3.36454\tvalid_1's rmse: 53.8975\n",
      "[1200]\ttraining's rmse: 3.18493\tvalid_1's rmse: 53.8933\n",
      "[1230]\ttraining's rmse: 3.01629\tvalid_1's rmse: 53.8843\n",
      "[1260]\ttraining's rmse: 2.85863\tvalid_1's rmse: 53.8792\n",
      "[1290]\ttraining's rmse: 2.70916\tvalid_1's rmse: 53.8795\n",
      "[1320]\ttraining's rmse: 2.56505\tvalid_1's rmse: 53.8709\n",
      "[1350]\ttraining's rmse: 2.43633\tvalid_1's rmse: 53.8687\n",
      "[1380]\ttraining's rmse: 2.31208\tvalid_1's rmse: 53.8661\n",
      "[1410]\ttraining's rmse: 2.19552\tvalid_1's rmse: 53.8607\n",
      "[1440]\ttraining's rmse: 2.08554\tvalid_1's rmse: 53.8531\n",
      "[1470]\ttraining's rmse: 1.98002\tvalid_1's rmse: 53.8473\n",
      "[1500]\ttraining's rmse: 1.88244\tvalid_1's rmse: 53.8423\n",
      "[1530]\ttraining's rmse: 1.78795\tvalid_1's rmse: 53.8422\n",
      "[1560]\ttraining's rmse: 1.69929\tvalid_1's rmse: 53.842\n",
      "[1590]\ttraining's rmse: 1.61435\tvalid_1's rmse: 53.8383\n",
      "[1620]\ttraining's rmse: 1.53469\tvalid_1's rmse: 53.8346\n",
      "[1650]\ttraining's rmse: 1.46319\tvalid_1's rmse: 53.8321\n",
      "[1680]\ttraining's rmse: 1.38976\tvalid_1's rmse: 53.8276\n",
      "[1710]\ttraining's rmse: 1.32313\tvalid_1's rmse: 53.8246\n",
      "[1740]\ttraining's rmse: 1.25949\tvalid_1's rmse: 53.8231\n",
      "[1770]\ttraining's rmse: 1.19822\tvalid_1's rmse: 53.8225\n",
      "[1800]\ttraining's rmse: 1.1396\tvalid_1's rmse: 53.8201\n",
      "[1830]\ttraining's rmse: 1.08551\tvalid_1's rmse: 53.8172\n",
      "[1860]\ttraining's rmse: 1.03291\tvalid_1's rmse: 53.8164\n",
      "[1890]\ttraining's rmse: 0.98303\tvalid_1's rmse: 53.8135\n",
      "[1920]\ttraining's rmse: 0.937062\tvalid_1's rmse: 53.8122\n",
      "[1950]\ttraining's rmse: 0.893712\tvalid_1's rmse: 53.8106\n",
      "[1980]\ttraining's rmse: 0.85125\tvalid_1's rmse: 53.8101\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's rmse: 0.824801\tvalid_1's rmse: 53.8096\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003077 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 20021\n",
      "[LightGBM] [Info] Number of data points in the train set: 9219, number of used features: 79\n",
      "[LightGBM] [Info] Start training from score 363.290863\n",
      "Training until validation scores don't improve for 125 rounds\n",
      "[30]\ttraining's rmse: 153.665\tvalid_1's rmse: 155.869\n",
      "[60]\ttraining's rmse: 97.0983\tvalid_1's rmse: 106.35\n",
      "[90]\ttraining's rmse: 66.7194\tvalid_1's rmse: 82.5227\n",
      "[120]\ttraining's rmse: 49.9521\tvalid_1's rmse: 71.327\n",
      "[150]\ttraining's rmse: 40.3338\tvalid_1's rmse: 65.9796\n",
      "[180]\ttraining's rmse: 34.2442\tvalid_1's rmse: 63.3199\n",
      "[210]\ttraining's rmse: 30.0336\tvalid_1's rmse: 61.671\n",
      "[240]\ttraining's rmse: 26.8158\tvalid_1's rmse: 60.5687\n",
      "[270]\ttraining's rmse: 24.1969\tvalid_1's rmse: 59.7933\n",
      "[300]\ttraining's rmse: 21.9687\tvalid_1's rmse: 59.1755\n",
      "[330]\ttraining's rmse: 20.0826\tvalid_1's rmse: 58.802\n",
      "[360]\ttraining's rmse: 18.4474\tvalid_1's rmse: 58.4406\n",
      "[390]\ttraining's rmse: 17.0136\tvalid_1's rmse: 58.1598\n",
      "[420]\ttraining's rmse: 15.6964\tvalid_1's rmse: 57.9348\n",
      "[450]\ttraining's rmse: 14.5554\tvalid_1's rmse: 57.7376\n",
      "[480]\ttraining's rmse: 13.5036\tvalid_1's rmse: 57.5625\n",
      "[510]\ttraining's rmse: 12.5867\tvalid_1's rmse: 57.4301\n",
      "[540]\ttraining's rmse: 11.7182\tvalid_1's rmse: 57.3404\n",
      "[570]\ttraining's rmse: 10.9367\tvalid_1's rmse: 57.2318\n",
      "[600]\ttraining's rmse: 10.2333\tvalid_1's rmse: 57.1451\n",
      "[630]\ttraining's rmse: 9.58359\tvalid_1's rmse: 57.0883\n",
      "[660]\ttraining's rmse: 8.98505\tvalid_1's rmse: 57.0172\n",
      "[690]\ttraining's rmse: 8.43148\tvalid_1's rmse: 56.9577\n",
      "[720]\ttraining's rmse: 7.91541\tvalid_1's rmse: 56.9139\n",
      "[750]\ttraining's rmse: 7.43205\tvalid_1's rmse: 56.8572\n",
      "[780]\ttraining's rmse: 6.99554\tvalid_1's rmse: 56.832\n",
      "[810]\ttraining's rmse: 6.58605\tvalid_1's rmse: 56.82\n",
      "[840]\ttraining's rmse: 6.19383\tvalid_1's rmse: 56.774\n",
      "[870]\ttraining's rmse: 5.83194\tvalid_1's rmse: 56.7526\n",
      "[900]\ttraining's rmse: 5.49861\tvalid_1's rmse: 56.7264\n",
      "[930]\ttraining's rmse: 5.18959\tvalid_1's rmse: 56.7094\n",
      "[960]\ttraining's rmse: 4.89378\tvalid_1's rmse: 56.6996\n",
      "[990]\ttraining's rmse: 4.62642\tvalid_1's rmse: 56.6938\n",
      "[1020]\ttraining's rmse: 4.37243\tvalid_1's rmse: 56.6725\n",
      "[1050]\ttraining's rmse: 4.1371\tvalid_1's rmse: 56.6587\n",
      "[1080]\ttraining's rmse: 3.91074\tvalid_1's rmse: 56.6554\n",
      "[1110]\ttraining's rmse: 3.7001\tvalid_1's rmse: 56.6413\n",
      "[1140]\ttraining's rmse: 3.49989\tvalid_1's rmse: 56.6236\n",
      "[1170]\ttraining's rmse: 3.31094\tvalid_1's rmse: 56.6113\n",
      "[1200]\ttraining's rmse: 3.13623\tvalid_1's rmse: 56.6017\n",
      "[1230]\ttraining's rmse: 2.97258\tvalid_1's rmse: 56.5932\n",
      "[1260]\ttraining's rmse: 2.81692\tvalid_1's rmse: 56.5898\n",
      "[1290]\ttraining's rmse: 2.6705\tvalid_1's rmse: 56.5875\n",
      "[1320]\ttraining's rmse: 2.53128\tvalid_1's rmse: 56.5903\n",
      "[1350]\ttraining's rmse: 2.40083\tvalid_1's rmse: 56.5827\n",
      "[1380]\ttraining's rmse: 2.27677\tvalid_1's rmse: 56.5756\n",
      "[1410]\ttraining's rmse: 2.16149\tvalid_1's rmse: 56.5723\n",
      "[1440]\ttraining's rmse: 2.04998\tvalid_1's rmse: 56.5691\n",
      "[1470]\ttraining's rmse: 1.94573\tvalid_1's rmse: 56.5622\n",
      "[1500]\ttraining's rmse: 1.84581\tvalid_1's rmse: 56.559\n",
      "[1530]\ttraining's rmse: 1.75104\tvalid_1's rmse: 56.5554\n",
      "[1560]\ttraining's rmse: 1.66463\tvalid_1's rmse: 56.5515\n",
      "[1590]\ttraining's rmse: 1.58215\tvalid_1's rmse: 56.5446\n",
      "[1620]\ttraining's rmse: 1.5053\tvalid_1's rmse: 56.5425\n",
      "[1650]\ttraining's rmse: 1.42949\tvalid_1's rmse: 56.5406\n",
      "[1680]\ttraining's rmse: 1.35909\tvalid_1's rmse: 56.5423\n",
      "[1710]\ttraining's rmse: 1.29247\tvalid_1's rmse: 56.5404\n",
      "[1740]\ttraining's rmse: 1.22794\tvalid_1's rmse: 56.5394\n",
      "[1770]\ttraining's rmse: 1.16658\tvalid_1's rmse: 56.5398\n",
      "[1800]\ttraining's rmse: 1.10978\tvalid_1's rmse: 56.5377\n",
      "[1830]\ttraining's rmse: 1.05517\tvalid_1's rmse: 56.5363\n",
      "[1860]\ttraining's rmse: 1.00489\tvalid_1's rmse: 56.5353\n",
      "[1890]\ttraining's rmse: 0.955841\tvalid_1's rmse: 56.5325\n",
      "[1920]\ttraining's rmse: 0.911005\tvalid_1's rmse: 56.5303\n",
      "[1950]\ttraining's rmse: 0.866568\tvalid_1's rmse: 56.53\n",
      "[1980]\ttraining's rmse: 0.825132\tvalid_1's rmse: 56.529\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's rmse: 0.798181\tvalid_1's rmse: 56.5283\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003509 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 20021\n",
      "[LightGBM] [Info] Number of data points in the train set: 9219, number of used features: 79\n",
      "[LightGBM] [Info] Start training from score 357.747073\n",
      "Training until validation scores don't improve for 125 rounds\n",
      "[30]\ttraining's rmse: 151.055\tvalid_1's rmse: 158.584\n",
      "[60]\ttraining's rmse: 94.8526\tvalid_1's rmse: 106.431\n",
      "[90]\ttraining's rmse: 64.9446\tvalid_1's rmse: 81.041\n",
      "[120]\ttraining's rmse: 48.5711\tvalid_1's rmse: 68.844\n",
      "[150]\ttraining's rmse: 39.0812\tvalid_1's rmse: 62.7326\n",
      "[180]\ttraining's rmse: 33.2842\tvalid_1's rmse: 59.8203\n",
      "[210]\ttraining's rmse: 29.2401\tvalid_1's rmse: 58.1087\n",
      "[240]\ttraining's rmse: 26.1248\tvalid_1's rmse: 56.9658\n",
      "[270]\ttraining's rmse: 23.5869\tvalid_1's rmse: 56.1099\n",
      "[300]\ttraining's rmse: 21.4548\tvalid_1's rmse: 55.4502\n",
      "[330]\ttraining's rmse: 19.6799\tvalid_1's rmse: 55.0282\n",
      "[360]\ttraining's rmse: 18.0922\tvalid_1's rmse: 54.6451\n",
      "[390]\ttraining's rmse: 16.7003\tvalid_1's rmse: 54.3267\n",
      "[420]\ttraining's rmse: 15.4548\tvalid_1's rmse: 54.0938\n",
      "[450]\ttraining's rmse: 14.3264\tvalid_1's rmse: 53.8812\n",
      "[480]\ttraining's rmse: 13.322\tvalid_1's rmse: 53.7195\n",
      "[510]\ttraining's rmse: 12.4035\tvalid_1's rmse: 53.6227\n",
      "[540]\ttraining's rmse: 11.5753\tvalid_1's rmse: 53.4854\n",
      "[570]\ttraining's rmse: 10.82\tvalid_1's rmse: 53.4116\n",
      "[600]\ttraining's rmse: 10.1142\tvalid_1's rmse: 53.2997\n",
      "[630]\ttraining's rmse: 9.48604\tvalid_1's rmse: 53.2308\n",
      "[660]\ttraining's rmse: 8.88803\tvalid_1's rmse: 53.1628\n",
      "[690]\ttraining's rmse: 8.33495\tvalid_1's rmse: 53.1114\n",
      "[720]\ttraining's rmse: 7.81606\tvalid_1's rmse: 53.0629\n",
      "[750]\ttraining's rmse: 7.34731\tvalid_1's rmse: 53.0274\n",
      "[780]\ttraining's rmse: 6.91641\tvalid_1's rmse: 52.9862\n",
      "[810]\ttraining's rmse: 6.51442\tvalid_1's rmse: 52.9613\n",
      "[840]\ttraining's rmse: 6.13389\tvalid_1's rmse: 52.9465\n",
      "[870]\ttraining's rmse: 5.78774\tvalid_1's rmse: 52.921\n",
      "[900]\ttraining's rmse: 5.45831\tvalid_1's rmse: 52.9023\n",
      "[930]\ttraining's rmse: 5.15412\tvalid_1's rmse: 52.8685\n",
      "[960]\ttraining's rmse: 4.86644\tvalid_1's rmse: 52.8515\n",
      "[990]\ttraining's rmse: 4.59631\tvalid_1's rmse: 52.8383\n",
      "[1020]\ttraining's rmse: 4.34155\tvalid_1's rmse: 52.8151\n",
      "[1050]\ttraining's rmse: 4.10398\tvalid_1's rmse: 52.8024\n",
      "[1080]\ttraining's rmse: 3.88346\tvalid_1's rmse: 52.7813\n",
      "[1110]\ttraining's rmse: 3.6788\tvalid_1's rmse: 52.7637\n",
      "[1140]\ttraining's rmse: 3.47947\tvalid_1's rmse: 52.7453\n",
      "[1170]\ttraining's rmse: 3.29697\tvalid_1's rmse: 52.7386\n",
      "[1200]\ttraining's rmse: 3.11919\tvalid_1's rmse: 52.7312\n",
      "[1230]\ttraining's rmse: 2.9589\tvalid_1's rmse: 52.7273\n",
      "[1260]\ttraining's rmse: 2.80298\tvalid_1's rmse: 52.7129\n",
      "[1290]\ttraining's rmse: 2.66075\tvalid_1's rmse: 52.7037\n",
      "[1320]\ttraining's rmse: 2.51567\tvalid_1's rmse: 52.691\n",
      "[1350]\ttraining's rmse: 2.38263\tvalid_1's rmse: 52.6845\n",
      "[1380]\ttraining's rmse: 2.25803\tvalid_1's rmse: 52.6829\n",
      "[1410]\ttraining's rmse: 2.14423\tvalid_1's rmse: 52.6832\n",
      "[1440]\ttraining's rmse: 2.03646\tvalid_1's rmse: 52.6787\n",
      "[1470]\ttraining's rmse: 1.93459\tvalid_1's rmse: 52.6729\n",
      "[1500]\ttraining's rmse: 1.83677\tvalid_1's rmse: 52.6714\n",
      "[1530]\ttraining's rmse: 1.74409\tvalid_1's rmse: 52.6683\n",
      "[1560]\ttraining's rmse: 1.65587\tvalid_1's rmse: 52.6651\n",
      "[1590]\ttraining's rmse: 1.57187\tvalid_1's rmse: 52.6589\n",
      "[1620]\ttraining's rmse: 1.49353\tvalid_1's rmse: 52.6563\n",
      "[1650]\ttraining's rmse: 1.42049\tvalid_1's rmse: 52.6525\n",
      "[1680]\ttraining's rmse: 1.35094\tvalid_1's rmse: 52.6476\n",
      "[1710]\ttraining's rmse: 1.2835\tvalid_1's rmse: 52.6468\n",
      "[1740]\ttraining's rmse: 1.21983\tvalid_1's rmse: 52.641\n",
      "[1770]\ttraining's rmse: 1.1595\tvalid_1's rmse: 52.6379\n",
      "[1800]\ttraining's rmse: 1.10296\tvalid_1's rmse: 52.636\n",
      "[1830]\ttraining's rmse: 1.04974\tvalid_1's rmse: 52.6356\n",
      "[1860]\ttraining's rmse: 0.998875\tvalid_1's rmse: 52.6334\n",
      "[1890]\ttraining's rmse: 0.949685\tvalid_1's rmse: 52.6326\n",
      "[1920]\ttraining's rmse: 0.903781\tvalid_1's rmse: 52.6284\n",
      "[1950]\ttraining's rmse: 0.861098\tvalid_1's rmse: 52.6278\n",
      "[1980]\ttraining's rmse: 0.819651\tvalid_1's rmse: 52.6267\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's rmse: 0.792925\tvalid_1's rmse: 52.6266\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003822 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 20021\n",
      "[LightGBM] [Info] Number of data points in the train set: 9219, number of used features: 79\n",
      "[LightGBM] [Info] Start training from score 354.939235\n",
      "Training until validation scores don't improve for 125 rounds\n",
      "[30]\ttraining's rmse: 152.075\tvalid_1's rmse: 158.329\n",
      "[60]\ttraining's rmse: 95.0385\tvalid_1's rmse: 104.754\n",
      "[90]\ttraining's rmse: 64.5541\tvalid_1's rmse: 78.7356\n",
      "[120]\ttraining's rmse: 47.8814\tvalid_1's rmse: 66.4239\n",
      "[150]\ttraining's rmse: 38.5073\tvalid_1's rmse: 60.588\n",
      "[180]\ttraining's rmse: 32.7693\tvalid_1's rmse: 57.7181\n",
      "[210]\ttraining's rmse: 28.8026\tvalid_1's rmse: 56.0721\n",
      "[240]\ttraining's rmse: 25.7398\tvalid_1's rmse: 54.973\n",
      "[270]\ttraining's rmse: 23.2192\tvalid_1's rmse: 54.1916\n",
      "[300]\ttraining's rmse: 21.1021\tvalid_1's rmse: 53.6849\n",
      "[330]\ttraining's rmse: 19.3058\tvalid_1's rmse: 53.2424\n",
      "[360]\ttraining's rmse: 17.7568\tvalid_1's rmse: 52.9664\n",
      "[390]\ttraining's rmse: 16.3784\tvalid_1's rmse: 52.7136\n",
      "[420]\ttraining's rmse: 15.1668\tvalid_1's rmse: 52.4993\n",
      "[450]\ttraining's rmse: 14.0423\tvalid_1's rmse: 52.3698\n",
      "[480]\ttraining's rmse: 13.0378\tvalid_1's rmse: 52.23\n",
      "[510]\ttraining's rmse: 12.1286\tvalid_1's rmse: 52.1051\n",
      "[540]\ttraining's rmse: 11.3005\tvalid_1's rmse: 52.0267\n",
      "[570]\ttraining's rmse: 10.5569\tvalid_1's rmse: 51.9539\n",
      "[600]\ttraining's rmse: 9.86519\tvalid_1's rmse: 51.9049\n",
      "[630]\ttraining's rmse: 9.22641\tvalid_1's rmse: 51.8292\n",
      "[660]\ttraining's rmse: 8.6441\tvalid_1's rmse: 51.7924\n",
      "[690]\ttraining's rmse: 8.10014\tvalid_1's rmse: 51.7296\n",
      "[720]\ttraining's rmse: 7.59255\tvalid_1's rmse: 51.6759\n",
      "[750]\ttraining's rmse: 7.13787\tvalid_1's rmse: 51.6572\n",
      "[780]\ttraining's rmse: 6.70151\tvalid_1's rmse: 51.6359\n",
      "[810]\ttraining's rmse: 6.31124\tvalid_1's rmse: 51.5902\n",
      "[840]\ttraining's rmse: 5.93333\tvalid_1's rmse: 51.5643\n",
      "[870]\ttraining's rmse: 5.58923\tvalid_1's rmse: 51.5462\n",
      "[900]\ttraining's rmse: 5.27116\tvalid_1's rmse: 51.5342\n",
      "[930]\ttraining's rmse: 4.97046\tvalid_1's rmse: 51.5224\n",
      "[960]\ttraining's rmse: 4.68472\tvalid_1's rmse: 51.5114\n",
      "[990]\ttraining's rmse: 4.4262\tvalid_1's rmse: 51.5125\n",
      "[1020]\ttraining's rmse: 4.17877\tvalid_1's rmse: 51.5009\n",
      "[1050]\ttraining's rmse: 3.95038\tvalid_1's rmse: 51.4863\n",
      "[1080]\ttraining's rmse: 3.72761\tvalid_1's rmse: 51.471\n",
      "[1110]\ttraining's rmse: 3.5196\tvalid_1's rmse: 51.465\n",
      "[1140]\ttraining's rmse: 3.32797\tvalid_1's rmse: 51.456\n",
      "[1170]\ttraining's rmse: 3.15155\tvalid_1's rmse: 51.4529\n",
      "[1200]\ttraining's rmse: 2.98188\tvalid_1's rmse: 51.4511\n",
      "[1230]\ttraining's rmse: 2.81934\tvalid_1's rmse: 51.4471\n",
      "[1260]\ttraining's rmse: 2.67144\tvalid_1's rmse: 51.4467\n",
      "[1290]\ttraining's rmse: 2.53041\tvalid_1's rmse: 51.4383\n",
      "[1320]\ttraining's rmse: 2.39759\tvalid_1's rmse: 51.4298\n",
      "[1350]\ttraining's rmse: 2.2732\tvalid_1's rmse: 51.4253\n",
      "[1380]\ttraining's rmse: 2.15628\tvalid_1's rmse: 51.4217\n",
      "[1410]\ttraining's rmse: 2.04562\tvalid_1's rmse: 51.4163\n",
      "[1440]\ttraining's rmse: 1.9378\tvalid_1's rmse: 51.4151\n",
      "[1470]\ttraining's rmse: 1.83788\tvalid_1's rmse: 51.4132\n",
      "[1500]\ttraining's rmse: 1.74479\tvalid_1's rmse: 51.4075\n",
      "[1530]\ttraining's rmse: 1.65729\tvalid_1's rmse: 51.4071\n",
      "[1560]\ttraining's rmse: 1.57344\tvalid_1's rmse: 51.4049\n",
      "[1590]\ttraining's rmse: 1.49386\tvalid_1's rmse: 51.4042\n",
      "[1620]\ttraining's rmse: 1.41894\tvalid_1's rmse: 51.4007\n",
      "[1650]\ttraining's rmse: 1.34713\tvalid_1's rmse: 51.4\n",
      "[1680]\ttraining's rmse: 1.27804\tvalid_1's rmse: 51.3982\n",
      "[1710]\ttraining's rmse: 1.21534\tvalid_1's rmse: 51.3969\n",
      "[1740]\ttraining's rmse: 1.1555\tvalid_1's rmse: 51.3949\n",
      "[1770]\ttraining's rmse: 1.09887\tvalid_1's rmse: 51.3922\n",
      "[1800]\ttraining's rmse: 1.04501\tvalid_1's rmse: 51.3906\n",
      "[1830]\ttraining's rmse: 0.993086\tvalid_1's rmse: 51.3889\n",
      "[1860]\ttraining's rmse: 0.944843\tvalid_1's rmse: 51.3889\n",
      "[1890]\ttraining's rmse: 0.899078\tvalid_1's rmse: 51.3866\n",
      "[1920]\ttraining's rmse: 0.856824\tvalid_1's rmse: 51.3863\n",
      "[1950]\ttraining's rmse: 0.816893\tvalid_1's rmse: 51.3847\n",
      "[1980]\ttraining's rmse: 0.777686\tvalid_1's rmse: 51.3838\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's rmse: 0.752494\tvalid_1's rmse: 51.3834\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003664 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 20021\n",
      "[LightGBM] [Info] Number of data points in the train set: 9219, number of used features: 79\n",
      "[LightGBM] [Info] Start training from score 352.453781\n",
      "Training until validation scores don't improve for 125 rounds\n",
      "[30]\ttraining's rmse: 152.684\tvalid_1's rmse: 157.468\n",
      "[60]\ttraining's rmse: 95.5086\tvalid_1's rmse: 104.709\n",
      "[90]\ttraining's rmse: 64.6813\tvalid_1's rmse: 79.0772\n",
      "[120]\ttraining's rmse: 48.0335\tvalid_1's rmse: 67.4917\n",
      "[150]\ttraining's rmse: 38.6911\tvalid_1's rmse: 62.2885\n",
      "[180]\ttraining's rmse: 32.9469\tvalid_1's rmse: 59.7316\n",
      "[210]\ttraining's rmse: 28.9788\tvalid_1's rmse: 58.2829\n",
      "[240]\ttraining's rmse: 25.9125\tvalid_1's rmse: 57.2652\n",
      "[270]\ttraining's rmse: 23.3851\tvalid_1's rmse: 56.5738\n",
      "[300]\ttraining's rmse: 21.2898\tvalid_1's rmse: 55.9827\n",
      "[330]\ttraining's rmse: 19.5384\tvalid_1's rmse: 55.5831\n",
      "[360]\ttraining's rmse: 17.9929\tvalid_1's rmse: 55.3185\n",
      "[390]\ttraining's rmse: 16.6031\tvalid_1's rmse: 55.0958\n",
      "[420]\ttraining's rmse: 15.3899\tvalid_1's rmse: 54.9399\n",
      "[450]\ttraining's rmse: 14.2717\tvalid_1's rmse: 54.7881\n",
      "[480]\ttraining's rmse: 13.2635\tvalid_1's rmse: 54.667\n",
      "[510]\ttraining's rmse: 12.3459\tvalid_1's rmse: 54.5622\n",
      "[540]\ttraining's rmse: 11.5052\tvalid_1's rmse: 54.4504\n",
      "[570]\ttraining's rmse: 10.7495\tvalid_1's rmse: 54.4022\n",
      "[600]\ttraining's rmse: 10.0586\tvalid_1's rmse: 54.3325\n",
      "[630]\ttraining's rmse: 9.42973\tvalid_1's rmse: 54.2785\n",
      "[660]\ttraining's rmse: 8.82671\tvalid_1's rmse: 54.237\n",
      "[690]\ttraining's rmse: 8.28951\tvalid_1's rmse: 54.1974\n",
      "[720]\ttraining's rmse: 7.78326\tvalid_1's rmse: 54.1497\n",
      "[750]\ttraining's rmse: 7.30913\tvalid_1's rmse: 54.0987\n",
      "[780]\ttraining's rmse: 6.87968\tvalid_1's rmse: 54.0644\n",
      "[810]\ttraining's rmse: 6.47707\tvalid_1's rmse: 54.0269\n",
      "[840]\ttraining's rmse: 6.09795\tvalid_1's rmse: 54.004\n",
      "[870]\ttraining's rmse: 5.74884\tvalid_1's rmse: 53.991\n",
      "[900]\ttraining's rmse: 5.41804\tvalid_1's rmse: 53.9624\n",
      "[930]\ttraining's rmse: 5.11346\tvalid_1's rmse: 53.9349\n",
      "[960]\ttraining's rmse: 4.82978\tvalid_1's rmse: 53.9192\n",
      "[990]\ttraining's rmse: 4.56039\tvalid_1's rmse: 53.8913\n",
      "[1020]\ttraining's rmse: 4.30964\tvalid_1's rmse: 53.8835\n",
      "[1050]\ttraining's rmse: 4.07694\tvalid_1's rmse: 53.8717\n",
      "[1080]\ttraining's rmse: 3.85718\tvalid_1's rmse: 53.8639\n",
      "[1110]\ttraining's rmse: 3.64987\tvalid_1's rmse: 53.8583\n",
      "[1140]\ttraining's rmse: 3.4571\tvalid_1's rmse: 53.8488\n",
      "[1170]\ttraining's rmse: 3.27187\tvalid_1's rmse: 53.8385\n",
      "[1200]\ttraining's rmse: 3.0979\tvalid_1's rmse: 53.8297\n",
      "[1230]\ttraining's rmse: 2.93442\tvalid_1's rmse: 53.8158\n",
      "[1260]\ttraining's rmse: 2.78357\tvalid_1's rmse: 53.8076\n",
      "[1290]\ttraining's rmse: 2.63738\tvalid_1's rmse: 53.7974\n",
      "[1320]\ttraining's rmse: 2.50002\tvalid_1's rmse: 53.7877\n",
      "[1350]\ttraining's rmse: 2.37464\tvalid_1's rmse: 53.7821\n",
      "[1380]\ttraining's rmse: 2.25373\tvalid_1's rmse: 53.7813\n",
      "[1410]\ttraining's rmse: 2.14136\tvalid_1's rmse: 53.7792\n",
      "[1440]\ttraining's rmse: 2.03256\tvalid_1's rmse: 53.7708\n",
      "[1470]\ttraining's rmse: 1.93079\tvalid_1's rmse: 53.7654\n",
      "[1500]\ttraining's rmse: 1.83659\tvalid_1's rmse: 53.7598\n",
      "[1530]\ttraining's rmse: 1.74728\tvalid_1's rmse: 53.7577\n",
      "[1560]\ttraining's rmse: 1.66138\tvalid_1's rmse: 53.7538\n",
      "[1590]\ttraining's rmse: 1.57991\tvalid_1's rmse: 53.7512\n",
      "[1620]\ttraining's rmse: 1.50252\tvalid_1's rmse: 53.7487\n",
      "[1650]\ttraining's rmse: 1.42958\tvalid_1's rmse: 53.7445\n",
      "[1680]\ttraining's rmse: 1.35959\tvalid_1's rmse: 53.742\n",
      "[1710]\ttraining's rmse: 1.29276\tvalid_1's rmse: 53.7396\n",
      "[1740]\ttraining's rmse: 1.23089\tvalid_1's rmse: 53.7387\n",
      "[1770]\ttraining's rmse: 1.17179\tvalid_1's rmse: 53.7356\n",
      "[1800]\ttraining's rmse: 1.11625\tvalid_1's rmse: 53.732\n",
      "[1830]\ttraining's rmse: 1.06374\tvalid_1's rmse: 53.7307\n",
      "[1860]\ttraining's rmse: 1.01384\tvalid_1's rmse: 53.7322\n",
      "[1890]\ttraining's rmse: 0.967691\tvalid_1's rmse: 53.7293\n",
      "[1920]\ttraining's rmse: 0.922473\tvalid_1's rmse: 53.7292\n",
      "[1950]\ttraining's rmse: 0.878806\tvalid_1's rmse: 53.7284\n",
      "[1980]\ttraining's rmse: 0.839227\tvalid_1's rmse: 53.728\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's rmse: 0.812618\tvalid_1's rmse: 53.7261\n",
      "31\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002205 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 20022\n",
      "[LightGBM] [Info] Number of data points in the train set: 9219, number of used features: 79\n",
      "[LightGBM] [Info] Start training from score 362.962657\n",
      "Training until validation scores don't improve for 125 rounds\n",
      "[30]\ttraining's rmse: 146.679\tvalid_1's rmse: 150.134\n",
      "[60]\ttraining's rmse: 91.1394\tvalid_1's rmse: 101.29\n",
      "[90]\ttraining's rmse: 61.259\tvalid_1's rmse: 77.4823\n",
      "[120]\ttraining's rmse: 45.2355\tvalid_1's rmse: 66.4181\n",
      "[150]\ttraining's rmse: 36.2974\tvalid_1's rmse: 61.1068\n",
      "[180]\ttraining's rmse: 30.7941\tvalid_1's rmse: 58.2584\n",
      "[210]\ttraining's rmse: 26.9324\tvalid_1's rmse: 56.4577\n",
      "[240]\ttraining's rmse: 23.9053\tvalid_1's rmse: 55.1556\n",
      "[270]\ttraining's rmse: 21.4661\tvalid_1's rmse: 54.2537\n",
      "[300]\ttraining's rmse: 19.4943\tvalid_1's rmse: 53.7246\n",
      "[330]\ttraining's rmse: 17.8666\tvalid_1's rmse: 53.306\n",
      "[360]\ttraining's rmse: 16.4628\tvalid_1's rmse: 52.9934\n",
      "[390]\ttraining's rmse: 15.1924\tvalid_1's rmse: 52.7573\n",
      "[420]\ttraining's rmse: 14.08\tvalid_1's rmse: 52.5552\n",
      "[450]\ttraining's rmse: 13.0968\tvalid_1's rmse: 52.4122\n",
      "[480]\ttraining's rmse: 12.1768\tvalid_1's rmse: 52.3129\n",
      "[510]\ttraining's rmse: 11.3587\tvalid_1's rmse: 52.2342\n",
      "[540]\ttraining's rmse: 10.6001\tvalid_1's rmse: 52.1614\n",
      "[570]\ttraining's rmse: 9.91365\tvalid_1's rmse: 52.1175\n",
      "[600]\ttraining's rmse: 9.28297\tvalid_1's rmse: 52.0572\n",
      "[630]\ttraining's rmse: 8.69025\tvalid_1's rmse: 51.9831\n",
      "[660]\ttraining's rmse: 8.1498\tvalid_1's rmse: 51.9392\n",
      "[690]\ttraining's rmse: 7.65665\tvalid_1's rmse: 51.8871\n",
      "[720]\ttraining's rmse: 7.18643\tvalid_1's rmse: 51.8483\n",
      "[750]\ttraining's rmse: 6.75719\tvalid_1's rmse: 51.7999\n",
      "[780]\ttraining's rmse: 6.36655\tvalid_1's rmse: 51.7762\n",
      "[810]\ttraining's rmse: 5.98429\tvalid_1's rmse: 51.759\n",
      "[840]\ttraining's rmse: 5.63888\tvalid_1's rmse: 51.7508\n",
      "[870]\ttraining's rmse: 5.32101\tvalid_1's rmse: 51.7256\n",
      "[900]\ttraining's rmse: 5.01778\tvalid_1's rmse: 51.7126\n",
      "[930]\ttraining's rmse: 4.73378\tvalid_1's rmse: 51.6872\n",
      "[960]\ttraining's rmse: 4.47201\tvalid_1's rmse: 51.6822\n",
      "[990]\ttraining's rmse: 4.22606\tvalid_1's rmse: 51.6732\n",
      "[1020]\ttraining's rmse: 3.98889\tvalid_1's rmse: 51.6659\n",
      "[1050]\ttraining's rmse: 3.77449\tvalid_1's rmse: 51.6513\n",
      "[1080]\ttraining's rmse: 3.57497\tvalid_1's rmse: 51.64\n",
      "[1110]\ttraining's rmse: 3.38314\tvalid_1's rmse: 51.621\n",
      "[1140]\ttraining's rmse: 3.20317\tvalid_1's rmse: 51.6163\n",
      "[1170]\ttraining's rmse: 3.03261\tvalid_1's rmse: 51.6029\n",
      "[1200]\ttraining's rmse: 2.87308\tvalid_1's rmse: 51.5939\n",
      "[1230]\ttraining's rmse: 2.72222\tvalid_1's rmse: 51.585\n",
      "[1260]\ttraining's rmse: 2.58145\tvalid_1's rmse: 51.5781\n",
      "[1290]\ttraining's rmse: 2.44804\tvalid_1's rmse: 51.569\n",
      "[1320]\ttraining's rmse: 2.32195\tvalid_1's rmse: 51.5648\n",
      "[1350]\ttraining's rmse: 2.20035\tvalid_1's rmse: 51.56\n",
      "[1380]\ttraining's rmse: 2.09043\tvalid_1's rmse: 51.5577\n",
      "[1410]\ttraining's rmse: 1.98565\tvalid_1's rmse: 51.5564\n",
      "[1440]\ttraining's rmse: 1.88487\tvalid_1's rmse: 51.5522\n",
      "[1470]\ttraining's rmse: 1.79014\tvalid_1's rmse: 51.5495\n",
      "[1500]\ttraining's rmse: 1.70056\tvalid_1's rmse: 51.5475\n",
      "[1530]\ttraining's rmse: 1.61812\tvalid_1's rmse: 51.5429\n",
      "[1560]\ttraining's rmse: 1.53788\tvalid_1's rmse: 51.541\n",
      "[1590]\ttraining's rmse: 1.46315\tvalid_1's rmse: 51.5375\n",
      "[1620]\ttraining's rmse: 1.39178\tvalid_1's rmse: 51.5357\n",
      "[1650]\ttraining's rmse: 1.32304\tvalid_1's rmse: 51.535\n",
      "[1680]\ttraining's rmse: 1.25713\tvalid_1's rmse: 51.5343\n",
      "[1710]\ttraining's rmse: 1.19478\tvalid_1's rmse: 51.5341\n",
      "[1740]\ttraining's rmse: 1.13656\tvalid_1's rmse: 51.5328\n",
      "[1770]\ttraining's rmse: 1.08312\tvalid_1's rmse: 51.5313\n",
      "[1800]\ttraining's rmse: 1.03094\tvalid_1's rmse: 51.5292\n",
      "[1830]\ttraining's rmse: 0.983056\tvalid_1's rmse: 51.527\n",
      "[1860]\ttraining's rmse: 0.935857\tvalid_1's rmse: 51.5257\n",
      "[1890]\ttraining's rmse: 0.89238\tvalid_1's rmse: 51.5234\n",
      "[1920]\ttraining's rmse: 0.85085\tvalid_1's rmse: 51.5247\n",
      "[1950]\ttraining's rmse: 0.809617\tvalid_1's rmse: 51.5237\n",
      "[1980]\ttraining's rmse: 0.771706\tvalid_1's rmse: 51.5227\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's rmse: 0.747968\tvalid_1's rmse: 51.5222\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003348 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 20022\n",
      "[LightGBM] [Info] Number of data points in the train set: 9219, number of used features: 79\n",
      "[LightGBM] [Info] Start training from score 361.838953\n",
      "Training until validation scores don't improve for 125 rounds\n",
      "[30]\ttraining's rmse: 148.664\tvalid_1's rmse: 150.911\n",
      "[60]\ttraining's rmse: 94.0378\tvalid_1's rmse: 102.583\n",
      "[90]\ttraining's rmse: 64.3527\tvalid_1's rmse: 78.4252\n",
      "[120]\ttraining's rmse: 48.0723\tvalid_1's rmse: 66.5521\n",
      "[150]\ttraining's rmse: 38.8921\tvalid_1's rmse: 60.5342\n",
      "[180]\ttraining's rmse: 33.0216\tvalid_1's rmse: 57.0808\n",
      "[210]\ttraining's rmse: 28.8658\tvalid_1's rmse: 55.0594\n",
      "[240]\ttraining's rmse: 25.6373\tvalid_1's rmse: 53.7389\n",
      "[270]\ttraining's rmse: 23.0437\tvalid_1's rmse: 52.8265\n",
      "[300]\ttraining's rmse: 20.8825\tvalid_1's rmse: 52.1741\n",
      "[330]\ttraining's rmse: 19.0822\tvalid_1's rmse: 51.8064\n",
      "[360]\ttraining's rmse: 17.522\tvalid_1's rmse: 51.4944\n",
      "[390]\ttraining's rmse: 16.1653\tvalid_1's rmse: 51.2482\n",
      "[420]\ttraining's rmse: 14.9489\tvalid_1's rmse: 51.0396\n",
      "[450]\ttraining's rmse: 13.8605\tvalid_1's rmse: 50.8833\n",
      "[480]\ttraining's rmse: 12.8591\tvalid_1's rmse: 50.7759\n",
      "[510]\ttraining's rmse: 11.9679\tvalid_1's rmse: 50.6972\n",
      "[540]\ttraining's rmse: 11.1501\tvalid_1's rmse: 50.6162\n",
      "[570]\ttraining's rmse: 10.4029\tvalid_1's rmse: 50.5348\n",
      "[600]\ttraining's rmse: 9.7406\tvalid_1's rmse: 50.4822\n",
      "[630]\ttraining's rmse: 9.11893\tvalid_1's rmse: 50.4204\n",
      "[660]\ttraining's rmse: 8.53907\tvalid_1's rmse: 50.3562\n",
      "[690]\ttraining's rmse: 8.01193\tvalid_1's rmse: 50.3093\n",
      "[720]\ttraining's rmse: 7.52395\tvalid_1's rmse: 50.2726\n",
      "[750]\ttraining's rmse: 7.07497\tvalid_1's rmse: 50.2322\n",
      "[780]\ttraining's rmse: 6.65343\tvalid_1's rmse: 50.2071\n",
      "[810]\ttraining's rmse: 6.26103\tvalid_1's rmse: 50.1919\n",
      "[840]\ttraining's rmse: 5.89513\tvalid_1's rmse: 50.1641\n",
      "[870]\ttraining's rmse: 5.5552\tvalid_1's rmse: 50.1527\n",
      "[900]\ttraining's rmse: 5.2357\tvalid_1's rmse: 50.1414\n",
      "[930]\ttraining's rmse: 4.94557\tvalid_1's rmse: 50.1321\n",
      "[960]\ttraining's rmse: 4.67343\tvalid_1's rmse: 50.1198\n",
      "[990]\ttraining's rmse: 4.41831\tvalid_1's rmse: 50.105\n",
      "[1020]\ttraining's rmse: 4.17926\tvalid_1's rmse: 50.1005\n",
      "[1050]\ttraining's rmse: 3.95879\tvalid_1's rmse: 50.0865\n",
      "[1080]\ttraining's rmse: 3.74464\tvalid_1's rmse: 50.0728\n",
      "[1110]\ttraining's rmse: 3.54645\tvalid_1's rmse: 50.0627\n",
      "[1140]\ttraining's rmse: 3.36071\tvalid_1's rmse: 50.0548\n",
      "[1170]\ttraining's rmse: 3.18174\tvalid_1's rmse: 50.0487\n",
      "[1200]\ttraining's rmse: 3.01665\tvalid_1's rmse: 50.0423\n",
      "[1230]\ttraining's rmse: 2.85999\tvalid_1's rmse: 50.0371\n",
      "[1260]\ttraining's rmse: 2.7123\tvalid_1's rmse: 50.0285\n",
      "[1290]\ttraining's rmse: 2.57245\tvalid_1's rmse: 50.023\n",
      "[1320]\ttraining's rmse: 2.44125\tvalid_1's rmse: 50.0181\n",
      "[1350]\ttraining's rmse: 2.31793\tvalid_1's rmse: 50.0131\n",
      "[1380]\ttraining's rmse: 2.20165\tvalid_1's rmse: 50.0113\n",
      "[1410]\ttraining's rmse: 2.09192\tvalid_1's rmse: 50.0071\n",
      "[1440]\ttraining's rmse: 1.98885\tvalid_1's rmse: 49.9995\n",
      "[1470]\ttraining's rmse: 1.89091\tvalid_1's rmse: 49.9976\n",
      "[1500]\ttraining's rmse: 1.79866\tvalid_1's rmse: 49.9927\n",
      "[1530]\ttraining's rmse: 1.70971\tvalid_1's rmse: 49.9893\n",
      "[1560]\ttraining's rmse: 1.62441\tvalid_1's rmse: 49.9846\n",
      "[1590]\ttraining's rmse: 1.54593\tvalid_1's rmse: 49.9829\n",
      "[1620]\ttraining's rmse: 1.47201\tvalid_1's rmse: 49.9819\n",
      "[1650]\ttraining's rmse: 1.40071\tvalid_1's rmse: 49.9819\n",
      "[1680]\ttraining's rmse: 1.33295\tvalid_1's rmse: 49.9804\n",
      "[1710]\ttraining's rmse: 1.26928\tvalid_1's rmse: 49.9801\n",
      "[1740]\ttraining's rmse: 1.20797\tvalid_1's rmse: 49.9797\n",
      "[1770]\ttraining's rmse: 1.15149\tvalid_1's rmse: 49.9814\n",
      "[1800]\ttraining's rmse: 1.0976\tvalid_1's rmse: 49.9798\n",
      "[1830]\ttraining's rmse: 1.04586\tvalid_1's rmse: 49.9787\n",
      "Early stopping, best iteration is:\n",
      "[1723]\ttraining's rmse: 1.24259\tvalid_1's rmse: 49.9782\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003697 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 20022\n",
      "[LightGBM] [Info] Number of data points in the train set: 9219, number of used features: 79\n",
      "[LightGBM] [Info] Start training from score 371.212692\n",
      "Training until validation scores don't improve for 125 rounds\n",
      "[30]\ttraining's rmse: 152.725\tvalid_1's rmse: 159.467\n",
      "[60]\ttraining's rmse: 96.7918\tvalid_1's rmse: 108.234\n",
      "[90]\ttraining's rmse: 66.3302\tvalid_1's rmse: 83.2638\n",
      "[120]\ttraining's rmse: 49.699\tvalid_1's rmse: 71.0655\n",
      "[150]\ttraining's rmse: 40.2368\tvalid_1's rmse: 65.0829\n",
      "[180]\ttraining's rmse: 34.2805\tvalid_1's rmse: 61.9253\n",
      "[210]\ttraining's rmse: 30.0205\tvalid_1's rmse: 60.0239\n",
      "[240]\ttraining's rmse: 26.7692\tvalid_1's rmse: 58.6691\n",
      "[270]\ttraining's rmse: 24.1133\tvalid_1's rmse: 57.7706\n",
      "[300]\ttraining's rmse: 21.9263\tvalid_1's rmse: 57.1844\n",
      "[330]\ttraining's rmse: 20.0384\tvalid_1's rmse: 56.7285\n",
      "[360]\ttraining's rmse: 18.4372\tvalid_1's rmse: 56.4047\n",
      "[390]\ttraining's rmse: 17.0143\tvalid_1's rmse: 56.1186\n",
      "[420]\ttraining's rmse: 15.7396\tvalid_1's rmse: 55.9162\n",
      "[450]\ttraining's rmse: 14.6002\tvalid_1's rmse: 55.7535\n",
      "[480]\ttraining's rmse: 13.5695\tvalid_1's rmse: 55.6111\n",
      "[510]\ttraining's rmse: 12.6232\tvalid_1's rmse: 55.4959\n",
      "[540]\ttraining's rmse: 11.7764\tvalid_1's rmse: 55.3989\n",
      "[570]\ttraining's rmse: 10.9994\tvalid_1's rmse: 55.3022\n",
      "[600]\ttraining's rmse: 10.2819\tvalid_1's rmse: 55.1968\n",
      "[630]\ttraining's rmse: 9.63339\tvalid_1's rmse: 55.1183\n",
      "[660]\ttraining's rmse: 9.03164\tvalid_1's rmse: 55.0646\n",
      "[690]\ttraining's rmse: 8.48566\tvalid_1's rmse: 55.019\n",
      "[720]\ttraining's rmse: 7.96865\tvalid_1's rmse: 54.9657\n",
      "[750]\ttraining's rmse: 7.49024\tvalid_1's rmse: 54.9202\n",
      "[780]\ttraining's rmse: 7.04888\tvalid_1's rmse: 54.8803\n",
      "[810]\ttraining's rmse: 6.63633\tvalid_1's rmse: 54.8659\n",
      "[840]\ttraining's rmse: 6.24397\tvalid_1's rmse: 54.8277\n",
      "[870]\ttraining's rmse: 5.89209\tvalid_1's rmse: 54.7982\n",
      "[900]\ttraining's rmse: 5.5656\tvalid_1's rmse: 54.7745\n",
      "[930]\ttraining's rmse: 5.2486\tvalid_1's rmse: 54.7528\n",
      "[960]\ttraining's rmse: 4.95767\tvalid_1's rmse: 54.734\n",
      "[990]\ttraining's rmse: 4.68265\tvalid_1's rmse: 54.7106\n",
      "[1020]\ttraining's rmse: 4.42106\tvalid_1's rmse: 54.6936\n",
      "[1050]\ttraining's rmse: 4.18146\tvalid_1's rmse: 54.6779\n",
      "[1080]\ttraining's rmse: 3.95585\tvalid_1's rmse: 54.6599\n",
      "[1110]\ttraining's rmse: 3.74019\tvalid_1's rmse: 54.6506\n",
      "[1140]\ttraining's rmse: 3.5373\tvalid_1's rmse: 54.6419\n",
      "[1170]\ttraining's rmse: 3.34979\tvalid_1's rmse: 54.6331\n",
      "[1200]\ttraining's rmse: 3.1703\tvalid_1's rmse: 54.6194\n",
      "[1230]\ttraining's rmse: 3.00077\tvalid_1's rmse: 54.6113\n",
      "[1260]\ttraining's rmse: 2.84166\tvalid_1's rmse: 54.605\n",
      "[1290]\ttraining's rmse: 2.69262\tvalid_1's rmse: 54.6022\n",
      "[1320]\ttraining's rmse: 2.55174\tvalid_1's rmse: 54.5968\n",
      "[1350]\ttraining's rmse: 2.42022\tvalid_1's rmse: 54.5938\n",
      "[1380]\ttraining's rmse: 2.29534\tvalid_1's rmse: 54.5848\n",
      "[1410]\ttraining's rmse: 2.17515\tvalid_1's rmse: 54.5802\n",
      "[1440]\ttraining's rmse: 2.0669\tvalid_1's rmse: 54.5755\n",
      "[1470]\ttraining's rmse: 1.9621\tvalid_1's rmse: 54.5717\n",
      "[1500]\ttraining's rmse: 1.8615\tvalid_1's rmse: 54.5698\n",
      "[1530]\ttraining's rmse: 1.76897\tvalid_1's rmse: 54.5655\n",
      "[1560]\ttraining's rmse: 1.68026\tvalid_1's rmse: 54.5623\n",
      "[1590]\ttraining's rmse: 1.5975\tvalid_1's rmse: 54.5596\n",
      "[1620]\ttraining's rmse: 1.5174\tvalid_1's rmse: 54.5577\n",
      "[1650]\ttraining's rmse: 1.4441\tvalid_1's rmse: 54.5559\n",
      "[1680]\ttraining's rmse: 1.37155\tvalid_1's rmse: 54.5535\n",
      "[1710]\ttraining's rmse: 1.30444\tvalid_1's rmse: 54.5487\n",
      "[1740]\ttraining's rmse: 1.24342\tvalid_1's rmse: 54.5457\n",
      "[1770]\ttraining's rmse: 1.18214\tvalid_1's rmse: 54.5452\n",
      "[1800]\ttraining's rmse: 1.12624\tvalid_1's rmse: 54.5441\n",
      "[1830]\ttraining's rmse: 1.07266\tvalid_1's rmse: 54.5419\n",
      "[1860]\ttraining's rmse: 1.02179\tvalid_1's rmse: 54.5406\n",
      "[1890]\ttraining's rmse: 0.971659\tvalid_1's rmse: 54.5394\n",
      "[1920]\ttraining's rmse: 0.924548\tvalid_1's rmse: 54.5388\n",
      "[1950]\ttraining's rmse: 0.879936\tvalid_1's rmse: 54.538\n",
      "[1980]\ttraining's rmse: 0.838343\tvalid_1's rmse: 54.5359\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's rmse: 0.811696\tvalid_1's rmse: 54.5334\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002971 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 20022\n",
      "[LightGBM] [Info] Number of data points in the train set: 9219, number of used features: 79\n",
      "[LightGBM] [Info] Start training from score 374.524728\n",
      "Training until validation scores don't improve for 125 rounds\n",
      "[30]\ttraining's rmse: 153.359\tvalid_1's rmse: 167.538\n",
      "[60]\ttraining's rmse: 97.1284\tvalid_1's rmse: 115.393\n",
      "[90]\ttraining's rmse: 66.9032\tvalid_1's rmse: 89.913\n",
      "[120]\ttraining's rmse: 50.1568\tvalid_1's rmse: 77.1173\n",
      "[150]\ttraining's rmse: 40.5633\tvalid_1's rmse: 70.7156\n",
      "[180]\ttraining's rmse: 34.4628\tvalid_1's rmse: 67.326\n",
      "[210]\ttraining's rmse: 30.1624\tvalid_1's rmse: 65.2487\n",
      "[240]\ttraining's rmse: 26.8682\tvalid_1's rmse: 63.9451\n",
      "[270]\ttraining's rmse: 24.1804\tvalid_1's rmse: 63.0187\n",
      "[300]\ttraining's rmse: 21.9705\tvalid_1's rmse: 62.4463\n",
      "[330]\ttraining's rmse: 20.0854\tvalid_1's rmse: 62.0004\n",
      "[360]\ttraining's rmse: 18.4598\tvalid_1's rmse: 61.6218\n",
      "[390]\ttraining's rmse: 17.0068\tvalid_1's rmse: 61.2484\n",
      "[420]\ttraining's rmse: 15.7056\tvalid_1's rmse: 61.0002\n",
      "[450]\ttraining's rmse: 14.542\tvalid_1's rmse: 60.7885\n",
      "[480]\ttraining's rmse: 13.5087\tvalid_1's rmse: 60.6338\n",
      "[510]\ttraining's rmse: 12.5702\tvalid_1's rmse: 60.4754\n",
      "[540]\ttraining's rmse: 11.7084\tvalid_1's rmse: 60.3385\n",
      "[570]\ttraining's rmse: 10.9468\tvalid_1's rmse: 60.2348\n",
      "[600]\ttraining's rmse: 10.2278\tvalid_1's rmse: 60.105\n",
      "[630]\ttraining's rmse: 9.5719\tvalid_1's rmse: 60.0482\n",
      "[660]\ttraining's rmse: 8.97172\tvalid_1's rmse: 59.9849\n",
      "[690]\ttraining's rmse: 8.40691\tvalid_1's rmse: 59.9453\n",
      "[720]\ttraining's rmse: 7.88588\tvalid_1's rmse: 59.8744\n",
      "[750]\ttraining's rmse: 7.40716\tvalid_1's rmse: 59.8227\n",
      "[780]\ttraining's rmse: 6.96136\tvalid_1's rmse: 59.7695\n",
      "[810]\ttraining's rmse: 6.5549\tvalid_1's rmse: 59.7393\n",
      "[840]\ttraining's rmse: 6.16699\tvalid_1's rmse: 59.7011\n",
      "[870]\ttraining's rmse: 5.80572\tvalid_1's rmse: 59.6689\n",
      "[900]\ttraining's rmse: 5.47557\tvalid_1's rmse: 59.6361\n",
      "[930]\ttraining's rmse: 5.16637\tvalid_1's rmse: 59.6069\n",
      "[960]\ttraining's rmse: 4.86947\tvalid_1's rmse: 59.594\n",
      "[990]\ttraining's rmse: 4.59676\tvalid_1's rmse: 59.5688\n",
      "[1020]\ttraining's rmse: 4.34299\tvalid_1's rmse: 59.5442\n",
      "[1050]\ttraining's rmse: 4.1057\tvalid_1's rmse: 59.5292\n",
      "[1080]\ttraining's rmse: 3.87758\tvalid_1's rmse: 59.5094\n",
      "[1110]\ttraining's rmse: 3.66884\tvalid_1's rmse: 59.4947\n",
      "[1140]\ttraining's rmse: 3.47097\tvalid_1's rmse: 59.4778\n",
      "[1170]\ttraining's rmse: 3.28347\tvalid_1's rmse: 59.4636\n",
      "[1200]\ttraining's rmse: 3.10712\tvalid_1's rmse: 59.4527\n",
      "[1230]\ttraining's rmse: 2.94234\tvalid_1's rmse: 59.4405\n",
      "[1260]\ttraining's rmse: 2.7876\tvalid_1's rmse: 59.432\n",
      "[1290]\ttraining's rmse: 2.63858\tvalid_1's rmse: 59.4169\n",
      "[1320]\ttraining's rmse: 2.49949\tvalid_1's rmse: 59.4098\n",
      "[1350]\ttraining's rmse: 2.37134\tvalid_1's rmse: 59.4037\n",
      "[1380]\ttraining's rmse: 2.24892\tvalid_1's rmse: 59.3973\n",
      "[1410]\ttraining's rmse: 2.13452\tvalid_1's rmse: 59.391\n",
      "[1440]\ttraining's rmse: 2.02613\tvalid_1's rmse: 59.3867\n",
      "[1470]\ttraining's rmse: 1.92282\tvalid_1's rmse: 59.3814\n",
      "[1500]\ttraining's rmse: 1.82279\tvalid_1's rmse: 59.3729\n",
      "[1530]\ttraining's rmse: 1.73019\tvalid_1's rmse: 59.3666\n",
      "[1560]\ttraining's rmse: 1.64237\tvalid_1's rmse: 59.365\n",
      "[1590]\ttraining's rmse: 1.55905\tvalid_1's rmse: 59.3601\n",
      "[1620]\ttraining's rmse: 1.48081\tvalid_1's rmse: 59.3599\n",
      "[1650]\ttraining's rmse: 1.40705\tvalid_1's rmse: 59.3573\n",
      "[1680]\ttraining's rmse: 1.33738\tvalid_1's rmse: 59.3545\n",
      "[1710]\ttraining's rmse: 1.27085\tvalid_1's rmse: 59.3494\n",
      "[1740]\ttraining's rmse: 1.20927\tvalid_1's rmse: 59.3458\n",
      "[1770]\ttraining's rmse: 1.15055\tvalid_1's rmse: 59.3448\n",
      "[1800]\ttraining's rmse: 1.09421\tvalid_1's rmse: 59.3423\n",
      "[1830]\ttraining's rmse: 1.03951\tvalid_1's rmse: 59.3404\n",
      "[1860]\ttraining's rmse: 0.98805\tvalid_1's rmse: 59.338\n",
      "[1890]\ttraining's rmse: 0.939368\tvalid_1's rmse: 59.3357\n",
      "[1920]\ttraining's rmse: 0.893179\tvalid_1's rmse: 59.3345\n",
      "[1950]\ttraining's rmse: 0.850812\tvalid_1's rmse: 59.3316\n",
      "[1980]\ttraining's rmse: 0.809225\tvalid_1's rmse: 59.3289\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's rmse: 0.782684\tvalid_1's rmse: 59.3278\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003475 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 20022\n",
      "[LightGBM] [Info] Number of data points in the train set: 9219, number of used features: 79\n",
      "[LightGBM] [Info] Start training from score 369.377868\n",
      "Training until validation scores don't improve for 125 rounds\n",
      "[30]\ttraining's rmse: 154.06\tvalid_1's rmse: 161.104\n",
      "[60]\ttraining's rmse: 97.0019\tvalid_1's rmse: 108.992\n",
      "[90]\ttraining's rmse: 66.3175\tvalid_1's rmse: 83.4639\n",
      "[120]\ttraining's rmse: 49.6707\tvalid_1's rmse: 71.285\n",
      "[150]\ttraining's rmse: 40.1205\tvalid_1's rmse: 65.3348\n",
      "[180]\ttraining's rmse: 34.2293\tvalid_1's rmse: 62.1973\n",
      "[210]\ttraining's rmse: 30.0822\tvalid_1's rmse: 60.3961\n",
      "[240]\ttraining's rmse: 26.8303\tvalid_1's rmse: 59.336\n",
      "[270]\ttraining's rmse: 24.1753\tvalid_1's rmse: 58.582\n",
      "[300]\ttraining's rmse: 22.0245\tvalid_1's rmse: 58.0472\n",
      "[330]\ttraining's rmse: 20.2027\tvalid_1's rmse: 57.7447\n",
      "[360]\ttraining's rmse: 18.5678\tvalid_1's rmse: 57.4427\n",
      "[390]\ttraining's rmse: 17.1075\tvalid_1's rmse: 57.1497\n",
      "[420]\ttraining's rmse: 15.8304\tvalid_1's rmse: 56.972\n",
      "[450]\ttraining's rmse: 14.6811\tvalid_1's rmse: 56.8067\n",
      "[480]\ttraining's rmse: 13.6344\tvalid_1's rmse: 56.68\n",
      "[510]\ttraining's rmse: 12.6911\tvalid_1's rmse: 56.5464\n",
      "[540]\ttraining's rmse: 11.8374\tvalid_1's rmse: 56.4581\n",
      "[570]\ttraining's rmse: 11.0695\tvalid_1's rmse: 56.3757\n",
      "[600]\ttraining's rmse: 10.3676\tvalid_1's rmse: 56.3347\n",
      "[630]\ttraining's rmse: 9.71502\tvalid_1's rmse: 56.2851\n",
      "[660]\ttraining's rmse: 9.0988\tvalid_1's rmse: 56.2248\n",
      "[690]\ttraining's rmse: 8.52214\tvalid_1's rmse: 56.1895\n",
      "[720]\ttraining's rmse: 8.00867\tvalid_1's rmse: 56.1437\n",
      "[750]\ttraining's rmse: 7.52492\tvalid_1's rmse: 56.1101\n",
      "[780]\ttraining's rmse: 7.07925\tvalid_1's rmse: 56.075\n",
      "[810]\ttraining's rmse: 6.65639\tvalid_1's rmse: 56.0449\n",
      "[840]\ttraining's rmse: 6.26472\tvalid_1's rmse: 56.0219\n",
      "[870]\ttraining's rmse: 5.90327\tvalid_1's rmse: 55.9897\n",
      "[900]\ttraining's rmse: 5.55923\tvalid_1's rmse: 55.9655\n",
      "[930]\ttraining's rmse: 5.24367\tvalid_1's rmse: 55.9404\n",
      "[960]\ttraining's rmse: 4.95681\tvalid_1's rmse: 55.93\n",
      "[990]\ttraining's rmse: 4.68213\tvalid_1's rmse: 55.9085\n",
      "[1020]\ttraining's rmse: 4.42148\tvalid_1's rmse: 55.9008\n",
      "[1050]\ttraining's rmse: 4.17824\tvalid_1's rmse: 55.886\n",
      "[1080]\ttraining's rmse: 3.9514\tvalid_1's rmse: 55.8627\n",
      "[1110]\ttraining's rmse: 3.7335\tvalid_1's rmse: 55.8493\n",
      "[1140]\ttraining's rmse: 3.5338\tvalid_1's rmse: 55.8291\n",
      "[1170]\ttraining's rmse: 3.34717\tvalid_1's rmse: 55.8211\n",
      "[1200]\ttraining's rmse: 3.16921\tvalid_1's rmse: 55.811\n",
      "[1230]\ttraining's rmse: 3.0072\tvalid_1's rmse: 55.8048\n",
      "[1260]\ttraining's rmse: 2.84707\tvalid_1's rmse: 55.8016\n",
      "[1290]\ttraining's rmse: 2.69917\tvalid_1's rmse: 55.7915\n",
      "[1320]\ttraining's rmse: 2.5578\tvalid_1's rmse: 55.7863\n",
      "[1350]\ttraining's rmse: 2.42584\tvalid_1's rmse: 55.7787\n",
      "[1380]\ttraining's rmse: 2.30052\tvalid_1's rmse: 55.7737\n",
      "[1410]\ttraining's rmse: 2.18587\tvalid_1's rmse: 55.7723\n",
      "[1440]\ttraining's rmse: 2.07845\tvalid_1's rmse: 55.7647\n",
      "[1470]\ttraining's rmse: 1.97442\tvalid_1's rmse: 55.759\n",
      "[1500]\ttraining's rmse: 1.87722\tvalid_1's rmse: 55.7555\n",
      "[1530]\ttraining's rmse: 1.78314\tvalid_1's rmse: 55.7508\n",
      "[1560]\ttraining's rmse: 1.6941\tvalid_1's rmse: 55.746\n",
      "[1590]\ttraining's rmse: 1.61083\tvalid_1's rmse: 55.7434\n",
      "[1620]\ttraining's rmse: 1.53361\tvalid_1's rmse: 55.7404\n",
      "[1650]\ttraining's rmse: 1.46121\tvalid_1's rmse: 55.739\n",
      "[1680]\ttraining's rmse: 1.38765\tvalid_1's rmse: 55.7352\n",
      "[1710]\ttraining's rmse: 1.32079\tvalid_1's rmse: 55.7324\n",
      "[1740]\ttraining's rmse: 1.25751\tvalid_1's rmse: 55.7302\n",
      "[1770]\ttraining's rmse: 1.19591\tvalid_1's rmse: 55.7284\n",
      "[1800]\ttraining's rmse: 1.13831\tvalid_1's rmse: 55.7272\n",
      "[1830]\ttraining's rmse: 1.08336\tvalid_1's rmse: 55.7254\n",
      "[1860]\ttraining's rmse: 1.03016\tvalid_1's rmse: 55.7224\n",
      "[1890]\ttraining's rmse: 0.980348\tvalid_1's rmse: 55.7215\n",
      "[1920]\ttraining's rmse: 0.934749\tvalid_1's rmse: 55.7206\n",
      "[1950]\ttraining's rmse: 0.889825\tvalid_1's rmse: 55.7177\n",
      "[1980]\ttraining's rmse: 0.847849\tvalid_1's rmse: 55.717\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's rmse: 0.821711\tvalid_1's rmse: 55.7169\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002519 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 20022\n",
      "[LightGBM] [Info] Number of data points in the train set: 9219, number of used features: 79\n",
      "[LightGBM] [Info] Start training from score 363.290863\n",
      "Training until validation scores don't improve for 125 rounds\n",
      "[30]\ttraining's rmse: 152.457\tvalid_1's rmse: 153.003\n",
      "[60]\ttraining's rmse: 95.1004\tvalid_1's rmse: 101.543\n",
      "[90]\ttraining's rmse: 64.5385\tvalid_1's rmse: 76.7394\n",
      "[120]\ttraining's rmse: 48.1856\tvalid_1's rmse: 65.3744\n",
      "[150]\ttraining's rmse: 38.7503\tvalid_1's rmse: 59.915\n",
      "[180]\ttraining's rmse: 32.9584\tvalid_1's rmse: 57.123\n",
      "[210]\ttraining's rmse: 28.9749\tvalid_1's rmse: 55.6808\n",
      "[240]\ttraining's rmse: 25.8857\tvalid_1's rmse: 54.6754\n",
      "[270]\ttraining's rmse: 23.3918\tvalid_1's rmse: 53.9468\n",
      "[300]\ttraining's rmse: 21.2814\tvalid_1's rmse: 53.4054\n",
      "[330]\ttraining's rmse: 19.5068\tvalid_1's rmse: 53.0557\n",
      "[360]\ttraining's rmse: 17.9283\tvalid_1's rmse: 52.7646\n",
      "[390]\ttraining's rmse: 16.5774\tvalid_1's rmse: 52.5357\n",
      "[420]\ttraining's rmse: 15.3363\tvalid_1's rmse: 52.3526\n",
      "[450]\ttraining's rmse: 14.2284\tvalid_1's rmse: 52.1982\n",
      "[480]\ttraining's rmse: 13.2143\tvalid_1's rmse: 52.0517\n",
      "[510]\ttraining's rmse: 12.2968\tvalid_1's rmse: 51.9258\n",
      "[540]\ttraining's rmse: 11.4697\tvalid_1's rmse: 51.8156\n",
      "[570]\ttraining's rmse: 10.7105\tvalid_1's rmse: 51.7422\n",
      "[600]\ttraining's rmse: 10.0131\tvalid_1's rmse: 51.6482\n",
      "[630]\ttraining's rmse: 9.37903\tvalid_1's rmse: 51.5763\n",
      "[660]\ttraining's rmse: 8.80168\tvalid_1's rmse: 51.512\n",
      "[690]\ttraining's rmse: 8.26622\tvalid_1's rmse: 51.4786\n",
      "[720]\ttraining's rmse: 7.75519\tvalid_1's rmse: 51.419\n",
      "[750]\ttraining's rmse: 7.28903\tvalid_1's rmse: 51.3718\n",
      "[780]\ttraining's rmse: 6.86315\tvalid_1's rmse: 51.3407\n",
      "[810]\ttraining's rmse: 6.46643\tvalid_1's rmse: 51.3351\n",
      "[840]\ttraining's rmse: 6.09405\tvalid_1's rmse: 51.3062\n",
      "[870]\ttraining's rmse: 5.73659\tvalid_1's rmse: 51.2819\n",
      "[900]\ttraining's rmse: 5.41007\tvalid_1's rmse: 51.2607\n",
      "[930]\ttraining's rmse: 5.11013\tvalid_1's rmse: 51.2407\n",
      "[960]\ttraining's rmse: 4.82777\tvalid_1's rmse: 51.2273\n",
      "[990]\ttraining's rmse: 4.55731\tvalid_1's rmse: 51.2026\n",
      "[1020]\ttraining's rmse: 4.30645\tvalid_1's rmse: 51.1888\n",
      "[1050]\ttraining's rmse: 4.06712\tvalid_1's rmse: 51.1717\n",
      "[1080]\ttraining's rmse: 3.84396\tvalid_1's rmse: 51.1595\n",
      "[1110]\ttraining's rmse: 3.63688\tvalid_1's rmse: 51.1435\n",
      "[1140]\ttraining's rmse: 3.43641\tvalid_1's rmse: 51.126\n",
      "[1170]\ttraining's rmse: 3.25523\tvalid_1's rmse: 51.1175\n",
      "[1200]\ttraining's rmse: 3.08181\tvalid_1's rmse: 51.1094\n",
      "[1230]\ttraining's rmse: 2.91998\tvalid_1's rmse: 51.1052\n",
      "[1260]\ttraining's rmse: 2.76564\tvalid_1's rmse: 51.0935\n",
      "[1290]\ttraining's rmse: 2.61931\tvalid_1's rmse: 51.0883\n",
      "[1320]\ttraining's rmse: 2.48019\tvalid_1's rmse: 51.0822\n",
      "[1350]\ttraining's rmse: 2.35256\tvalid_1's rmse: 51.0793\n",
      "[1380]\ttraining's rmse: 2.22981\tvalid_1's rmse: 51.0766\n",
      "[1410]\ttraining's rmse: 2.11445\tvalid_1's rmse: 51.0728\n",
      "[1440]\ttraining's rmse: 2.00887\tvalid_1's rmse: 51.0672\n",
      "[1470]\ttraining's rmse: 1.90595\tvalid_1's rmse: 51.0634\n",
      "[1500]\ttraining's rmse: 1.81134\tvalid_1's rmse: 51.0638\n",
      "[1530]\ttraining's rmse: 1.72081\tvalid_1's rmse: 51.0603\n",
      "[1560]\ttraining's rmse: 1.63485\tvalid_1's rmse: 51.057\n",
      "[1590]\ttraining's rmse: 1.55266\tvalid_1's rmse: 51.0539\n",
      "[1620]\ttraining's rmse: 1.47591\tvalid_1's rmse: 51.0513\n",
      "[1650]\ttraining's rmse: 1.40276\tvalid_1's rmse: 51.0495\n",
      "[1680]\ttraining's rmse: 1.33291\tvalid_1's rmse: 51.0497\n",
      "[1710]\ttraining's rmse: 1.26598\tvalid_1's rmse: 51.0479\n",
      "[1740]\ttraining's rmse: 1.20436\tvalid_1's rmse: 51.0489\n",
      "[1770]\ttraining's rmse: 1.146\tvalid_1's rmse: 51.0469\n",
      "[1800]\ttraining's rmse: 1.08908\tvalid_1's rmse: 51.0462\n",
      "[1830]\ttraining's rmse: 1.03739\tvalid_1's rmse: 51.0438\n",
      "[1860]\ttraining's rmse: 0.986389\tvalid_1's rmse: 51.0435\n",
      "[1890]\ttraining's rmse: 0.938399\tvalid_1's rmse: 51.0414\n",
      "[1920]\ttraining's rmse: 0.894204\tvalid_1's rmse: 51.0408\n",
      "[1950]\ttraining's rmse: 0.851993\tvalid_1's rmse: 51.0404\n",
      "[1980]\ttraining's rmse: 0.811495\tvalid_1's rmse: 51.0389\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's rmse: 0.785346\tvalid_1's rmse: 51.0386\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003502 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 20022\n",
      "[LightGBM] [Info] Number of data points in the train set: 9219, number of used features: 79\n",
      "[LightGBM] [Info] Start training from score 357.747073\n",
      "Training until validation scores don't improve for 125 rounds\n",
      "[30]\ttraining's rmse: 151.134\tvalid_1's rmse: 158.407\n",
      "[60]\ttraining's rmse: 94.7539\tvalid_1's rmse: 105.482\n",
      "[90]\ttraining's rmse: 64.4664\tvalid_1's rmse: 79.2119\n",
      "[120]\ttraining's rmse: 48.0099\tvalid_1's rmse: 66.7738\n",
      "[150]\ttraining's rmse: 38.6274\tvalid_1's rmse: 60.6538\n",
      "[180]\ttraining's rmse: 32.8389\tvalid_1's rmse: 57.5596\n",
      "[210]\ttraining's rmse: 28.8406\tvalid_1's rmse: 55.7615\n",
      "[240]\ttraining's rmse: 25.8238\tvalid_1's rmse: 54.5962\n",
      "[270]\ttraining's rmse: 23.3518\tvalid_1's rmse: 53.7626\n",
      "[300]\ttraining's rmse: 21.2517\tvalid_1's rmse: 53.1116\n",
      "[330]\ttraining's rmse: 19.4668\tvalid_1's rmse: 52.6254\n",
      "[360]\ttraining's rmse: 17.922\tvalid_1's rmse: 52.2635\n",
      "[390]\ttraining's rmse: 16.563\tvalid_1's rmse: 51.9938\n",
      "[420]\ttraining's rmse: 15.3269\tvalid_1's rmse: 51.778\n",
      "[450]\ttraining's rmse: 14.21\tvalid_1's rmse: 51.5769\n",
      "[480]\ttraining's rmse: 13.2043\tvalid_1's rmse: 51.4327\n",
      "[510]\ttraining's rmse: 12.2988\tvalid_1's rmse: 51.3135\n",
      "[540]\ttraining's rmse: 11.4693\tvalid_1's rmse: 51.2098\n",
      "[570]\ttraining's rmse: 10.7211\tvalid_1's rmse: 51.0778\n",
      "[600]\ttraining's rmse: 10.0249\tvalid_1's rmse: 51.0107\n",
      "[630]\ttraining's rmse: 9.39654\tvalid_1's rmse: 50.9423\n",
      "[660]\ttraining's rmse: 8.81428\tvalid_1's rmse: 50.8907\n",
      "[690]\ttraining's rmse: 8.27004\tvalid_1's rmse: 50.8482\n",
      "[720]\ttraining's rmse: 7.77622\tvalid_1's rmse: 50.8021\n",
      "[750]\ttraining's rmse: 7.30993\tvalid_1's rmse: 50.7605\n",
      "[780]\ttraining's rmse: 6.87386\tvalid_1's rmse: 50.7178\n",
      "[810]\ttraining's rmse: 6.47124\tvalid_1's rmse: 50.6889\n",
      "[840]\ttraining's rmse: 6.10224\tvalid_1's rmse: 50.6477\n",
      "[870]\ttraining's rmse: 5.75989\tvalid_1's rmse: 50.6284\n",
      "[900]\ttraining's rmse: 5.44215\tvalid_1's rmse: 50.5999\n",
      "[930]\ttraining's rmse: 5.14233\tvalid_1's rmse: 50.5705\n",
      "[960]\ttraining's rmse: 4.85883\tvalid_1's rmse: 50.5406\n",
      "[990]\ttraining's rmse: 4.60035\tvalid_1's rmse: 50.5216\n",
      "[1020]\ttraining's rmse: 4.34973\tvalid_1's rmse: 50.4958\n",
      "[1050]\ttraining's rmse: 4.1197\tvalid_1's rmse: 50.4878\n",
      "[1080]\ttraining's rmse: 3.89918\tvalid_1's rmse: 50.4761\n",
      "[1110]\ttraining's rmse: 3.69337\tvalid_1's rmse: 50.4629\n",
      "[1140]\ttraining's rmse: 3.49997\tvalid_1's rmse: 50.4492\n",
      "[1170]\ttraining's rmse: 3.32014\tvalid_1's rmse: 50.445\n",
      "[1200]\ttraining's rmse: 3.14781\tvalid_1's rmse: 50.4323\n",
      "[1230]\ttraining's rmse: 2.98662\tvalid_1's rmse: 50.4191\n",
      "[1260]\ttraining's rmse: 2.82756\tvalid_1's rmse: 50.4051\n",
      "[1290]\ttraining's rmse: 2.68271\tvalid_1's rmse: 50.3964\n",
      "[1320]\ttraining's rmse: 2.54436\tvalid_1's rmse: 50.3869\n",
      "[1350]\ttraining's rmse: 2.41485\tvalid_1's rmse: 50.3806\n",
      "[1380]\ttraining's rmse: 2.29865\tvalid_1's rmse: 50.3778\n",
      "[1410]\ttraining's rmse: 2.18529\tvalid_1's rmse: 50.378\n",
      "[1440]\ttraining's rmse: 2.07854\tvalid_1's rmse: 50.3783\n",
      "[1470]\ttraining's rmse: 1.97716\tvalid_1's rmse: 50.3719\n",
      "[1500]\ttraining's rmse: 1.87763\tvalid_1's rmse: 50.3671\n",
      "[1530]\ttraining's rmse: 1.78768\tvalid_1's rmse: 50.3604\n",
      "[1560]\ttraining's rmse: 1.70379\tvalid_1's rmse: 50.3526\n",
      "[1590]\ttraining's rmse: 1.62345\tvalid_1's rmse: 50.3478\n",
      "[1620]\ttraining's rmse: 1.5479\tvalid_1's rmse: 50.3441\n",
      "[1650]\ttraining's rmse: 1.47649\tvalid_1's rmse: 50.3403\n",
      "[1680]\ttraining's rmse: 1.40865\tvalid_1's rmse: 50.3377\n",
      "[1710]\ttraining's rmse: 1.34381\tvalid_1's rmse: 50.3343\n",
      "[1740]\ttraining's rmse: 1.28062\tvalid_1's rmse: 50.3294\n",
      "[1770]\ttraining's rmse: 1.22097\tvalid_1's rmse: 50.3269\n",
      "[1800]\ttraining's rmse: 1.16629\tvalid_1's rmse: 50.3241\n",
      "[1830]\ttraining's rmse: 1.11469\tvalid_1's rmse: 50.3216\n",
      "[1860]\ttraining's rmse: 1.06507\tvalid_1's rmse: 50.3207\n",
      "[1890]\ttraining's rmse: 1.01758\tvalid_1's rmse: 50.3189\n",
      "[1920]\ttraining's rmse: 0.973428\tvalid_1's rmse: 50.3172\n",
      "[1950]\ttraining's rmse: 0.931684\tvalid_1's rmse: 50.3143\n",
      "[1980]\ttraining's rmse: 0.889809\tvalid_1's rmse: 50.313\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's rmse: 0.863617\tvalid_1's rmse: 50.3113\n",
      "32\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002220 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 20022\n",
      "[LightGBM] [Info] Number of data points in the train set: 9219, number of used features: 79\n",
      "[LightGBM] [Info] Start training from score 367.363229\n",
      "Training until validation scores don't improve for 125 rounds\n",
      "[30]\ttraining's rmse: 147.012\tvalid_1's rmse: 150.883\n",
      "[60]\ttraining's rmse: 92.0494\tvalid_1's rmse: 100.581\n",
      "[90]\ttraining's rmse: 62.3667\tvalid_1's rmse: 75.7153\n",
      "[120]\ttraining's rmse: 46.2075\tvalid_1's rmse: 63.916\n",
      "[150]\ttraining's rmse: 37.1244\tvalid_1's rmse: 58.1633\n",
      "[180]\ttraining's rmse: 31.5082\tvalid_1's rmse: 55.1773\n",
      "[210]\ttraining's rmse: 27.5149\tvalid_1's rmse: 53.4482\n",
      "[240]\ttraining's rmse: 24.444\tvalid_1's rmse: 52.2693\n",
      "[270]\ttraining's rmse: 22.0212\tvalid_1's rmse: 51.4236\n",
      "[300]\ttraining's rmse: 20.0419\tvalid_1's rmse: 50.9098\n",
      "[330]\ttraining's rmse: 18.3786\tvalid_1's rmse: 50.5121\n",
      "[360]\ttraining's rmse: 16.928\tvalid_1's rmse: 50.2071\n",
      "[390]\ttraining's rmse: 15.6864\tvalid_1's rmse: 50.0004\n",
      "[420]\ttraining's rmse: 14.5495\tvalid_1's rmse: 49.7803\n",
      "[450]\ttraining's rmse: 13.5095\tvalid_1's rmse: 49.6317\n",
      "[480]\ttraining's rmse: 12.5672\tvalid_1's rmse: 49.4868\n",
      "[510]\ttraining's rmse: 11.7054\tvalid_1's rmse: 49.3825\n",
      "[540]\ttraining's rmse: 10.9374\tvalid_1's rmse: 49.2989\n",
      "[570]\ttraining's rmse: 10.2409\tvalid_1's rmse: 49.2133\n",
      "[600]\ttraining's rmse: 9.61226\tvalid_1's rmse: 49.1523\n",
      "[630]\ttraining's rmse: 9.02812\tvalid_1's rmse: 49.1101\n",
      "[660]\ttraining's rmse: 8.48267\tvalid_1's rmse: 49.0694\n",
      "[690]\ttraining's rmse: 7.96373\tvalid_1's rmse: 49.0413\n",
      "[720]\ttraining's rmse: 7.49416\tvalid_1's rmse: 49.0117\n",
      "[750]\ttraining's rmse: 7.05033\tvalid_1's rmse: 48.9849\n",
      "[780]\ttraining's rmse: 6.65387\tvalid_1's rmse: 48.9706\n",
      "[810]\ttraining's rmse: 6.27795\tvalid_1's rmse: 48.9462\n",
      "[840]\ttraining's rmse: 5.92726\tvalid_1's rmse: 48.9272\n",
      "[870]\ttraining's rmse: 5.59905\tvalid_1's rmse: 48.9264\n",
      "[900]\ttraining's rmse: 5.29475\tvalid_1's rmse: 48.9096\n",
      "[930]\ttraining's rmse: 5.01115\tvalid_1's rmse: 48.8848\n",
      "[960]\ttraining's rmse: 4.74022\tvalid_1's rmse: 48.8693\n",
      "[990]\ttraining's rmse: 4.48494\tvalid_1's rmse: 48.8542\n",
      "[1020]\ttraining's rmse: 4.24825\tvalid_1's rmse: 48.8504\n",
      "[1050]\ttraining's rmse: 4.03156\tvalid_1's rmse: 48.8387\n",
      "[1080]\ttraining's rmse: 3.81907\tvalid_1's rmse: 48.8312\n",
      "[1110]\ttraining's rmse: 3.62308\tvalid_1's rmse: 48.8103\n",
      "[1140]\ttraining's rmse: 3.44055\tvalid_1's rmse: 48.8021\n",
      "[1170]\ttraining's rmse: 3.27028\tvalid_1's rmse: 48.7943\n",
      "[1200]\ttraining's rmse: 3.10467\tvalid_1's rmse: 48.7854\n",
      "[1230]\ttraining's rmse: 2.95029\tvalid_1's rmse: 48.7735\n",
      "[1260]\ttraining's rmse: 2.80139\tvalid_1's rmse: 48.7683\n",
      "[1290]\ttraining's rmse: 2.66116\tvalid_1's rmse: 48.7659\n",
      "[1320]\ttraining's rmse: 2.52604\tvalid_1's rmse: 48.7567\n",
      "[1350]\ttraining's rmse: 2.39854\tvalid_1's rmse: 48.7493\n",
      "[1380]\ttraining's rmse: 2.28248\tvalid_1's rmse: 48.746\n",
      "[1410]\ttraining's rmse: 2.16837\tvalid_1's rmse: 48.7432\n",
      "[1440]\ttraining's rmse: 2.05955\tvalid_1's rmse: 48.7402\n",
      "[1470]\ttraining's rmse: 1.96063\tvalid_1's rmse: 48.7375\n",
      "[1500]\ttraining's rmse: 1.86648\tvalid_1's rmse: 48.7335\n",
      "[1530]\ttraining's rmse: 1.77665\tvalid_1's rmse: 48.7317\n",
      "[1560]\ttraining's rmse: 1.69337\tvalid_1's rmse: 48.7291\n",
      "[1590]\ttraining's rmse: 1.61172\tvalid_1's rmse: 48.7286\n",
      "[1620]\ttraining's rmse: 1.5368\tvalid_1's rmse: 48.7233\n",
      "[1650]\ttraining's rmse: 1.46227\tvalid_1's rmse: 48.7193\n",
      "[1680]\ttraining's rmse: 1.39575\tvalid_1's rmse: 48.7183\n",
      "[1710]\ttraining's rmse: 1.33037\tvalid_1's rmse: 48.7145\n",
      "[1740]\ttraining's rmse: 1.27023\tvalid_1's rmse: 48.7116\n",
      "[1770]\ttraining's rmse: 1.21009\tvalid_1's rmse: 48.7089\n",
      "[1800]\ttraining's rmse: 1.15527\tvalid_1's rmse: 48.7081\n",
      "[1830]\ttraining's rmse: 1.10148\tvalid_1's rmse: 48.7076\n",
      "[1860]\ttraining's rmse: 1.05027\tvalid_1's rmse: 48.7064\n",
      "[1890]\ttraining's rmse: 1.00179\tvalid_1's rmse: 48.7046\n",
      "[1920]\ttraining's rmse: 0.954714\tvalid_1's rmse: 48.7024\n",
      "[1950]\ttraining's rmse: 0.912131\tvalid_1's rmse: 48.7012\n",
      "[1980]\ttraining's rmse: 0.87115\tvalid_1's rmse: 48.698\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's rmse: 0.845995\tvalid_1's rmse: 48.6973\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002387 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 20022\n",
      "[LightGBM] [Info] Number of data points in the train set: 9219, number of used features: 79\n",
      "[LightGBM] [Info] Start training from score 362.563081\n",
      "Training until validation scores don't improve for 125 rounds\n",
      "[30]\ttraining's rmse: 149.125\tvalid_1's rmse: 152.643\n",
      "[60]\ttraining's rmse: 93.995\tvalid_1's rmse: 106.537\n",
      "[90]\ttraining's rmse: 64.1045\tvalid_1's rmse: 83.8223\n",
      "[120]\ttraining's rmse: 47.6701\tvalid_1's rmse: 72.9625\n",
      "[150]\ttraining's rmse: 38.4208\tvalid_1's rmse: 67.3156\n",
      "[180]\ttraining's rmse: 32.7054\tvalid_1's rmse: 64.0019\n",
      "[210]\ttraining's rmse: 28.7085\tvalid_1's rmse: 61.995\n",
      "[240]\ttraining's rmse: 25.6091\tvalid_1's rmse: 60.4898\n",
      "[270]\ttraining's rmse: 23.1018\tvalid_1's rmse: 59.4356\n",
      "[300]\ttraining's rmse: 20.9869\tvalid_1's rmse: 58.6604\n",
      "[330]\ttraining's rmse: 19.2303\tvalid_1's rmse: 58.1241\n",
      "[360]\ttraining's rmse: 17.6832\tvalid_1's rmse: 57.7698\n",
      "[390]\ttraining's rmse: 16.3224\tvalid_1's rmse: 57.4662\n",
      "[420]\ttraining's rmse: 15.1324\tvalid_1's rmse: 57.2431\n",
      "[450]\ttraining's rmse: 14.0173\tvalid_1's rmse: 57.0646\n",
      "[480]\ttraining's rmse: 13.0211\tvalid_1's rmse: 56.9123\n",
      "[510]\ttraining's rmse: 12.1451\tvalid_1's rmse: 56.7443\n",
      "[540]\ttraining's rmse: 11.3337\tvalid_1's rmse: 56.633\n",
      "[570]\ttraining's rmse: 10.6144\tvalid_1's rmse: 56.5076\n",
      "[600]\ttraining's rmse: 9.93151\tvalid_1's rmse: 56.4136\n",
      "[630]\ttraining's rmse: 9.315\tvalid_1's rmse: 56.3158\n",
      "[660]\ttraining's rmse: 8.75301\tvalid_1's rmse: 56.2466\n",
      "[690]\ttraining's rmse: 8.20946\tvalid_1's rmse: 56.1852\n",
      "[720]\ttraining's rmse: 7.71051\tvalid_1's rmse: 56.1208\n",
      "[750]\ttraining's rmse: 7.25298\tvalid_1's rmse: 56.0683\n",
      "[780]\ttraining's rmse: 6.81676\tvalid_1's rmse: 56.0273\n",
      "[810]\ttraining's rmse: 6.42729\tvalid_1's rmse: 55.9783\n",
      "[840]\ttraining's rmse: 6.05828\tvalid_1's rmse: 55.947\n",
      "[870]\ttraining's rmse: 5.71596\tvalid_1's rmse: 55.9072\n",
      "[900]\ttraining's rmse: 5.38956\tvalid_1's rmse: 55.8639\n",
      "[930]\ttraining's rmse: 5.09425\tvalid_1's rmse: 55.8546\n",
      "[960]\ttraining's rmse: 4.82536\tvalid_1's rmse: 55.8359\n",
      "[990]\ttraining's rmse: 4.56996\tvalid_1's rmse: 55.8202\n",
      "[1020]\ttraining's rmse: 4.33173\tvalid_1's rmse: 55.8099\n",
      "[1050]\ttraining's rmse: 4.10491\tvalid_1's rmse: 55.7956\n",
      "[1080]\ttraining's rmse: 3.88414\tvalid_1's rmse: 55.7867\n",
      "[1110]\ttraining's rmse: 3.68203\tvalid_1's rmse: 55.781\n",
      "[1140]\ttraining's rmse: 3.49223\tvalid_1's rmse: 55.7731\n",
      "[1170]\ttraining's rmse: 3.31243\tvalid_1's rmse: 55.7635\n",
      "[1200]\ttraining's rmse: 3.14275\tvalid_1's rmse: 55.7555\n",
      "[1230]\ttraining's rmse: 2.98576\tvalid_1's rmse: 55.7432\n",
      "[1260]\ttraining's rmse: 2.83353\tvalid_1's rmse: 55.7342\n",
      "[1290]\ttraining's rmse: 2.68925\tvalid_1's rmse: 55.7196\n",
      "[1320]\ttraining's rmse: 2.5534\tvalid_1's rmse: 55.7126\n",
      "[1350]\ttraining's rmse: 2.42663\tvalid_1's rmse: 55.7054\n",
      "[1380]\ttraining's rmse: 2.30657\tvalid_1's rmse: 55.7004\n",
      "[1410]\ttraining's rmse: 2.19354\tvalid_1's rmse: 55.6917\n",
      "[1440]\ttraining's rmse: 2.08598\tvalid_1's rmse: 55.6826\n",
      "[1470]\ttraining's rmse: 1.98694\tvalid_1's rmse: 55.6824\n",
      "[1500]\ttraining's rmse: 1.88966\tvalid_1's rmse: 55.6819\n",
      "[1530]\ttraining's rmse: 1.79961\tvalid_1's rmse: 55.6808\n",
      "[1560]\ttraining's rmse: 1.7126\tvalid_1's rmse: 55.6756\n",
      "[1590]\ttraining's rmse: 1.63129\tvalid_1's rmse: 55.6745\n",
      "[1620]\ttraining's rmse: 1.55517\tvalid_1's rmse: 55.6722\n",
      "[1650]\ttraining's rmse: 1.48141\tvalid_1's rmse: 55.6671\n",
      "[1680]\ttraining's rmse: 1.41244\tvalid_1's rmse: 55.6635\n",
      "[1710]\ttraining's rmse: 1.34747\tvalid_1's rmse: 55.6597\n",
      "[1740]\ttraining's rmse: 1.28506\tvalid_1's rmse: 55.6561\n",
      "[1770]\ttraining's rmse: 1.22798\tvalid_1's rmse: 55.6541\n",
      "[1800]\ttraining's rmse: 1.17277\tvalid_1's rmse: 55.6539\n",
      "[1830]\ttraining's rmse: 1.11719\tvalid_1's rmse: 55.6523\n",
      "[1860]\ttraining's rmse: 1.06722\tvalid_1's rmse: 55.6468\n",
      "[1890]\ttraining's rmse: 1.01898\tvalid_1's rmse: 55.6468\n",
      "[1920]\ttraining's rmse: 0.973493\tvalid_1's rmse: 55.645\n",
      "[1950]\ttraining's rmse: 0.931694\tvalid_1's rmse: 55.6429\n",
      "[1980]\ttraining's rmse: 0.889908\tvalid_1's rmse: 55.6427\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's rmse: 0.862948\tvalid_1's rmse: 55.6413\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002816 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 20022\n",
      "[LightGBM] [Info] Number of data points in the train set: 9219, number of used features: 79\n",
      "[LightGBM] [Info] Start training from score 362.962657\n",
      "Training until validation scores don't improve for 125 rounds\n",
      "[30]\ttraining's rmse: 149.303\tvalid_1's rmse: 153.616\n",
      "[60]\ttraining's rmse: 94.6777\tvalid_1's rmse: 107.156\n",
      "[90]\ttraining's rmse: 65.0098\tvalid_1's rmse: 84.2608\n",
      "[120]\ttraining's rmse: 48.4258\tvalid_1's rmse: 72.9783\n",
      "[150]\ttraining's rmse: 39.0527\tvalid_1's rmse: 67.3801\n",
      "[180]\ttraining's rmse: 33.1876\tvalid_1's rmse: 64.1951\n",
      "[210]\ttraining's rmse: 29.0025\tvalid_1's rmse: 62.2347\n",
      "[240]\ttraining's rmse: 25.7858\tvalid_1's rmse: 60.8856\n",
      "[270]\ttraining's rmse: 23.192\tvalid_1's rmse: 59.9119\n",
      "[300]\ttraining's rmse: 21.0723\tvalid_1's rmse: 59.2371\n",
      "[330]\ttraining's rmse: 19.2827\tvalid_1's rmse: 58.7701\n",
      "[360]\ttraining's rmse: 17.7278\tvalid_1's rmse: 58.4276\n",
      "[390]\ttraining's rmse: 16.3512\tvalid_1's rmse: 58.1303\n",
      "[420]\ttraining's rmse: 15.1377\tvalid_1's rmse: 57.903\n",
      "[450]\ttraining's rmse: 14.028\tvalid_1's rmse: 57.6832\n",
      "[480]\ttraining's rmse: 13.0319\tvalid_1's rmse: 57.5016\n",
      "[510]\ttraining's rmse: 12.1407\tvalid_1's rmse: 57.3967\n",
      "[540]\ttraining's rmse: 11.3452\tvalid_1's rmse: 57.3133\n",
      "[570]\ttraining's rmse: 10.5854\tvalid_1's rmse: 57.2188\n",
      "[600]\ttraining's rmse: 9.88427\tvalid_1's rmse: 57.1464\n",
      "[630]\ttraining's rmse: 9.25196\tvalid_1's rmse: 57.0706\n",
      "[660]\ttraining's rmse: 8.67858\tvalid_1's rmse: 57.0162\n",
      "[690]\ttraining's rmse: 8.14563\tvalid_1's rmse: 56.96\n",
      "[720]\ttraining's rmse: 7.65062\tvalid_1's rmse: 56.9151\n",
      "[750]\ttraining's rmse: 7.19744\tvalid_1's rmse: 56.8673\n",
      "[780]\ttraining's rmse: 6.77416\tvalid_1's rmse: 56.8378\n",
      "[810]\ttraining's rmse: 6.3697\tvalid_1's rmse: 56.807\n",
      "[840]\ttraining's rmse: 6.00523\tvalid_1's rmse: 56.7753\n",
      "[870]\ttraining's rmse: 5.66326\tvalid_1's rmse: 56.7428\n",
      "[900]\ttraining's rmse: 5.34224\tvalid_1's rmse: 56.7043\n",
      "[930]\ttraining's rmse: 5.03746\tvalid_1's rmse: 56.678\n",
      "[960]\ttraining's rmse: 4.75843\tvalid_1's rmse: 56.6521\n",
      "[990]\ttraining's rmse: 4.49259\tvalid_1's rmse: 56.634\n",
      "[1020]\ttraining's rmse: 4.24985\tvalid_1's rmse: 56.617\n",
      "[1050]\ttraining's rmse: 4.01849\tvalid_1's rmse: 56.6008\n",
      "[1080]\ttraining's rmse: 3.8031\tvalid_1's rmse: 56.5893\n",
      "[1110]\ttraining's rmse: 3.5997\tvalid_1's rmse: 56.5757\n",
      "[1140]\ttraining's rmse: 3.40839\tvalid_1's rmse: 56.5644\n",
      "[1170]\ttraining's rmse: 3.22962\tvalid_1's rmse: 56.5534\n",
      "[1200]\ttraining's rmse: 3.06021\tvalid_1's rmse: 56.5458\n",
      "[1230]\ttraining's rmse: 2.90381\tvalid_1's rmse: 56.5419\n",
      "[1260]\ttraining's rmse: 2.75559\tvalid_1's rmse: 56.5306\n",
      "[1290]\ttraining's rmse: 2.61272\tvalid_1's rmse: 56.5253\n",
      "[1320]\ttraining's rmse: 2.48182\tvalid_1's rmse: 56.5191\n",
      "[1350]\ttraining's rmse: 2.35846\tvalid_1's rmse: 56.5122\n",
      "[1380]\ttraining's rmse: 2.24315\tvalid_1's rmse: 56.5065\n",
      "[1410]\ttraining's rmse: 2.12908\tvalid_1's rmse: 56.5004\n",
      "[1440]\ttraining's rmse: 2.02375\tvalid_1's rmse: 56.4934\n",
      "[1470]\ttraining's rmse: 1.92095\tvalid_1's rmse: 56.4893\n",
      "[1500]\ttraining's rmse: 1.82667\tvalid_1's rmse: 56.485\n",
      "[1530]\ttraining's rmse: 1.73965\tvalid_1's rmse: 56.4816\n",
      "[1560]\ttraining's rmse: 1.6558\tvalid_1's rmse: 56.4799\n",
      "[1590]\ttraining's rmse: 1.57431\tvalid_1's rmse: 56.4743\n",
      "[1620]\ttraining's rmse: 1.49875\tvalid_1's rmse: 56.4687\n",
      "[1650]\ttraining's rmse: 1.42596\tvalid_1's rmse: 56.4667\n",
      "[1680]\ttraining's rmse: 1.35656\tvalid_1's rmse: 56.4634\n",
      "[1710]\ttraining's rmse: 1.29064\tvalid_1's rmse: 56.4602\n",
      "[1740]\ttraining's rmse: 1.22874\tvalid_1's rmse: 56.4611\n",
      "[1770]\ttraining's rmse: 1.17317\tvalid_1's rmse: 56.4598\n",
      "[1800]\ttraining's rmse: 1.1179\tvalid_1's rmse: 56.4582\n",
      "[1830]\ttraining's rmse: 1.06505\tvalid_1's rmse: 56.4549\n",
      "[1860]\ttraining's rmse: 1.0144\tvalid_1's rmse: 56.4556\n",
      "[1890]\ttraining's rmse: 0.966606\tvalid_1's rmse: 56.4555\n",
      "[1920]\ttraining's rmse: 0.921674\tvalid_1's rmse: 56.4527\n",
      "[1950]\ttraining's rmse: 0.878576\tvalid_1's rmse: 56.4515\n",
      "[1980]\ttraining's rmse: 0.838717\tvalid_1's rmse: 56.45\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's rmse: 0.812452\tvalid_1's rmse: 56.4488\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003785 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 20022\n",
      "[LightGBM] [Info] Number of data points in the train set: 9219, number of used features: 79\n",
      "[LightGBM] [Info] Start training from score 361.838953\n",
      "Training until validation scores don't improve for 125 rounds\n",
      "[30]\ttraining's rmse: 150.116\tvalid_1's rmse: 153.323\n",
      "[60]\ttraining's rmse: 95.7195\tvalid_1's rmse: 105.254\n",
      "[90]\ttraining's rmse: 65.9852\tvalid_1's rmse: 81.2502\n",
      "[120]\ttraining's rmse: 49.5092\tvalid_1's rmse: 69.2032\n",
      "[150]\ttraining's rmse: 40.0148\tvalid_1's rmse: 63.1479\n",
      "[180]\ttraining's rmse: 33.9952\tvalid_1's rmse: 59.8378\n",
      "[210]\ttraining's rmse: 29.7046\tvalid_1's rmse: 57.7927\n",
      "[240]\ttraining's rmse: 26.3299\tvalid_1's rmse: 56.5038\n",
      "[270]\ttraining's rmse: 23.6426\tvalid_1's rmse: 55.5716\n",
      "[300]\ttraining's rmse: 21.4236\tvalid_1's rmse: 54.9045\n",
      "[330]\ttraining's rmse: 19.586\tvalid_1's rmse: 54.5173\n",
      "[360]\ttraining's rmse: 18.0037\tvalid_1's rmse: 54.1898\n",
      "[390]\ttraining's rmse: 16.6214\tvalid_1's rmse: 53.9197\n",
      "[420]\ttraining's rmse: 15.3562\tvalid_1's rmse: 53.6945\n",
      "[450]\ttraining's rmse: 14.2354\tvalid_1's rmse: 53.5377\n",
      "[480]\ttraining's rmse: 13.2122\tvalid_1's rmse: 53.4076\n",
      "[510]\ttraining's rmse: 12.2864\tvalid_1's rmse: 53.2779\n",
      "[540]\ttraining's rmse: 11.4596\tvalid_1's rmse: 53.1654\n",
      "[570]\ttraining's rmse: 10.7115\tvalid_1's rmse: 53.0748\n",
      "[600]\ttraining's rmse: 10.0242\tvalid_1's rmse: 52.9985\n",
      "[630]\ttraining's rmse: 9.38574\tvalid_1's rmse: 52.9212\n",
      "[660]\ttraining's rmse: 8.80215\tvalid_1's rmse: 52.8646\n",
      "[690]\ttraining's rmse: 8.26477\tvalid_1's rmse: 52.8349\n",
      "[720]\ttraining's rmse: 7.76748\tvalid_1's rmse: 52.7891\n",
      "[750]\ttraining's rmse: 7.30995\tvalid_1's rmse: 52.7625\n",
      "[780]\ttraining's rmse: 6.88212\tvalid_1's rmse: 52.7402\n",
      "[810]\ttraining's rmse: 6.48525\tvalid_1's rmse: 52.726\n",
      "[840]\ttraining's rmse: 6.11191\tvalid_1's rmse: 52.7028\n",
      "[870]\ttraining's rmse: 5.77157\tvalid_1's rmse: 52.6624\n",
      "[900]\ttraining's rmse: 5.45708\tvalid_1's rmse: 52.6477\n",
      "[930]\ttraining's rmse: 5.16108\tvalid_1's rmse: 52.6249\n",
      "[960]\ttraining's rmse: 4.86786\tvalid_1's rmse: 52.6092\n",
      "[990]\ttraining's rmse: 4.60722\tvalid_1's rmse: 52.6001\n",
      "[1020]\ttraining's rmse: 4.35914\tvalid_1's rmse: 52.586\n",
      "[1050]\ttraining's rmse: 4.12924\tvalid_1's rmse: 52.5738\n",
      "[1080]\ttraining's rmse: 3.90877\tvalid_1's rmse: 52.5588\n",
      "[1110]\ttraining's rmse: 3.70742\tvalid_1's rmse: 52.5533\n",
      "[1140]\ttraining's rmse: 3.5176\tvalid_1's rmse: 52.5439\n",
      "[1170]\ttraining's rmse: 3.33521\tvalid_1's rmse: 52.5348\n",
      "[1200]\ttraining's rmse: 3.16764\tvalid_1's rmse: 52.536\n",
      "[1230]\ttraining's rmse: 3.00915\tvalid_1's rmse: 52.5255\n",
      "[1260]\ttraining's rmse: 2.85397\tvalid_1's rmse: 52.5194\n",
      "[1290]\ttraining's rmse: 2.7105\tvalid_1's rmse: 52.5132\n",
      "[1320]\ttraining's rmse: 2.57515\tvalid_1's rmse: 52.5077\n",
      "[1350]\ttraining's rmse: 2.44914\tvalid_1's rmse: 52.498\n",
      "[1380]\ttraining's rmse: 2.32747\tvalid_1's rmse: 52.4924\n",
      "[1410]\ttraining's rmse: 2.21264\tvalid_1's rmse: 52.4908\n",
      "[1440]\ttraining's rmse: 2.1056\tvalid_1's rmse: 52.4886\n",
      "[1470]\ttraining's rmse: 2.00258\tvalid_1's rmse: 52.4808\n",
      "[1500]\ttraining's rmse: 1.90489\tvalid_1's rmse: 52.478\n",
      "[1530]\ttraining's rmse: 1.81588\tvalid_1's rmse: 52.4783\n",
      "[1560]\ttraining's rmse: 1.7284\tvalid_1's rmse: 52.4777\n",
      "[1590]\ttraining's rmse: 1.64498\tvalid_1's rmse: 52.4764\n",
      "[1620]\ttraining's rmse: 1.56769\tvalid_1's rmse: 52.4741\n",
      "[1650]\ttraining's rmse: 1.4921\tvalid_1's rmse: 52.4727\n",
      "[1680]\ttraining's rmse: 1.42227\tvalid_1's rmse: 52.4714\n",
      "[1710]\ttraining's rmse: 1.35604\tvalid_1's rmse: 52.4703\n",
      "[1740]\ttraining's rmse: 1.29427\tvalid_1's rmse: 52.4705\n",
      "[1770]\ttraining's rmse: 1.23283\tvalid_1's rmse: 52.4695\n",
      "[1800]\ttraining's rmse: 1.17866\tvalid_1's rmse: 52.4675\n",
      "[1830]\ttraining's rmse: 1.12408\tvalid_1's rmse: 52.4669\n",
      "[1860]\ttraining's rmse: 1.07294\tvalid_1's rmse: 52.4631\n",
      "[1890]\ttraining's rmse: 1.02465\tvalid_1's rmse: 52.4627\n",
      "[1920]\ttraining's rmse: 0.977751\tvalid_1's rmse: 52.4628\n",
      "[1950]\ttraining's rmse: 0.933587\tvalid_1's rmse: 52.4629\n",
      "[1980]\ttraining's rmse: 0.890949\tvalid_1's rmse: 52.462\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's rmse: 0.864546\tvalid_1's rmse: 52.4598\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003349 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 20022\n",
      "[LightGBM] [Info] Number of data points in the train set: 9219, number of used features: 79\n",
      "[LightGBM] [Info] Start training from score 371.212692\n",
      "Training until validation scores don't improve for 125 rounds\n",
      "[30]\ttraining's rmse: 151.943\tvalid_1's rmse: 158.514\n",
      "[60]\ttraining's rmse: 95.8215\tvalid_1's rmse: 106.824\n",
      "[90]\ttraining's rmse: 65.5811\tvalid_1's rmse: 82.0069\n",
      "[120]\ttraining's rmse: 49.0665\tvalid_1's rmse: 69.9076\n",
      "[150]\ttraining's rmse: 39.638\tvalid_1's rmse: 63.8812\n",
      "[180]\ttraining's rmse: 33.7621\tvalid_1's rmse: 60.8212\n",
      "[210]\ttraining's rmse: 29.6134\tvalid_1's rmse: 58.9309\n",
      "[240]\ttraining's rmse: 26.4096\tvalid_1's rmse: 57.6772\n",
      "[270]\ttraining's rmse: 23.8092\tvalid_1's rmse: 56.8118\n",
      "[300]\ttraining's rmse: 21.6325\tvalid_1's rmse: 56.1705\n",
      "[330]\ttraining's rmse: 19.8341\tvalid_1's rmse: 55.791\n",
      "[360]\ttraining's rmse: 18.2137\tvalid_1's rmse: 55.4804\n",
      "[390]\ttraining's rmse: 16.7977\tvalid_1's rmse: 55.2304\n",
      "[420]\ttraining's rmse: 15.519\tvalid_1's rmse: 55.0007\n",
      "[450]\ttraining's rmse: 14.4066\tvalid_1's rmse: 54.8386\n",
      "[480]\ttraining's rmse: 13.3907\tvalid_1's rmse: 54.6853\n",
      "[510]\ttraining's rmse: 12.4675\tvalid_1's rmse: 54.5576\n",
      "[540]\ttraining's rmse: 11.6389\tvalid_1's rmse: 54.4349\n",
      "[570]\ttraining's rmse: 10.8653\tvalid_1's rmse: 54.3386\n",
      "[600]\ttraining's rmse: 10.1739\tvalid_1's rmse: 54.2617\n",
      "[630]\ttraining's rmse: 9.52887\tvalid_1's rmse: 54.2176\n",
      "[660]\ttraining's rmse: 8.94022\tvalid_1's rmse: 54.1605\n",
      "[690]\ttraining's rmse: 8.39155\tvalid_1's rmse: 54.0908\n",
      "[720]\ttraining's rmse: 7.88202\tvalid_1's rmse: 54.0399\n",
      "[750]\ttraining's rmse: 7.40518\tvalid_1's rmse: 53.9941\n",
      "[780]\ttraining's rmse: 6.96024\tvalid_1's rmse: 53.9633\n",
      "[810]\ttraining's rmse: 6.5439\tvalid_1's rmse: 53.9297\n",
      "[840]\ttraining's rmse: 6.16468\tvalid_1's rmse: 53.9083\n",
      "[870]\ttraining's rmse: 5.80944\tvalid_1's rmse: 53.8774\n",
      "[900]\ttraining's rmse: 5.48395\tvalid_1's rmse: 53.8522\n",
      "[930]\ttraining's rmse: 5.17185\tvalid_1's rmse: 53.8324\n",
      "[960]\ttraining's rmse: 4.87813\tvalid_1's rmse: 53.8218\n",
      "[990]\ttraining's rmse: 4.60155\tvalid_1's rmse: 53.804\n",
      "[1020]\ttraining's rmse: 4.34371\tvalid_1's rmse: 53.7875\n",
      "[1050]\ttraining's rmse: 4.10743\tvalid_1's rmse: 53.7758\n",
      "[1080]\ttraining's rmse: 3.88413\tvalid_1's rmse: 53.758\n",
      "[1110]\ttraining's rmse: 3.67252\tvalid_1's rmse: 53.7457\n",
      "[1140]\ttraining's rmse: 3.4743\tvalid_1's rmse: 53.74\n",
      "[1170]\ttraining's rmse: 3.2874\tvalid_1's rmse: 53.7286\n",
      "[1200]\ttraining's rmse: 3.11333\tvalid_1's rmse: 53.7189\n",
      "[1230]\ttraining's rmse: 2.94654\tvalid_1's rmse: 53.7117\n",
      "[1260]\ttraining's rmse: 2.78847\tvalid_1's rmse: 53.7063\n",
      "[1290]\ttraining's rmse: 2.64317\tvalid_1's rmse: 53.6986\n",
      "[1320]\ttraining's rmse: 2.50483\tvalid_1's rmse: 53.6919\n",
      "[1350]\ttraining's rmse: 2.37379\tvalid_1's rmse: 53.6875\n",
      "[1380]\ttraining's rmse: 2.24921\tvalid_1's rmse: 53.6811\n",
      "[1410]\ttraining's rmse: 2.13046\tvalid_1's rmse: 53.6785\n",
      "[1440]\ttraining's rmse: 2.01855\tvalid_1's rmse: 53.6716\n",
      "[1470]\ttraining's rmse: 1.91434\tvalid_1's rmse: 53.6698\n",
      "[1500]\ttraining's rmse: 1.81725\tvalid_1's rmse: 53.6675\n",
      "[1530]\ttraining's rmse: 1.72462\tvalid_1's rmse: 53.6627\n",
      "[1560]\ttraining's rmse: 1.63723\tvalid_1's rmse: 53.6633\n",
      "[1590]\ttraining's rmse: 1.5542\tvalid_1's rmse: 53.6581\n",
      "[1620]\ttraining's rmse: 1.47589\tvalid_1's rmse: 53.6539\n",
      "[1650]\ttraining's rmse: 1.40205\tvalid_1's rmse: 53.648\n",
      "[1680]\ttraining's rmse: 1.33077\tvalid_1's rmse: 53.6449\n",
      "[1710]\ttraining's rmse: 1.26543\tvalid_1's rmse: 53.6437\n",
      "[1740]\ttraining's rmse: 1.20259\tvalid_1's rmse: 53.6445\n",
      "[1770]\ttraining's rmse: 1.14407\tvalid_1's rmse: 53.6423\n",
      "[1800]\ttraining's rmse: 1.08791\tvalid_1's rmse: 53.6408\n",
      "[1830]\ttraining's rmse: 1.03436\tvalid_1's rmse: 53.6392\n",
      "[1860]\ttraining's rmse: 0.982892\tvalid_1's rmse: 53.6378\n",
      "[1890]\ttraining's rmse: 0.934502\tvalid_1's rmse: 53.6362\n",
      "[1920]\ttraining's rmse: 0.889725\tvalid_1's rmse: 53.6341\n",
      "[1950]\ttraining's rmse: 0.846761\tvalid_1's rmse: 53.6332\n",
      "[1980]\ttraining's rmse: 0.805808\tvalid_1's rmse: 53.6315\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's rmse: 0.779795\tvalid_1's rmse: 53.6318\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002948 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 20022\n",
      "[LightGBM] [Info] Number of data points in the train set: 9219, number of used features: 79\n",
      "[LightGBM] [Info] Start training from score 374.524728\n",
      "Training until validation scores don't improve for 125 rounds\n",
      "[30]\ttraining's rmse: 152.183\tvalid_1's rmse: 164.682\n",
      "[60]\ttraining's rmse: 95.4867\tvalid_1's rmse: 110.926\n",
      "[90]\ttraining's rmse: 64.8911\tvalid_1's rmse: 84.835\n",
      "[120]\ttraining's rmse: 48.4529\tvalid_1's rmse: 72.5887\n",
      "[150]\ttraining's rmse: 39.0457\tvalid_1's rmse: 66.4513\n",
      "[180]\ttraining's rmse: 33.1834\tvalid_1's rmse: 63.0816\n",
      "[210]\ttraining's rmse: 29.0566\tvalid_1's rmse: 61.179\n",
      "[240]\ttraining's rmse: 25.9177\tvalid_1's rmse: 60.0686\n",
      "[270]\ttraining's rmse: 23.3349\tvalid_1's rmse: 59.2521\n",
      "[300]\ttraining's rmse: 21.2132\tvalid_1's rmse: 58.6016\n",
      "[330]\ttraining's rmse: 19.453\tvalid_1's rmse: 58.1508\n",
      "[360]\ttraining's rmse: 17.8746\tvalid_1's rmse: 57.8511\n",
      "[390]\ttraining's rmse: 16.4848\tvalid_1's rmse: 57.5657\n",
      "[420]\ttraining's rmse: 15.2539\tvalid_1's rmse: 57.3345\n",
      "[450]\ttraining's rmse: 14.1601\tvalid_1's rmse: 57.1347\n",
      "[480]\ttraining's rmse: 13.1498\tvalid_1's rmse: 56.9943\n",
      "[510]\ttraining's rmse: 12.2418\tvalid_1's rmse: 56.8764\n",
      "[540]\ttraining's rmse: 11.4083\tvalid_1's rmse: 56.7752\n",
      "[570]\ttraining's rmse: 10.6618\tvalid_1's rmse: 56.7037\n",
      "[600]\ttraining's rmse: 9.97872\tvalid_1's rmse: 56.6246\n",
      "[630]\ttraining's rmse: 9.33475\tvalid_1's rmse: 56.5629\n",
      "[660]\ttraining's rmse: 8.74663\tvalid_1's rmse: 56.4893\n",
      "[690]\ttraining's rmse: 8.19949\tvalid_1's rmse: 56.4146\n",
      "[720]\ttraining's rmse: 7.70249\tvalid_1's rmse: 56.3772\n",
      "[750]\ttraining's rmse: 7.24151\tvalid_1's rmse: 56.3191\n",
      "[780]\ttraining's rmse: 6.81372\tvalid_1's rmse: 56.2899\n",
      "[810]\ttraining's rmse: 6.4051\tvalid_1's rmse: 56.2598\n",
      "[840]\ttraining's rmse: 6.02733\tvalid_1's rmse: 56.2334\n",
      "[870]\ttraining's rmse: 5.6782\tvalid_1's rmse: 56.2072\n",
      "[900]\ttraining's rmse: 5.35214\tvalid_1's rmse: 56.1891\n",
      "[930]\ttraining's rmse: 5.04989\tvalid_1's rmse: 56.1656\n",
      "[960]\ttraining's rmse: 4.76092\tvalid_1's rmse: 56.1473\n",
      "[990]\ttraining's rmse: 4.49358\tvalid_1's rmse: 56.1375\n",
      "[1020]\ttraining's rmse: 4.24325\tvalid_1's rmse: 56.1192\n",
      "[1050]\ttraining's rmse: 4.01084\tvalid_1's rmse: 56.1066\n",
      "[1080]\ttraining's rmse: 3.79305\tvalid_1's rmse: 56.1007\n",
      "[1110]\ttraining's rmse: 3.58994\tvalid_1's rmse: 56.0882\n",
      "[1140]\ttraining's rmse: 3.39615\tvalid_1's rmse: 56.0794\n",
      "[1170]\ttraining's rmse: 3.21273\tvalid_1's rmse: 56.0722\n",
      "[1200]\ttraining's rmse: 3.04142\tvalid_1's rmse: 56.063\n",
      "[1230]\ttraining's rmse: 2.87797\tvalid_1's rmse: 56.0522\n",
      "[1260]\ttraining's rmse: 2.72703\tvalid_1's rmse: 56.0446\n",
      "[1290]\ttraining's rmse: 2.5807\tvalid_1's rmse: 56.0373\n",
      "[1320]\ttraining's rmse: 2.4446\tvalid_1's rmse: 56.0303\n",
      "[1350]\ttraining's rmse: 2.31582\tvalid_1's rmse: 56.0271\n",
      "[1380]\ttraining's rmse: 2.19568\tvalid_1's rmse: 56.0247\n",
      "[1410]\ttraining's rmse: 2.08216\tvalid_1's rmse: 56.022\n",
      "[1440]\ttraining's rmse: 1.97497\tvalid_1's rmse: 56.0186\n",
      "[1470]\ttraining's rmse: 1.8759\tvalid_1's rmse: 56.0169\n",
      "[1500]\ttraining's rmse: 1.78084\tvalid_1's rmse: 56.013\n",
      "[1530]\ttraining's rmse: 1.6921\tvalid_1's rmse: 56.0091\n",
      "[1560]\ttraining's rmse: 1.60693\tvalid_1's rmse: 56.0099\n",
      "[1590]\ttraining's rmse: 1.52528\tvalid_1's rmse: 56.0062\n",
      "[1620]\ttraining's rmse: 1.44863\tvalid_1's rmse: 56.0023\n",
      "[1650]\ttraining's rmse: 1.37484\tvalid_1's rmse: 55.9998\n",
      "[1680]\ttraining's rmse: 1.30634\tvalid_1's rmse: 55.9982\n",
      "[1710]\ttraining's rmse: 1.24173\tvalid_1's rmse: 55.9955\n",
      "[1740]\ttraining's rmse: 1.18066\tvalid_1's rmse: 55.9936\n",
      "[1770]\ttraining's rmse: 1.12186\tvalid_1's rmse: 55.9911\n",
      "[1800]\ttraining's rmse: 1.06808\tvalid_1's rmse: 55.9895\n",
      "[1830]\ttraining's rmse: 1.01525\tvalid_1's rmse: 55.9877\n",
      "[1860]\ttraining's rmse: 0.965078\tvalid_1's rmse: 55.9859\n",
      "[1890]\ttraining's rmse: 0.918088\tvalid_1's rmse: 55.9854\n",
      "[1920]\ttraining's rmse: 0.874756\tvalid_1's rmse: 55.9837\n",
      "[1950]\ttraining's rmse: 0.832305\tvalid_1's rmse: 55.982\n",
      "[1980]\ttraining's rmse: 0.79195\tvalid_1's rmse: 55.9802\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's rmse: 0.766111\tvalid_1's rmse: 55.9795\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002237 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 20022\n",
      "[LightGBM] [Info] Number of data points in the train set: 9219, number of used features: 79\n",
      "[LightGBM] [Info] Start training from score 369.377868\n",
      "Training until validation scores don't improve for 125 rounds\n",
      "[30]\ttraining's rmse: 153.687\tvalid_1's rmse: 160.506\n",
      "[60]\ttraining's rmse: 96.6229\tvalid_1's rmse: 108.489\n",
      "[90]\ttraining's rmse: 65.8141\tvalid_1's rmse: 83.0384\n",
      "[120]\ttraining's rmse: 48.974\tvalid_1's rmse: 70.8364\n",
      "[150]\ttraining's rmse: 39.4623\tvalid_1's rmse: 64.8025\n",
      "[180]\ttraining's rmse: 33.5808\tvalid_1's rmse: 61.6712\n",
      "[210]\ttraining's rmse: 29.4729\tvalid_1's rmse: 59.7678\n",
      "[240]\ttraining's rmse: 26.2824\tvalid_1's rmse: 58.6986\n",
      "[270]\ttraining's rmse: 23.7045\tvalid_1's rmse: 57.8867\n",
      "[300]\ttraining's rmse: 21.5783\tvalid_1's rmse: 57.3243\n",
      "[330]\ttraining's rmse: 19.7741\tvalid_1's rmse: 56.9276\n",
      "[360]\ttraining's rmse: 18.1946\tvalid_1's rmse: 56.6343\n",
      "[390]\ttraining's rmse: 16.7953\tvalid_1's rmse: 56.3995\n",
      "[420]\ttraining's rmse: 15.5502\tvalid_1's rmse: 56.1713\n",
      "[450]\ttraining's rmse: 14.409\tvalid_1's rmse: 56.0413\n",
      "[480]\ttraining's rmse: 13.3928\tvalid_1's rmse: 55.8784\n",
      "[510]\ttraining's rmse: 12.48\tvalid_1's rmse: 55.7876\n",
      "[540]\ttraining's rmse: 11.663\tvalid_1's rmse: 55.6542\n",
      "[570]\ttraining's rmse: 10.9028\tvalid_1's rmse: 55.534\n",
      "[600]\ttraining's rmse: 10.2212\tvalid_1's rmse: 55.4683\n",
      "[630]\ttraining's rmse: 9.58683\tvalid_1's rmse: 55.4\n",
      "[660]\ttraining's rmse: 8.98841\tvalid_1's rmse: 55.3319\n",
      "[690]\ttraining's rmse: 8.43348\tvalid_1's rmse: 55.275\n",
      "[720]\ttraining's rmse: 7.92509\tvalid_1's rmse: 55.226\n",
      "[750]\ttraining's rmse: 7.45221\tvalid_1's rmse: 55.1896\n",
      "[780]\ttraining's rmse: 7.01291\tvalid_1's rmse: 55.1573\n",
      "[810]\ttraining's rmse: 6.59926\tvalid_1's rmse: 55.1265\n",
      "[840]\ttraining's rmse: 6.22202\tvalid_1's rmse: 55.1082\n",
      "[870]\ttraining's rmse: 5.85633\tvalid_1's rmse: 55.0744\n",
      "[900]\ttraining's rmse: 5.52178\tvalid_1's rmse: 55.0439\n",
      "[930]\ttraining's rmse: 5.21646\tvalid_1's rmse: 55.0239\n",
      "[960]\ttraining's rmse: 4.92874\tvalid_1's rmse: 55.0017\n",
      "[990]\ttraining's rmse: 4.66433\tvalid_1's rmse: 54.9794\n",
      "[1020]\ttraining's rmse: 4.40782\tvalid_1's rmse: 54.9643\n",
      "[1050]\ttraining's rmse: 4.17202\tvalid_1's rmse: 54.9583\n",
      "[1080]\ttraining's rmse: 3.94767\tvalid_1's rmse: 54.9407\n",
      "[1110]\ttraining's rmse: 3.7389\tvalid_1's rmse: 54.9314\n",
      "[1140]\ttraining's rmse: 3.53841\tvalid_1's rmse: 54.9258\n",
      "[1170]\ttraining's rmse: 3.35248\tvalid_1's rmse: 54.911\n",
      "[1200]\ttraining's rmse: 3.17399\tvalid_1's rmse: 54.9023\n",
      "[1230]\ttraining's rmse: 3.00993\tvalid_1's rmse: 54.8957\n",
      "[1260]\ttraining's rmse: 2.85255\tvalid_1's rmse: 54.8837\n",
      "[1290]\ttraining's rmse: 2.70257\tvalid_1's rmse: 54.8805\n",
      "[1320]\ttraining's rmse: 2.56449\tvalid_1's rmse: 54.8725\n",
      "[1350]\ttraining's rmse: 2.43599\tvalid_1's rmse: 54.8631\n",
      "[1380]\ttraining's rmse: 2.30977\tvalid_1's rmse: 54.8534\n",
      "[1410]\ttraining's rmse: 2.1928\tvalid_1's rmse: 54.849\n",
      "[1440]\ttraining's rmse: 2.08447\tvalid_1's rmse: 54.845\n",
      "[1470]\ttraining's rmse: 1.97989\tvalid_1's rmse: 54.845\n",
      "[1500]\ttraining's rmse: 1.88165\tvalid_1's rmse: 54.8441\n",
      "[1530]\ttraining's rmse: 1.7921\tvalid_1's rmse: 54.8391\n",
      "[1560]\ttraining's rmse: 1.70648\tvalid_1's rmse: 54.8388\n",
      "[1590]\ttraining's rmse: 1.62377\tvalid_1's rmse: 54.8356\n",
      "[1620]\ttraining's rmse: 1.54757\tvalid_1's rmse: 54.8323\n",
      "[1650]\ttraining's rmse: 1.47366\tvalid_1's rmse: 54.827\n",
      "[1680]\ttraining's rmse: 1.40303\tvalid_1's rmse: 54.8287\n",
      "[1710]\ttraining's rmse: 1.33568\tvalid_1's rmse: 54.8248\n",
      "[1740]\ttraining's rmse: 1.27355\tvalid_1's rmse: 54.8234\n",
      "[1770]\ttraining's rmse: 1.21143\tvalid_1's rmse: 54.8203\n",
      "[1800]\ttraining's rmse: 1.15481\tvalid_1's rmse: 54.8186\n",
      "[1830]\ttraining's rmse: 1.10228\tvalid_1's rmse: 54.8158\n",
      "[1860]\ttraining's rmse: 1.05008\tvalid_1's rmse: 54.8146\n",
      "[1890]\ttraining's rmse: 1.0012\tvalid_1's rmse: 54.8118\n",
      "[1920]\ttraining's rmse: 0.955443\tvalid_1's rmse: 54.8119\n",
      "[1950]\ttraining's rmse: 0.912445\tvalid_1's rmse: 54.8105\n",
      "[1980]\ttraining's rmse: 0.87105\tvalid_1's rmse: 54.809\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's rmse: 0.844145\tvalid_1's rmse: 54.8081\n",
      "33\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002990 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 20021\n",
      "[LightGBM] [Info] Number of data points in the train set: 9219, number of used features: 79\n",
      "[LightGBM] [Info] Start training from score 368.107116\n",
      "Training until validation scores don't improve for 125 rounds\n",
      "[30]\ttraining's rmse: 146.531\tvalid_1's rmse: 150.363\n",
      "[60]\ttraining's rmse: 91.6233\tvalid_1's rmse: 101.711\n",
      "[90]\ttraining's rmse: 61.8137\tvalid_1's rmse: 77.8233\n",
      "[120]\ttraining's rmse: 45.7911\tvalid_1's rmse: 66.8653\n",
      "[150]\ttraining's rmse: 36.7087\tvalid_1's rmse: 61.6034\n",
      "[180]\ttraining's rmse: 31.1454\tvalid_1's rmse: 58.9794\n",
      "[210]\ttraining's rmse: 27.2809\tvalid_1's rmse: 57.3357\n",
      "[240]\ttraining's rmse: 24.2987\tvalid_1's rmse: 56.1553\n",
      "[270]\ttraining's rmse: 21.8707\tvalid_1's rmse: 55.2921\n",
      "[300]\ttraining's rmse: 19.9333\tvalid_1's rmse: 54.7398\n",
      "[330]\ttraining's rmse: 18.2972\tvalid_1's rmse: 54.3718\n",
      "[360]\ttraining's rmse: 16.8528\tvalid_1's rmse: 54.0987\n",
      "[390]\ttraining's rmse: 15.5526\tvalid_1's rmse: 53.804\n",
      "[420]\ttraining's rmse: 14.4006\tvalid_1's rmse: 53.5837\n",
      "[450]\ttraining's rmse: 13.3763\tvalid_1's rmse: 53.4482\n",
      "[480]\ttraining's rmse: 12.432\tvalid_1's rmse: 53.3212\n",
      "[510]\ttraining's rmse: 11.6168\tvalid_1's rmse: 53.1787\n",
      "[540]\ttraining's rmse: 10.8585\tvalid_1's rmse: 53.117\n",
      "[570]\ttraining's rmse: 10.1575\tvalid_1's rmse: 53.0602\n",
      "[600]\ttraining's rmse: 9.5081\tvalid_1's rmse: 52.9607\n",
      "[630]\ttraining's rmse: 8.91888\tvalid_1's rmse: 52.9261\n",
      "[660]\ttraining's rmse: 8.35358\tvalid_1's rmse: 52.868\n",
      "[690]\ttraining's rmse: 7.85299\tvalid_1's rmse: 52.8229\n",
      "[720]\ttraining's rmse: 7.36505\tvalid_1's rmse: 52.7761\n",
      "[750]\ttraining's rmse: 6.92859\tvalid_1's rmse: 52.7458\n",
      "[780]\ttraining's rmse: 6.5235\tvalid_1's rmse: 52.7151\n",
      "[810]\ttraining's rmse: 6.15346\tvalid_1's rmse: 52.6953\n",
      "[840]\ttraining's rmse: 5.80737\tvalid_1's rmse: 52.6733\n",
      "[870]\ttraining's rmse: 5.47861\tvalid_1's rmse: 52.6371\n",
      "[900]\ttraining's rmse: 5.17393\tvalid_1's rmse: 52.6094\n",
      "[930]\ttraining's rmse: 4.88711\tvalid_1's rmse: 52.5892\n",
      "[960]\ttraining's rmse: 4.62025\tvalid_1's rmse: 52.5795\n",
      "[990]\ttraining's rmse: 4.36387\tvalid_1's rmse: 52.5601\n",
      "[1020]\ttraining's rmse: 4.12684\tvalid_1's rmse: 52.542\n",
      "[1050]\ttraining's rmse: 3.90828\tvalid_1's rmse: 52.5352\n",
      "[1080]\ttraining's rmse: 3.69933\tvalid_1's rmse: 52.5233\n",
      "[1110]\ttraining's rmse: 3.50603\tvalid_1's rmse: 52.5173\n",
      "[1140]\ttraining's rmse: 3.32285\tvalid_1's rmse: 52.5004\n",
      "[1170]\ttraining's rmse: 3.15026\tvalid_1's rmse: 52.5003\n",
      "[1200]\ttraining's rmse: 2.98686\tvalid_1's rmse: 52.4936\n",
      "[1230]\ttraining's rmse: 2.83647\tvalid_1's rmse: 52.488\n",
      "[1260]\ttraining's rmse: 2.69087\tvalid_1's rmse: 52.4819\n",
      "[1290]\ttraining's rmse: 2.55577\tvalid_1's rmse: 52.4712\n",
      "[1320]\ttraining's rmse: 2.42757\tvalid_1's rmse: 52.4651\n",
      "[1350]\ttraining's rmse: 2.30635\tvalid_1's rmse: 52.459\n",
      "[1380]\ttraining's rmse: 2.19378\tvalid_1's rmse: 52.4551\n",
      "[1410]\ttraining's rmse: 2.08493\tvalid_1's rmse: 52.4551\n",
      "[1440]\ttraining's rmse: 1.98341\tvalid_1's rmse: 52.4529\n",
      "[1470]\ttraining's rmse: 1.88487\tvalid_1's rmse: 52.4505\n",
      "[1500]\ttraining's rmse: 1.79478\tvalid_1's rmse: 52.446\n",
      "[1530]\ttraining's rmse: 1.70636\tvalid_1's rmse: 52.443\n",
      "[1560]\ttraining's rmse: 1.62229\tvalid_1's rmse: 52.4382\n",
      "[1590]\ttraining's rmse: 1.54527\tvalid_1's rmse: 52.4386\n",
      "[1620]\ttraining's rmse: 1.47131\tvalid_1's rmse: 52.4334\n",
      "[1650]\ttraining's rmse: 1.40095\tvalid_1's rmse: 52.4283\n",
      "[1680]\ttraining's rmse: 1.33705\tvalid_1's rmse: 52.4244\n",
      "[1710]\ttraining's rmse: 1.27111\tvalid_1's rmse: 52.4219\n",
      "[1740]\ttraining's rmse: 1.21174\tvalid_1's rmse: 52.4195\n",
      "[1770]\ttraining's rmse: 1.15478\tvalid_1's rmse: 52.4182\n",
      "[1800]\ttraining's rmse: 1.10003\tvalid_1's rmse: 52.4181\n",
      "[1830]\ttraining's rmse: 1.04942\tvalid_1's rmse: 52.4142\n",
      "[1860]\ttraining's rmse: 1.00117\tvalid_1's rmse: 52.4134\n",
      "[1890]\ttraining's rmse: 0.955535\tvalid_1's rmse: 52.4124\n",
      "[1920]\ttraining's rmse: 0.912567\tvalid_1's rmse: 52.4114\n",
      "[1950]\ttraining's rmse: 0.87249\tvalid_1's rmse: 52.409\n",
      "[1980]\ttraining's rmse: 0.832031\tvalid_1's rmse: 52.4071\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's rmse: 0.806785\tvalid_1's rmse: 52.4065\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003025 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 20021\n",
      "[LightGBM] [Info] Number of data points in the train set: 9219, number of used features: 79\n",
      "[LightGBM] [Info] Start training from score 370.838451\n",
      "Training until validation scores don't improve for 125 rounds\n",
      "[30]\ttraining's rmse: 148.483\tvalid_1's rmse: 150.681\n",
      "[60]\ttraining's rmse: 94.2542\tvalid_1's rmse: 104.603\n",
      "[90]\ttraining's rmse: 64.7416\tvalid_1's rmse: 82.0092\n",
      "[120]\ttraining's rmse: 48.2449\tvalid_1's rmse: 71.0975\n",
      "[150]\ttraining's rmse: 38.8897\tvalid_1's rmse: 65.493\n",
      "[180]\ttraining's rmse: 32.9916\tvalid_1's rmse: 62.2546\n",
      "[210]\ttraining's rmse: 28.9021\tvalid_1's rmse: 60.3891\n",
      "[240]\ttraining's rmse: 25.7242\tvalid_1's rmse: 59.1089\n",
      "[270]\ttraining's rmse: 23.1862\tvalid_1's rmse: 58.2817\n",
      "[300]\ttraining's rmse: 21.0702\tvalid_1's rmse: 57.6583\n",
      "[330]\ttraining's rmse: 19.3113\tvalid_1's rmse: 57.1742\n",
      "[360]\ttraining's rmse: 17.7744\tvalid_1's rmse: 56.8436\n",
      "[390]\ttraining's rmse: 16.4322\tvalid_1's rmse: 56.6354\n",
      "[420]\ttraining's rmse: 15.2376\tvalid_1's rmse: 56.4502\n",
      "[450]\ttraining's rmse: 14.1552\tvalid_1's rmse: 56.2933\n",
      "[480]\ttraining's rmse: 13.1678\tvalid_1's rmse: 56.1561\n",
      "[510]\ttraining's rmse: 12.2713\tvalid_1's rmse: 55.9936\n",
      "[540]\ttraining's rmse: 11.4585\tvalid_1's rmse: 55.892\n",
      "[570]\ttraining's rmse: 10.7204\tvalid_1's rmse: 55.8124\n",
      "[600]\ttraining's rmse: 10.0305\tvalid_1's rmse: 55.7211\n",
      "[630]\ttraining's rmse: 9.39681\tvalid_1's rmse: 55.636\n",
      "[660]\ttraining's rmse: 8.80885\tvalid_1's rmse: 55.5786\n",
      "[690]\ttraining's rmse: 8.25936\tvalid_1's rmse: 55.5321\n",
      "[720]\ttraining's rmse: 7.75461\tvalid_1's rmse: 55.4704\n",
      "[750]\ttraining's rmse: 7.288\tvalid_1's rmse: 55.4387\n",
      "[780]\ttraining's rmse: 6.85126\tvalid_1's rmse: 55.391\n",
      "[810]\ttraining's rmse: 6.44856\tvalid_1's rmse: 55.3632\n",
      "[840]\ttraining's rmse: 6.072\tvalid_1's rmse: 55.3195\n",
      "[870]\ttraining's rmse: 5.72112\tvalid_1's rmse: 55.2845\n",
      "[900]\ttraining's rmse: 5.39364\tvalid_1's rmse: 55.2666\n",
      "[930]\ttraining's rmse: 5.07887\tvalid_1's rmse: 55.248\n",
      "[960]\ttraining's rmse: 4.79158\tvalid_1's rmse: 55.2253\n",
      "[990]\ttraining's rmse: 4.5239\tvalid_1's rmse: 55.2083\n",
      "[1020]\ttraining's rmse: 4.27623\tvalid_1's rmse: 55.1943\n",
      "[1050]\ttraining's rmse: 4.04037\tvalid_1's rmse: 55.1782\n",
      "[1080]\ttraining's rmse: 3.82121\tvalid_1's rmse: 55.1654\n",
      "[1110]\ttraining's rmse: 3.61777\tvalid_1's rmse: 55.1623\n",
      "[1140]\ttraining's rmse: 3.42533\tvalid_1's rmse: 55.1496\n",
      "[1170]\ttraining's rmse: 3.24171\tvalid_1's rmse: 55.1432\n",
      "[1200]\ttraining's rmse: 3.06697\tvalid_1's rmse: 55.1338\n",
      "[1230]\ttraining's rmse: 2.90295\tvalid_1's rmse: 55.1258\n",
      "[1260]\ttraining's rmse: 2.75149\tvalid_1's rmse: 55.1127\n",
      "[1290]\ttraining's rmse: 2.60862\tvalid_1's rmse: 55.1085\n",
      "[1320]\ttraining's rmse: 2.47118\tvalid_1's rmse: 55.1015\n",
      "[1350]\ttraining's rmse: 2.34375\tvalid_1's rmse: 55.0949\n",
      "[1380]\ttraining's rmse: 2.22333\tvalid_1's rmse: 55.0895\n",
      "[1410]\ttraining's rmse: 2.10918\tvalid_1's rmse: 55.0864\n",
      "[1440]\ttraining's rmse: 1.9993\tvalid_1's rmse: 55.083\n",
      "[1470]\ttraining's rmse: 1.89848\tvalid_1's rmse: 55.0771\n",
      "[1500]\ttraining's rmse: 1.80336\tvalid_1's rmse: 55.0743\n",
      "[1530]\ttraining's rmse: 1.71286\tvalid_1's rmse: 55.0698\n",
      "[1560]\ttraining's rmse: 1.62629\tvalid_1's rmse: 55.066\n",
      "[1590]\ttraining's rmse: 1.54498\tvalid_1's rmse: 55.064\n",
      "[1620]\ttraining's rmse: 1.46995\tvalid_1's rmse: 55.0641\n",
      "[1650]\ttraining's rmse: 1.3975\tvalid_1's rmse: 55.0614\n",
      "[1680]\ttraining's rmse: 1.32753\tvalid_1's rmse: 55.0593\n",
      "[1710]\ttraining's rmse: 1.26052\tvalid_1's rmse: 55.0562\n",
      "[1740]\ttraining's rmse: 1.19654\tvalid_1's rmse: 55.0534\n",
      "[1770]\ttraining's rmse: 1.13836\tvalid_1's rmse: 55.0487\n",
      "[1800]\ttraining's rmse: 1.08206\tvalid_1's rmse: 55.0455\n",
      "[1830]\ttraining's rmse: 1.02897\tvalid_1's rmse: 55.0431\n",
      "[1860]\ttraining's rmse: 0.979702\tvalid_1's rmse: 55.0422\n",
      "[1890]\ttraining's rmse: 0.932605\tvalid_1's rmse: 55.0405\n",
      "[1920]\ttraining's rmse: 0.887216\tvalid_1's rmse: 55.0393\n",
      "[1950]\ttraining's rmse: 0.845253\tvalid_1's rmse: 55.0374\n",
      "[1980]\ttraining's rmse: 0.80484\tvalid_1's rmse: 55.0359\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's rmse: 0.779093\tvalid_1's rmse: 55.0362\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003458 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 20021\n",
      "[LightGBM] [Info] Number of data points in the train set: 9219, number of used features: 79\n",
      "[LightGBM] [Info] Start training from score 367.363229\n",
      "Training until validation scores don't improve for 125 rounds\n",
      "[30]\ttraining's rmse: 149.736\tvalid_1's rmse: 153.491\n",
      "[60]\ttraining's rmse: 95.5314\tvalid_1's rmse: 104.238\n",
      "[90]\ttraining's rmse: 65.8092\tvalid_1's rmse: 79.219\n",
      "[120]\ttraining's rmse: 49.2717\tvalid_1's rmse: 66.8308\n",
      "[150]\ttraining's rmse: 39.6946\tvalid_1's rmse: 60.5516\n",
      "[180]\ttraining's rmse: 33.7373\tvalid_1's rmse: 57.3715\n",
      "[210]\ttraining's rmse: 29.5739\tvalid_1's rmse: 55.3577\n",
      "[240]\ttraining's rmse: 26.274\tvalid_1's rmse: 54.0856\n",
      "[270]\ttraining's rmse: 23.6531\tvalid_1's rmse: 53.1386\n",
      "[300]\ttraining's rmse: 21.4753\tvalid_1's rmse: 52.5051\n",
      "[330]\ttraining's rmse: 19.6536\tvalid_1's rmse: 52.092\n",
      "[360]\ttraining's rmse: 18.0519\tvalid_1's rmse: 51.7285\n",
      "[390]\ttraining's rmse: 16.6735\tvalid_1's rmse: 51.4981\n",
      "[420]\ttraining's rmse: 15.4562\tvalid_1's rmse: 51.267\n",
      "[450]\ttraining's rmse: 14.3512\tvalid_1's rmse: 51.1252\n",
      "[480]\ttraining's rmse: 13.3214\tvalid_1's rmse: 50.9856\n",
      "[510]\ttraining's rmse: 12.3927\tvalid_1's rmse: 50.8807\n",
      "[540]\ttraining's rmse: 11.5542\tvalid_1's rmse: 50.7339\n",
      "[570]\ttraining's rmse: 10.8055\tvalid_1's rmse: 50.6679\n",
      "[600]\ttraining's rmse: 10.1107\tvalid_1's rmse: 50.5524\n",
      "[630]\ttraining's rmse: 9.46706\tvalid_1's rmse: 50.4968\n",
      "[660]\ttraining's rmse: 8.87963\tvalid_1's rmse: 50.4376\n",
      "[690]\ttraining's rmse: 8.33003\tvalid_1's rmse: 50.3825\n",
      "[720]\ttraining's rmse: 7.82061\tvalid_1's rmse: 50.3248\n",
      "[750]\ttraining's rmse: 7.35113\tvalid_1's rmse: 50.2744\n",
      "[780]\ttraining's rmse: 6.92901\tvalid_1's rmse: 50.2346\n",
      "[810]\ttraining's rmse: 6.53234\tvalid_1's rmse: 50.2052\n",
      "[840]\ttraining's rmse: 6.16198\tvalid_1's rmse: 50.1758\n",
      "[870]\ttraining's rmse: 5.80765\tvalid_1's rmse: 50.1403\n",
      "[900]\ttraining's rmse: 5.48164\tvalid_1's rmse: 50.1136\n",
      "[930]\ttraining's rmse: 5.17587\tvalid_1's rmse: 50.097\n",
      "[960]\ttraining's rmse: 4.89379\tvalid_1's rmse: 50.0848\n",
      "[990]\ttraining's rmse: 4.62604\tvalid_1's rmse: 50.0744\n",
      "[1020]\ttraining's rmse: 4.38076\tvalid_1's rmse: 50.0582\n",
      "[1050]\ttraining's rmse: 4.14897\tvalid_1's rmse: 50.0411\n",
      "[1080]\ttraining's rmse: 3.92411\tvalid_1's rmse: 50.0347\n",
      "[1110]\ttraining's rmse: 3.7204\tvalid_1's rmse: 50.0155\n",
      "[1140]\ttraining's rmse: 3.53068\tvalid_1's rmse: 50.0141\n",
      "[1170]\ttraining's rmse: 3.3529\tvalid_1's rmse: 50.0019\n",
      "[1200]\ttraining's rmse: 3.18282\tvalid_1's rmse: 49.9919\n",
      "[1230]\ttraining's rmse: 3.02015\tvalid_1's rmse: 49.9796\n",
      "[1260]\ttraining's rmse: 2.86735\tvalid_1's rmse: 49.9757\n",
      "[1290]\ttraining's rmse: 2.72476\tvalid_1's rmse: 49.9657\n",
      "[1320]\ttraining's rmse: 2.58781\tvalid_1's rmse: 49.9604\n",
      "[1350]\ttraining's rmse: 2.46096\tvalid_1's rmse: 49.9523\n",
      "[1380]\ttraining's rmse: 2.33987\tvalid_1's rmse: 49.9481\n",
      "[1410]\ttraining's rmse: 2.22375\tvalid_1's rmse: 49.9398\n",
      "[1440]\ttraining's rmse: 2.11559\tvalid_1's rmse: 49.9386\n",
      "[1470]\ttraining's rmse: 2.01302\tvalid_1's rmse: 49.9338\n",
      "[1500]\ttraining's rmse: 1.91631\tvalid_1's rmse: 49.932\n",
      "[1530]\ttraining's rmse: 1.82387\tvalid_1's rmse: 49.9265\n",
      "[1560]\ttraining's rmse: 1.73578\tvalid_1's rmse: 49.9213\n",
      "[1590]\ttraining's rmse: 1.65431\tvalid_1's rmse: 49.9173\n",
      "[1620]\ttraining's rmse: 1.57781\tvalid_1's rmse: 49.9151\n",
      "[1650]\ttraining's rmse: 1.50191\tvalid_1's rmse: 49.9126\n",
      "[1680]\ttraining's rmse: 1.43226\tvalid_1's rmse: 49.9072\n",
      "[1710]\ttraining's rmse: 1.36314\tvalid_1's rmse: 49.9043\n",
      "[1740]\ttraining's rmse: 1.3023\tvalid_1's rmse: 49.9028\n",
      "[1770]\ttraining's rmse: 1.24158\tvalid_1's rmse: 49.8995\n",
      "[1800]\ttraining's rmse: 1.1848\tvalid_1's rmse: 49.8986\n",
      "[1830]\ttraining's rmse: 1.12976\tvalid_1's rmse: 49.8972\n",
      "[1860]\ttraining's rmse: 1.07834\tvalid_1's rmse: 49.8967\n",
      "[1890]\ttraining's rmse: 1.02943\tvalid_1's rmse: 49.8956\n",
      "[1920]\ttraining's rmse: 0.983077\tvalid_1's rmse: 49.8945\n",
      "[1950]\ttraining's rmse: 0.939874\tvalid_1's rmse: 49.8924\n",
      "[1980]\ttraining's rmse: 0.898156\tvalid_1's rmse: 49.8907\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's rmse: 0.872405\tvalid_1's rmse: 49.8907\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003533 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 20021\n",
      "[LightGBM] [Info] Number of data points in the train set: 9219, number of used features: 79\n",
      "[LightGBM] [Info] Start training from score 362.563081\n",
      "Training until validation scores don't improve for 125 rounds\n",
      "[30]\ttraining's rmse: 149.855\tvalid_1's rmse: 153.469\n",
      "[60]\ttraining's rmse: 95.1072\tvalid_1's rmse: 107.663\n",
      "[90]\ttraining's rmse: 65.29\tvalid_1's rmse: 85.4404\n",
      "[120]\ttraining's rmse: 48.8092\tvalid_1's rmse: 74.4603\n",
      "[150]\ttraining's rmse: 39.4521\tvalid_1's rmse: 68.913\n",
      "[180]\ttraining's rmse: 33.4856\tvalid_1's rmse: 65.5952\n",
      "[210]\ttraining's rmse: 29.3097\tvalid_1's rmse: 63.3764\n",
      "[240]\ttraining's rmse: 26.1219\tvalid_1's rmse: 61.8823\n",
      "[270]\ttraining's rmse: 23.5597\tvalid_1's rmse: 60.8368\n",
      "[300]\ttraining's rmse: 21.4173\tvalid_1's rmse: 60.0599\n",
      "[330]\ttraining's rmse: 19.6222\tvalid_1's rmse: 59.5035\n",
      "[360]\ttraining's rmse: 18.0191\tvalid_1's rmse: 59.0579\n",
      "[390]\ttraining's rmse: 16.6208\tvalid_1's rmse: 58.695\n",
      "[420]\ttraining's rmse: 15.3799\tvalid_1's rmse: 58.466\n",
      "[450]\ttraining's rmse: 14.2614\tvalid_1's rmse: 58.2719\n",
      "[480]\ttraining's rmse: 13.2522\tvalid_1's rmse: 58.0928\n",
      "[510]\ttraining's rmse: 12.3419\tvalid_1's rmse: 57.9316\n",
      "[540]\ttraining's rmse: 11.5228\tvalid_1's rmse: 57.7792\n",
      "[570]\ttraining's rmse: 10.7783\tvalid_1's rmse: 57.6847\n",
      "[600]\ttraining's rmse: 10.0861\tvalid_1's rmse: 57.6155\n",
      "[630]\ttraining's rmse: 9.45224\tvalid_1's rmse: 57.5347\n",
      "[660]\ttraining's rmse: 8.86445\tvalid_1's rmse: 57.4718\n",
      "[690]\ttraining's rmse: 8.3196\tvalid_1's rmse: 57.4237\n",
      "[720]\ttraining's rmse: 7.81116\tvalid_1's rmse: 57.3555\n",
      "[750]\ttraining's rmse: 7.34397\tvalid_1's rmse: 57.3112\n",
      "[780]\ttraining's rmse: 6.91259\tvalid_1's rmse: 57.2734\n",
      "[810]\ttraining's rmse: 6.51641\tvalid_1's rmse: 57.2327\n",
      "[840]\ttraining's rmse: 6.14354\tvalid_1's rmse: 57.1915\n",
      "[870]\ttraining's rmse: 5.79601\tvalid_1's rmse: 57.1645\n",
      "[900]\ttraining's rmse: 5.46765\tvalid_1's rmse: 57.1437\n",
      "[930]\ttraining's rmse: 5.16211\tvalid_1's rmse: 57.1306\n",
      "[960]\ttraining's rmse: 4.87752\tvalid_1's rmse: 57.1042\n",
      "[990]\ttraining's rmse: 4.60937\tvalid_1's rmse: 57.0903\n",
      "[1020]\ttraining's rmse: 4.35901\tvalid_1's rmse: 57.08\n",
      "[1050]\ttraining's rmse: 4.12363\tvalid_1's rmse: 57.0707\n",
      "[1080]\ttraining's rmse: 3.90348\tvalid_1's rmse: 57.0543\n",
      "[1110]\ttraining's rmse: 3.69417\tvalid_1's rmse: 57.0412\n",
      "[1140]\ttraining's rmse: 3.49973\tvalid_1's rmse: 57.0293\n",
      "[1170]\ttraining's rmse: 3.31715\tvalid_1's rmse: 57.0152\n",
      "[1200]\ttraining's rmse: 3.14242\tvalid_1's rmse: 57.0007\n",
      "[1230]\ttraining's rmse: 2.98175\tvalid_1's rmse: 56.9891\n",
      "[1260]\ttraining's rmse: 2.82918\tvalid_1's rmse: 56.9772\n",
      "[1290]\ttraining's rmse: 2.68286\tvalid_1's rmse: 56.9688\n",
      "[1320]\ttraining's rmse: 2.54359\tvalid_1's rmse: 56.9638\n",
      "[1350]\ttraining's rmse: 2.41391\tvalid_1's rmse: 56.9608\n",
      "[1380]\ttraining's rmse: 2.28889\tvalid_1's rmse: 56.9591\n",
      "[1410]\ttraining's rmse: 2.17265\tvalid_1's rmse: 56.9554\n",
      "[1440]\ttraining's rmse: 2.06238\tvalid_1's rmse: 56.9541\n",
      "[1470]\ttraining's rmse: 1.95728\tvalid_1's rmse: 56.9484\n",
      "[1500]\ttraining's rmse: 1.85965\tvalid_1's rmse: 56.9425\n",
      "[1530]\ttraining's rmse: 1.76643\tvalid_1's rmse: 56.9408\n",
      "[1560]\ttraining's rmse: 1.67941\tvalid_1's rmse: 56.935\n",
      "[1590]\ttraining's rmse: 1.59702\tvalid_1's rmse: 56.9293\n",
      "[1620]\ttraining's rmse: 1.51901\tvalid_1's rmse: 56.9257\n",
      "[1650]\ttraining's rmse: 1.44552\tvalid_1's rmse: 56.9203\n",
      "[1680]\ttraining's rmse: 1.3754\tvalid_1's rmse: 56.9179\n",
      "[1710]\ttraining's rmse: 1.30868\tvalid_1's rmse: 56.9161\n",
      "[1740]\ttraining's rmse: 1.24482\tvalid_1's rmse: 56.9131\n",
      "[1770]\ttraining's rmse: 1.18365\tvalid_1's rmse: 56.9095\n",
      "[1800]\ttraining's rmse: 1.12749\tvalid_1's rmse: 56.906\n",
      "[1830]\ttraining's rmse: 1.07242\tvalid_1's rmse: 56.9037\n",
      "[1860]\ttraining's rmse: 1.02176\tvalid_1's rmse: 56.9019\n",
      "[1890]\ttraining's rmse: 0.973393\tvalid_1's rmse: 56.8993\n",
      "[1920]\ttraining's rmse: 0.926273\tvalid_1's rmse: 56.897\n",
      "[1950]\ttraining's rmse: 0.882554\tvalid_1's rmse: 56.8955\n",
      "[1980]\ttraining's rmse: 0.841999\tvalid_1's rmse: 56.894\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's rmse: 0.815427\tvalid_1's rmse: 56.895\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003339 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 20021\n",
      "[LightGBM] [Info] Number of data points in the train set: 9219, number of used features: 79\n",
      "[LightGBM] [Info] Start training from score 362.962657\n",
      "Training until validation scores don't improve for 125 rounds\n",
      "[30]\ttraining's rmse: 148.586\tvalid_1's rmse: 152.925\n",
      "[60]\ttraining's rmse: 93.8172\tvalid_1's rmse: 105.895\n",
      "[90]\ttraining's rmse: 64.2841\tvalid_1's rmse: 83.2033\n",
      "[120]\ttraining's rmse: 48.113\tvalid_1's rmse: 72.0985\n",
      "[150]\ttraining's rmse: 38.8286\tvalid_1's rmse: 66.6296\n",
      "[180]\ttraining's rmse: 33.0345\tvalid_1's rmse: 63.7108\n",
      "[210]\ttraining's rmse: 29.0152\tvalid_1's rmse: 61.8338\n",
      "[240]\ttraining's rmse: 25.8272\tvalid_1's rmse: 60.567\n",
      "[270]\ttraining's rmse: 23.2897\tvalid_1's rmse: 59.693\n",
      "[300]\ttraining's rmse: 21.1673\tvalid_1's rmse: 59.069\n",
      "[330]\ttraining's rmse: 19.3629\tvalid_1's rmse: 58.5248\n",
      "[360]\ttraining's rmse: 17.7889\tvalid_1's rmse: 58.1637\n",
      "[390]\ttraining's rmse: 16.4253\tvalid_1's rmse: 57.8392\n",
      "[420]\ttraining's rmse: 15.2075\tvalid_1's rmse: 57.5763\n",
      "[450]\ttraining's rmse: 14.0948\tvalid_1's rmse: 57.3666\n",
      "[480]\ttraining's rmse: 13.0882\tvalid_1's rmse: 57.1967\n",
      "[510]\ttraining's rmse: 12.1985\tvalid_1's rmse: 57.0601\n",
      "[540]\ttraining's rmse: 11.3774\tvalid_1's rmse: 56.9203\n",
      "[570]\ttraining's rmse: 10.6322\tvalid_1's rmse: 56.7989\n",
      "[600]\ttraining's rmse: 9.94216\tvalid_1's rmse: 56.6884\n",
      "[630]\ttraining's rmse: 9.29623\tvalid_1's rmse: 56.6045\n",
      "[660]\ttraining's rmse: 8.71896\tvalid_1's rmse: 56.5303\n",
      "[690]\ttraining's rmse: 8.18133\tvalid_1's rmse: 56.4823\n",
      "[720]\ttraining's rmse: 7.68387\tvalid_1's rmse: 56.4266\n",
      "[750]\ttraining's rmse: 7.21455\tvalid_1's rmse: 56.3739\n",
      "[780]\ttraining's rmse: 6.79374\tvalid_1's rmse: 56.3299\n",
      "[810]\ttraining's rmse: 6.39197\tvalid_1's rmse: 56.2841\n",
      "[840]\ttraining's rmse: 6.01881\tvalid_1's rmse: 56.2442\n",
      "[870]\ttraining's rmse: 5.67563\tvalid_1's rmse: 56.2238\n",
      "[900]\ttraining's rmse: 5.35401\tvalid_1's rmse: 56.2053\n",
      "[930]\ttraining's rmse: 5.04855\tvalid_1's rmse: 56.1851\n",
      "[960]\ttraining's rmse: 4.76654\tvalid_1's rmse: 56.1485\n",
      "[990]\ttraining's rmse: 4.50123\tvalid_1's rmse: 56.1282\n",
      "[1020]\ttraining's rmse: 4.25428\tvalid_1's rmse: 56.1036\n",
      "[1050]\ttraining's rmse: 4.02428\tvalid_1's rmse: 56.085\n",
      "[1080]\ttraining's rmse: 3.80911\tvalid_1's rmse: 56.0735\n",
      "[1110]\ttraining's rmse: 3.60334\tvalid_1's rmse: 56.0578\n",
      "[1140]\ttraining's rmse: 3.41077\tvalid_1's rmse: 56.0379\n",
      "[1170]\ttraining's rmse: 3.23011\tvalid_1's rmse: 56.0277\n",
      "[1200]\ttraining's rmse: 3.05927\tvalid_1's rmse: 56.0116\n",
      "[1230]\ttraining's rmse: 2.90211\tvalid_1's rmse: 56.0012\n",
      "[1260]\ttraining's rmse: 2.75318\tvalid_1's rmse: 55.9919\n",
      "[1290]\ttraining's rmse: 2.60989\tvalid_1's rmse: 55.9792\n",
      "[1320]\ttraining's rmse: 2.47333\tvalid_1's rmse: 55.9739\n",
      "[1350]\ttraining's rmse: 2.34986\tvalid_1's rmse: 55.9658\n",
      "[1380]\ttraining's rmse: 2.23443\tvalid_1's rmse: 55.9582\n",
      "[1410]\ttraining's rmse: 2.12086\tvalid_1's rmse: 55.9478\n",
      "[1440]\ttraining's rmse: 2.01435\tvalid_1's rmse: 55.9403\n",
      "[1470]\ttraining's rmse: 1.91522\tvalid_1's rmse: 55.9354\n",
      "[1500]\ttraining's rmse: 1.81891\tvalid_1's rmse: 55.9315\n",
      "[1530]\ttraining's rmse: 1.72712\tvalid_1's rmse: 55.9273\n",
      "[1560]\ttraining's rmse: 1.64141\tvalid_1's rmse: 55.9216\n",
      "[1590]\ttraining's rmse: 1.55893\tvalid_1's rmse: 55.9171\n",
      "[1620]\ttraining's rmse: 1.48144\tvalid_1's rmse: 55.9117\n",
      "[1650]\ttraining's rmse: 1.40986\tvalid_1's rmse: 55.9083\n",
      "[1680]\ttraining's rmse: 1.34105\tvalid_1's rmse: 55.9044\n",
      "[1710]\ttraining's rmse: 1.2768\tvalid_1's rmse: 55.9029\n",
      "[1740]\ttraining's rmse: 1.21322\tvalid_1's rmse: 55.8975\n",
      "[1770]\ttraining's rmse: 1.15483\tvalid_1's rmse: 55.8967\n",
      "[1800]\ttraining's rmse: 1.09976\tvalid_1's rmse: 55.8936\n",
      "[1830]\ttraining's rmse: 1.04949\tvalid_1's rmse: 55.891\n",
      "[1860]\ttraining's rmse: 1.00052\tvalid_1's rmse: 55.8877\n",
      "[1890]\ttraining's rmse: 0.951926\tvalid_1's rmse: 55.8867\n",
      "[1920]\ttraining's rmse: 0.90647\tvalid_1's rmse: 55.8851\n",
      "[1950]\ttraining's rmse: 0.863235\tvalid_1's rmse: 55.8822\n",
      "[1980]\ttraining's rmse: 0.823472\tvalid_1's rmse: 55.8803\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's rmse: 0.797077\tvalid_1's rmse: 55.8792\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002429 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 20021\n",
      "[LightGBM] [Info] Number of data points in the train set: 9219, number of used features: 79\n",
      "[LightGBM] [Info] Start training from score 361.838953\n",
      "Training until validation scores don't improve for 125 rounds\n",
      "[30]\ttraining's rmse: 148.589\tvalid_1's rmse: 151.246\n",
      "[60]\ttraining's rmse: 93.1393\tvalid_1's rmse: 102.215\n",
      "[90]\ttraining's rmse: 63.4214\tvalid_1's rmse: 78.0928\n",
      "[120]\ttraining's rmse: 47.2605\tvalid_1's rmse: 66.4728\n",
      "[150]\ttraining's rmse: 38.0444\tvalid_1's rmse: 60.5403\n",
      "[180]\ttraining's rmse: 32.2769\tvalid_1's rmse: 57.5334\n",
      "[210]\ttraining's rmse: 28.2556\tvalid_1's rmse: 55.6772\n",
      "[240]\ttraining's rmse: 25.1403\tvalid_1's rmse: 54.5375\n",
      "[270]\ttraining's rmse: 22.6379\tvalid_1's rmse: 53.6852\n",
      "[300]\ttraining's rmse: 20.5874\tvalid_1's rmse: 53.1331\n",
      "[330]\ttraining's rmse: 18.8653\tvalid_1's rmse: 52.7349\n",
      "[360]\ttraining's rmse: 17.3546\tvalid_1's rmse: 52.4473\n",
      "[390]\ttraining's rmse: 15.9882\tvalid_1's rmse: 52.2199\n",
      "[420]\ttraining's rmse: 14.7908\tvalid_1's rmse: 52.0472\n",
      "[450]\ttraining's rmse: 13.7214\tvalid_1's rmse: 51.8796\n",
      "[480]\ttraining's rmse: 12.7481\tvalid_1's rmse: 51.7934\n",
      "[510]\ttraining's rmse: 11.8729\tvalid_1's rmse: 51.6748\n",
      "[540]\ttraining's rmse: 11.0628\tvalid_1's rmse: 51.6182\n",
      "[570]\ttraining's rmse: 10.3361\tvalid_1's rmse: 51.5435\n",
      "[600]\ttraining's rmse: 9.68059\tvalid_1's rmse: 51.4887\n",
      "[630]\ttraining's rmse: 9.07767\tvalid_1's rmse: 51.4373\n",
      "[660]\ttraining's rmse: 8.51072\tvalid_1's rmse: 51.4064\n",
      "[690]\ttraining's rmse: 7.98719\tvalid_1's rmse: 51.3658\n",
      "[720]\ttraining's rmse: 7.50263\tvalid_1's rmse: 51.3277\n",
      "[750]\ttraining's rmse: 7.0543\tvalid_1's rmse: 51.2875\n",
      "[780]\ttraining's rmse: 6.63707\tvalid_1's rmse: 51.2587\n",
      "[810]\ttraining's rmse: 6.24482\tvalid_1's rmse: 51.2323\n",
      "[840]\ttraining's rmse: 5.8841\tvalid_1's rmse: 51.2168\n",
      "[870]\ttraining's rmse: 5.55012\tvalid_1's rmse: 51.1883\n",
      "[900]\ttraining's rmse: 5.24567\tvalid_1's rmse: 51.1772\n",
      "[930]\ttraining's rmse: 4.94727\tvalid_1's rmse: 51.1586\n",
      "[960]\ttraining's rmse: 4.67077\tvalid_1's rmse: 51.1473\n",
      "[990]\ttraining's rmse: 4.4128\tvalid_1's rmse: 51.1399\n",
      "[1020]\ttraining's rmse: 4.17267\tvalid_1's rmse: 51.1247\n",
      "[1050]\ttraining's rmse: 3.94906\tvalid_1's rmse: 51.1112\n",
      "[1080]\ttraining's rmse: 3.73621\tvalid_1's rmse: 51.1071\n",
      "[1110]\ttraining's rmse: 3.53648\tvalid_1's rmse: 51.1\n",
      "[1140]\ttraining's rmse: 3.35016\tvalid_1's rmse: 51.0863\n",
      "[1170]\ttraining's rmse: 3.17358\tvalid_1's rmse: 51.0825\n",
      "[1200]\ttraining's rmse: 3.00876\tvalid_1's rmse: 51.073\n",
      "[1230]\ttraining's rmse: 2.85113\tvalid_1's rmse: 51.0605\n",
      "[1260]\ttraining's rmse: 2.70294\tvalid_1's rmse: 51.0602\n",
      "[1290]\ttraining's rmse: 2.56314\tvalid_1's rmse: 51.0532\n",
      "[1320]\ttraining's rmse: 2.42925\tvalid_1's rmse: 51.0495\n",
      "[1350]\ttraining's rmse: 2.30422\tvalid_1's rmse: 51.0439\n",
      "[1380]\ttraining's rmse: 2.18964\tvalid_1's rmse: 51.04\n",
      "[1410]\ttraining's rmse: 2.0778\tvalid_1's rmse: 51.0384\n",
      "[1440]\ttraining's rmse: 1.97574\tvalid_1's rmse: 51.0348\n",
      "[1470]\ttraining's rmse: 1.87854\tvalid_1's rmse: 51.0327\n",
      "[1500]\ttraining's rmse: 1.78357\tvalid_1's rmse: 51.0332\n",
      "[1530]\ttraining's rmse: 1.69547\tvalid_1's rmse: 51.0316\n",
      "[1560]\ttraining's rmse: 1.6101\tvalid_1's rmse: 51.0323\n",
      "[1590]\ttraining's rmse: 1.5317\tvalid_1's rmse: 51.0298\n",
      "[1620]\ttraining's rmse: 1.45535\tvalid_1's rmse: 51.0252\n",
      "[1650]\ttraining's rmse: 1.38597\tvalid_1's rmse: 51.0251\n",
      "[1680]\ttraining's rmse: 1.31817\tvalid_1's rmse: 51.0238\n",
      "[1710]\ttraining's rmse: 1.25544\tvalid_1's rmse: 51.0218\n",
      "[1740]\ttraining's rmse: 1.19493\tvalid_1's rmse: 51.0198\n",
      "[1770]\ttraining's rmse: 1.13777\tvalid_1's rmse: 51.0198\n",
      "[1800]\ttraining's rmse: 1.08323\tvalid_1's rmse: 51.019\n",
      "[1830]\ttraining's rmse: 1.03185\tvalid_1's rmse: 51.0171\n",
      "[1860]\ttraining's rmse: 0.983545\tvalid_1's rmse: 51.0147\n",
      "[1890]\ttraining's rmse: 0.937607\tvalid_1's rmse: 51.0134\n",
      "[1920]\ttraining's rmse: 0.894007\tvalid_1's rmse: 51.0128\n",
      "[1950]\ttraining's rmse: 0.852703\tvalid_1's rmse: 51.0119\n",
      "[1980]\ttraining's rmse: 0.8119\tvalid_1's rmse: 51.0109\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's rmse: 0.786885\tvalid_1's rmse: 51.0104\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003290 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 20021\n",
      "[LightGBM] [Info] Number of data points in the train set: 9219, number of used features: 79\n",
      "[LightGBM] [Info] Start training from score 371.212692\n",
      "Training until validation scores don't improve for 125 rounds\n",
      "[30]\ttraining's rmse: 152\tvalid_1's rmse: 158.284\n",
      "[60]\ttraining's rmse: 95.8584\tvalid_1's rmse: 107.335\n",
      "[90]\ttraining's rmse: 65.5018\tvalid_1's rmse: 82.5215\n",
      "[120]\ttraining's rmse: 49.0883\tvalid_1's rmse: 70.8359\n",
      "[150]\ttraining's rmse: 39.5442\tvalid_1's rmse: 64.9215\n",
      "[180]\ttraining's rmse: 33.7075\tvalid_1's rmse: 61.775\n",
      "[210]\ttraining's rmse: 29.5596\tvalid_1's rmse: 59.9942\n",
      "[240]\ttraining's rmse: 26.3297\tvalid_1's rmse: 58.6403\n",
      "[270]\ttraining's rmse: 23.7262\tvalid_1's rmse: 57.85\n",
      "[300]\ttraining's rmse: 21.5848\tvalid_1's rmse: 57.2571\n",
      "[330]\ttraining's rmse: 19.7398\tvalid_1's rmse: 56.8797\n",
      "[360]\ttraining's rmse: 18.1588\tvalid_1's rmse: 56.5866\n",
      "[390]\ttraining's rmse: 16.7706\tvalid_1's rmse: 56.3701\n",
      "[420]\ttraining's rmse: 15.5194\tvalid_1's rmse: 56.1834\n",
      "[450]\ttraining's rmse: 14.4141\tvalid_1's rmse: 56.0405\n",
      "[480]\ttraining's rmse: 13.4014\tvalid_1's rmse: 55.9033\n",
      "[510]\ttraining's rmse: 12.4751\tvalid_1's rmse: 55.776\n",
      "[540]\ttraining's rmse: 11.6286\tvalid_1's rmse: 55.6731\n",
      "[570]\ttraining's rmse: 10.8815\tvalid_1's rmse: 55.577\n",
      "[600]\ttraining's rmse: 10.1936\tvalid_1's rmse: 55.5184\n",
      "[630]\ttraining's rmse: 9.56536\tvalid_1's rmse: 55.4657\n",
      "[660]\ttraining's rmse: 8.98058\tvalid_1's rmse: 55.4129\n",
      "[690]\ttraining's rmse: 8.43636\tvalid_1's rmse: 55.3565\n",
      "[720]\ttraining's rmse: 7.93109\tvalid_1's rmse: 55.3146\n",
      "[750]\ttraining's rmse: 7.45628\tvalid_1's rmse: 55.2665\n",
      "[780]\ttraining's rmse: 7.01816\tvalid_1's rmse: 55.2514\n",
      "[810]\ttraining's rmse: 6.60863\tvalid_1's rmse: 55.2309\n",
      "[840]\ttraining's rmse: 6.22182\tvalid_1's rmse: 55.1982\n",
      "[870]\ttraining's rmse: 5.86447\tvalid_1's rmse: 55.1735\n",
      "[900]\ttraining's rmse: 5.52686\tvalid_1's rmse: 55.1633\n",
      "[930]\ttraining's rmse: 5.21421\tvalid_1's rmse: 55.1397\n",
      "[960]\ttraining's rmse: 4.92407\tvalid_1's rmse: 55.13\n",
      "[990]\ttraining's rmse: 4.64632\tvalid_1's rmse: 55.1123\n",
      "[1020]\ttraining's rmse: 4.39033\tvalid_1's rmse: 55.0991\n",
      "[1050]\ttraining's rmse: 4.14565\tvalid_1's rmse: 55.0997\n",
      "[1080]\ttraining's rmse: 3.92236\tvalid_1's rmse: 55.0904\n",
      "[1110]\ttraining's rmse: 3.71127\tvalid_1's rmse: 55.08\n",
      "[1140]\ttraining's rmse: 3.51336\tvalid_1's rmse: 55.0669\n",
      "[1170]\ttraining's rmse: 3.32673\tvalid_1's rmse: 55.0554\n",
      "[1200]\ttraining's rmse: 3.14962\tvalid_1's rmse: 55.0484\n",
      "[1230]\ttraining's rmse: 2.98279\tvalid_1's rmse: 55.0364\n",
      "[1260]\ttraining's rmse: 2.82794\tvalid_1's rmse: 55.0288\n",
      "[1290]\ttraining's rmse: 2.68121\tvalid_1's rmse: 55.0231\n",
      "[1320]\ttraining's rmse: 2.53932\tvalid_1's rmse: 55.0188\n",
      "[1350]\ttraining's rmse: 2.40846\tvalid_1's rmse: 55.0161\n",
      "[1380]\ttraining's rmse: 2.28691\tvalid_1's rmse: 55.0087\n",
      "[1410]\ttraining's rmse: 2.16745\tvalid_1's rmse: 55.0043\n",
      "[1440]\ttraining's rmse: 2.05903\tvalid_1's rmse: 55.0017\n",
      "[1470]\ttraining's rmse: 1.95586\tvalid_1's rmse: 54.9991\n",
      "[1500]\ttraining's rmse: 1.85674\tvalid_1's rmse: 54.997\n",
      "[1530]\ttraining's rmse: 1.76649\tvalid_1's rmse: 54.9918\n",
      "[1560]\ttraining's rmse: 1.67994\tvalid_1's rmse: 54.9909\n",
      "[1590]\ttraining's rmse: 1.59997\tvalid_1's rmse: 54.9906\n",
      "[1620]\ttraining's rmse: 1.52199\tvalid_1's rmse: 54.9877\n",
      "[1650]\ttraining's rmse: 1.44683\tvalid_1's rmse: 54.9879\n",
      "[1680]\ttraining's rmse: 1.37592\tvalid_1's rmse: 54.9874\n",
      "[1710]\ttraining's rmse: 1.30936\tvalid_1's rmse: 54.9845\n",
      "[1740]\ttraining's rmse: 1.2468\tvalid_1's rmse: 54.9845\n",
      "[1770]\ttraining's rmse: 1.18802\tvalid_1's rmse: 54.9825\n",
      "[1800]\ttraining's rmse: 1.13236\tvalid_1's rmse: 54.981\n",
      "[1830]\ttraining's rmse: 1.07781\tvalid_1's rmse: 54.9799\n",
      "[1860]\ttraining's rmse: 1.02611\tvalid_1's rmse: 54.977\n",
      "[1890]\ttraining's rmse: 0.979414\tvalid_1's rmse: 54.9756\n",
      "[1920]\ttraining's rmse: 0.933088\tvalid_1's rmse: 54.9737\n",
      "[1950]\ttraining's rmse: 0.889492\tvalid_1's rmse: 54.9737\n",
      "[1980]\ttraining's rmse: 0.847973\tvalid_1's rmse: 54.9715\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's rmse: 0.82105\tvalid_1's rmse: 54.9712\n",
      "34\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002227 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 20021\n",
      "[LightGBM] [Info] Number of data points in the train set: 9219, number of used features: 79\n",
      "[LightGBM] [Info] Start training from score 371.327908\n",
      "Training until validation scores don't improve for 125 rounds\n",
      "[30]\ttraining's rmse: 146.251\tvalid_1's rmse: 149.42\n",
      "[60]\ttraining's rmse: 91.7886\tvalid_1's rmse: 100.633\n",
      "[90]\ttraining's rmse: 62.3029\tvalid_1's rmse: 75.9301\n",
      "[120]\ttraining's rmse: 46.2628\tvalid_1's rmse: 63.9284\n",
      "[150]\ttraining's rmse: 37.2145\tvalid_1's rmse: 58.2074\n",
      "[180]\ttraining's rmse: 31.6791\tvalid_1's rmse: 55.3698\n",
      "[210]\ttraining's rmse: 27.8046\tvalid_1's rmse: 53.7305\n",
      "[240]\ttraining's rmse: 24.7864\tvalid_1's rmse: 52.5999\n",
      "[270]\ttraining's rmse: 22.3452\tvalid_1's rmse: 51.9546\n",
      "[300]\ttraining's rmse: 20.372\tvalid_1's rmse: 51.4576\n",
      "[330]\ttraining's rmse: 18.6809\tvalid_1's rmse: 51.1146\n",
      "[360]\ttraining's rmse: 17.2243\tvalid_1's rmse: 50.8845\n",
      "[390]\ttraining's rmse: 15.935\tvalid_1's rmse: 50.6709\n",
      "[420]\ttraining's rmse: 14.7856\tvalid_1's rmse: 50.519\n",
      "[450]\ttraining's rmse: 13.7481\tvalid_1's rmse: 50.3824\n",
      "[480]\ttraining's rmse: 12.7913\tvalid_1's rmse: 50.2771\n",
      "[510]\ttraining's rmse: 11.9423\tvalid_1's rmse: 50.1946\n",
      "[540]\ttraining's rmse: 11.1568\tvalid_1's rmse: 50.1081\n",
      "[570]\ttraining's rmse: 10.4497\tvalid_1's rmse: 50.0281\n",
      "[600]\ttraining's rmse: 9.81116\tvalid_1's rmse: 49.9744\n",
      "[630]\ttraining's rmse: 9.21156\tvalid_1's rmse: 49.9301\n",
      "[660]\ttraining's rmse: 8.64609\tvalid_1's rmse: 49.8697\n",
      "[690]\ttraining's rmse: 8.13171\tvalid_1's rmse: 49.8365\n",
      "[720]\ttraining's rmse: 7.65657\tvalid_1's rmse: 49.7912\n",
      "[750]\ttraining's rmse: 7.21749\tvalid_1's rmse: 49.7801\n",
      "[780]\ttraining's rmse: 6.80724\tvalid_1's rmse: 49.7583\n",
      "[810]\ttraining's rmse: 6.42098\tvalid_1's rmse: 49.7246\n",
      "[840]\ttraining's rmse: 6.05705\tvalid_1's rmse: 49.718\n",
      "[870]\ttraining's rmse: 5.71114\tvalid_1's rmse: 49.7029\n",
      "[900]\ttraining's rmse: 5.39948\tvalid_1's rmse: 49.6919\n",
      "[930]\ttraining's rmse: 5.10882\tvalid_1's rmse: 49.688\n",
      "[960]\ttraining's rmse: 4.83398\tvalid_1's rmse: 49.6686\n",
      "[990]\ttraining's rmse: 4.57522\tvalid_1's rmse: 49.6667\n",
      "[1020]\ttraining's rmse: 4.34047\tvalid_1's rmse: 49.6604\n",
      "[1050]\ttraining's rmse: 4.11599\tvalid_1's rmse: 49.6496\n",
      "[1080]\ttraining's rmse: 3.90331\tvalid_1's rmse: 49.6407\n",
      "[1110]\ttraining's rmse: 3.69938\tvalid_1's rmse: 49.6354\n",
      "[1140]\ttraining's rmse: 3.51303\tvalid_1's rmse: 49.6299\n",
      "[1170]\ttraining's rmse: 3.3341\tvalid_1's rmse: 49.6249\n",
      "[1200]\ttraining's rmse: 3.16629\tvalid_1's rmse: 49.6188\n",
      "[1230]\ttraining's rmse: 3.01417\tvalid_1's rmse: 49.6158\n",
      "[1260]\ttraining's rmse: 2.86698\tvalid_1's rmse: 49.6116\n",
      "[1290]\ttraining's rmse: 2.72415\tvalid_1's rmse: 49.6114\n",
      "[1320]\ttraining's rmse: 2.59457\tvalid_1's rmse: 49.6098\n",
      "[1350]\ttraining's rmse: 2.46875\tvalid_1's rmse: 49.6027\n",
      "[1380]\ttraining's rmse: 2.34988\tvalid_1's rmse: 49.6027\n",
      "[1410]\ttraining's rmse: 2.23493\tvalid_1's rmse: 49.6038\n",
      "[1440]\ttraining's rmse: 2.12517\tvalid_1's rmse: 49.6025\n",
      "[1470]\ttraining's rmse: 2.02463\tvalid_1's rmse: 49.6018\n",
      "[1500]\ttraining's rmse: 1.92682\tvalid_1's rmse: 49.6027\n",
      "[1530]\ttraining's rmse: 1.83674\tvalid_1's rmse: 49.5992\n",
      "[1560]\ttraining's rmse: 1.74874\tvalid_1's rmse: 49.5945\n",
      "[1590]\ttraining's rmse: 1.66923\tvalid_1's rmse: 49.589\n",
      "[1620]\ttraining's rmse: 1.59405\tvalid_1's rmse: 49.5882\n",
      "[1650]\ttraining's rmse: 1.52051\tvalid_1's rmse: 49.5888\n",
      "[1680]\ttraining's rmse: 1.44851\tvalid_1's rmse: 49.5876\n",
      "[1710]\ttraining's rmse: 1.38183\tvalid_1's rmse: 49.5884\n",
      "[1740]\ttraining's rmse: 1.32027\tvalid_1's rmse: 49.5882\n",
      "[1770]\ttraining's rmse: 1.26435\tvalid_1's rmse: 49.5843\n",
      "[1800]\ttraining's rmse: 1.20737\tvalid_1's rmse: 49.5838\n",
      "[1830]\ttraining's rmse: 1.15195\tvalid_1's rmse: 49.5819\n",
      "[1860]\ttraining's rmse: 1.09933\tvalid_1's rmse: 49.5811\n",
      "[1890]\ttraining's rmse: 1.04823\tvalid_1's rmse: 49.5821\n",
      "[1920]\ttraining's rmse: 1.0017\tvalid_1's rmse: 49.5834\n",
      "[1950]\ttraining's rmse: 0.955917\tvalid_1's rmse: 49.5843\n",
      "Early stopping, best iteration is:\n",
      "[1840]\ttraining's rmse: 1.13486\tvalid_1's rmse: 49.5803\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003334 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 20021\n",
      "[LightGBM] [Info] Number of data points in the train set: 9219, number of used features: 79\n",
      "[LightGBM] [Info] Start training from score 366.728918\n",
      "Training until validation scores don't improve for 125 rounds\n",
      "[30]\ttraining's rmse: 148.645\tvalid_1's rmse: 155.851\n",
      "[60]\ttraining's rmse: 94.8694\tvalid_1's rmse: 105.325\n",
      "[90]\ttraining's rmse: 65.3095\tvalid_1's rmse: 79.4034\n",
      "[120]\ttraining's rmse: 48.8889\tvalid_1's rmse: 66.6161\n",
      "[150]\ttraining's rmse: 39.4536\tvalid_1's rmse: 60.1515\n",
      "[180]\ttraining's rmse: 33.5385\tvalid_1's rmse: 56.6737\n",
      "[210]\ttraining's rmse: 29.4034\tvalid_1's rmse: 54.6561\n",
      "[240]\ttraining's rmse: 26.1807\tvalid_1's rmse: 53.2629\n",
      "[270]\ttraining's rmse: 23.5925\tvalid_1's rmse: 52.2136\n",
      "[300]\ttraining's rmse: 21.4551\tvalid_1's rmse: 51.4737\n",
      "[330]\ttraining's rmse: 19.6318\tvalid_1's rmse: 50.9661\n",
      "[360]\ttraining's rmse: 18.0557\tvalid_1's rmse: 50.6204\n",
      "[390]\ttraining's rmse: 16.6838\tvalid_1's rmse: 50.3412\n",
      "[420]\ttraining's rmse: 15.4731\tvalid_1's rmse: 50.0646\n",
      "[450]\ttraining's rmse: 14.3635\tvalid_1's rmse: 49.8616\n",
      "[480]\ttraining's rmse: 13.3636\tvalid_1's rmse: 49.701\n",
      "[510]\ttraining's rmse: 12.461\tvalid_1's rmse: 49.5547\n",
      "[540]\ttraining's rmse: 11.6191\tvalid_1's rmse: 49.406\n",
      "[570]\ttraining's rmse: 10.8513\tvalid_1's rmse: 49.2864\n",
      "[600]\ttraining's rmse: 10.1588\tvalid_1's rmse: 49.1827\n",
      "[630]\ttraining's rmse: 9.51723\tvalid_1's rmse: 49.0973\n",
      "[660]\ttraining's rmse: 8.92082\tvalid_1's rmse: 49.0375\n",
      "[690]\ttraining's rmse: 8.36983\tvalid_1's rmse: 48.9747\n",
      "[720]\ttraining's rmse: 7.86162\tvalid_1's rmse: 48.9204\n",
      "[750]\ttraining's rmse: 7.39252\tvalid_1's rmse: 48.883\n",
      "[780]\ttraining's rmse: 6.95375\tvalid_1's rmse: 48.8535\n",
      "[810]\ttraining's rmse: 6.54354\tvalid_1's rmse: 48.8234\n",
      "[840]\ttraining's rmse: 6.16826\tvalid_1's rmse: 48.7898\n",
      "[870]\ttraining's rmse: 5.82128\tvalid_1's rmse: 48.7805\n",
      "[900]\ttraining's rmse: 5.49922\tvalid_1's rmse: 48.7438\n",
      "[930]\ttraining's rmse: 5.19036\tvalid_1's rmse: 48.7246\n",
      "[960]\ttraining's rmse: 4.90641\tvalid_1's rmse: 48.7027\n",
      "[990]\ttraining's rmse: 4.639\tvalid_1's rmse: 48.695\n",
      "[1020]\ttraining's rmse: 4.39305\tvalid_1's rmse: 48.6913\n",
      "[1050]\ttraining's rmse: 4.15769\tvalid_1's rmse: 48.6584\n",
      "[1080]\ttraining's rmse: 3.94047\tvalid_1's rmse: 48.6392\n",
      "[1110]\ttraining's rmse: 3.72975\tvalid_1's rmse: 48.6279\n",
      "[1140]\ttraining's rmse: 3.5359\tvalid_1's rmse: 48.6114\n",
      "[1170]\ttraining's rmse: 3.35021\tvalid_1's rmse: 48.6058\n",
      "[1200]\ttraining's rmse: 3.17455\tvalid_1's rmse: 48.5972\n",
      "[1230]\ttraining's rmse: 3.01113\tvalid_1's rmse: 48.5861\n",
      "[1260]\ttraining's rmse: 2.85463\tvalid_1's rmse: 48.5839\n",
      "[1290]\ttraining's rmse: 2.70852\tvalid_1's rmse: 48.5759\n",
      "[1320]\ttraining's rmse: 2.57691\tvalid_1's rmse: 48.5727\n",
      "[1350]\ttraining's rmse: 2.44306\tvalid_1's rmse: 48.566\n",
      "[1380]\ttraining's rmse: 2.31944\tvalid_1's rmse: 48.5602\n",
      "[1410]\ttraining's rmse: 2.20315\tvalid_1's rmse: 48.5526\n",
      "[1440]\ttraining's rmse: 2.09143\tvalid_1's rmse: 48.5464\n",
      "[1470]\ttraining's rmse: 1.98866\tvalid_1's rmse: 48.5397\n",
      "[1500]\ttraining's rmse: 1.89023\tvalid_1's rmse: 48.5318\n",
      "[1530]\ttraining's rmse: 1.79917\tvalid_1's rmse: 48.527\n",
      "[1560]\ttraining's rmse: 1.7126\tvalid_1's rmse: 48.5223\n",
      "[1590]\ttraining's rmse: 1.62896\tvalid_1's rmse: 48.5192\n",
      "[1620]\ttraining's rmse: 1.54959\tvalid_1's rmse: 48.5169\n",
      "[1650]\ttraining's rmse: 1.47728\tvalid_1's rmse: 48.5136\n",
      "[1680]\ttraining's rmse: 1.40893\tvalid_1's rmse: 48.5099\n",
      "[1710]\ttraining's rmse: 1.34102\tvalid_1's rmse: 48.507\n",
      "[1740]\ttraining's rmse: 1.2776\tvalid_1's rmse: 48.5035\n",
      "[1770]\ttraining's rmse: 1.21816\tvalid_1's rmse: 48.502\n",
      "[1800]\ttraining's rmse: 1.1619\tvalid_1's rmse: 48.4997\n",
      "[1830]\ttraining's rmse: 1.10836\tvalid_1's rmse: 48.4972\n",
      "[1860]\ttraining's rmse: 1.05537\tvalid_1's rmse: 48.4968\n",
      "[1890]\ttraining's rmse: 1.00686\tvalid_1's rmse: 48.4929\n",
      "[1920]\ttraining's rmse: 0.959945\tvalid_1's rmse: 48.4918\n",
      "[1950]\ttraining's rmse: 0.91657\tvalid_1's rmse: 48.4912\n",
      "[1980]\ttraining's rmse: 0.873885\tvalid_1's rmse: 48.4888\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's rmse: 0.847803\tvalid_1's rmse: 48.4893\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003799 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 20021\n",
      "[LightGBM] [Info] Number of data points in the train set: 9219, number of used features: 79\n",
      "[LightGBM] [Info] Start training from score 368.107116\n",
      "Training until validation scores don't improve for 125 rounds\n",
      "[30]\ttraining's rmse: 149.607\tvalid_1's rmse: 153.569\n",
      "[60]\ttraining's rmse: 95.6286\tvalid_1's rmse: 105.816\n",
      "[90]\ttraining's rmse: 65.9445\tvalid_1's rmse: 82.0475\n",
      "[120]\ttraining's rmse: 49.4003\tvalid_1's rmse: 70.028\n",
      "[150]\ttraining's rmse: 39.8955\tvalid_1's rmse: 64.162\n",
      "[180]\ttraining's rmse: 33.8833\tvalid_1's rmse: 60.9903\n",
      "[210]\ttraining's rmse: 29.6356\tvalid_1's rmse: 59.0234\n",
      "[240]\ttraining's rmse: 26.4088\tvalid_1's rmse: 57.8113\n",
      "[270]\ttraining's rmse: 23.7764\tvalid_1's rmse: 56.8775\n",
      "[300]\ttraining's rmse: 21.6026\tvalid_1's rmse: 56.2195\n",
      "[330]\ttraining's rmse: 19.7843\tvalid_1's rmse: 55.7792\n",
      "[360]\ttraining's rmse: 18.1665\tvalid_1's rmse: 55.4652\n",
      "[390]\ttraining's rmse: 16.7689\tvalid_1's rmse: 55.212\n",
      "[420]\ttraining's rmse: 15.5309\tvalid_1's rmse: 55.0274\n",
      "[450]\ttraining's rmse: 14.4106\tvalid_1's rmse: 54.8189\n",
      "[480]\ttraining's rmse: 13.3851\tvalid_1's rmse: 54.6657\n",
      "[510]\ttraining's rmse: 12.4621\tvalid_1's rmse: 54.5447\n",
      "[540]\ttraining's rmse: 11.6167\tvalid_1's rmse: 54.416\n",
      "[570]\ttraining's rmse: 10.863\tvalid_1's rmse: 54.3048\n",
      "[600]\ttraining's rmse: 10.164\tvalid_1's rmse: 54.2226\n",
      "[630]\ttraining's rmse: 9.51807\tvalid_1's rmse: 54.1542\n",
      "[660]\ttraining's rmse: 8.92906\tvalid_1's rmse: 54.1058\n",
      "[690]\ttraining's rmse: 8.37655\tvalid_1's rmse: 54.0354\n",
      "[720]\ttraining's rmse: 7.8711\tvalid_1's rmse: 53.9629\n",
      "[750]\ttraining's rmse: 7.41075\tvalid_1's rmse: 53.9185\n",
      "[780]\ttraining's rmse: 6.97516\tvalid_1's rmse: 53.8916\n",
      "[810]\ttraining's rmse: 6.56629\tvalid_1's rmse: 53.8571\n",
      "[840]\ttraining's rmse: 6.18897\tvalid_1's rmse: 53.8149\n",
      "[870]\ttraining's rmse: 5.82498\tvalid_1's rmse: 53.788\n",
      "[900]\ttraining's rmse: 5.49856\tvalid_1's rmse: 53.7637\n",
      "[930]\ttraining's rmse: 5.185\tvalid_1's rmse: 53.7434\n",
      "[960]\ttraining's rmse: 4.89851\tvalid_1's rmse: 53.7182\n",
      "[990]\ttraining's rmse: 4.63095\tvalid_1's rmse: 53.6964\n",
      "[1020]\ttraining's rmse: 4.38163\tvalid_1's rmse: 53.6824\n",
      "[1050]\ttraining's rmse: 4.144\tvalid_1's rmse: 53.6671\n",
      "[1080]\ttraining's rmse: 3.91981\tvalid_1's rmse: 53.653\n",
      "[1110]\ttraining's rmse: 3.70956\tvalid_1's rmse: 53.6418\n",
      "[1140]\ttraining's rmse: 3.52124\tvalid_1's rmse: 53.6262\n",
      "[1170]\ttraining's rmse: 3.3363\tvalid_1's rmse: 53.6209\n",
      "[1200]\ttraining's rmse: 3.15999\tvalid_1's rmse: 53.6079\n",
      "[1230]\ttraining's rmse: 3.00014\tvalid_1's rmse: 53.6017\n",
      "[1260]\ttraining's rmse: 2.84788\tvalid_1's rmse: 53.5893\n",
      "[1290]\ttraining's rmse: 2.70015\tvalid_1's rmse: 53.587\n",
      "[1320]\ttraining's rmse: 2.56306\tvalid_1's rmse: 53.5789\n",
      "[1350]\ttraining's rmse: 2.43456\tvalid_1's rmse: 53.5727\n",
      "[1380]\ttraining's rmse: 2.31557\tvalid_1's rmse: 53.5679\n",
      "[1410]\ttraining's rmse: 2.19834\tvalid_1's rmse: 53.567\n",
      "[1440]\ttraining's rmse: 2.09185\tvalid_1's rmse: 53.5601\n",
      "[1470]\ttraining's rmse: 1.99087\tvalid_1's rmse: 53.5573\n",
      "[1500]\ttraining's rmse: 1.89359\tvalid_1's rmse: 53.5534\n",
      "[1530]\ttraining's rmse: 1.79896\tvalid_1's rmse: 53.5522\n",
      "[1560]\ttraining's rmse: 1.71042\tvalid_1's rmse: 53.5522\n",
      "[1590]\ttraining's rmse: 1.62788\tvalid_1's rmse: 53.5464\n",
      "[1620]\ttraining's rmse: 1.54953\tvalid_1's rmse: 53.543\n",
      "[1650]\ttraining's rmse: 1.47626\tvalid_1's rmse: 53.54\n",
      "[1680]\ttraining's rmse: 1.40678\tvalid_1's rmse: 53.5376\n",
      "[1710]\ttraining's rmse: 1.34027\tvalid_1's rmse: 53.5366\n",
      "[1740]\ttraining's rmse: 1.2778\tvalid_1's rmse: 53.531\n",
      "[1770]\ttraining's rmse: 1.21866\tvalid_1's rmse: 53.5292\n",
      "[1800]\ttraining's rmse: 1.15938\tvalid_1's rmse: 53.5277\n",
      "[1830]\ttraining's rmse: 1.106\tvalid_1's rmse: 53.5273\n",
      "[1860]\ttraining's rmse: 1.0549\tvalid_1's rmse: 53.5252\n",
      "[1890]\ttraining's rmse: 1.00585\tvalid_1's rmse: 53.5241\n",
      "[1920]\ttraining's rmse: 0.961007\tvalid_1's rmse: 53.524\n",
      "[1950]\ttraining's rmse: 0.917823\tvalid_1's rmse: 53.524\n",
      "[1980]\ttraining's rmse: 0.875491\tvalid_1's rmse: 53.5224\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's rmse: 0.849791\tvalid_1's rmse: 53.522\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002523 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 20021\n",
      "[LightGBM] [Info] Number of data points in the train set: 9219, number of used features: 79\n",
      "[LightGBM] [Info] Start training from score 370.838451\n",
      "Training until validation scores don't improve for 125 rounds\n",
      "[30]\ttraining's rmse: 149.344\tvalid_1's rmse: 151.554\n",
      "[60]\ttraining's rmse: 95.3171\tvalid_1's rmse: 105.356\n",
      "[90]\ttraining's rmse: 65.9012\tvalid_1's rmse: 82.9304\n",
      "[120]\ttraining's rmse: 49.6071\tvalid_1's rmse: 71.8511\n",
      "[150]\ttraining's rmse: 40.1745\tvalid_1's rmse: 66.1381\n",
      "[180]\ttraining's rmse: 34.0376\tvalid_1's rmse: 62.7994\n",
      "[210]\ttraining's rmse: 29.7626\tvalid_1's rmse: 60.771\n",
      "[240]\ttraining's rmse: 26.5173\tvalid_1's rmse: 59.4759\n",
      "[270]\ttraining's rmse: 23.9176\tvalid_1's rmse: 58.5702\n",
      "[300]\ttraining's rmse: 21.7601\tvalid_1's rmse: 58.0204\n",
      "[330]\ttraining's rmse: 19.9473\tvalid_1's rmse: 57.5053\n",
      "[360]\ttraining's rmse: 18.363\tvalid_1's rmse: 57.2509\n",
      "[390]\ttraining's rmse: 16.9797\tvalid_1's rmse: 56.9732\n",
      "[420]\ttraining's rmse: 15.7355\tvalid_1's rmse: 56.7767\n",
      "[450]\ttraining's rmse: 14.598\tvalid_1's rmse: 56.5939\n",
      "[480]\ttraining's rmse: 13.5588\tvalid_1's rmse: 56.4296\n",
      "[510]\ttraining's rmse: 12.6334\tvalid_1's rmse: 56.2785\n",
      "[540]\ttraining's rmse: 11.7912\tvalid_1's rmse: 56.1684\n",
      "[570]\ttraining's rmse: 11.0246\tvalid_1's rmse: 56.0753\n",
      "[600]\ttraining's rmse: 10.3211\tvalid_1's rmse: 55.9768\n",
      "[630]\ttraining's rmse: 9.67198\tvalid_1's rmse: 55.9064\n",
      "[660]\ttraining's rmse: 9.0709\tvalid_1's rmse: 55.8411\n",
      "[690]\ttraining's rmse: 8.51386\tvalid_1's rmse: 55.7967\n",
      "[720]\ttraining's rmse: 8.00267\tvalid_1's rmse: 55.7483\n",
      "[750]\ttraining's rmse: 7.5327\tvalid_1's rmse: 55.7226\n",
      "[780]\ttraining's rmse: 7.09932\tvalid_1's rmse: 55.686\n",
      "[810]\ttraining's rmse: 6.68064\tvalid_1's rmse: 55.642\n",
      "[840]\ttraining's rmse: 6.30158\tvalid_1's rmse: 55.6217\n",
      "[870]\ttraining's rmse: 5.94536\tvalid_1's rmse: 55.6039\n",
      "[900]\ttraining's rmse: 5.60961\tvalid_1's rmse: 55.5596\n",
      "[930]\ttraining's rmse: 5.30042\tvalid_1's rmse: 55.5275\n",
      "[960]\ttraining's rmse: 5.01401\tvalid_1's rmse: 55.4949\n",
      "[990]\ttraining's rmse: 4.73575\tvalid_1's rmse: 55.4788\n",
      "[1020]\ttraining's rmse: 4.48101\tvalid_1's rmse: 55.4609\n",
      "[1050]\ttraining's rmse: 4.24551\tvalid_1's rmse: 55.443\n",
      "[1080]\ttraining's rmse: 4.01902\tvalid_1's rmse: 55.4252\n",
      "[1110]\ttraining's rmse: 3.81233\tvalid_1's rmse: 55.4126\n",
      "[1140]\ttraining's rmse: 3.6206\tvalid_1's rmse: 55.3993\n",
      "[1170]\ttraining's rmse: 3.43503\tvalid_1's rmse: 55.3944\n",
      "[1200]\ttraining's rmse: 3.25716\tvalid_1's rmse: 55.385\n",
      "[1230]\ttraining's rmse: 3.0882\tvalid_1's rmse: 55.3782\n",
      "[1260]\ttraining's rmse: 2.93056\tvalid_1's rmse: 55.3741\n",
      "[1290]\ttraining's rmse: 2.78276\tvalid_1's rmse: 55.3659\n",
      "[1320]\ttraining's rmse: 2.64622\tvalid_1's rmse: 55.3644\n",
      "[1350]\ttraining's rmse: 2.51641\tvalid_1's rmse: 55.3564\n",
      "[1380]\ttraining's rmse: 2.39323\tvalid_1's rmse: 55.3527\n",
      "[1410]\ttraining's rmse: 2.27714\tvalid_1's rmse: 55.3479\n",
      "[1440]\ttraining's rmse: 2.16678\tvalid_1's rmse: 55.34\n",
      "[1470]\ttraining's rmse: 2.06387\tvalid_1's rmse: 55.3344\n",
      "[1500]\ttraining's rmse: 1.9662\tvalid_1's rmse: 55.3273\n",
      "[1530]\ttraining's rmse: 1.87137\tvalid_1's rmse: 55.3254\n",
      "[1560]\ttraining's rmse: 1.78398\tvalid_1's rmse: 55.3246\n",
      "[1590]\ttraining's rmse: 1.69946\tvalid_1's rmse: 55.3216\n",
      "[1620]\ttraining's rmse: 1.62206\tvalid_1's rmse: 55.3191\n",
      "[1650]\ttraining's rmse: 1.55222\tvalid_1's rmse: 55.3169\n",
      "[1680]\ttraining's rmse: 1.48194\tvalid_1's rmse: 55.3142\n",
      "[1710]\ttraining's rmse: 1.41524\tvalid_1's rmse: 55.3114\n",
      "[1740]\ttraining's rmse: 1.35113\tvalid_1's rmse: 55.3099\n",
      "[1770]\ttraining's rmse: 1.29146\tvalid_1's rmse: 55.3071\n",
      "[1800]\ttraining's rmse: 1.23388\tvalid_1's rmse: 55.3016\n",
      "[1830]\ttraining's rmse: 1.1789\tvalid_1's rmse: 55.2999\n",
      "[1860]\ttraining's rmse: 1.12689\tvalid_1's rmse: 55.2987\n",
      "[1890]\ttraining's rmse: 1.07874\tvalid_1's rmse: 55.2984\n",
      "[1920]\ttraining's rmse: 1.03391\tvalid_1's rmse: 55.2968\n",
      "[1950]\ttraining's rmse: 0.988363\tvalid_1's rmse: 55.2968\n",
      "[1980]\ttraining's rmse: 0.948358\tvalid_1's rmse: 55.2945\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's rmse: 0.922314\tvalid_1's rmse: 55.2945\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003309 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 20021\n",
      "[LightGBM] [Info] Number of data points in the train set: 9219, number of used features: 79\n",
      "[LightGBM] [Info] Start training from score 367.363229\n",
      "Training until validation scores don't improve for 125 rounds\n",
      "[30]\ttraining's rmse: 148.66\tvalid_1's rmse: 153.457\n",
      "[60]\ttraining's rmse: 94.3434\tvalid_1's rmse: 103.696\n",
      "[90]\ttraining's rmse: 64.9017\tvalid_1's rmse: 78.7352\n",
      "[120]\ttraining's rmse: 48.6868\tvalid_1's rmse: 66.6434\n",
      "[150]\ttraining's rmse: 39.375\tvalid_1's rmse: 60.6424\n",
      "[180]\ttraining's rmse: 33.4589\tvalid_1's rmse: 57.4214\n",
      "[210]\ttraining's rmse: 29.2579\tvalid_1's rmse: 55.4912\n",
      "[240]\ttraining's rmse: 26.0039\tvalid_1's rmse: 54.1937\n",
      "[270]\ttraining's rmse: 23.4392\tvalid_1's rmse: 53.41\n",
      "[300]\ttraining's rmse: 21.3155\tvalid_1's rmse: 52.8132\n",
      "[330]\ttraining's rmse: 19.4916\tvalid_1's rmse: 52.47\n",
      "[360]\ttraining's rmse: 17.8885\tvalid_1's rmse: 52.1738\n",
      "[390]\ttraining's rmse: 16.4819\tvalid_1's rmse: 51.9697\n",
      "[420]\ttraining's rmse: 15.2356\tvalid_1's rmse: 51.7838\n",
      "[450]\ttraining's rmse: 14.1304\tvalid_1's rmse: 51.6417\n",
      "[480]\ttraining's rmse: 13.137\tvalid_1's rmse: 51.5122\n",
      "[510]\ttraining's rmse: 12.2065\tvalid_1's rmse: 51.4126\n",
      "[540]\ttraining's rmse: 11.388\tvalid_1's rmse: 51.3209\n",
      "[570]\ttraining's rmse: 10.635\tvalid_1's rmse: 51.2463\n",
      "[600]\ttraining's rmse: 9.93753\tvalid_1's rmse: 51.1924\n",
      "[630]\ttraining's rmse: 9.3133\tvalid_1's rmse: 51.1375\n",
      "[660]\ttraining's rmse: 8.70558\tvalid_1's rmse: 51.0752\n",
      "[690]\ttraining's rmse: 8.16023\tvalid_1's rmse: 51.0314\n",
      "[720]\ttraining's rmse: 7.66453\tvalid_1's rmse: 50.9783\n",
      "[750]\ttraining's rmse: 7.20806\tvalid_1's rmse: 50.935\n",
      "[780]\ttraining's rmse: 6.77418\tvalid_1's rmse: 50.9068\n",
      "[810]\ttraining's rmse: 6.37119\tvalid_1's rmse: 50.8842\n",
      "[840]\ttraining's rmse: 6.00588\tvalid_1's rmse: 50.8839\n",
      "[870]\ttraining's rmse: 5.65496\tvalid_1's rmse: 50.8498\n",
      "[900]\ttraining's rmse: 5.33875\tvalid_1's rmse: 50.8191\n",
      "[930]\ttraining's rmse: 5.03434\tvalid_1's rmse: 50.8107\n",
      "[960]\ttraining's rmse: 4.7543\tvalid_1's rmse: 50.7881\n",
      "[990]\ttraining's rmse: 4.48891\tvalid_1's rmse: 50.7712\n",
      "[1020]\ttraining's rmse: 4.24082\tvalid_1's rmse: 50.7551\n",
      "[1050]\ttraining's rmse: 4.00779\tvalid_1's rmse: 50.7405\n",
      "[1080]\ttraining's rmse: 3.78888\tvalid_1's rmse: 50.7305\n",
      "[1110]\ttraining's rmse: 3.58129\tvalid_1's rmse: 50.721\n",
      "[1140]\ttraining's rmse: 3.38908\tvalid_1's rmse: 50.7119\n",
      "[1170]\ttraining's rmse: 3.20703\tvalid_1's rmse: 50.6974\n",
      "[1200]\ttraining's rmse: 3.03612\tvalid_1's rmse: 50.6853\n",
      "[1230]\ttraining's rmse: 2.8772\tvalid_1's rmse: 50.6815\n",
      "[1260]\ttraining's rmse: 2.72517\tvalid_1's rmse: 50.6727\n",
      "[1290]\ttraining's rmse: 2.58481\tvalid_1's rmse: 50.6668\n",
      "[1320]\ttraining's rmse: 2.45074\tvalid_1's rmse: 50.6556\n",
      "[1350]\ttraining's rmse: 2.3238\tvalid_1's rmse: 50.6459\n",
      "[1380]\ttraining's rmse: 2.2044\tvalid_1's rmse: 50.6394\n",
      "[1410]\ttraining's rmse: 2.09157\tvalid_1's rmse: 50.6367\n",
      "[1440]\ttraining's rmse: 1.98593\tvalid_1's rmse: 50.6309\n",
      "[1470]\ttraining's rmse: 1.8831\tvalid_1's rmse: 50.6265\n",
      "[1500]\ttraining's rmse: 1.78969\tvalid_1's rmse: 50.6213\n",
      "[1530]\ttraining's rmse: 1.69856\tvalid_1's rmse: 50.6187\n",
      "[1560]\ttraining's rmse: 1.61238\tvalid_1's rmse: 50.6152\n",
      "[1590]\ttraining's rmse: 1.53121\tvalid_1's rmse: 50.6121\n",
      "[1620]\ttraining's rmse: 1.45614\tvalid_1's rmse: 50.6071\n",
      "[1650]\ttraining's rmse: 1.38517\tvalid_1's rmse: 50.6036\n",
      "[1680]\ttraining's rmse: 1.3157\tvalid_1's rmse: 50.6015\n",
      "[1710]\ttraining's rmse: 1.25035\tvalid_1's rmse: 50.5992\n",
      "[1740]\ttraining's rmse: 1.18923\tvalid_1's rmse: 50.5978\n",
      "[1770]\ttraining's rmse: 1.13081\tvalid_1's rmse: 50.5946\n",
      "[1800]\ttraining's rmse: 1.07536\tvalid_1's rmse: 50.5903\n",
      "[1830]\ttraining's rmse: 1.02347\tvalid_1's rmse: 50.5881\n",
      "[1860]\ttraining's rmse: 0.974807\tvalid_1's rmse: 50.5874\n",
      "[1890]\ttraining's rmse: 0.927266\tvalid_1's rmse: 50.5847\n",
      "[1920]\ttraining's rmse: 0.883152\tvalid_1's rmse: 50.583\n",
      "[1950]\ttraining's rmse: 0.841303\tvalid_1's rmse: 50.5831\n",
      "[1980]\ttraining's rmse: 0.802663\tvalid_1's rmse: 50.5824\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's rmse: 0.777211\tvalid_1's rmse: 50.5816\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003511 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 20021\n",
      "[LightGBM] [Info] Number of data points in the train set: 9219, number of used features: 79\n",
      "[LightGBM] [Info] Start training from score 362.563081\n",
      "Training until validation scores don't improve for 125 rounds\n",
      "[30]\ttraining's rmse: 149.055\tvalid_1's rmse: 150.581\n",
      "[60]\ttraining's rmse: 93.8918\tvalid_1's rmse: 102.779\n",
      "[90]\ttraining's rmse: 63.8435\tvalid_1's rmse: 79.1343\n",
      "[120]\ttraining's rmse: 47.5945\tvalid_1's rmse: 68.1674\n",
      "[150]\ttraining's rmse: 38.4852\tvalid_1's rmse: 62.8651\n",
      "[180]\ttraining's rmse: 32.6963\tvalid_1's rmse: 59.7811\n",
      "[210]\ttraining's rmse: 28.6445\tvalid_1's rmse: 57.7019\n",
      "[240]\ttraining's rmse: 25.5205\tvalid_1's rmse: 56.4071\n",
      "[270]\ttraining's rmse: 23.0386\tvalid_1's rmse: 55.3887\n",
      "[300]\ttraining's rmse: 20.9727\tvalid_1's rmse: 54.6777\n",
      "[330]\ttraining's rmse: 19.2438\tvalid_1's rmse: 54.2403\n",
      "[360]\ttraining's rmse: 17.7206\tvalid_1's rmse: 53.8954\n",
      "[390]\ttraining's rmse: 16.3429\tvalid_1's rmse: 53.5832\n",
      "[420]\ttraining's rmse: 15.1339\tvalid_1's rmse: 53.3413\n",
      "[450]\ttraining's rmse: 14.0366\tvalid_1's rmse: 53.1379\n",
      "[480]\ttraining's rmse: 13.0432\tvalid_1's rmse: 52.9616\n",
      "[510]\ttraining's rmse: 12.1588\tvalid_1's rmse: 52.8156\n",
      "[540]\ttraining's rmse: 11.3417\tvalid_1's rmse: 52.6988\n",
      "[570]\ttraining's rmse: 10.6095\tvalid_1's rmse: 52.6361\n",
      "[600]\ttraining's rmse: 9.92653\tvalid_1's rmse: 52.5674\n",
      "[630]\ttraining's rmse: 9.29843\tvalid_1's rmse: 52.4888\n",
      "[660]\ttraining's rmse: 8.7171\tvalid_1's rmse: 52.4186\n",
      "[690]\ttraining's rmse: 8.19213\tvalid_1's rmse: 52.3649\n",
      "[720]\ttraining's rmse: 7.69513\tvalid_1's rmse: 52.3169\n",
      "[750]\ttraining's rmse: 7.23638\tvalid_1's rmse: 52.3029\n",
      "[780]\ttraining's rmse: 6.8151\tvalid_1's rmse: 52.2649\n",
      "[810]\ttraining's rmse: 6.41288\tvalid_1's rmse: 52.2398\n",
      "[840]\ttraining's rmse: 6.04466\tvalid_1's rmse: 52.2169\n",
      "[870]\ttraining's rmse: 5.70616\tvalid_1's rmse: 52.2031\n",
      "[900]\ttraining's rmse: 5.37714\tvalid_1's rmse: 52.1823\n",
      "[930]\ttraining's rmse: 5.08315\tvalid_1's rmse: 52.1632\n",
      "[960]\ttraining's rmse: 4.79902\tvalid_1's rmse: 52.139\n",
      "[990]\ttraining's rmse: 4.53961\tvalid_1's rmse: 52.1254\n",
      "[1020]\ttraining's rmse: 4.30135\tvalid_1's rmse: 52.1102\n",
      "[1050]\ttraining's rmse: 4.07195\tvalid_1's rmse: 52.0955\n",
      "[1080]\ttraining's rmse: 3.8542\tvalid_1's rmse: 52.0826\n",
      "[1110]\ttraining's rmse: 3.64792\tvalid_1's rmse: 52.0727\n",
      "[1140]\ttraining's rmse: 3.45822\tvalid_1's rmse: 52.0624\n",
      "[1170]\ttraining's rmse: 3.27548\tvalid_1's rmse: 52.0546\n",
      "[1200]\ttraining's rmse: 3.1086\tvalid_1's rmse: 52.0486\n",
      "[1230]\ttraining's rmse: 2.94324\tvalid_1's rmse: 52.0411\n",
      "[1260]\ttraining's rmse: 2.79324\tvalid_1's rmse: 52.0351\n",
      "[1290]\ttraining's rmse: 2.65051\tvalid_1's rmse: 52.0244\n",
      "[1320]\ttraining's rmse: 2.51671\tvalid_1's rmse: 52.0151\n",
      "[1350]\ttraining's rmse: 2.39136\tvalid_1's rmse: 52.012\n",
      "[1380]\ttraining's rmse: 2.27107\tvalid_1's rmse: 52.0041\n",
      "[1410]\ttraining's rmse: 2.15647\tvalid_1's rmse: 51.9988\n",
      "[1440]\ttraining's rmse: 2.04772\tvalid_1's rmse: 51.9941\n",
      "[1470]\ttraining's rmse: 1.94405\tvalid_1's rmse: 51.9885\n",
      "[1500]\ttraining's rmse: 1.84822\tvalid_1's rmse: 51.9862\n",
      "[1530]\ttraining's rmse: 1.75638\tvalid_1's rmse: 51.9865\n",
      "[1560]\ttraining's rmse: 1.67018\tvalid_1's rmse: 51.9828\n",
      "[1590]\ttraining's rmse: 1.58918\tvalid_1's rmse: 51.9788\n",
      "[1620]\ttraining's rmse: 1.51447\tvalid_1's rmse: 51.9728\n",
      "[1650]\ttraining's rmse: 1.44021\tvalid_1's rmse: 51.9689\n",
      "[1680]\ttraining's rmse: 1.37074\tvalid_1's rmse: 51.9674\n",
      "[1710]\ttraining's rmse: 1.30293\tvalid_1's rmse: 51.9659\n",
      "[1740]\ttraining's rmse: 1.23956\tvalid_1's rmse: 51.9628\n",
      "[1770]\ttraining's rmse: 1.18055\tvalid_1's rmse: 51.9612\n",
      "[1800]\ttraining's rmse: 1.12377\tvalid_1's rmse: 51.961\n",
      "[1830]\ttraining's rmse: 1.07039\tvalid_1's rmse: 51.9599\n",
      "[1860]\ttraining's rmse: 1.01963\tvalid_1's rmse: 51.9595\n",
      "[1890]\ttraining's rmse: 0.971556\tvalid_1's rmse: 51.9554\n",
      "[1920]\ttraining's rmse: 0.925952\tvalid_1's rmse: 51.9534\n",
      "[1950]\ttraining's rmse: 0.884189\tvalid_1's rmse: 51.9521\n",
      "[1980]\ttraining's rmse: 0.844429\tvalid_1's rmse: 51.9508\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's rmse: 0.818809\tvalid_1's rmse: 51.9496\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003462 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 20021\n",
      "[LightGBM] [Info] Number of data points in the train set: 9219, number of used features: 79\n",
      "[LightGBM] [Info] Start training from score 362.962657\n",
      "Training until validation scores don't improve for 125 rounds\n",
      "[30]\ttraining's rmse: 148.6\tvalid_1's rmse: 152.775\n",
      "[60]\ttraining's rmse: 93.727\tvalid_1's rmse: 105.699\n",
      "[90]\ttraining's rmse: 64.0284\tvalid_1's rmse: 83.2694\n",
      "[120]\ttraining's rmse: 47.7324\tvalid_1's rmse: 72.2906\n",
      "[150]\ttraining's rmse: 38.5488\tvalid_1's rmse: 67.0611\n",
      "[180]\ttraining's rmse: 32.8614\tvalid_1's rmse: 64.0704\n",
      "[210]\ttraining's rmse: 28.8429\tvalid_1's rmse: 62.1577\n",
      "[240]\ttraining's rmse: 25.7501\tvalid_1's rmse: 60.9195\n",
      "[270]\ttraining's rmse: 23.2489\tvalid_1's rmse: 59.9977\n",
      "[300]\ttraining's rmse: 21.1093\tvalid_1's rmse: 59.2944\n",
      "[330]\ttraining's rmse: 19.3609\tvalid_1's rmse: 58.8837\n",
      "[360]\ttraining's rmse: 17.8274\tvalid_1's rmse: 58.4776\n",
      "[390]\ttraining's rmse: 16.4809\tvalid_1's rmse: 58.2368\n",
      "[420]\ttraining's rmse: 15.2745\tvalid_1's rmse: 57.983\n",
      "[450]\ttraining's rmse: 14.1779\tvalid_1's rmse: 57.8248\n",
      "[480]\ttraining's rmse: 13.2062\tvalid_1's rmse: 57.704\n",
      "[510]\ttraining's rmse: 12.3148\tvalid_1's rmse: 57.563\n",
      "[540]\ttraining's rmse: 11.5038\tvalid_1's rmse: 57.4261\n",
      "[570]\ttraining's rmse: 10.7614\tvalid_1's rmse: 57.3426\n",
      "[600]\ttraining's rmse: 10.0678\tvalid_1's rmse: 57.2461\n",
      "[630]\ttraining's rmse: 9.44419\tvalid_1's rmse: 57.1534\n",
      "[660]\ttraining's rmse: 8.87082\tvalid_1's rmse: 57.0912\n",
      "[690]\ttraining's rmse: 8.32026\tvalid_1's rmse: 57.026\n",
      "[720]\ttraining's rmse: 7.81868\tvalid_1's rmse: 56.9741\n",
      "[750]\ttraining's rmse: 7.35505\tvalid_1's rmse: 56.9193\n",
      "[780]\ttraining's rmse: 6.93492\tvalid_1's rmse: 56.8859\n",
      "[810]\ttraining's rmse: 6.53381\tvalid_1's rmse: 56.8548\n",
      "[840]\ttraining's rmse: 6.16377\tvalid_1's rmse: 56.8261\n",
      "[870]\ttraining's rmse: 5.82603\tvalid_1's rmse: 56.8085\n",
      "[900]\ttraining's rmse: 5.49394\tvalid_1's rmse: 56.7822\n",
      "[930]\ttraining's rmse: 5.18732\tvalid_1's rmse: 56.7657\n",
      "[960]\ttraining's rmse: 4.90402\tvalid_1's rmse: 56.7418\n",
      "[990]\ttraining's rmse: 4.63583\tvalid_1's rmse: 56.7138\n",
      "[1020]\ttraining's rmse: 4.39078\tvalid_1's rmse: 56.6992\n",
      "[1050]\ttraining's rmse: 4.15672\tvalid_1's rmse: 56.6764\n",
      "[1080]\ttraining's rmse: 3.93733\tvalid_1's rmse: 56.6614\n",
      "[1110]\ttraining's rmse: 3.73115\tvalid_1's rmse: 56.6509\n",
      "[1140]\ttraining's rmse: 3.53655\tvalid_1's rmse: 56.6365\n",
      "[1170]\ttraining's rmse: 3.3579\tvalid_1's rmse: 56.627\n",
      "[1200]\ttraining's rmse: 3.18545\tvalid_1's rmse: 56.6168\n",
      "[1230]\ttraining's rmse: 3.02044\tvalid_1's rmse: 56.605\n",
      "[1260]\ttraining's rmse: 2.8683\tvalid_1's rmse: 56.599\n",
      "[1290]\ttraining's rmse: 2.71938\tvalid_1's rmse: 56.5976\n",
      "[1320]\ttraining's rmse: 2.582\tvalid_1's rmse: 56.5918\n",
      "[1350]\ttraining's rmse: 2.45259\tvalid_1's rmse: 56.585\n",
      "[1380]\ttraining's rmse: 2.33392\tvalid_1's rmse: 56.5802\n",
      "[1410]\ttraining's rmse: 2.21789\tvalid_1's rmse: 56.5731\n",
      "[1440]\ttraining's rmse: 2.10788\tvalid_1's rmse: 56.5684\n",
      "[1470]\ttraining's rmse: 2.00658\tvalid_1's rmse: 56.5607\n",
      "[1500]\ttraining's rmse: 1.91086\tvalid_1's rmse: 56.5527\n",
      "[1530]\ttraining's rmse: 1.82058\tvalid_1's rmse: 56.5489\n",
      "[1560]\ttraining's rmse: 1.73463\tvalid_1's rmse: 56.5454\n",
      "[1590]\ttraining's rmse: 1.6515\tvalid_1's rmse: 56.5427\n",
      "[1620]\ttraining's rmse: 1.5741\tvalid_1's rmse: 56.5377\n",
      "[1650]\ttraining's rmse: 1.5008\tvalid_1's rmse: 56.5322\n",
      "[1680]\ttraining's rmse: 1.43084\tvalid_1's rmse: 56.5302\n",
      "[1710]\ttraining's rmse: 1.3641\tvalid_1's rmse: 56.5258\n",
      "[1740]\ttraining's rmse: 1.29923\tvalid_1's rmse: 56.5249\n",
      "[1770]\ttraining's rmse: 1.23974\tvalid_1's rmse: 56.5231\n",
      "[1800]\ttraining's rmse: 1.18348\tvalid_1's rmse: 56.5222\n",
      "[1830]\ttraining's rmse: 1.13081\tvalid_1's rmse: 56.5229\n",
      "[1860]\ttraining's rmse: 1.07897\tvalid_1's rmse: 56.5214\n",
      "[1890]\ttraining's rmse: 1.03088\tvalid_1's rmse: 56.5186\n",
      "[1920]\ttraining's rmse: 0.985707\tvalid_1's rmse: 56.5164\n",
      "[1950]\ttraining's rmse: 0.941299\tvalid_1's rmse: 56.5162\n",
      "[1980]\ttraining's rmse: 0.900316\tvalid_1's rmse: 56.5145\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's rmse: 0.8743\tvalid_1's rmse: 56.5143\n",
      "35\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002374 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 20022\n",
      "[LightGBM] [Info] Number of data points in the train set: 9219, number of used features: 79\n",
      "[LightGBM] [Info] Start training from score 369.984226\n",
      "Training until validation scores don't improve for 125 rounds\n",
      "[30]\ttraining's rmse: 146.911\tvalid_1's rmse: 148.454\n",
      "[60]\ttraining's rmse: 92.0937\tvalid_1's rmse: 101.31\n",
      "[90]\ttraining's rmse: 62.4891\tvalid_1's rmse: 78.2945\n",
      "[120]\ttraining's rmse: 46.3714\tvalid_1's rmse: 67.6256\n",
      "[150]\ttraining's rmse: 37.3258\tvalid_1's rmse: 62.5377\n",
      "[180]\ttraining's rmse: 31.7485\tvalid_1's rmse: 59.9475\n",
      "[210]\ttraining's rmse: 27.7505\tvalid_1's rmse: 58.3589\n",
      "[240]\ttraining's rmse: 24.7543\tvalid_1's rmse: 57.2045\n",
      "[270]\ttraining's rmse: 22.2977\tvalid_1's rmse: 56.4196\n",
      "[300]\ttraining's rmse: 20.2861\tvalid_1's rmse: 55.8567\n",
      "[330]\ttraining's rmse: 18.5969\tvalid_1's rmse: 55.5716\n",
      "[360]\ttraining's rmse: 17.1435\tvalid_1's rmse: 55.2431\n",
      "[390]\ttraining's rmse: 15.8367\tvalid_1's rmse: 55.0288\n",
      "[420]\ttraining's rmse: 14.6625\tvalid_1's rmse: 54.8547\n",
      "[450]\ttraining's rmse: 13.6237\tvalid_1's rmse: 54.6791\n",
      "[480]\ttraining's rmse: 12.6707\tvalid_1's rmse: 54.5709\n",
      "[510]\ttraining's rmse: 11.7953\tvalid_1's rmse: 54.4319\n",
      "[540]\ttraining's rmse: 11.0178\tvalid_1's rmse: 54.338\n",
      "[570]\ttraining's rmse: 10.3077\tvalid_1's rmse: 54.2783\n",
      "[600]\ttraining's rmse: 9.64675\tvalid_1's rmse: 54.183\n",
      "[630]\ttraining's rmse: 9.04665\tvalid_1's rmse: 54.1171\n",
      "[660]\ttraining's rmse: 8.49138\tvalid_1's rmse: 54.0576\n",
      "[690]\ttraining's rmse: 7.97792\tvalid_1's rmse: 54.0039\n",
      "[720]\ttraining's rmse: 7.48818\tvalid_1's rmse: 53.9667\n",
      "[750]\ttraining's rmse: 7.04814\tvalid_1's rmse: 53.9583\n",
      "[780]\ttraining's rmse: 6.64755\tvalid_1's rmse: 53.9287\n",
      "[810]\ttraining's rmse: 6.25726\tvalid_1's rmse: 53.8959\n",
      "[840]\ttraining's rmse: 5.89655\tvalid_1's rmse: 53.8668\n",
      "[870]\ttraining's rmse: 5.56401\tvalid_1's rmse: 53.8456\n",
      "[900]\ttraining's rmse: 5.24814\tvalid_1's rmse: 53.8144\n",
      "[930]\ttraining's rmse: 4.95104\tvalid_1's rmse: 53.7998\n",
      "[960]\ttraining's rmse: 4.67606\tvalid_1's rmse: 53.785\n",
      "[990]\ttraining's rmse: 4.417\tvalid_1's rmse: 53.7656\n",
      "[1020]\ttraining's rmse: 4.17557\tvalid_1's rmse: 53.7455\n",
      "[1050]\ttraining's rmse: 3.94314\tvalid_1's rmse: 53.7402\n",
      "[1080]\ttraining's rmse: 3.72833\tvalid_1's rmse: 53.7288\n",
      "[1110]\ttraining's rmse: 3.5325\tvalid_1's rmse: 53.7152\n",
      "[1140]\ttraining's rmse: 3.34393\tvalid_1's rmse: 53.7093\n",
      "[1170]\ttraining's rmse: 3.16947\tvalid_1's rmse: 53.6951\n",
      "[1200]\ttraining's rmse: 3.00487\tvalid_1's rmse: 53.6816\n",
      "[1230]\ttraining's rmse: 2.84932\tvalid_1's rmse: 53.6756\n",
      "[1260]\ttraining's rmse: 2.7001\tvalid_1's rmse: 53.6625\n",
      "[1290]\ttraining's rmse: 2.56066\tvalid_1's rmse: 53.6607\n",
      "[1320]\ttraining's rmse: 2.42874\tvalid_1's rmse: 53.6561\n",
      "[1350]\ttraining's rmse: 2.30069\tvalid_1's rmse: 53.6572\n",
      "[1380]\ttraining's rmse: 2.1814\tvalid_1's rmse: 53.6553\n",
      "[1410]\ttraining's rmse: 2.07059\tvalid_1's rmse: 53.6545\n",
      "[1440]\ttraining's rmse: 1.96748\tvalid_1's rmse: 53.6499\n",
      "[1470]\ttraining's rmse: 1.86854\tvalid_1's rmse: 53.6489\n",
      "[1500]\ttraining's rmse: 1.77494\tvalid_1's rmse: 53.6465\n",
      "[1530]\ttraining's rmse: 1.68438\tvalid_1's rmse: 53.6388\n",
      "[1560]\ttraining's rmse: 1.59992\tvalid_1's rmse: 53.6349\n",
      "[1590]\ttraining's rmse: 1.5188\tvalid_1's rmse: 53.6302\n",
      "[1620]\ttraining's rmse: 1.44353\tvalid_1's rmse: 53.6276\n",
      "[1650]\ttraining's rmse: 1.37179\tvalid_1's rmse: 53.6263\n",
      "[1680]\ttraining's rmse: 1.30286\tvalid_1's rmse: 53.6253\n",
      "[1710]\ttraining's rmse: 1.2388\tvalid_1's rmse: 53.6235\n",
      "[1740]\ttraining's rmse: 1.17702\tvalid_1's rmse: 53.6219\n",
      "[1770]\ttraining's rmse: 1.11982\tvalid_1's rmse: 53.621\n",
      "[1800]\ttraining's rmse: 1.06468\tvalid_1's rmse: 53.6195\n",
      "[1830]\ttraining's rmse: 1.01284\tvalid_1's rmse: 53.6186\n",
      "[1860]\ttraining's rmse: 0.962872\tvalid_1's rmse: 53.6159\n",
      "[1890]\ttraining's rmse: 0.917243\tvalid_1's rmse: 53.6146\n",
      "[1920]\ttraining's rmse: 0.872621\tvalid_1's rmse: 53.6119\n",
      "[1950]\ttraining's rmse: 0.830591\tvalid_1's rmse: 53.6104\n",
      "[1980]\ttraining's rmse: 0.790596\tvalid_1's rmse: 53.6094\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's rmse: 0.765425\tvalid_1's rmse: 53.609\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002612 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 20022\n",
      "[LightGBM] [Info] Number of data points in the train set: 9219, number of used features: 79\n",
      "[LightGBM] [Info] Start training from score 372.870075\n",
      "Training until validation scores don't improve for 125 rounds\n",
      "[30]\ttraining's rmse: 148.255\tvalid_1's rmse: 154.591\n",
      "[60]\ttraining's rmse: 94.7007\tvalid_1's rmse: 107.498\n",
      "[90]\ttraining's rmse: 65.6005\tvalid_1's rmse: 84.5782\n",
      "[120]\ttraining's rmse: 49.3239\tvalid_1's rmse: 73.4509\n",
      "[150]\ttraining's rmse: 40.0145\tvalid_1's rmse: 67.6897\n",
      "[180]\ttraining's rmse: 34.1544\tvalid_1's rmse: 64.618\n",
      "[210]\ttraining's rmse: 30.0194\tvalid_1's rmse: 62.6047\n",
      "[240]\ttraining's rmse: 26.8048\tvalid_1's rmse: 61.1667\n",
      "[270]\ttraining's rmse: 24.2583\tvalid_1's rmse: 60.1287\n",
      "[300]\ttraining's rmse: 22.1369\tvalid_1's rmse: 59.5137\n",
      "[330]\ttraining's rmse: 20.3517\tvalid_1's rmse: 59.1415\n",
      "[360]\ttraining's rmse: 18.8043\tvalid_1's rmse: 58.8009\n",
      "[390]\ttraining's rmse: 17.421\tvalid_1's rmse: 58.4825\n",
      "[420]\ttraining's rmse: 16.1799\tvalid_1's rmse: 58.2616\n",
      "[450]\ttraining's rmse: 15.0617\tvalid_1's rmse: 58.0938\n",
      "[480]\ttraining's rmse: 14.053\tvalid_1's rmse: 57.9022\n",
      "[510]\ttraining's rmse: 13.1016\tvalid_1's rmse: 57.7075\n",
      "[540]\ttraining's rmse: 12.258\tvalid_1's rmse: 57.6047\n",
      "[570]\ttraining's rmse: 11.4866\tvalid_1's rmse: 57.51\n",
      "[600]\ttraining's rmse: 10.7633\tvalid_1's rmse: 57.3939\n",
      "[630]\ttraining's rmse: 10.0997\tvalid_1's rmse: 57.2788\n",
      "[660]\ttraining's rmse: 9.50967\tvalid_1's rmse: 57.1863\n",
      "[690]\ttraining's rmse: 8.95723\tvalid_1's rmse: 57.1583\n",
      "[720]\ttraining's rmse: 8.42497\tvalid_1's rmse: 57.1118\n",
      "[750]\ttraining's rmse: 7.9491\tvalid_1's rmse: 57.0821\n",
      "[780]\ttraining's rmse: 7.49891\tvalid_1's rmse: 57.0431\n",
      "[810]\ttraining's rmse: 7.07686\tvalid_1's rmse: 56.9961\n",
      "[840]\ttraining's rmse: 6.69357\tvalid_1's rmse: 56.963\n",
      "[870]\ttraining's rmse: 6.33131\tvalid_1's rmse: 56.9467\n",
      "[900]\ttraining's rmse: 5.98371\tvalid_1's rmse: 56.9137\n",
      "[930]\ttraining's rmse: 5.66838\tvalid_1's rmse: 56.8952\n",
      "[960]\ttraining's rmse: 5.36217\tvalid_1's rmse: 56.8862\n",
      "[990]\ttraining's rmse: 5.0739\tvalid_1's rmse: 56.8504\n",
      "[1020]\ttraining's rmse: 4.8092\tvalid_1's rmse: 56.8234\n",
      "[1050]\ttraining's rmse: 4.56247\tvalid_1's rmse: 56.8098\n",
      "[1080]\ttraining's rmse: 4.33097\tvalid_1's rmse: 56.7906\n",
      "[1110]\ttraining's rmse: 4.10922\tvalid_1's rmse: 56.7804\n",
      "[1140]\ttraining's rmse: 3.90185\tvalid_1's rmse: 56.7576\n",
      "[1170]\ttraining's rmse: 3.70566\tvalid_1's rmse: 56.7447\n",
      "[1200]\ttraining's rmse: 3.52253\tvalid_1's rmse: 56.7286\n",
      "[1230]\ttraining's rmse: 3.34849\tvalid_1's rmse: 56.7137\n",
      "[1260]\ttraining's rmse: 3.18267\tvalid_1's rmse: 56.6971\n",
      "[1290]\ttraining's rmse: 3.03412\tvalid_1's rmse: 56.6858\n",
      "[1320]\ttraining's rmse: 2.88721\tvalid_1's rmse: 56.6747\n",
      "[1350]\ttraining's rmse: 2.74598\tvalid_1's rmse: 56.6659\n",
      "[1380]\ttraining's rmse: 2.60722\tvalid_1's rmse: 56.661\n",
      "[1410]\ttraining's rmse: 2.47715\tvalid_1's rmse: 56.6489\n",
      "[1440]\ttraining's rmse: 2.3597\tvalid_1's rmse: 56.6415\n",
      "[1470]\ttraining's rmse: 2.24883\tvalid_1's rmse: 56.6341\n",
      "[1500]\ttraining's rmse: 2.14338\tvalid_1's rmse: 56.6308\n",
      "[1530]\ttraining's rmse: 2.04973\tvalid_1's rmse: 56.6265\n",
      "[1560]\ttraining's rmse: 1.95092\tvalid_1's rmse: 56.6248\n",
      "[1590]\ttraining's rmse: 1.86237\tvalid_1's rmse: 56.6233\n",
      "[1620]\ttraining's rmse: 1.77327\tvalid_1's rmse: 56.6128\n",
      "[1650]\ttraining's rmse: 1.69585\tvalid_1's rmse: 56.6116\n",
      "[1680]\ttraining's rmse: 1.61735\tvalid_1's rmse: 56.6084\n",
      "[1710]\ttraining's rmse: 1.5411\tvalid_1's rmse: 56.6059\n",
      "[1740]\ttraining's rmse: 1.47359\tvalid_1's rmse: 56.607\n",
      "[1770]\ttraining's rmse: 1.40398\tvalid_1's rmse: 56.5975\n",
      "[1800]\ttraining's rmse: 1.33908\tvalid_1's rmse: 56.5937\n",
      "[1830]\ttraining's rmse: 1.27956\tvalid_1's rmse: 56.5908\n",
      "[1860]\ttraining's rmse: 1.22082\tvalid_1's rmse: 56.5841\n",
      "[1890]\ttraining's rmse: 1.16956\tvalid_1's rmse: 56.5792\n",
      "[1920]\ttraining's rmse: 1.12109\tvalid_1's rmse: 56.5779\n",
      "[1950]\ttraining's rmse: 1.07142\tvalid_1's rmse: 56.574\n",
      "[1980]\ttraining's rmse: 1.02445\tvalid_1's rmse: 56.5726\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's rmse: 0.994332\tvalid_1's rmse: 56.5713\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003466 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 20022\n",
      "[LightGBM] [Info] Number of data points in the train set: 9219, number of used features: 79\n",
      "[LightGBM] [Info] Start training from score 371.327908\n",
      "Training until validation scores don't improve for 125 rounds\n",
      "[30]\ttraining's rmse: 149.482\tvalid_1's rmse: 154.455\n",
      "[60]\ttraining's rmse: 95.9777\tvalid_1's rmse: 107.845\n",
      "[90]\ttraining's rmse: 66.5605\tvalid_1's rmse: 84.1718\n",
      "[120]\ttraining's rmse: 50.0692\tvalid_1's rmse: 72.4294\n",
      "[150]\ttraining's rmse: 40.491\tvalid_1's rmse: 66.5529\n",
      "[180]\ttraining's rmse: 34.5816\tvalid_1's rmse: 63.2696\n",
      "[210]\ttraining's rmse: 30.3878\tvalid_1's rmse: 61.3674\n",
      "[240]\ttraining's rmse: 27.1226\tvalid_1's rmse: 60.1213\n",
      "[270]\ttraining's rmse: 24.5158\tvalid_1's rmse: 59.2356\n",
      "[300]\ttraining's rmse: 22.3616\tvalid_1's rmse: 58.6706\n",
      "[330]\ttraining's rmse: 20.5045\tvalid_1's rmse: 58.2713\n",
      "[360]\ttraining's rmse: 18.8912\tvalid_1's rmse: 57.977\n",
      "[390]\ttraining's rmse: 17.5037\tvalid_1's rmse: 57.7569\n",
      "[420]\ttraining's rmse: 16.2383\tvalid_1's rmse: 57.5932\n",
      "[450]\ttraining's rmse: 15.0884\tvalid_1's rmse: 57.4451\n",
      "[480]\ttraining's rmse: 14.0375\tvalid_1's rmse: 57.2893\n",
      "[510]\ttraining's rmse: 13.0969\tvalid_1's rmse: 57.1697\n",
      "[540]\ttraining's rmse: 12.2517\tvalid_1's rmse: 57.0736\n",
      "[570]\ttraining's rmse: 11.465\tvalid_1's rmse: 56.9776\n",
      "[600]\ttraining's rmse: 10.7529\tvalid_1's rmse: 56.8894\n",
      "[630]\ttraining's rmse: 10.0864\tvalid_1's rmse: 56.8133\n",
      "[660]\ttraining's rmse: 9.48298\tvalid_1's rmse: 56.7697\n",
      "[690]\ttraining's rmse: 8.9248\tvalid_1's rmse: 56.7397\n",
      "[720]\ttraining's rmse: 8.40046\tvalid_1's rmse: 56.6846\n",
      "[750]\ttraining's rmse: 7.92156\tvalid_1's rmse: 56.634\n",
      "[780]\ttraining's rmse: 7.47261\tvalid_1's rmse: 56.5999\n",
      "[810]\ttraining's rmse: 7.04413\tvalid_1's rmse: 56.5733\n",
      "[840]\ttraining's rmse: 6.64133\tvalid_1's rmse: 56.5416\n",
      "[870]\ttraining's rmse: 6.26528\tvalid_1's rmse: 56.5105\n",
      "[900]\ttraining's rmse: 5.92642\tvalid_1's rmse: 56.4947\n",
      "[930]\ttraining's rmse: 5.60038\tvalid_1's rmse: 56.4656\n",
      "[960]\ttraining's rmse: 5.29371\tvalid_1's rmse: 56.4465\n",
      "[990]\ttraining's rmse: 5.00393\tvalid_1's rmse: 56.4313\n",
      "[1020]\ttraining's rmse: 4.73678\tvalid_1's rmse: 56.4182\n",
      "[1050]\ttraining's rmse: 4.49028\tvalid_1's rmse: 56.4099\n",
      "[1080]\ttraining's rmse: 4.25644\tvalid_1's rmse: 56.4027\n",
      "[1110]\ttraining's rmse: 4.042\tvalid_1's rmse: 56.3939\n",
      "[1140]\ttraining's rmse: 3.83117\tvalid_1's rmse: 56.3822\n",
      "[1170]\ttraining's rmse: 3.63488\tvalid_1's rmse: 56.3793\n",
      "[1200]\ttraining's rmse: 3.45157\tvalid_1's rmse: 56.3753\n",
      "[1230]\ttraining's rmse: 3.27824\tvalid_1's rmse: 56.3745\n",
      "[1260]\ttraining's rmse: 3.11108\tvalid_1's rmse: 56.3663\n",
      "[1290]\ttraining's rmse: 2.95983\tvalid_1's rmse: 56.3607\n",
      "[1320]\ttraining's rmse: 2.81113\tvalid_1's rmse: 56.348\n",
      "[1350]\ttraining's rmse: 2.67061\tvalid_1's rmse: 56.3409\n",
      "[1380]\ttraining's rmse: 2.53516\tvalid_1's rmse: 56.3356\n",
      "[1410]\ttraining's rmse: 2.40633\tvalid_1's rmse: 56.332\n",
      "[1440]\ttraining's rmse: 2.28904\tvalid_1's rmse: 56.3324\n",
      "[1470]\ttraining's rmse: 2.18033\tvalid_1's rmse: 56.3258\n",
      "[1500]\ttraining's rmse: 2.07754\tvalid_1's rmse: 56.3224\n",
      "[1530]\ttraining's rmse: 1.9834\tvalid_1's rmse: 56.3204\n",
      "[1560]\ttraining's rmse: 1.88841\tvalid_1's rmse: 56.3181\n",
      "[1590]\ttraining's rmse: 1.80164\tvalid_1's rmse: 56.3156\n",
      "[1620]\ttraining's rmse: 1.71565\tvalid_1's rmse: 56.3141\n",
      "[1650]\ttraining's rmse: 1.63542\tvalid_1's rmse: 56.3153\n",
      "[1680]\ttraining's rmse: 1.55733\tvalid_1's rmse: 56.3147\n",
      "[1710]\ttraining's rmse: 1.48235\tvalid_1's rmse: 56.3138\n",
      "[1740]\ttraining's rmse: 1.41437\tvalid_1's rmse: 56.3124\n",
      "[1770]\ttraining's rmse: 1.34792\tvalid_1's rmse: 56.3111\n",
      "[1800]\ttraining's rmse: 1.28439\tvalid_1's rmse: 56.3098\n",
      "[1830]\ttraining's rmse: 1.22482\tvalid_1's rmse: 56.3102\n",
      "[1860]\ttraining's rmse: 1.16777\tvalid_1's rmse: 56.3083\n",
      "[1890]\ttraining's rmse: 1.11589\tvalid_1's rmse: 56.309\n",
      "[1920]\ttraining's rmse: 1.06677\tvalid_1's rmse: 56.3084\n",
      "[1950]\ttraining's rmse: 1.01808\tvalid_1's rmse: 56.3078\n",
      "[1980]\ttraining's rmse: 0.970898\tvalid_1's rmse: 56.3087\n",
      "Early stopping, best iteration is:\n",
      "[1870]\ttraining's rmse: 1.14892\tvalid_1's rmse: 56.3073\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002651 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 20022\n",
      "[LightGBM] [Info] Number of data points in the train set: 9219, number of used features: 79\n",
      "[LightGBM] [Info] Start training from score 366.728918\n",
      "Training until validation scores don't improve for 125 rounds\n",
      "[30]\ttraining's rmse: 149.48\tvalid_1's rmse: 157.257\n",
      "[60]\ttraining's rmse: 95.7203\tvalid_1's rmse: 107.202\n",
      "[90]\ttraining's rmse: 66.39\tvalid_1's rmse: 82.8972\n",
      "[120]\ttraining's rmse: 49.9958\tvalid_1's rmse: 70.9348\n",
      "[150]\ttraining's rmse: 40.4808\tvalid_1's rmse: 65.148\n",
      "[180]\ttraining's rmse: 34.4132\tvalid_1's rmse: 61.8818\n",
      "[210]\ttraining's rmse: 30.1277\tvalid_1's rmse: 59.9012\n",
      "[240]\ttraining's rmse: 26.7824\tvalid_1's rmse: 58.6137\n",
      "[270]\ttraining's rmse: 24.1061\tvalid_1's rmse: 57.5628\n",
      "[300]\ttraining's rmse: 21.8912\tvalid_1's rmse: 56.868\n",
      "[330]\ttraining's rmse: 20.0362\tvalid_1's rmse: 56.4207\n",
      "[360]\ttraining's rmse: 18.4438\tvalid_1's rmse: 56.078\n",
      "[390]\ttraining's rmse: 17.0222\tvalid_1's rmse: 55.8276\n",
      "[420]\ttraining's rmse: 15.7787\tvalid_1's rmse: 55.6127\n",
      "[450]\ttraining's rmse: 14.6386\tvalid_1's rmse: 55.4254\n",
      "[480]\ttraining's rmse: 13.6228\tvalid_1's rmse: 55.3066\n",
      "[510]\ttraining's rmse: 12.6756\tvalid_1's rmse: 55.1737\n",
      "[540]\ttraining's rmse: 11.8533\tvalid_1's rmse: 55.0895\n",
      "[570]\ttraining's rmse: 11.0732\tvalid_1's rmse: 54.9917\n",
      "[600]\ttraining's rmse: 10.3669\tvalid_1's rmse: 54.9178\n",
      "[630]\ttraining's rmse: 9.72129\tvalid_1's rmse: 54.858\n",
      "[660]\ttraining's rmse: 9.11726\tvalid_1's rmse: 54.8035\n",
      "[690]\ttraining's rmse: 8.56486\tvalid_1's rmse: 54.7434\n",
      "[720]\ttraining's rmse: 8.06168\tvalid_1's rmse: 54.6987\n",
      "[750]\ttraining's rmse: 7.59127\tvalid_1's rmse: 54.6507\n",
      "[780]\ttraining's rmse: 7.14661\tvalid_1's rmse: 54.6116\n",
      "[810]\ttraining's rmse: 6.74065\tvalid_1's rmse: 54.5741\n",
      "[840]\ttraining's rmse: 6.36163\tvalid_1's rmse: 54.5562\n",
      "[870]\ttraining's rmse: 6.00557\tvalid_1's rmse: 54.5182\n",
      "[900]\ttraining's rmse: 5.67526\tvalid_1's rmse: 54.4927\n",
      "[930]\ttraining's rmse: 5.36335\tvalid_1's rmse: 54.468\n",
      "[960]\ttraining's rmse: 5.07564\tvalid_1's rmse: 54.4502\n",
      "[990]\ttraining's rmse: 4.80283\tvalid_1's rmse: 54.4226\n",
      "[1020]\ttraining's rmse: 4.5531\tvalid_1's rmse: 54.3997\n",
      "[1050]\ttraining's rmse: 4.31834\tvalid_1's rmse: 54.381\n",
      "[1080]\ttraining's rmse: 4.09704\tvalid_1's rmse: 54.3657\n",
      "[1110]\ttraining's rmse: 3.88485\tvalid_1's rmse: 54.3549\n",
      "[1140]\ttraining's rmse: 3.6874\tvalid_1's rmse: 54.3462\n",
      "[1170]\ttraining's rmse: 3.50115\tvalid_1's rmse: 54.3329\n",
      "[1200]\ttraining's rmse: 3.32943\tvalid_1's rmse: 54.322\n",
      "[1230]\ttraining's rmse: 3.16998\tvalid_1's rmse: 54.3184\n",
      "[1260]\ttraining's rmse: 3.01515\tvalid_1's rmse: 54.3172\n",
      "[1290]\ttraining's rmse: 2.86825\tvalid_1's rmse: 54.3109\n",
      "[1320]\ttraining's rmse: 2.72955\tvalid_1's rmse: 54.2992\n",
      "[1350]\ttraining's rmse: 2.6019\tvalid_1's rmse: 54.2996\n",
      "[1380]\ttraining's rmse: 2.47642\tvalid_1's rmse: 54.2918\n",
      "[1410]\ttraining's rmse: 2.36231\tvalid_1's rmse: 54.2833\n",
      "[1440]\ttraining's rmse: 2.25151\tvalid_1's rmse: 54.2756\n",
      "[1470]\ttraining's rmse: 2.14808\tvalid_1's rmse: 54.2723\n",
      "[1500]\ttraining's rmse: 2.04731\tvalid_1's rmse: 54.2722\n",
      "[1530]\ttraining's rmse: 1.95734\tvalid_1's rmse: 54.27\n",
      "[1560]\ttraining's rmse: 1.86833\tvalid_1's rmse: 54.2643\n",
      "[1590]\ttraining's rmse: 1.78692\tvalid_1's rmse: 54.2586\n",
      "[1620]\ttraining's rmse: 1.70836\tvalid_1's rmse: 54.2547\n",
      "[1650]\ttraining's rmse: 1.63526\tvalid_1's rmse: 54.2514\n",
      "[1680]\ttraining's rmse: 1.5678\tvalid_1's rmse: 54.2485\n",
      "[1710]\ttraining's rmse: 1.50173\tvalid_1's rmse: 54.2458\n",
      "[1740]\ttraining's rmse: 1.43862\tvalid_1's rmse: 54.2443\n",
      "[1770]\ttraining's rmse: 1.37944\tvalid_1's rmse: 54.2418\n",
      "[1800]\ttraining's rmse: 1.32357\tvalid_1's rmse: 54.2389\n",
      "[1830]\ttraining's rmse: 1.26855\tvalid_1's rmse: 54.2358\n",
      "[1860]\ttraining's rmse: 1.21729\tvalid_1's rmse: 54.2375\n",
      "[1890]\ttraining's rmse: 1.16628\tvalid_1's rmse: 54.2355\n",
      "[1920]\ttraining's rmse: 1.11927\tvalid_1's rmse: 54.2338\n",
      "[1950]\ttraining's rmse: 1.07535\tvalid_1's rmse: 54.2319\n",
      "[1980]\ttraining's rmse: 1.03509\tvalid_1's rmse: 54.2303\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's rmse: 1.00984\tvalid_1's rmse: 54.2293\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002321 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 20022\n",
      "[LightGBM] [Info] Number of data points in the train set: 9219, number of used features: 79\n",
      "[LightGBM] [Info] Start training from score 368.107116\n",
      "Training until validation scores don't improve for 125 rounds\n",
      "[30]\ttraining's rmse: 148.191\tvalid_1's rmse: 153.416\n",
      "[60]\ttraining's rmse: 93.8286\tvalid_1's rmse: 106.086\n",
      "[90]\ttraining's rmse: 64.523\tvalid_1's rmse: 83.3366\n",
      "[120]\ttraining's rmse: 48.4376\tvalid_1's rmse: 72.5805\n",
      "[150]\ttraining's rmse: 39.116\tvalid_1's rmse: 67.269\n",
      "[180]\ttraining's rmse: 33.3098\tvalid_1's rmse: 64.2408\n",
      "[210]\ttraining's rmse: 29.2123\tvalid_1's rmse: 62.4698\n",
      "[240]\ttraining's rmse: 26.0596\tvalid_1's rmse: 61.2098\n",
      "[270]\ttraining's rmse: 23.5201\tvalid_1's rmse: 60.3175\n",
      "[300]\ttraining's rmse: 21.3995\tvalid_1's rmse: 59.6907\n",
      "[330]\ttraining's rmse: 19.6089\tvalid_1's rmse: 59.28\n",
      "[360]\ttraining's rmse: 18.0208\tvalid_1's rmse: 58.9824\n",
      "[390]\ttraining's rmse: 16.6305\tvalid_1's rmse: 58.6903\n",
      "[420]\ttraining's rmse: 15.4033\tvalid_1's rmse: 58.4956\n",
      "[450]\ttraining's rmse: 14.2903\tvalid_1's rmse: 58.2978\n",
      "[480]\ttraining's rmse: 13.2671\tvalid_1's rmse: 58.1138\n",
      "[510]\ttraining's rmse: 12.3337\tvalid_1's rmse: 57.9654\n",
      "[540]\ttraining's rmse: 11.4953\tvalid_1's rmse: 57.8184\n",
      "[570]\ttraining's rmse: 10.7387\tvalid_1's rmse: 57.7445\n",
      "[600]\ttraining's rmse: 10.0518\tvalid_1's rmse: 57.6627\n",
      "[630]\ttraining's rmse: 9.40378\tvalid_1's rmse: 57.5715\n",
      "[660]\ttraining's rmse: 8.81196\tvalid_1's rmse: 57.5178\n",
      "[690]\ttraining's rmse: 8.25976\tvalid_1's rmse: 57.4423\n",
      "[720]\ttraining's rmse: 7.75042\tvalid_1's rmse: 57.3886\n",
      "[750]\ttraining's rmse: 7.27778\tvalid_1's rmse: 57.3354\n",
      "[780]\ttraining's rmse: 6.83473\tvalid_1's rmse: 57.2809\n",
      "[810]\ttraining's rmse: 6.43656\tvalid_1's rmse: 57.2593\n",
      "[840]\ttraining's rmse: 6.05978\tvalid_1's rmse: 57.2317\n",
      "[870]\ttraining's rmse: 5.70747\tvalid_1's rmse: 57.1966\n",
      "[900]\ttraining's rmse: 5.36848\tvalid_1's rmse: 57.1601\n",
      "[930]\ttraining's rmse: 5.05803\tvalid_1's rmse: 57.1411\n",
      "[960]\ttraining's rmse: 4.76686\tvalid_1's rmse: 57.1203\n",
      "[990]\ttraining's rmse: 4.49852\tvalid_1's rmse: 57.1032\n",
      "[1020]\ttraining's rmse: 4.25168\tvalid_1's rmse: 57.0852\n",
      "[1050]\ttraining's rmse: 4.01271\tvalid_1's rmse: 57.0641\n",
      "[1080]\ttraining's rmse: 3.78921\tvalid_1's rmse: 57.0508\n",
      "[1110]\ttraining's rmse: 3.58704\tvalid_1's rmse: 57.0407\n",
      "[1140]\ttraining's rmse: 3.39464\tvalid_1's rmse: 57.027\n",
      "[1170]\ttraining's rmse: 3.21107\tvalid_1's rmse: 57.0188\n",
      "[1200]\ttraining's rmse: 3.03982\tvalid_1's rmse: 57.0115\n",
      "[1230]\ttraining's rmse: 2.87752\tvalid_1's rmse: 57.0074\n",
      "[1260]\ttraining's rmse: 2.72434\tvalid_1's rmse: 57.0005\n",
      "[1290]\ttraining's rmse: 2.58244\tvalid_1's rmse: 56.9976\n",
      "[1320]\ttraining's rmse: 2.44793\tvalid_1's rmse: 56.9879\n",
      "[1350]\ttraining's rmse: 2.32077\tvalid_1's rmse: 56.9845\n",
      "[1380]\ttraining's rmse: 2.19913\tvalid_1's rmse: 56.9781\n",
      "[1410]\ttraining's rmse: 2.08498\tvalid_1's rmse: 56.9705\n",
      "[1440]\ttraining's rmse: 1.97825\tvalid_1's rmse: 56.9671\n",
      "[1470]\ttraining's rmse: 1.87719\tvalid_1's rmse: 56.9617\n",
      "[1500]\ttraining's rmse: 1.78289\tvalid_1's rmse: 56.958\n",
      "[1530]\ttraining's rmse: 1.69315\tvalid_1's rmse: 56.9566\n",
      "[1560]\ttraining's rmse: 1.60622\tvalid_1's rmse: 56.9564\n",
      "[1590]\ttraining's rmse: 1.52455\tvalid_1's rmse: 56.9512\n",
      "[1620]\ttraining's rmse: 1.44873\tvalid_1's rmse: 56.9465\n",
      "[1650]\ttraining's rmse: 1.37785\tvalid_1's rmse: 56.9428\n",
      "[1680]\ttraining's rmse: 1.30935\tvalid_1's rmse: 56.9395\n",
      "[1710]\ttraining's rmse: 1.24426\tvalid_1's rmse: 56.9379\n",
      "[1740]\ttraining's rmse: 1.18272\tvalid_1's rmse: 56.9363\n",
      "[1770]\ttraining's rmse: 1.12406\tvalid_1's rmse: 56.9336\n",
      "[1800]\ttraining's rmse: 1.06943\tvalid_1's rmse: 56.9325\n",
      "[1830]\ttraining's rmse: 1.01667\tvalid_1's rmse: 56.9308\n",
      "[1860]\ttraining's rmse: 0.967127\tvalid_1's rmse: 56.9297\n",
      "[1890]\ttraining's rmse: 0.920112\tvalid_1's rmse: 56.9287\n",
      "[1920]\ttraining's rmse: 0.876283\tvalid_1's rmse: 56.9268\n",
      "[1950]\ttraining's rmse: 0.833491\tvalid_1's rmse: 56.9252\n",
      "[1980]\ttraining's rmse: 0.791778\tvalid_1's rmse: 56.9243\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's rmse: 0.765954\tvalid_1's rmse: 56.9243\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003322 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 20022\n",
      "[LightGBM] [Info] Number of data points in the train set: 9219, number of used features: 79\n",
      "[LightGBM] [Info] Start training from score 370.838451\n",
      "Training until validation scores don't improve for 125 rounds\n",
      "[30]\ttraining's rmse: 148.078\tvalid_1's rmse: 149.724\n",
      "[60]\ttraining's rmse: 93.3857\tvalid_1's rmse: 102.864\n",
      "[90]\ttraining's rmse: 63.9173\tvalid_1's rmse: 80.1467\n",
      "[120]\ttraining's rmse: 47.9505\tvalid_1's rmse: 69.3672\n",
      "[150]\ttraining's rmse: 38.8075\tvalid_1's rmse: 63.582\n",
      "[180]\ttraining's rmse: 33.0333\tvalid_1's rmse: 60.484\n",
      "[210]\ttraining's rmse: 29.0191\tvalid_1's rmse: 58.6585\n",
      "[240]\ttraining's rmse: 25.8213\tvalid_1's rmse: 57.3069\n",
      "[270]\ttraining's rmse: 23.2909\tvalid_1's rmse: 56.4368\n",
      "[300]\ttraining's rmse: 21.2185\tvalid_1's rmse: 55.939\n",
      "[330]\ttraining's rmse: 19.4821\tvalid_1's rmse: 55.4866\n",
      "[360]\ttraining's rmse: 17.9474\tvalid_1's rmse: 55.2297\n",
      "[390]\ttraining's rmse: 16.584\tvalid_1's rmse: 54.9565\n",
      "[420]\ttraining's rmse: 15.3644\tvalid_1's rmse: 54.7769\n",
      "[450]\ttraining's rmse: 14.2679\tvalid_1's rmse: 54.6035\n",
      "[480]\ttraining's rmse: 13.2827\tvalid_1's rmse: 54.4348\n",
      "[510]\ttraining's rmse: 12.3851\tvalid_1's rmse: 54.296\n",
      "[540]\ttraining's rmse: 11.5607\tvalid_1's rmse: 54.1852\n",
      "[570]\ttraining's rmse: 10.8127\tvalid_1's rmse: 54.1073\n",
      "[600]\ttraining's rmse: 10.1183\tvalid_1's rmse: 54.0347\n",
      "[630]\ttraining's rmse: 9.48201\tvalid_1's rmse: 53.9582\n",
      "[660]\ttraining's rmse: 8.89532\tvalid_1's rmse: 53.8961\n",
      "[690]\ttraining's rmse: 8.3574\tvalid_1's rmse: 53.8438\n",
      "[720]\ttraining's rmse: 7.86754\tvalid_1's rmse: 53.792\n",
      "[750]\ttraining's rmse: 7.39943\tvalid_1's rmse: 53.7354\n",
      "[780]\ttraining's rmse: 6.95784\tvalid_1's rmse: 53.6837\n",
      "[810]\ttraining's rmse: 6.55968\tvalid_1's rmse: 53.6523\n",
      "[840]\ttraining's rmse: 6.19803\tvalid_1's rmse: 53.6345\n",
      "[870]\ttraining's rmse: 5.84569\tvalid_1's rmse: 53.5915\n",
      "[900]\ttraining's rmse: 5.5232\tvalid_1's rmse: 53.5843\n",
      "[930]\ttraining's rmse: 5.22416\tvalid_1's rmse: 53.568\n",
      "[960]\ttraining's rmse: 4.93801\tvalid_1's rmse: 53.5552\n",
      "[990]\ttraining's rmse: 4.67072\tvalid_1's rmse: 53.5384\n",
      "[1020]\ttraining's rmse: 4.42267\tvalid_1's rmse: 53.522\n",
      "[1050]\ttraining's rmse: 4.19644\tvalid_1's rmse: 53.4938\n",
      "[1080]\ttraining's rmse: 3.97333\tvalid_1's rmse: 53.4775\n",
      "[1110]\ttraining's rmse: 3.76293\tvalid_1's rmse: 53.4586\n",
      "[1140]\ttraining's rmse: 3.56718\tvalid_1's rmse: 53.4485\n",
      "[1170]\ttraining's rmse: 3.38735\tvalid_1's rmse: 53.439\n",
      "[1200]\ttraining's rmse: 3.2122\tvalid_1's rmse: 53.4287\n",
      "[1230]\ttraining's rmse: 3.04609\tvalid_1's rmse: 53.4149\n",
      "[1260]\ttraining's rmse: 2.89637\tvalid_1's rmse: 53.4102\n",
      "[1290]\ttraining's rmse: 2.75067\tvalid_1's rmse: 53.4039\n",
      "[1320]\ttraining's rmse: 2.61353\tvalid_1's rmse: 53.3968\n",
      "[1350]\ttraining's rmse: 2.4855\tvalid_1's rmse: 53.3886\n",
      "[1380]\ttraining's rmse: 2.36302\tvalid_1's rmse: 53.3871\n",
      "[1410]\ttraining's rmse: 2.25145\tvalid_1's rmse: 53.3833\n",
      "[1440]\ttraining's rmse: 2.14463\tvalid_1's rmse: 53.3799\n",
      "[1470]\ttraining's rmse: 2.04107\tvalid_1's rmse: 53.3741\n",
      "[1500]\ttraining's rmse: 1.94375\tvalid_1's rmse: 53.3723\n",
      "[1530]\ttraining's rmse: 1.85216\tvalid_1's rmse: 53.3693\n",
      "[1560]\ttraining's rmse: 1.76708\tvalid_1's rmse: 53.3662\n",
      "[1590]\ttraining's rmse: 1.68556\tvalid_1's rmse: 53.3603\n",
      "[1620]\ttraining's rmse: 1.60876\tvalid_1's rmse: 53.3562\n",
      "[1650]\ttraining's rmse: 1.53719\tvalid_1's rmse: 53.3524\n",
      "[1680]\ttraining's rmse: 1.4681\tvalid_1's rmse: 53.3511\n",
      "[1710]\ttraining's rmse: 1.39923\tvalid_1's rmse: 53.3484\n",
      "[1740]\ttraining's rmse: 1.33643\tvalid_1's rmse: 53.3443\n",
      "[1770]\ttraining's rmse: 1.27737\tvalid_1's rmse: 53.341\n",
      "[1800]\ttraining's rmse: 1.22079\tvalid_1's rmse: 53.3396\n",
      "[1830]\ttraining's rmse: 1.16672\tvalid_1's rmse: 53.3365\n",
      "[1860]\ttraining's rmse: 1.11526\tvalid_1's rmse: 53.3347\n",
      "[1890]\ttraining's rmse: 1.06647\tvalid_1's rmse: 53.3343\n",
      "[1920]\ttraining's rmse: 1.01892\tvalid_1's rmse: 53.3338\n",
      "[1950]\ttraining's rmse: 0.975214\tvalid_1's rmse: 53.3311\n",
      "[1980]\ttraining's rmse: 0.935057\tvalid_1's rmse: 53.3293\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's rmse: 0.908599\tvalid_1's rmse: 53.3284\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003886 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 20022\n",
      "[LightGBM] [Info] Number of data points in the train set: 9219, number of used features: 79\n",
      "[LightGBM] [Info] Start training from score 367.363229\n",
      "Training until validation scores don't improve for 125 rounds\n",
      "[30]\ttraining's rmse: 148.776\tvalid_1's rmse: 153.484\n",
      "[60]\ttraining's rmse: 94.1499\tvalid_1's rmse: 103.242\n",
      "[90]\ttraining's rmse: 64.5799\tvalid_1's rmse: 77.8877\n",
      "[120]\ttraining's rmse: 48.5296\tvalid_1's rmse: 65.7187\n",
      "[150]\ttraining's rmse: 39.3218\tvalid_1's rmse: 59.5852\n",
      "[180]\ttraining's rmse: 33.4995\tvalid_1's rmse: 56.4283\n",
      "[210]\ttraining's rmse: 29.3111\tvalid_1's rmse: 54.3338\n",
      "[240]\ttraining's rmse: 26.0937\tvalid_1's rmse: 53.1092\n",
      "[270]\ttraining's rmse: 23.528\tvalid_1's rmse: 52.3151\n",
      "[300]\ttraining's rmse: 21.4309\tvalid_1's rmse: 51.7973\n",
      "[330]\ttraining's rmse: 19.6506\tvalid_1's rmse: 51.4422\n",
      "[360]\ttraining's rmse: 18.06\tvalid_1's rmse: 51.186\n",
      "[390]\ttraining's rmse: 16.6882\tvalid_1's rmse: 50.9902\n",
      "[420]\ttraining's rmse: 15.49\tvalid_1's rmse: 50.8232\n",
      "[450]\ttraining's rmse: 14.3695\tvalid_1's rmse: 50.6649\n",
      "[480]\ttraining's rmse: 13.3668\tvalid_1's rmse: 50.5217\n",
      "[510]\ttraining's rmse: 12.4583\tvalid_1's rmse: 50.4347\n",
      "[540]\ttraining's rmse: 11.6436\tvalid_1's rmse: 50.339\n",
      "[570]\ttraining's rmse: 10.9026\tvalid_1's rmse: 50.2609\n",
      "[600]\ttraining's rmse: 10.2067\tvalid_1's rmse: 50.1895\n",
      "[630]\ttraining's rmse: 9.56147\tvalid_1's rmse: 50.1331\n",
      "[660]\ttraining's rmse: 8.97227\tvalid_1's rmse: 50.0746\n",
      "[690]\ttraining's rmse: 8.42286\tvalid_1's rmse: 50.0242\n",
      "[720]\ttraining's rmse: 7.92326\tvalid_1's rmse: 50.0021\n",
      "[750]\ttraining's rmse: 7.4448\tvalid_1's rmse: 49.9635\n",
      "[780]\ttraining's rmse: 7.00429\tvalid_1's rmse: 49.9263\n",
      "[810]\ttraining's rmse: 6.60075\tvalid_1's rmse: 49.8865\n",
      "[840]\ttraining's rmse: 6.2223\tvalid_1's rmse: 49.8631\n",
      "[870]\ttraining's rmse: 5.85822\tvalid_1's rmse: 49.8395\n",
      "[900]\ttraining's rmse: 5.52317\tvalid_1's rmse: 49.8323\n",
      "[930]\ttraining's rmse: 5.21504\tvalid_1's rmse: 49.8133\n",
      "[960]\ttraining's rmse: 4.92621\tvalid_1's rmse: 49.808\n",
      "[990]\ttraining's rmse: 4.65661\tvalid_1's rmse: 49.7931\n",
      "[1020]\ttraining's rmse: 4.4036\tvalid_1's rmse: 49.777\n",
      "[1050]\ttraining's rmse: 4.16157\tvalid_1's rmse: 49.769\n",
      "[1080]\ttraining's rmse: 3.94262\tvalid_1's rmse: 49.7589\n",
      "[1110]\ttraining's rmse: 3.73261\tvalid_1's rmse: 49.749\n",
      "[1140]\ttraining's rmse: 3.53622\tvalid_1's rmse: 49.7479\n",
      "[1170]\ttraining's rmse: 3.35139\tvalid_1's rmse: 49.741\n",
      "[1200]\ttraining's rmse: 3.17675\tvalid_1's rmse: 49.7311\n",
      "[1230]\ttraining's rmse: 3.01292\tvalid_1's rmse: 49.7252\n",
      "[1260]\ttraining's rmse: 2.85861\tvalid_1's rmse: 49.7219\n",
      "[1290]\ttraining's rmse: 2.71301\tvalid_1's rmse: 49.7149\n",
      "[1320]\ttraining's rmse: 2.57142\tvalid_1's rmse: 49.7096\n",
      "[1350]\ttraining's rmse: 2.44115\tvalid_1's rmse: 49.7104\n",
      "[1380]\ttraining's rmse: 2.31644\tvalid_1's rmse: 49.7078\n",
      "[1410]\ttraining's rmse: 2.19904\tvalid_1's rmse: 49.7054\n",
      "[1440]\ttraining's rmse: 2.08685\tvalid_1's rmse: 49.7006\n",
      "[1470]\ttraining's rmse: 1.9853\tvalid_1's rmse: 49.6973\n",
      "[1500]\ttraining's rmse: 1.88601\tvalid_1's rmse: 49.694\n",
      "[1530]\ttraining's rmse: 1.79415\tvalid_1's rmse: 49.6906\n",
      "[1560]\ttraining's rmse: 1.70677\tvalid_1's rmse: 49.6877\n",
      "[1590]\ttraining's rmse: 1.62589\tvalid_1's rmse: 49.6859\n",
      "[1620]\ttraining's rmse: 1.5483\tvalid_1's rmse: 49.6874\n",
      "[1650]\ttraining's rmse: 1.47324\tvalid_1's rmse: 49.6874\n",
      "[1680]\ttraining's rmse: 1.40284\tvalid_1's rmse: 49.6862\n",
      "[1710]\ttraining's rmse: 1.3366\tvalid_1's rmse: 49.6861\n",
      "[1740]\ttraining's rmse: 1.27452\tvalid_1's rmse: 49.6847\n",
      "[1770]\ttraining's rmse: 1.21344\tvalid_1's rmse: 49.6833\n",
      "[1800]\ttraining's rmse: 1.15503\tvalid_1's rmse: 49.6823\n",
      "[1830]\ttraining's rmse: 1.10071\tvalid_1's rmse: 49.6795\n",
      "[1860]\ttraining's rmse: 1.04974\tvalid_1's rmse: 49.6812\n",
      "[1890]\ttraining's rmse: 1.00201\tvalid_1's rmse: 49.6792\n",
      "[1920]\ttraining's rmse: 0.95629\tvalid_1's rmse: 49.6782\n",
      "[1950]\ttraining's rmse: 0.913388\tvalid_1's rmse: 49.6796\n",
      "[1980]\ttraining's rmse: 0.873886\tvalid_1's rmse: 49.6808\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's rmse: 0.847439\tvalid_1's rmse: 49.6807\n",
      "36\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003371 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 20023\n",
      "[LightGBM] [Info] Number of data points in the train set: 9219, number of used features: 79\n",
      "[LightGBM] [Info] Start training from score 370.719177\n",
      "Training until validation scores don't improve for 125 rounds\n",
      "[30]\ttraining's rmse: 146.857\tvalid_1's rmse: 149.785\n",
      "[60]\ttraining's rmse: 93.0838\tvalid_1's rmse: 99.6762\n",
      "[90]\ttraining's rmse: 63.763\tvalid_1's rmse: 74.3225\n",
      "[120]\ttraining's rmse: 47.6857\tvalid_1's rmse: 62.0423\n",
      "[150]\ttraining's rmse: 38.5421\tvalid_1's rmse: 56.1675\n",
      "[180]\ttraining's rmse: 32.8141\tvalid_1's rmse: 53.1447\n",
      "[210]\ttraining's rmse: 28.8099\tvalid_1's rmse: 51.3677\n",
      "[240]\ttraining's rmse: 25.7267\tvalid_1's rmse: 50.2817\n",
      "[270]\ttraining's rmse: 23.2865\tvalid_1's rmse: 49.6285\n",
      "[300]\ttraining's rmse: 21.1902\tvalid_1's rmse: 49.1322\n",
      "[330]\ttraining's rmse: 19.4677\tvalid_1's rmse: 48.7884\n",
      "[360]\ttraining's rmse: 17.981\tvalid_1's rmse: 48.4964\n",
      "[390]\ttraining's rmse: 16.6623\tvalid_1's rmse: 48.3108\n",
      "[420]\ttraining's rmse: 15.4446\tvalid_1's rmse: 48.1764\n",
      "[450]\ttraining's rmse: 14.3456\tvalid_1's rmse: 48.0284\n",
      "[480]\ttraining's rmse: 13.3686\tvalid_1's rmse: 47.8917\n",
      "[510]\ttraining's rmse: 12.5054\tvalid_1's rmse: 47.8266\n",
      "[540]\ttraining's rmse: 11.6986\tvalid_1's rmse: 47.7317\n",
      "[570]\ttraining's rmse: 10.9613\tvalid_1's rmse: 47.666\n",
      "[600]\ttraining's rmse: 10.299\tvalid_1's rmse: 47.604\n",
      "[630]\ttraining's rmse: 9.68107\tvalid_1's rmse: 47.5326\n",
      "[660]\ttraining's rmse: 9.12075\tvalid_1's rmse: 47.5059\n",
      "[690]\ttraining's rmse: 8.60823\tvalid_1's rmse: 47.4739\n",
      "[720]\ttraining's rmse: 8.12273\tvalid_1's rmse: 47.44\n",
      "[750]\ttraining's rmse: 7.66221\tvalid_1's rmse: 47.4246\n",
      "[780]\ttraining's rmse: 7.22452\tvalid_1's rmse: 47.3825\n",
      "[810]\ttraining's rmse: 6.81753\tvalid_1's rmse: 47.3615\n",
      "[840]\ttraining's rmse: 6.44815\tvalid_1's rmse: 47.329\n",
      "[870]\ttraining's rmse: 6.11079\tvalid_1's rmse: 47.3008\n",
      "[900]\ttraining's rmse: 5.7928\tvalid_1's rmse: 47.278\n",
      "[930]\ttraining's rmse: 5.48395\tvalid_1's rmse: 47.2543\n",
      "[960]\ttraining's rmse: 5.1974\tvalid_1's rmse: 47.2452\n",
      "[990]\ttraining's rmse: 4.93357\tvalid_1's rmse: 47.232\n",
      "[1020]\ttraining's rmse: 4.68285\tvalid_1's rmse: 47.2246\n",
      "[1050]\ttraining's rmse: 4.44543\tvalid_1's rmse: 47.2111\n",
      "[1080]\ttraining's rmse: 4.22403\tvalid_1's rmse: 47.2085\n",
      "[1110]\ttraining's rmse: 4.01836\tvalid_1's rmse: 47.2002\n",
      "[1140]\ttraining's rmse: 3.81605\tvalid_1's rmse: 47.1912\n",
      "[1170]\ttraining's rmse: 3.6338\tvalid_1's rmse: 47.1787\n",
      "[1200]\ttraining's rmse: 3.45435\tvalid_1's rmse: 47.1698\n",
      "[1230]\ttraining's rmse: 3.28823\tvalid_1's rmse: 47.1658\n",
      "[1260]\ttraining's rmse: 3.12849\tvalid_1's rmse: 47.163\n",
      "[1290]\ttraining's rmse: 2.98256\tvalid_1's rmse: 47.157\n",
      "[1320]\ttraining's rmse: 2.84246\tvalid_1's rmse: 47.1536\n",
      "[1350]\ttraining's rmse: 2.70625\tvalid_1's rmse: 47.1494\n",
      "[1380]\ttraining's rmse: 2.5832\tvalid_1's rmse: 47.1476\n",
      "[1410]\ttraining's rmse: 2.46758\tvalid_1's rmse: 47.1458\n",
      "[1440]\ttraining's rmse: 2.35417\tvalid_1's rmse: 47.1418\n",
      "[1470]\ttraining's rmse: 2.24404\tvalid_1's rmse: 47.1423\n",
      "[1500]\ttraining's rmse: 2.14265\tvalid_1's rmse: 47.1376\n",
      "[1530]\ttraining's rmse: 2.04313\tvalid_1's rmse: 47.1322\n",
      "[1560]\ttraining's rmse: 1.95172\tvalid_1's rmse: 47.133\n",
      "[1590]\ttraining's rmse: 1.86471\tvalid_1's rmse: 47.1346\n",
      "[1620]\ttraining's rmse: 1.78408\tvalid_1's rmse: 47.1351\n",
      "[1650]\ttraining's rmse: 1.70103\tvalid_1's rmse: 47.1349\n",
      "[1680]\ttraining's rmse: 1.6281\tvalid_1's rmse: 47.1308\n",
      "[1710]\ttraining's rmse: 1.55596\tvalid_1's rmse: 47.133\n",
      "[1740]\ttraining's rmse: 1.4873\tvalid_1's rmse: 47.1288\n",
      "[1770]\ttraining's rmse: 1.42237\tvalid_1's rmse: 47.1272\n",
      "[1800]\ttraining's rmse: 1.36249\tvalid_1's rmse: 47.1251\n",
      "[1830]\ttraining's rmse: 1.30109\tvalid_1's rmse: 47.1257\n",
      "[1860]\ttraining's rmse: 1.24597\tvalid_1's rmse: 47.1244\n",
      "[1890]\ttraining's rmse: 1.19597\tvalid_1's rmse: 47.1239\n",
      "[1920]\ttraining's rmse: 1.14801\tvalid_1's rmse: 47.1212\n",
      "[1950]\ttraining's rmse: 1.1009\tvalid_1's rmse: 47.1196\n",
      "[1980]\ttraining's rmse: 1.05201\tvalid_1's rmse: 47.1209\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's rmse: 1.02435\tvalid_1's rmse: 47.1206\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003372 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 20023\n",
      "[LightGBM] [Info] Number of data points in the train set: 9219, number of used features: 79\n",
      "[LightGBM] [Info] Start training from score 368.005407\n",
      "Training until validation scores don't improve for 125 rounds\n",
      "[30]\ttraining's rmse: 149.231\tvalid_1's rmse: 151.437\n",
      "[60]\ttraining's rmse: 95.6181\tvalid_1's rmse: 102.483\n",
      "[90]\ttraining's rmse: 66.3769\tvalid_1's rmse: 77.2865\n",
      "[120]\ttraining's rmse: 50.1064\tvalid_1's rmse: 64.4597\n",
      "[150]\ttraining's rmse: 40.7141\tvalid_1's rmse: 57.9592\n",
      "[180]\ttraining's rmse: 34.7567\tvalid_1's rmse: 54.6721\n",
      "[210]\ttraining's rmse: 30.4744\tvalid_1's rmse: 52.5345\n",
      "[240]\ttraining's rmse: 27.2567\tvalid_1's rmse: 51.1941\n",
      "[270]\ttraining's rmse: 24.6339\tvalid_1's rmse: 50.2639\n",
      "[300]\ttraining's rmse: 22.4596\tvalid_1's rmse: 49.5485\n",
      "[330]\ttraining's rmse: 20.611\tvalid_1's rmse: 49.0419\n",
      "[360]\ttraining's rmse: 19.0092\tvalid_1's rmse: 48.7064\n",
      "[390]\ttraining's rmse: 17.6064\tvalid_1's rmse: 48.465\n",
      "[420]\ttraining's rmse: 16.271\tvalid_1's rmse: 48.2344\n",
      "[450]\ttraining's rmse: 15.1052\tvalid_1's rmse: 48.0187\n",
      "[480]\ttraining's rmse: 14.0901\tvalid_1's rmse: 47.8819\n",
      "[510]\ttraining's rmse: 13.1693\tvalid_1's rmse: 47.7646\n",
      "[540]\ttraining's rmse: 12.2986\tvalid_1's rmse: 47.6839\n",
      "[570]\ttraining's rmse: 11.5041\tvalid_1's rmse: 47.6286\n",
      "[600]\ttraining's rmse: 10.7706\tvalid_1's rmse: 47.5609\n",
      "[630]\ttraining's rmse: 10.1004\tvalid_1's rmse: 47.4997\n",
      "[660]\ttraining's rmse: 9.4808\tvalid_1's rmse: 47.4425\n",
      "[690]\ttraining's rmse: 8.91349\tvalid_1's rmse: 47.3894\n",
      "[720]\ttraining's rmse: 8.37528\tvalid_1's rmse: 47.3478\n",
      "[750]\ttraining's rmse: 7.89629\tvalid_1's rmse: 47.3303\n",
      "[780]\ttraining's rmse: 7.44032\tvalid_1's rmse: 47.2988\n",
      "[810]\ttraining's rmse: 7.01048\tvalid_1's rmse: 47.2785\n",
      "[840]\ttraining's rmse: 6.61668\tvalid_1's rmse: 47.2542\n",
      "[870]\ttraining's rmse: 6.24252\tvalid_1's rmse: 47.2361\n",
      "[900]\ttraining's rmse: 5.89337\tvalid_1's rmse: 47.2128\n",
      "[930]\ttraining's rmse: 5.55865\tvalid_1's rmse: 47.1985\n",
      "[960]\ttraining's rmse: 5.23429\tvalid_1's rmse: 47.1727\n",
      "[990]\ttraining's rmse: 4.94902\tvalid_1's rmse: 47.1568\n",
      "[1020]\ttraining's rmse: 4.67924\tvalid_1's rmse: 47.1456\n",
      "[1050]\ttraining's rmse: 4.43019\tvalid_1's rmse: 47.1281\n",
      "[1080]\ttraining's rmse: 4.19324\tvalid_1's rmse: 47.1231\n",
      "[1110]\ttraining's rmse: 3.96647\tvalid_1's rmse: 47.112\n",
      "[1140]\ttraining's rmse: 3.75005\tvalid_1's rmse: 47.1071\n",
      "[1170]\ttraining's rmse: 3.555\tvalid_1's rmse: 47.0976\n",
      "[1200]\ttraining's rmse: 3.37318\tvalid_1's rmse: 47.0977\n",
      "[1230]\ttraining's rmse: 3.19507\tvalid_1's rmse: 47.088\n",
      "[1260]\ttraining's rmse: 3.02781\tvalid_1's rmse: 47.0838\n",
      "[1290]\ttraining's rmse: 2.87393\tvalid_1's rmse: 47.0811\n",
      "[1320]\ttraining's rmse: 2.72788\tvalid_1's rmse: 47.0793\n",
      "[1350]\ttraining's rmse: 2.59035\tvalid_1's rmse: 47.0781\n",
      "[1380]\ttraining's rmse: 2.45753\tvalid_1's rmse: 47.0744\n",
      "[1410]\ttraining's rmse: 2.33425\tvalid_1's rmse: 47.0769\n",
      "[1440]\ttraining's rmse: 2.21764\tvalid_1's rmse: 47.0706\n",
      "[1470]\ttraining's rmse: 2.10359\tvalid_1's rmse: 47.069\n",
      "[1500]\ttraining's rmse: 1.99857\tvalid_1's rmse: 47.0645\n",
      "[1530]\ttraining's rmse: 1.89588\tvalid_1's rmse: 47.0595\n",
      "[1560]\ttraining's rmse: 1.80053\tvalid_1's rmse: 47.0585\n",
      "[1590]\ttraining's rmse: 1.71144\tvalid_1's rmse: 47.0557\n",
      "[1620]\ttraining's rmse: 1.62771\tvalid_1's rmse: 47.0531\n",
      "[1650]\ttraining's rmse: 1.54605\tvalid_1's rmse: 47.0518\n",
      "[1680]\ttraining's rmse: 1.47225\tvalid_1's rmse: 47.0502\n",
      "[1710]\ttraining's rmse: 1.40091\tvalid_1's rmse: 47.0498\n",
      "[1740]\ttraining's rmse: 1.334\tvalid_1's rmse: 47.0479\n",
      "[1770]\ttraining's rmse: 1.26955\tvalid_1's rmse: 47.0471\n",
      "[1800]\ttraining's rmse: 1.20878\tvalid_1's rmse: 47.0437\n",
      "[1830]\ttraining's rmse: 1.14914\tvalid_1's rmse: 47.042\n",
      "[1860]\ttraining's rmse: 1.09462\tvalid_1's rmse: 47.0398\n",
      "[1890]\ttraining's rmse: 1.04346\tvalid_1's rmse: 47.0374\n",
      "[1920]\ttraining's rmse: 0.993546\tvalid_1's rmse: 47.0374\n",
      "[1950]\ttraining's rmse: 0.94759\tvalid_1's rmse: 47.0358\n",
      "[1980]\ttraining's rmse: 0.90237\tvalid_1's rmse: 47.035\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's rmse: 0.874886\tvalid_1's rmse: 47.0342\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002616 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 20023\n",
      "[LightGBM] [Info] Number of data points in the train set: 9219, number of used features: 79\n",
      "[LightGBM] [Info] Start training from score 369.984226\n",
      "Training until validation scores don't improve for 125 rounds\n",
      "[30]\ttraining's rmse: 150.09\tvalid_1's rmse: 151.433\n",
      "[60]\ttraining's rmse: 96.763\tvalid_1's rmse: 105.95\n",
      "[90]\ttraining's rmse: 67.0893\tvalid_1's rmse: 82.6425\n",
      "[120]\ttraining's rmse: 50.4238\tvalid_1's rmse: 71.0574\n",
      "[150]\ttraining's rmse: 40.8731\tvalid_1's rmse: 65.3646\n",
      "[180]\ttraining's rmse: 34.8346\tvalid_1's rmse: 62.3161\n",
      "[210]\ttraining's rmse: 30.5432\tvalid_1's rmse: 60.2728\n",
      "[240]\ttraining's rmse: 27.2894\tvalid_1's rmse: 59.0946\n",
      "[270]\ttraining's rmse: 24.5985\tvalid_1's rmse: 58.2252\n",
      "[300]\ttraining's rmse: 22.4134\tvalid_1's rmse: 57.7677\n",
      "[330]\ttraining's rmse: 20.5443\tvalid_1's rmse: 57.3132\n",
      "[360]\ttraining's rmse: 18.9176\tvalid_1's rmse: 56.9684\n",
      "[390]\ttraining's rmse: 17.4971\tvalid_1's rmse: 56.6678\n",
      "[420]\ttraining's rmse: 16.206\tvalid_1's rmse: 56.5039\n",
      "[450]\ttraining's rmse: 15.0484\tvalid_1's rmse: 56.3113\n",
      "[480]\ttraining's rmse: 13.9968\tvalid_1's rmse: 56.1761\n",
      "[510]\ttraining's rmse: 13.0501\tvalid_1's rmse: 56.0232\n",
      "[540]\ttraining's rmse: 12.1836\tvalid_1's rmse: 55.9332\n",
      "[570]\ttraining's rmse: 11.382\tvalid_1's rmse: 55.8333\n",
      "[600]\ttraining's rmse: 10.6538\tvalid_1's rmse: 55.7306\n",
      "[630]\ttraining's rmse: 9.98448\tvalid_1's rmse: 55.668\n",
      "[660]\ttraining's rmse: 9.37526\tvalid_1's rmse: 55.5849\n",
      "[690]\ttraining's rmse: 8.81656\tvalid_1's rmse: 55.5356\n",
      "[720]\ttraining's rmse: 8.29343\tvalid_1's rmse: 55.4819\n",
      "[750]\ttraining's rmse: 7.81537\tvalid_1's rmse: 55.4516\n",
      "[780]\ttraining's rmse: 7.37397\tvalid_1's rmse: 55.4102\n",
      "[810]\ttraining's rmse: 6.95749\tvalid_1's rmse: 55.3732\n",
      "[840]\ttraining's rmse: 6.56319\tvalid_1's rmse: 55.3364\n",
      "[870]\ttraining's rmse: 6.19077\tvalid_1's rmse: 55.3064\n",
      "[900]\ttraining's rmse: 5.85499\tvalid_1's rmse: 55.2975\n",
      "[930]\ttraining's rmse: 5.52669\tvalid_1's rmse: 55.2832\n",
      "[960]\ttraining's rmse: 5.22936\tvalid_1's rmse: 55.2739\n",
      "[990]\ttraining's rmse: 4.94662\tvalid_1's rmse: 55.2586\n",
      "[1020]\ttraining's rmse: 4.68445\tvalid_1's rmse: 55.2501\n",
      "[1050]\ttraining's rmse: 4.43719\tvalid_1's rmse: 55.2379\n",
      "[1080]\ttraining's rmse: 4.20582\tvalid_1's rmse: 55.2225\n",
      "[1110]\ttraining's rmse: 3.98949\tvalid_1's rmse: 55.2159\n",
      "[1140]\ttraining's rmse: 3.7789\tvalid_1's rmse: 55.2074\n",
      "[1170]\ttraining's rmse: 3.58748\tvalid_1's rmse: 55.1982\n",
      "[1200]\ttraining's rmse: 3.41287\tvalid_1's rmse: 55.1936\n",
      "[1230]\ttraining's rmse: 3.24476\tvalid_1's rmse: 55.1864\n",
      "[1260]\ttraining's rmse: 3.0775\tvalid_1's rmse: 55.1784\n",
      "[1290]\ttraining's rmse: 2.9239\tvalid_1's rmse: 55.1749\n",
      "[1320]\ttraining's rmse: 2.781\tvalid_1's rmse: 55.1692\n",
      "[1350]\ttraining's rmse: 2.64502\tvalid_1's rmse: 55.1657\n",
      "[1380]\ttraining's rmse: 2.51415\tvalid_1's rmse: 55.1582\n",
      "[1410]\ttraining's rmse: 2.38954\tvalid_1's rmse: 55.155\n",
      "[1440]\ttraining's rmse: 2.27364\tvalid_1's rmse: 55.1508\n",
      "[1470]\ttraining's rmse: 2.16099\tvalid_1's rmse: 55.1473\n",
      "[1500]\ttraining's rmse: 2.06059\tvalid_1's rmse: 55.1427\n",
      "[1530]\ttraining's rmse: 1.96351\tvalid_1's rmse: 55.1358\n",
      "[1560]\ttraining's rmse: 1.87008\tvalid_1's rmse: 55.132\n",
      "[1590]\ttraining's rmse: 1.78057\tvalid_1's rmse: 55.1285\n",
      "[1620]\ttraining's rmse: 1.6964\tvalid_1's rmse: 55.1269\n",
      "[1650]\ttraining's rmse: 1.61486\tvalid_1's rmse: 55.1267\n",
      "[1680]\ttraining's rmse: 1.54011\tvalid_1's rmse: 55.1251\n",
      "[1710]\ttraining's rmse: 1.4684\tvalid_1's rmse: 55.1223\n",
      "[1740]\ttraining's rmse: 1.40233\tvalid_1's rmse: 55.1183\n",
      "[1770]\ttraining's rmse: 1.33561\tvalid_1's rmse: 55.1141\n",
      "[1800]\ttraining's rmse: 1.27295\tvalid_1's rmse: 55.1133\n",
      "[1830]\ttraining's rmse: 1.21305\tvalid_1's rmse: 55.1129\n",
      "[1860]\ttraining's rmse: 1.15927\tvalid_1's rmse: 55.1137\n",
      "[1890]\ttraining's rmse: 1.10563\tvalid_1's rmse: 55.1119\n",
      "[1920]\ttraining's rmse: 1.05444\tvalid_1's rmse: 55.1101\n",
      "[1950]\ttraining's rmse: 1.00813\tvalid_1's rmse: 55.1065\n",
      "[1980]\ttraining's rmse: 0.962513\tvalid_1's rmse: 55.1032\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's rmse: 0.932564\tvalid_1's rmse: 55.1035\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002354 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 20023\n",
      "[LightGBM] [Info] Number of data points in the train set: 9219, number of used features: 79\n",
      "[LightGBM] [Info] Start training from score 372.870075\n",
      "Training until validation scores don't improve for 125 rounds\n",
      "[30]\ttraining's rmse: 149.665\tvalid_1's rmse: 155.958\n",
      "[60]\ttraining's rmse: 96.436\tvalid_1's rmse: 109.672\n",
      "[90]\ttraining's rmse: 67.5473\tvalid_1's rmse: 87.0498\n",
      "[120]\ttraining's rmse: 51.4947\tvalid_1's rmse: 75.8497\n",
      "[150]\ttraining's rmse: 41.9077\tvalid_1's rmse: 69.8238\n",
      "[180]\ttraining's rmse: 35.707\tvalid_1's rmse: 66.319\n",
      "[210]\ttraining's rmse: 31.285\tvalid_1's rmse: 64.0062\n",
      "[240]\ttraining's rmse: 27.91\tvalid_1's rmse: 62.5457\n",
      "[270]\ttraining's rmse: 25.2182\tvalid_1's rmse: 61.5746\n",
      "[300]\ttraining's rmse: 22.9865\tvalid_1's rmse: 60.9889\n",
      "[330]\ttraining's rmse: 21.0816\tvalid_1's rmse: 60.4773\n",
      "[360]\ttraining's rmse: 19.432\tvalid_1's rmse: 60.1501\n",
      "[390]\ttraining's rmse: 17.9906\tvalid_1's rmse: 59.8751\n",
      "[420]\ttraining's rmse: 16.6643\tvalid_1's rmse: 59.567\n",
      "[450]\ttraining's rmse: 15.5036\tvalid_1's rmse: 59.3699\n",
      "[480]\ttraining's rmse: 14.4291\tvalid_1's rmse: 59.1752\n",
      "[510]\ttraining's rmse: 13.4383\tvalid_1's rmse: 58.991\n",
      "[540]\ttraining's rmse: 12.5703\tvalid_1's rmse: 58.8686\n",
      "[570]\ttraining's rmse: 11.7764\tvalid_1's rmse: 58.7792\n",
      "[600]\ttraining's rmse: 11.0422\tvalid_1's rmse: 58.6988\n",
      "[630]\ttraining's rmse: 10.3814\tvalid_1's rmse: 58.6289\n",
      "[660]\ttraining's rmse: 9.75766\tvalid_1's rmse: 58.5502\n",
      "[690]\ttraining's rmse: 9.18985\tvalid_1's rmse: 58.4932\n",
      "[720]\ttraining's rmse: 8.63949\tvalid_1's rmse: 58.4473\n",
      "[750]\ttraining's rmse: 8.1484\tvalid_1's rmse: 58.4052\n",
      "[780]\ttraining's rmse: 7.68867\tvalid_1's rmse: 58.366\n",
      "[810]\ttraining's rmse: 7.25672\tvalid_1's rmse: 58.3356\n",
      "[840]\ttraining's rmse: 6.85965\tvalid_1's rmse: 58.2986\n",
      "[870]\ttraining's rmse: 6.47624\tvalid_1's rmse: 58.2494\n",
      "[900]\ttraining's rmse: 6.12002\tvalid_1's rmse: 58.206\n",
      "[930]\ttraining's rmse: 5.80041\tvalid_1's rmse: 58.178\n",
      "[960]\ttraining's rmse: 5.49715\tvalid_1's rmse: 58.1607\n",
      "[990]\ttraining's rmse: 5.20634\tvalid_1's rmse: 58.1383\n",
      "[1020]\ttraining's rmse: 4.93066\tvalid_1's rmse: 58.1188\n",
      "[1050]\ttraining's rmse: 4.67613\tvalid_1's rmse: 58.0882\n",
      "[1080]\ttraining's rmse: 4.43049\tvalid_1's rmse: 58.0672\n",
      "[1110]\ttraining's rmse: 4.20232\tvalid_1's rmse: 58.0553\n",
      "[1140]\ttraining's rmse: 3.97864\tvalid_1's rmse: 58.0305\n",
      "[1170]\ttraining's rmse: 3.77828\tvalid_1's rmse: 58.0175\n",
      "[1200]\ttraining's rmse: 3.59253\tvalid_1's rmse: 58.0167\n",
      "[1230]\ttraining's rmse: 3.41544\tvalid_1's rmse: 58\n",
      "[1260]\ttraining's rmse: 3.24635\tvalid_1's rmse: 57.9873\n",
      "[1290]\ttraining's rmse: 3.08989\tvalid_1's rmse: 57.9743\n",
      "[1320]\ttraining's rmse: 2.9356\tvalid_1's rmse: 57.9611\n",
      "[1350]\ttraining's rmse: 2.79341\tvalid_1's rmse: 57.9589\n",
      "[1380]\ttraining's rmse: 2.65046\tvalid_1's rmse: 57.9499\n",
      "[1410]\ttraining's rmse: 2.51549\tvalid_1's rmse: 57.94\n",
      "[1440]\ttraining's rmse: 2.39477\tvalid_1's rmse: 57.9369\n",
      "[1470]\ttraining's rmse: 2.28199\tvalid_1's rmse: 57.9303\n",
      "[1500]\ttraining's rmse: 2.17448\tvalid_1's rmse: 57.9284\n",
      "[1530]\ttraining's rmse: 2.07605\tvalid_1's rmse: 57.9232\n",
      "[1560]\ttraining's rmse: 1.97467\tvalid_1's rmse: 57.9198\n",
      "[1590]\ttraining's rmse: 1.88584\tvalid_1's rmse: 57.9142\n",
      "[1620]\ttraining's rmse: 1.79437\tvalid_1's rmse: 57.9077\n",
      "[1650]\ttraining's rmse: 1.71056\tvalid_1's rmse: 57.9065\n",
      "[1680]\ttraining's rmse: 1.63007\tvalid_1's rmse: 57.9077\n",
      "[1710]\ttraining's rmse: 1.55233\tvalid_1's rmse: 57.9016\n",
      "[1740]\ttraining's rmse: 1.48037\tvalid_1's rmse: 57.8946\n",
      "[1770]\ttraining's rmse: 1.41045\tvalid_1's rmse: 57.8916\n",
      "[1800]\ttraining's rmse: 1.34361\tvalid_1's rmse: 57.8899\n",
      "[1830]\ttraining's rmse: 1.28269\tvalid_1's rmse: 57.8913\n",
      "[1860]\ttraining's rmse: 1.22265\tvalid_1's rmse: 57.8896\n",
      "[1890]\ttraining's rmse: 1.16983\tvalid_1's rmse: 57.8867\n",
      "[1920]\ttraining's rmse: 1.11995\tvalid_1's rmse: 57.8875\n",
      "[1950]\ttraining's rmse: 1.06748\tvalid_1's rmse: 57.8874\n",
      "[1980]\ttraining's rmse: 1.01957\tvalid_1's rmse: 57.8842\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's rmse: 0.989239\tvalid_1's rmse: 57.8835\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003492 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 20023\n",
      "[LightGBM] [Info] Number of data points in the train set: 9219, number of used features: 79\n",
      "[LightGBM] [Info] Start training from score 371.327908\n",
      "Training until validation scores don't improve for 125 rounds\n",
      "[30]\ttraining's rmse: 148.378\tvalid_1's rmse: 152.124\n",
      "[60]\ttraining's rmse: 94.4817\tvalid_1's rmse: 104.603\n",
      "[90]\ttraining's rmse: 65.1891\tvalid_1's rmse: 81.1245\n",
      "[120]\ttraining's rmse: 49.0623\tvalid_1's rmse: 69.9076\n",
      "[150]\ttraining's rmse: 39.7522\tvalid_1's rmse: 64.3752\n",
      "[180]\ttraining's rmse: 33.9282\tvalid_1's rmse: 61.3581\n",
      "[210]\ttraining's rmse: 29.8222\tvalid_1's rmse: 59.5635\n",
      "[240]\ttraining's rmse: 26.5954\tvalid_1's rmse: 58.3373\n",
      "[270]\ttraining's rmse: 24.0219\tvalid_1's rmse: 57.5073\n",
      "[300]\ttraining's rmse: 21.9044\tvalid_1's rmse: 57.0442\n",
      "[330]\ttraining's rmse: 20.0538\tvalid_1's rmse: 56.5662\n",
      "[360]\ttraining's rmse: 18.458\tvalid_1's rmse: 56.251\n",
      "[390]\ttraining's rmse: 17.0732\tvalid_1's rmse: 56.0033\n",
      "[420]\ttraining's rmse: 15.8215\tvalid_1's rmse: 55.8232\n",
      "[450]\ttraining's rmse: 14.6886\tvalid_1's rmse: 55.6497\n",
      "[480]\ttraining's rmse: 13.6671\tvalid_1's rmse: 55.4903\n",
      "[510]\ttraining's rmse: 12.7436\tvalid_1's rmse: 55.3877\n",
      "[540]\ttraining's rmse: 11.8955\tvalid_1's rmse: 55.252\n",
      "[570]\ttraining's rmse: 11.1201\tvalid_1's rmse: 55.1396\n",
      "[600]\ttraining's rmse: 10.4355\tvalid_1's rmse: 55.0642\n",
      "[630]\ttraining's rmse: 9.79296\tvalid_1's rmse: 54.996\n",
      "[660]\ttraining's rmse: 9.17935\tvalid_1's rmse: 54.9262\n",
      "[690]\ttraining's rmse: 8.61505\tvalid_1's rmse: 54.8819\n",
      "[720]\ttraining's rmse: 8.10352\tvalid_1's rmse: 54.8296\n",
      "[750]\ttraining's rmse: 7.63144\tvalid_1's rmse: 54.8058\n",
      "[780]\ttraining's rmse: 7.182\tvalid_1's rmse: 54.7726\n",
      "[810]\ttraining's rmse: 6.76644\tvalid_1's rmse: 54.7381\n",
      "[840]\ttraining's rmse: 6.3702\tvalid_1's rmse: 54.7058\n",
      "[870]\ttraining's rmse: 6.01082\tvalid_1's rmse: 54.6882\n",
      "[900]\ttraining's rmse: 5.67119\tvalid_1's rmse: 54.6621\n",
      "[930]\ttraining's rmse: 5.34919\tvalid_1's rmse: 54.6389\n",
      "[960]\ttraining's rmse: 5.05506\tvalid_1's rmse: 54.6212\n",
      "[990]\ttraining's rmse: 4.77531\tvalid_1's rmse: 54.6065\n",
      "[1020]\ttraining's rmse: 4.51271\tvalid_1's rmse: 54.5795\n",
      "[1050]\ttraining's rmse: 4.26999\tvalid_1's rmse: 54.5631\n",
      "[1080]\ttraining's rmse: 4.03845\tvalid_1's rmse: 54.5546\n",
      "[1110]\ttraining's rmse: 3.82492\tvalid_1's rmse: 54.5319\n",
      "[1140]\ttraining's rmse: 3.62185\tvalid_1's rmse: 54.5229\n",
      "[1170]\ttraining's rmse: 3.43185\tvalid_1's rmse: 54.5169\n",
      "[1200]\ttraining's rmse: 3.2523\tvalid_1's rmse: 54.5097\n",
      "[1230]\ttraining's rmse: 3.08411\tvalid_1's rmse: 54.5076\n",
      "[1260]\ttraining's rmse: 2.92405\tvalid_1's rmse: 54.5044\n",
      "[1290]\ttraining's rmse: 2.77415\tvalid_1's rmse: 54.4975\n",
      "[1320]\ttraining's rmse: 2.6323\tvalid_1's rmse: 54.4946\n",
      "[1350]\ttraining's rmse: 2.49673\tvalid_1's rmse: 54.4876\n",
      "[1380]\ttraining's rmse: 2.36898\tvalid_1's rmse: 54.4791\n",
      "[1410]\ttraining's rmse: 2.24912\tvalid_1's rmse: 54.4749\n",
      "[1440]\ttraining's rmse: 2.13626\tvalid_1's rmse: 54.4713\n",
      "[1470]\ttraining's rmse: 2.02968\tvalid_1's rmse: 54.4678\n",
      "[1500]\ttraining's rmse: 1.92619\tvalid_1's rmse: 54.4649\n",
      "[1530]\ttraining's rmse: 1.83068\tvalid_1's rmse: 54.4588\n",
      "[1560]\ttraining's rmse: 1.7374\tvalid_1's rmse: 54.4547\n",
      "[1590]\ttraining's rmse: 1.65039\tvalid_1's rmse: 54.4536\n",
      "[1620]\ttraining's rmse: 1.56843\tvalid_1's rmse: 54.4504\n",
      "[1650]\ttraining's rmse: 1.49147\tvalid_1's rmse: 54.449\n",
      "[1680]\ttraining's rmse: 1.41888\tvalid_1's rmse: 54.4467\n",
      "[1710]\ttraining's rmse: 1.34948\tvalid_1's rmse: 54.4441\n",
      "[1740]\ttraining's rmse: 1.28288\tvalid_1's rmse: 54.4431\n",
      "[1770]\ttraining's rmse: 1.22033\tvalid_1's rmse: 54.4401\n",
      "[1800]\ttraining's rmse: 1.16028\tvalid_1's rmse: 54.4391\n",
      "[1830]\ttraining's rmse: 1.1042\tvalid_1's rmse: 54.4355\n",
      "[1860]\ttraining's rmse: 1.05175\tvalid_1's rmse: 54.4342\n",
      "[1890]\ttraining's rmse: 1.0014\tvalid_1's rmse: 54.4331\n",
      "[1920]\ttraining's rmse: 0.953696\tvalid_1's rmse: 54.432\n",
      "[1950]\ttraining's rmse: 0.907872\tvalid_1's rmse: 54.4306\n",
      "[1980]\ttraining's rmse: 0.864307\tvalid_1's rmse: 54.4283\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's rmse: 0.836221\tvalid_1's rmse: 54.4273\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003613 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 20023\n",
      "[LightGBM] [Info] Number of data points in the train set: 9219, number of used features: 79\n",
      "[LightGBM] [Info] Start training from score 366.728918\n",
      "Training until validation scores don't improve for 125 rounds\n",
      "[30]\ttraining's rmse: 147.879\tvalid_1's rmse: 155.436\n",
      "[60]\ttraining's rmse: 93.665\tvalid_1's rmse: 104.004\n",
      "[90]\ttraining's rmse: 64.2201\tvalid_1's rmse: 78.4979\n",
      "[120]\ttraining's rmse: 48.2696\tvalid_1's rmse: 66.7687\n",
      "[150]\ttraining's rmse: 39.1583\tvalid_1's rmse: 61.086\n",
      "[180]\ttraining's rmse: 33.4184\tvalid_1's rmse: 58.0177\n",
      "[210]\ttraining's rmse: 29.3866\tvalid_1's rmse: 56.2511\n",
      "[240]\ttraining's rmse: 26.1769\tvalid_1's rmse: 54.9698\n",
      "[270]\ttraining's rmse: 23.6198\tvalid_1's rmse: 54.0762\n",
      "[300]\ttraining's rmse: 21.5164\tvalid_1's rmse: 53.4126\n",
      "[330]\ttraining's rmse: 19.7082\tvalid_1's rmse: 53.0514\n",
      "[360]\ttraining's rmse: 18.1412\tvalid_1's rmse: 52.7449\n",
      "[390]\ttraining's rmse: 16.7501\tvalid_1's rmse: 52.4584\n",
      "[420]\ttraining's rmse: 15.531\tvalid_1's rmse: 52.2819\n",
      "[450]\ttraining's rmse: 14.4075\tvalid_1's rmse: 52.1643\n",
      "[480]\ttraining's rmse: 13.3638\tvalid_1's rmse: 52.0531\n",
      "[510]\ttraining's rmse: 12.4304\tvalid_1's rmse: 51.9321\n",
      "[540]\ttraining's rmse: 11.622\tvalid_1's rmse: 51.8903\n",
      "[570]\ttraining's rmse: 10.8549\tvalid_1's rmse: 51.8074\n",
      "[600]\ttraining's rmse: 10.1623\tvalid_1's rmse: 51.7187\n",
      "[630]\ttraining's rmse: 9.52961\tvalid_1's rmse: 51.6679\n",
      "[660]\ttraining's rmse: 8.93241\tvalid_1's rmse: 51.596\n",
      "[690]\ttraining's rmse: 8.39536\tvalid_1's rmse: 51.5537\n",
      "[720]\ttraining's rmse: 7.89411\tvalid_1's rmse: 51.4891\n",
      "[750]\ttraining's rmse: 7.42137\tvalid_1's rmse: 51.4482\n",
      "[780]\ttraining's rmse: 6.97828\tvalid_1's rmse: 51.408\n",
      "[810]\ttraining's rmse: 6.56939\tvalid_1's rmse: 51.3989\n",
      "[840]\ttraining's rmse: 6.19005\tvalid_1's rmse: 51.3687\n",
      "[870]\ttraining's rmse: 5.83967\tvalid_1's rmse: 51.3592\n",
      "[900]\ttraining's rmse: 5.50761\tvalid_1's rmse: 51.3344\n",
      "[930]\ttraining's rmse: 5.19529\tvalid_1's rmse: 51.3265\n",
      "[960]\ttraining's rmse: 4.90487\tvalid_1's rmse: 51.3094\n",
      "[990]\ttraining's rmse: 4.64096\tvalid_1's rmse: 51.2965\n",
      "[1020]\ttraining's rmse: 4.38817\tvalid_1's rmse: 51.2898\n",
      "[1050]\ttraining's rmse: 4.14722\tvalid_1's rmse: 51.2772\n",
      "[1080]\ttraining's rmse: 3.92551\tvalid_1's rmse: 51.2651\n",
      "[1110]\ttraining's rmse: 3.71495\tvalid_1's rmse: 51.2521\n",
      "[1140]\ttraining's rmse: 3.521\tvalid_1's rmse: 51.247\n",
      "[1170]\ttraining's rmse: 3.33303\tvalid_1's rmse: 51.2401\n",
      "[1200]\ttraining's rmse: 3.15473\tvalid_1's rmse: 51.2316\n",
      "[1230]\ttraining's rmse: 2.99034\tvalid_1's rmse: 51.225\n",
      "[1260]\ttraining's rmse: 2.8333\tvalid_1's rmse: 51.2245\n",
      "[1290]\ttraining's rmse: 2.68665\tvalid_1's rmse: 51.2206\n",
      "[1320]\ttraining's rmse: 2.54981\tvalid_1's rmse: 51.2162\n",
      "[1350]\ttraining's rmse: 2.42314\tvalid_1's rmse: 51.2078\n",
      "[1380]\ttraining's rmse: 2.29511\tvalid_1's rmse: 51.1993\n",
      "[1410]\ttraining's rmse: 2.17723\tvalid_1's rmse: 51.1915\n",
      "[1440]\ttraining's rmse: 2.0677\tvalid_1's rmse: 51.1911\n",
      "[1470]\ttraining's rmse: 1.96078\tvalid_1's rmse: 51.1865\n",
      "[1500]\ttraining's rmse: 1.86359\tvalid_1's rmse: 51.1853\n",
      "[1530]\ttraining's rmse: 1.76964\tvalid_1's rmse: 51.1801\n",
      "[1560]\ttraining's rmse: 1.68302\tvalid_1's rmse: 51.1802\n",
      "[1590]\ttraining's rmse: 1.59893\tvalid_1's rmse: 51.1795\n",
      "[1620]\ttraining's rmse: 1.52097\tvalid_1's rmse: 51.1781\n",
      "[1650]\ttraining's rmse: 1.44594\tvalid_1's rmse: 51.1735\n",
      "[1680]\ttraining's rmse: 1.37411\tvalid_1's rmse: 51.1681\n",
      "[1710]\ttraining's rmse: 1.3075\tvalid_1's rmse: 51.1669\n",
      "[1740]\ttraining's rmse: 1.24452\tvalid_1's rmse: 51.1649\n",
      "[1770]\ttraining's rmse: 1.18393\tvalid_1's rmse: 51.1621\n",
      "[1800]\ttraining's rmse: 1.12812\tvalid_1's rmse: 51.16\n",
      "[1830]\ttraining's rmse: 1.0743\tvalid_1's rmse: 51.1576\n",
      "[1860]\ttraining's rmse: 1.02128\tvalid_1's rmse: 51.1584\n",
      "[1890]\ttraining's rmse: 0.972373\tvalid_1's rmse: 51.1567\n",
      "[1920]\ttraining's rmse: 0.925792\tvalid_1's rmse: 51.1547\n",
      "[1950]\ttraining's rmse: 0.881372\tvalid_1's rmse: 51.156\n",
      "[1980]\ttraining's rmse: 0.839579\tvalid_1's rmse: 51.1548\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's rmse: 0.813106\tvalid_1's rmse: 51.1548\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002753 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 20023\n",
      "[LightGBM] [Info] Number of data points in the train set: 9219, number of used features: 79\n",
      "[LightGBM] [Info] Start training from score 368.107116\n",
      "Training until validation scores don't improve for 125 rounds\n",
      "[30]\ttraining's rmse: 148.31\tvalid_1's rmse: 153.436\n",
      "[60]\ttraining's rmse: 93.8837\tvalid_1's rmse: 106.089\n",
      "[90]\ttraining's rmse: 64.462\tvalid_1's rmse: 83.4613\n",
      "[120]\ttraining's rmse: 48.4147\tvalid_1's rmse: 72.552\n",
      "[150]\ttraining's rmse: 39.1561\tvalid_1's rmse: 67.2175\n",
      "[180]\ttraining's rmse: 33.3729\tvalid_1's rmse: 64.3692\n",
      "[210]\ttraining's rmse: 29.2879\tvalid_1's rmse: 62.5556\n",
      "[240]\ttraining's rmse: 26.1483\tvalid_1's rmse: 61.2084\n",
      "[270]\ttraining's rmse: 23.6151\tvalid_1's rmse: 60.2759\n",
      "[300]\ttraining's rmse: 21.5374\tvalid_1's rmse: 59.7064\n",
      "[330]\ttraining's rmse: 19.7671\tvalid_1's rmse: 59.2673\n",
      "[360]\ttraining's rmse: 18.2002\tvalid_1's rmse: 58.8686\n",
      "[390]\ttraining's rmse: 16.8098\tvalid_1's rmse: 58.6235\n",
      "[420]\ttraining's rmse: 15.5715\tvalid_1's rmse: 58.3655\n",
      "[450]\ttraining's rmse: 14.4632\tvalid_1's rmse: 58.168\n",
      "[480]\ttraining's rmse: 13.4398\tvalid_1's rmse: 57.9427\n",
      "[510]\ttraining's rmse: 12.5318\tvalid_1's rmse: 57.8114\n",
      "[540]\ttraining's rmse: 11.6944\tvalid_1's rmse: 57.6885\n",
      "[570]\ttraining's rmse: 10.9477\tvalid_1's rmse: 57.5808\n",
      "[600]\ttraining's rmse: 10.2403\tvalid_1's rmse: 57.4905\n",
      "[630]\ttraining's rmse: 9.59423\tvalid_1's rmse: 57.411\n",
      "[660]\ttraining's rmse: 8.99851\tvalid_1's rmse: 57.3275\n",
      "[690]\ttraining's rmse: 8.44299\tvalid_1's rmse: 57.278\n",
      "[720]\ttraining's rmse: 7.92964\tvalid_1's rmse: 57.2259\n",
      "[750]\ttraining's rmse: 7.46334\tvalid_1's rmse: 57.1898\n",
      "[780]\ttraining's rmse: 7.03036\tvalid_1's rmse: 57.1572\n",
      "[810]\ttraining's rmse: 6.61883\tvalid_1's rmse: 57.1232\n",
      "[840]\ttraining's rmse: 6.23746\tvalid_1's rmse: 57.0854\n",
      "[870]\ttraining's rmse: 5.88063\tvalid_1's rmse: 57.0525\n",
      "[900]\ttraining's rmse: 5.54779\tvalid_1's rmse: 57.0196\n",
      "[930]\ttraining's rmse: 5.23645\tvalid_1's rmse: 56.9901\n",
      "[960]\ttraining's rmse: 4.94626\tvalid_1's rmse: 56.9614\n",
      "[990]\ttraining's rmse: 4.67052\tvalid_1's rmse: 56.9421\n",
      "[1020]\ttraining's rmse: 4.42187\tvalid_1's rmse: 56.9289\n",
      "[1050]\ttraining's rmse: 4.17876\tvalid_1's rmse: 56.9072\n",
      "[1080]\ttraining's rmse: 3.95116\tvalid_1's rmse: 56.8917\n",
      "[1110]\ttraining's rmse: 3.73823\tvalid_1's rmse: 56.881\n",
      "[1140]\ttraining's rmse: 3.53871\tvalid_1's rmse: 56.8642\n",
      "[1170]\ttraining's rmse: 3.35426\tvalid_1's rmse: 56.8526\n",
      "[1200]\ttraining's rmse: 3.17841\tvalid_1's rmse: 56.8434\n",
      "[1230]\ttraining's rmse: 3.01\tvalid_1's rmse: 56.835\n",
      "[1260]\ttraining's rmse: 2.85158\tvalid_1's rmse: 56.83\n",
      "[1290]\ttraining's rmse: 2.70336\tvalid_1's rmse: 56.8225\n",
      "[1320]\ttraining's rmse: 2.5642\tvalid_1's rmse: 56.8184\n",
      "[1350]\ttraining's rmse: 2.43589\tvalid_1's rmse: 56.8139\n",
      "[1380]\ttraining's rmse: 2.31246\tvalid_1's rmse: 56.8054\n",
      "[1410]\ttraining's rmse: 2.19715\tvalid_1's rmse: 56.7971\n",
      "[1440]\ttraining's rmse: 2.08882\tvalid_1's rmse: 56.7911\n",
      "[1470]\ttraining's rmse: 1.98593\tvalid_1's rmse: 56.7867\n",
      "[1500]\ttraining's rmse: 1.88647\tvalid_1's rmse: 56.7821\n",
      "[1530]\ttraining's rmse: 1.79298\tvalid_1's rmse: 56.7765\n",
      "[1560]\ttraining's rmse: 1.70423\tvalid_1's rmse: 56.7711\n",
      "[1590]\ttraining's rmse: 1.61999\tvalid_1's rmse: 56.7683\n",
      "[1620]\ttraining's rmse: 1.54009\tvalid_1's rmse: 56.7658\n",
      "[1650]\ttraining's rmse: 1.46704\tvalid_1's rmse: 56.7629\n",
      "[1680]\ttraining's rmse: 1.39631\tvalid_1's rmse: 56.7588\n",
      "[1710]\ttraining's rmse: 1.32919\tvalid_1's rmse: 56.7564\n",
      "[1740]\ttraining's rmse: 1.26515\tvalid_1's rmse: 56.7554\n",
      "[1770]\ttraining's rmse: 1.20382\tvalid_1's rmse: 56.7526\n",
      "[1800]\ttraining's rmse: 1.14646\tvalid_1's rmse: 56.7523\n",
      "[1830]\ttraining's rmse: 1.09152\tvalid_1's rmse: 56.7526\n",
      "[1860]\ttraining's rmse: 1.03965\tvalid_1's rmse: 56.7492\n",
      "[1890]\ttraining's rmse: 0.989855\tvalid_1's rmse: 56.7464\n",
      "[1920]\ttraining's rmse: 0.943209\tvalid_1's rmse: 56.7432\n",
      "[1950]\ttraining's rmse: 0.899035\tvalid_1's rmse: 56.7418\n",
      "[1980]\ttraining's rmse: 0.856775\tvalid_1's rmse: 56.7401\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's rmse: 0.83061\tvalid_1's rmse: 56.7406\n",
      "37\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002328 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 20024\n",
      "[LightGBM] [Info] Number of data points in the train set: 9219, number of used features: 79\n",
      "[LightGBM] [Info] Start training from score 369.610226\n",
      "Training until validation scores don't improve for 125 rounds\n",
      "[30]\ttraining's rmse: 146.413\tvalid_1's rmse: 151.512\n",
      "[60]\ttraining's rmse: 92.0259\tvalid_1's rmse: 102.325\n",
      "[90]\ttraining's rmse: 62.7151\tvalid_1's rmse: 77.9785\n",
      "[120]\ttraining's rmse: 46.7436\tvalid_1's rmse: 66.1589\n",
      "[150]\ttraining's rmse: 37.7824\tvalid_1's rmse: 60.3793\n",
      "[180]\ttraining's rmse: 32.1758\tvalid_1's rmse: 57.2977\n",
      "[210]\ttraining's rmse: 28.2707\tvalid_1's rmse: 55.3293\n",
      "[240]\ttraining's rmse: 25.2475\tvalid_1's rmse: 54.0163\n",
      "[270]\ttraining's rmse: 22.7694\tvalid_1's rmse: 53.1957\n",
      "[300]\ttraining's rmse: 20.754\tvalid_1's rmse: 52.6274\n",
      "[330]\ttraining's rmse: 19.0351\tvalid_1's rmse: 52.1543\n",
      "[360]\ttraining's rmse: 17.5478\tvalid_1's rmse: 51.8118\n",
      "[390]\ttraining's rmse: 16.2476\tvalid_1's rmse: 51.6632\n",
      "[420]\ttraining's rmse: 15.0569\tvalid_1's rmse: 51.4463\n",
      "[450]\ttraining's rmse: 13.9894\tvalid_1's rmse: 51.2652\n",
      "[480]\ttraining's rmse: 13.0692\tvalid_1's rmse: 51.1626\n",
      "[510]\ttraining's rmse: 12.1883\tvalid_1's rmse: 51.055\n",
      "[540]\ttraining's rmse: 11.3922\tvalid_1's rmse: 50.9921\n",
      "[570]\ttraining's rmse: 10.6775\tvalid_1's rmse: 50.9173\n",
      "[600]\ttraining's rmse: 10.0276\tvalid_1's rmse: 50.8855\n",
      "[630]\ttraining's rmse: 9.4296\tvalid_1's rmse: 50.8415\n",
      "[660]\ttraining's rmse: 8.86143\tvalid_1's rmse: 50.7898\n",
      "[690]\ttraining's rmse: 8.34748\tvalid_1's rmse: 50.76\n",
      "[720]\ttraining's rmse: 7.86659\tvalid_1's rmse: 50.7219\n",
      "[750]\ttraining's rmse: 7.41802\tvalid_1's rmse: 50.7272\n",
      "[780]\ttraining's rmse: 6.99962\tvalid_1's rmse: 50.7025\n",
      "[810]\ttraining's rmse: 6.61983\tvalid_1's rmse: 50.6887\n",
      "[840]\ttraining's rmse: 6.25016\tvalid_1's rmse: 50.6522\n",
      "[870]\ttraining's rmse: 5.90499\tvalid_1's rmse: 50.6281\n",
      "[900]\ttraining's rmse: 5.5919\tvalid_1's rmse: 50.6166\n",
      "[930]\ttraining's rmse: 5.30082\tvalid_1's rmse: 50.5993\n",
      "[960]\ttraining's rmse: 5.02555\tvalid_1's rmse: 50.5892\n",
      "[990]\ttraining's rmse: 4.76336\tvalid_1's rmse: 50.5832\n",
      "[1020]\ttraining's rmse: 4.5191\tvalid_1's rmse: 50.5823\n",
      "[1050]\ttraining's rmse: 4.28525\tvalid_1's rmse: 50.5687\n",
      "[1080]\ttraining's rmse: 4.07627\tvalid_1's rmse: 50.5679\n",
      "[1110]\ttraining's rmse: 3.87656\tvalid_1's rmse: 50.5581\n",
      "[1140]\ttraining's rmse: 3.68259\tvalid_1's rmse: 50.5503\n",
      "[1170]\ttraining's rmse: 3.50182\tvalid_1's rmse: 50.5429\n",
      "[1200]\ttraining's rmse: 3.33375\tvalid_1's rmse: 50.5408\n",
      "[1230]\ttraining's rmse: 3.16989\tvalid_1's rmse: 50.5352\n",
      "[1260]\ttraining's rmse: 3.01699\tvalid_1's rmse: 50.5414\n",
      "[1290]\ttraining's rmse: 2.87759\tvalid_1's rmse: 50.5408\n",
      "[1320]\ttraining's rmse: 2.7389\tvalid_1's rmse: 50.5393\n",
      "[1350]\ttraining's rmse: 2.60658\tvalid_1's rmse: 50.5341\n",
      "[1380]\ttraining's rmse: 2.48019\tvalid_1's rmse: 50.5293\n",
      "[1410]\ttraining's rmse: 2.3601\tvalid_1's rmse: 50.5284\n",
      "[1440]\ttraining's rmse: 2.25466\tvalid_1's rmse: 50.5272\n",
      "[1470]\ttraining's rmse: 2.15445\tvalid_1's rmse: 50.5285\n",
      "[1500]\ttraining's rmse: 2.05291\tvalid_1's rmse: 50.5225\n",
      "[1530]\ttraining's rmse: 1.95859\tvalid_1's rmse: 50.5241\n",
      "[1560]\ttraining's rmse: 1.87111\tvalid_1's rmse: 50.528\n",
      "[1590]\ttraining's rmse: 1.78544\tvalid_1's rmse: 50.5275\n",
      "[1620]\ttraining's rmse: 1.70628\tvalid_1's rmse: 50.5334\n",
      "Early stopping, best iteration is:\n",
      "[1503]\ttraining's rmse: 2.04381\tvalid_1's rmse: 50.5215\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002551 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 20024\n",
      "[LightGBM] [Info] Number of data points in the train set: 9219, number of used features: 79\n",
      "[LightGBM] [Info] Start training from score 370.036594\n",
      "Training until validation scores don't improve for 125 rounds\n",
      "[30]\ttraining's rmse: 148.384\tvalid_1's rmse: 154.501\n",
      "[60]\ttraining's rmse: 94.9527\tvalid_1's rmse: 106.166\n",
      "[90]\ttraining's rmse: 65.8169\tvalid_1's rmse: 82.3451\n",
      "[120]\ttraining's rmse: 49.5105\tvalid_1's rmse: 70.613\n",
      "[150]\ttraining's rmse: 40.1455\tvalid_1's rmse: 64.9191\n",
      "[180]\ttraining's rmse: 34.2643\tvalid_1's rmse: 61.8962\n",
      "[210]\ttraining's rmse: 30.0457\tvalid_1's rmse: 59.9597\n",
      "[240]\ttraining's rmse: 26.8005\tvalid_1's rmse: 58.7367\n",
      "[270]\ttraining's rmse: 24.2225\tvalid_1's rmse: 57.8898\n",
      "[300]\ttraining's rmse: 22.0972\tvalid_1's rmse: 57.3612\n",
      "[330]\ttraining's rmse: 20.2828\tvalid_1's rmse: 56.8224\n",
      "[360]\ttraining's rmse: 18.6997\tvalid_1's rmse: 56.549\n",
      "[390]\ttraining's rmse: 17.3265\tvalid_1's rmse: 56.2794\n",
      "[420]\ttraining's rmse: 16.0704\tvalid_1's rmse: 56.0409\n",
      "[450]\ttraining's rmse: 14.9475\tvalid_1's rmse: 55.9001\n",
      "[480]\ttraining's rmse: 13.9421\tvalid_1's rmse: 55.7983\n",
      "[510]\ttraining's rmse: 13.0106\tvalid_1's rmse: 55.662\n",
      "[540]\ttraining's rmse: 12.153\tvalid_1's rmse: 55.5882\n",
      "[570]\ttraining's rmse: 11.3633\tvalid_1's rmse: 55.5097\n",
      "[600]\ttraining's rmse: 10.6705\tvalid_1's rmse: 55.4781\n",
      "[630]\ttraining's rmse: 10.0014\tvalid_1's rmse: 55.4097\n",
      "[660]\ttraining's rmse: 9.39017\tvalid_1's rmse: 55.3433\n",
      "[690]\ttraining's rmse: 8.83394\tvalid_1's rmse: 55.3021\n",
      "[720]\ttraining's rmse: 8.31537\tvalid_1's rmse: 55.2593\n",
      "[750]\ttraining's rmse: 7.83158\tvalid_1's rmse: 55.2267\n",
      "[780]\ttraining's rmse: 7.39167\tvalid_1's rmse: 55.1842\n",
      "[810]\ttraining's rmse: 6.95834\tvalid_1's rmse: 55.1537\n",
      "[840]\ttraining's rmse: 6.56715\tvalid_1's rmse: 55.1328\n",
      "[870]\ttraining's rmse: 6.20277\tvalid_1's rmse: 55.0923\n",
      "[900]\ttraining's rmse: 5.86462\tvalid_1's rmse: 55.0823\n",
      "[930]\ttraining's rmse: 5.5462\tvalid_1's rmse: 55.053\n",
      "[960]\ttraining's rmse: 5.24431\tvalid_1's rmse: 55.0286\n",
      "[990]\ttraining's rmse: 4.96689\tvalid_1's rmse: 55.0156\n",
      "[1020]\ttraining's rmse: 4.70232\tvalid_1's rmse: 55.012\n",
      "[1050]\ttraining's rmse: 4.45061\tvalid_1's rmse: 55.0016\n",
      "[1080]\ttraining's rmse: 4.21472\tvalid_1's rmse: 54.9967\n",
      "[1110]\ttraining's rmse: 4.00091\tvalid_1's rmse: 54.9825\n",
      "[1140]\ttraining's rmse: 3.7924\tvalid_1's rmse: 54.9619\n",
      "[1170]\ttraining's rmse: 3.59541\tvalid_1's rmse: 54.9529\n",
      "[1200]\ttraining's rmse: 3.40934\tvalid_1's rmse: 54.9393\n",
      "[1230]\ttraining's rmse: 3.2348\tvalid_1's rmse: 54.9334\n",
      "[1260]\ttraining's rmse: 3.06636\tvalid_1's rmse: 54.9288\n",
      "[1290]\ttraining's rmse: 2.91184\tvalid_1's rmse: 54.9228\n",
      "[1320]\ttraining's rmse: 2.76315\tvalid_1's rmse: 54.9254\n",
      "[1350]\ttraining's rmse: 2.6214\tvalid_1's rmse: 54.9201\n",
      "[1380]\ttraining's rmse: 2.48814\tvalid_1's rmse: 54.9091\n",
      "[1410]\ttraining's rmse: 2.36385\tvalid_1's rmse: 54.9078\n",
      "[1440]\ttraining's rmse: 2.24604\tvalid_1's rmse: 54.9057\n",
      "[1470]\ttraining's rmse: 2.13738\tvalid_1's rmse: 54.9012\n",
      "[1500]\ttraining's rmse: 2.03198\tvalid_1's rmse: 54.9032\n",
      "[1530]\ttraining's rmse: 1.9326\tvalid_1's rmse: 54.9022\n",
      "[1560]\ttraining's rmse: 1.83779\tvalid_1's rmse: 54.9031\n",
      "[1590]\ttraining's rmse: 1.74561\tvalid_1's rmse: 54.8981\n",
      "[1620]\ttraining's rmse: 1.66574\tvalid_1's rmse: 54.8948\n",
      "[1650]\ttraining's rmse: 1.58709\tvalid_1's rmse: 54.8923\n",
      "[1680]\ttraining's rmse: 1.5095\tvalid_1's rmse: 54.8895\n",
      "[1710]\ttraining's rmse: 1.43845\tvalid_1's rmse: 54.8878\n",
      "[1740]\ttraining's rmse: 1.37204\tvalid_1's rmse: 54.8843\n",
      "[1770]\ttraining's rmse: 1.30797\tvalid_1's rmse: 54.8846\n",
      "[1800]\ttraining's rmse: 1.2441\tvalid_1's rmse: 54.8827\n",
      "[1830]\ttraining's rmse: 1.18458\tvalid_1's rmse: 54.8785\n",
      "[1860]\ttraining's rmse: 1.12978\tvalid_1's rmse: 54.8771\n",
      "[1890]\ttraining's rmse: 1.07635\tvalid_1's rmse: 54.8757\n",
      "[1920]\ttraining's rmse: 1.02553\tvalid_1's rmse: 54.8753\n",
      "[1950]\ttraining's rmse: 0.979279\tvalid_1's rmse: 54.8745\n",
      "[1980]\ttraining's rmse: 0.935294\tvalid_1's rmse: 54.8758\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's rmse: 0.906205\tvalid_1's rmse: 54.8738\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002406 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 20024\n",
      "[LightGBM] [Info] Number of data points in the train set: 9219, number of used features: 79\n",
      "[LightGBM] [Info] Start training from score 370.719177\n",
      "Training until validation scores don't improve for 125 rounds\n",
      "[30]\ttraining's rmse: 149.69\tvalid_1's rmse: 153.705\n",
      "[60]\ttraining's rmse: 96.785\tvalid_1's rmse: 105.284\n",
      "[90]\ttraining's rmse: 67.5356\tvalid_1's rmse: 80.8008\n",
      "[120]\ttraining's rmse: 51.0566\tvalid_1's rmse: 68.2879\n",
      "[150]\ttraining's rmse: 41.5199\tvalid_1's rmse: 62.101\n",
      "[180]\ttraining's rmse: 35.4442\tvalid_1's rmse: 58.7495\n",
      "[210]\ttraining's rmse: 31.1265\tvalid_1's rmse: 56.7803\n",
      "[240]\ttraining's rmse: 27.8088\tvalid_1's rmse: 55.4979\n",
      "[270]\ttraining's rmse: 25.107\tvalid_1's rmse: 54.6547\n",
      "[300]\ttraining's rmse: 22.8724\tvalid_1's rmse: 54.1077\n",
      "[330]\ttraining's rmse: 20.9892\tvalid_1's rmse: 53.6803\n",
      "[360]\ttraining's rmse: 19.3539\tvalid_1's rmse: 53.3424\n",
      "[390]\ttraining's rmse: 17.9072\tvalid_1's rmse: 53.1102\n",
      "[420]\ttraining's rmse: 16.6091\tvalid_1's rmse: 52.9152\n",
      "[450]\ttraining's rmse: 15.4242\tvalid_1's rmse: 52.7596\n",
      "[480]\ttraining's rmse: 14.3682\tvalid_1's rmse: 52.602\n",
      "[510]\ttraining's rmse: 13.3857\tvalid_1's rmse: 52.4981\n",
      "[540]\ttraining's rmse: 12.4992\tvalid_1's rmse: 52.3997\n",
      "[570]\ttraining's rmse: 11.6835\tvalid_1's rmse: 52.3287\n",
      "[600]\ttraining's rmse: 10.9398\tvalid_1's rmse: 52.273\n",
      "[630]\ttraining's rmse: 10.2544\tvalid_1's rmse: 52.2102\n",
      "[660]\ttraining's rmse: 9.62018\tvalid_1's rmse: 52.1365\n",
      "[690]\ttraining's rmse: 9.03367\tvalid_1's rmse: 52.0679\n",
      "[720]\ttraining's rmse: 8.50097\tvalid_1's rmse: 52.0335\n",
      "[750]\ttraining's rmse: 7.99477\tvalid_1's rmse: 51.9967\n",
      "[780]\ttraining's rmse: 7.52769\tvalid_1's rmse: 51.9646\n",
      "[810]\ttraining's rmse: 7.08536\tvalid_1's rmse: 51.9402\n",
      "[840]\ttraining's rmse: 6.68466\tvalid_1's rmse: 51.9263\n",
      "[870]\ttraining's rmse: 6.31007\tvalid_1's rmse: 51.9078\n",
      "[900]\ttraining's rmse: 5.95967\tvalid_1's rmse: 51.8914\n",
      "[930]\ttraining's rmse: 5.63196\tvalid_1's rmse: 51.8743\n",
      "[960]\ttraining's rmse: 5.32245\tvalid_1's rmse: 51.8596\n",
      "[990]\ttraining's rmse: 5.03264\tvalid_1's rmse: 51.8393\n",
      "[1020]\ttraining's rmse: 4.77008\tvalid_1's rmse: 51.8223\n",
      "[1050]\ttraining's rmse: 4.50886\tvalid_1's rmse: 51.7999\n",
      "[1080]\ttraining's rmse: 4.27035\tvalid_1's rmse: 51.7877\n",
      "[1110]\ttraining's rmse: 4.04266\tvalid_1's rmse: 51.7788\n",
      "[1140]\ttraining's rmse: 3.82841\tvalid_1's rmse: 51.7609\n",
      "[1170]\ttraining's rmse: 3.62873\tvalid_1's rmse: 51.7633\n",
      "[1200]\ttraining's rmse: 3.44407\tvalid_1's rmse: 51.7547\n",
      "[1230]\ttraining's rmse: 3.26471\tvalid_1's rmse: 51.7464\n",
      "[1260]\ttraining's rmse: 3.09707\tvalid_1's rmse: 51.7415\n",
      "[1290]\ttraining's rmse: 2.93744\tvalid_1's rmse: 51.7368\n",
      "[1320]\ttraining's rmse: 2.78689\tvalid_1's rmse: 51.7329\n",
      "[1350]\ttraining's rmse: 2.64725\tvalid_1's rmse: 51.7292\n",
      "[1380]\ttraining's rmse: 2.51604\tvalid_1's rmse: 51.7188\n",
      "[1410]\ttraining's rmse: 2.39131\tvalid_1's rmse: 51.716\n",
      "[1440]\ttraining's rmse: 2.27151\tvalid_1's rmse: 51.7105\n",
      "[1470]\ttraining's rmse: 2.16315\tvalid_1's rmse: 51.7084\n",
      "[1500]\ttraining's rmse: 2.058\tvalid_1's rmse: 51.7069\n",
      "[1530]\ttraining's rmse: 1.95605\tvalid_1's rmse: 51.7047\n",
      "[1560]\ttraining's rmse: 1.86008\tvalid_1's rmse: 51.7029\n",
      "[1590]\ttraining's rmse: 1.76878\tvalid_1's rmse: 51.7018\n",
      "[1620]\ttraining's rmse: 1.68257\tvalid_1's rmse: 51.7019\n",
      "[1650]\ttraining's rmse: 1.60296\tvalid_1's rmse: 51.7023\n",
      "[1680]\ttraining's rmse: 1.5251\tvalid_1's rmse: 51.7013\n",
      "[1710]\ttraining's rmse: 1.45414\tvalid_1's rmse: 51.6968\n",
      "[1740]\ttraining's rmse: 1.3851\tvalid_1's rmse: 51.6962\n",
      "[1770]\ttraining's rmse: 1.31988\tvalid_1's rmse: 51.6935\n",
      "[1800]\ttraining's rmse: 1.25889\tvalid_1's rmse: 51.691\n",
      "[1830]\ttraining's rmse: 1.20019\tvalid_1's rmse: 51.6925\n",
      "[1860]\ttraining's rmse: 1.14494\tvalid_1's rmse: 51.6918\n",
      "[1890]\ttraining's rmse: 1.09332\tvalid_1's rmse: 51.6901\n",
      "[1920]\ttraining's rmse: 1.04425\tvalid_1's rmse: 51.6879\n",
      "[1950]\ttraining's rmse: 0.996816\tvalid_1's rmse: 51.6865\n",
      "[1980]\ttraining's rmse: 0.949885\tvalid_1's rmse: 51.6853\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's rmse: 0.920369\tvalid_1's rmse: 51.683\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002257 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 20024\n",
      "[LightGBM] [Info] Number of data points in the train set: 9219, number of used features: 79\n",
      "[LightGBM] [Info] Start training from score 368.005407\n",
      "Training until validation scores don't improve for 125 rounds\n",
      "[30]\ttraining's rmse: 150.023\tvalid_1's rmse: 152.593\n",
      "[60]\ttraining's rmse: 96.6062\tvalid_1's rmse: 105.136\n",
      "[90]\ttraining's rmse: 67.3021\tvalid_1's rmse: 81.4949\n",
      "[120]\ttraining's rmse: 51.0677\tvalid_1's rmse: 69.9787\n",
      "[150]\ttraining's rmse: 41.5577\tvalid_1's rmse: 64.216\n",
      "[180]\ttraining's rmse: 35.3325\tvalid_1's rmse: 60.8766\n",
      "[210]\ttraining's rmse: 30.9542\tvalid_1's rmse: 58.8692\n",
      "[240]\ttraining's rmse: 27.616\tvalid_1's rmse: 57.5784\n",
      "[270]\ttraining's rmse: 24.9178\tvalid_1's rmse: 56.7187\n",
      "[300]\ttraining's rmse: 22.7139\tvalid_1's rmse: 56.0867\n",
      "[330]\ttraining's rmse: 20.841\tvalid_1's rmse: 55.6265\n",
      "[360]\ttraining's rmse: 19.245\tvalid_1's rmse: 55.2758\n",
      "[390]\ttraining's rmse: 17.8184\tvalid_1's rmse: 55.0633\n",
      "[420]\ttraining's rmse: 16.5039\tvalid_1's rmse: 54.8342\n",
      "[450]\ttraining's rmse: 15.3469\tvalid_1's rmse: 54.6661\n",
      "[480]\ttraining's rmse: 14.2854\tvalid_1's rmse: 54.5272\n",
      "[510]\ttraining's rmse: 13.3167\tvalid_1's rmse: 54.41\n",
      "[540]\ttraining's rmse: 12.4521\tvalid_1's rmse: 54.3098\n",
      "[570]\ttraining's rmse: 11.6663\tvalid_1's rmse: 54.2423\n",
      "[600]\ttraining's rmse: 10.9421\tvalid_1's rmse: 54.1913\n",
      "[630]\ttraining's rmse: 10.2697\tvalid_1's rmse: 54.1243\n",
      "[660]\ttraining's rmse: 9.64287\tvalid_1's rmse: 54.0601\n",
      "[690]\ttraining's rmse: 9.06611\tvalid_1's rmse: 54.0014\n",
      "[720]\ttraining's rmse: 8.54533\tvalid_1's rmse: 53.9637\n",
      "[750]\ttraining's rmse: 8.06055\tvalid_1's rmse: 53.9349\n",
      "[780]\ttraining's rmse: 7.6058\tvalid_1's rmse: 53.9075\n",
      "[810]\ttraining's rmse: 7.17562\tvalid_1's rmse: 53.876\n",
      "[840]\ttraining's rmse: 6.78092\tvalid_1's rmse: 53.8571\n",
      "[870]\ttraining's rmse: 6.41674\tvalid_1's rmse: 53.8188\n",
      "[900]\ttraining's rmse: 6.07689\tvalid_1's rmse: 53.7965\n",
      "[930]\ttraining's rmse: 5.7471\tvalid_1's rmse: 53.7696\n",
      "[960]\ttraining's rmse: 5.43667\tvalid_1's rmse: 53.7659\n",
      "[990]\ttraining's rmse: 5.15971\tvalid_1's rmse: 53.7632\n",
      "[1020]\ttraining's rmse: 4.89083\tvalid_1's rmse: 53.7493\n",
      "[1050]\ttraining's rmse: 4.64417\tvalid_1's rmse: 53.7335\n",
      "[1080]\ttraining's rmse: 4.4089\tvalid_1's rmse: 53.7231\n",
      "[1110]\ttraining's rmse: 4.18653\tvalid_1's rmse: 53.7061\n",
      "[1140]\ttraining's rmse: 3.97588\tvalid_1's rmse: 53.6942\n",
      "[1170]\ttraining's rmse: 3.78521\tvalid_1's rmse: 53.6835\n",
      "[1200]\ttraining's rmse: 3.60304\tvalid_1's rmse: 53.6779\n",
      "[1230]\ttraining's rmse: 3.42882\tvalid_1's rmse: 53.6673\n",
      "[1260]\ttraining's rmse: 3.26381\tvalid_1's rmse: 53.6619\n",
      "[1290]\ttraining's rmse: 3.10859\tvalid_1's rmse: 53.6543\n",
      "[1320]\ttraining's rmse: 2.96246\tvalid_1's rmse: 53.6498\n",
      "[1350]\ttraining's rmse: 2.81511\tvalid_1's rmse: 53.6438\n",
      "[1380]\ttraining's rmse: 2.68739\tvalid_1's rmse: 53.6433\n",
      "[1410]\ttraining's rmse: 2.56588\tvalid_1's rmse: 53.6395\n",
      "[1440]\ttraining's rmse: 2.44815\tvalid_1's rmse: 53.6353\n",
      "[1470]\ttraining's rmse: 2.3331\tvalid_1's rmse: 53.6354\n",
      "[1500]\ttraining's rmse: 2.22785\tvalid_1's rmse: 53.6349\n",
      "[1530]\ttraining's rmse: 2.12618\tvalid_1's rmse: 53.6313\n",
      "[1560]\ttraining's rmse: 2.03314\tvalid_1's rmse: 53.6309\n",
      "[1590]\ttraining's rmse: 1.94422\tvalid_1's rmse: 53.6282\n",
      "[1620]\ttraining's rmse: 1.85975\tvalid_1's rmse: 53.625\n",
      "[1650]\ttraining's rmse: 1.77611\tvalid_1's rmse: 53.6236\n",
      "[1680]\ttraining's rmse: 1.6998\tvalid_1's rmse: 53.6212\n",
      "[1710]\ttraining's rmse: 1.62768\tvalid_1's rmse: 53.6198\n",
      "[1740]\ttraining's rmse: 1.55794\tvalid_1's rmse: 53.6187\n",
      "[1770]\ttraining's rmse: 1.49357\tvalid_1's rmse: 53.6178\n",
      "[1800]\ttraining's rmse: 1.43027\tvalid_1's rmse: 53.6154\n",
      "[1830]\ttraining's rmse: 1.36891\tvalid_1's rmse: 53.6172\n",
      "[1860]\ttraining's rmse: 1.31286\tvalid_1's rmse: 53.617\n",
      "[1890]\ttraining's rmse: 1.25958\tvalid_1's rmse: 53.6123\n",
      "[1920]\ttraining's rmse: 1.21061\tvalid_1's rmse: 53.6113\n",
      "[1950]\ttraining's rmse: 1.16231\tvalid_1's rmse: 53.609\n",
      "[1980]\ttraining's rmse: 1.11341\tvalid_1's rmse: 53.6098\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's rmse: 1.08299\tvalid_1's rmse: 53.6081\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003413 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 20024\n",
      "[LightGBM] [Info] Number of data points in the train set: 9219, number of used features: 79\n",
      "[LightGBM] [Info] Start training from score 369.984226\n",
      "Training until validation scores don't improve for 125 rounds\n",
      "[30]\ttraining's rmse: 149.372\tvalid_1's rmse: 151.267\n",
      "[60]\ttraining's rmse: 95.4363\tvalid_1's rmse: 104.835\n",
      "[90]\ttraining's rmse: 66.0194\tvalid_1's rmse: 81.7979\n",
      "[120]\ttraining's rmse: 49.8413\tvalid_1's rmse: 70.785\n",
      "[150]\ttraining's rmse: 40.3664\tvalid_1's rmse: 65.0129\n",
      "[180]\ttraining's rmse: 34.4885\tvalid_1's rmse: 61.8996\n",
      "[210]\ttraining's rmse: 30.231\tvalid_1's rmse: 60.0566\n",
      "[240]\ttraining's rmse: 26.9362\tvalid_1's rmse: 58.7895\n",
      "[270]\ttraining's rmse: 24.2835\tvalid_1's rmse: 58.0122\n",
      "[300]\ttraining's rmse: 22.0879\tvalid_1's rmse: 57.445\n",
      "[330]\ttraining's rmse: 20.2373\tvalid_1's rmse: 56.998\n",
      "[360]\ttraining's rmse: 18.6286\tvalid_1's rmse: 56.6713\n",
      "[390]\ttraining's rmse: 17.2165\tvalid_1's rmse: 56.3784\n",
      "[420]\ttraining's rmse: 15.9493\tvalid_1's rmse: 56.1715\n",
      "[450]\ttraining's rmse: 14.8072\tvalid_1's rmse: 55.9764\n",
      "[480]\ttraining's rmse: 13.7492\tvalid_1's rmse: 55.7876\n",
      "[510]\ttraining's rmse: 12.7933\tvalid_1's rmse: 55.6759\n",
      "[540]\ttraining's rmse: 11.929\tvalid_1's rmse: 55.5968\n",
      "[570]\ttraining's rmse: 11.1515\tvalid_1's rmse: 55.4929\n",
      "[600]\ttraining's rmse: 10.4308\tvalid_1's rmse: 55.3798\n",
      "[630]\ttraining's rmse: 9.76266\tvalid_1's rmse: 55.2945\n",
      "[660]\ttraining's rmse: 9.15321\tvalid_1's rmse: 55.2265\n",
      "[690]\ttraining's rmse: 8.60633\tvalid_1's rmse: 55.1687\n",
      "[720]\ttraining's rmse: 8.0882\tvalid_1's rmse: 55.1028\n",
      "[750]\ttraining's rmse: 7.60389\tvalid_1's rmse: 55.0604\n",
      "[780]\ttraining's rmse: 7.16681\tvalid_1's rmse: 55.0173\n",
      "[810]\ttraining's rmse: 6.74218\tvalid_1's rmse: 54.9764\n",
      "[840]\ttraining's rmse: 6.35898\tvalid_1's rmse: 54.932\n",
      "[870]\ttraining's rmse: 5.99754\tvalid_1's rmse: 54.9132\n",
      "[900]\ttraining's rmse: 5.65858\tvalid_1's rmse: 54.8742\n",
      "[930]\ttraining's rmse: 5.34161\tvalid_1's rmse: 54.8497\n",
      "[960]\ttraining's rmse: 5.0449\tvalid_1's rmse: 54.8339\n",
      "[990]\ttraining's rmse: 4.77006\tvalid_1's rmse: 54.8166\n",
      "[1020]\ttraining's rmse: 4.51207\tvalid_1's rmse: 54.7866\n",
      "[1050]\ttraining's rmse: 4.26681\tvalid_1's rmse: 54.7718\n",
      "[1080]\ttraining's rmse: 4.04472\tvalid_1's rmse: 54.7587\n",
      "[1110]\ttraining's rmse: 3.8266\tvalid_1's rmse: 54.7471\n",
      "[1140]\ttraining's rmse: 3.62217\tvalid_1's rmse: 54.7304\n",
      "[1170]\ttraining's rmse: 3.43375\tvalid_1's rmse: 54.7167\n",
      "[1200]\ttraining's rmse: 3.25375\tvalid_1's rmse: 54.7019\n",
      "[1230]\ttraining's rmse: 3.08689\tvalid_1's rmse: 54.6869\n",
      "[1260]\ttraining's rmse: 2.92365\tvalid_1's rmse: 54.6725\n",
      "[1290]\ttraining's rmse: 2.77296\tvalid_1's rmse: 54.6618\n",
      "[1320]\ttraining's rmse: 2.63061\tvalid_1's rmse: 54.6478\n",
      "[1350]\ttraining's rmse: 2.49645\tvalid_1's rmse: 54.6421\n",
      "[1380]\ttraining's rmse: 2.36894\tvalid_1's rmse: 54.6337\n",
      "[1410]\ttraining's rmse: 2.24766\tvalid_1's rmse: 54.625\n",
      "[1440]\ttraining's rmse: 2.13905\tvalid_1's rmse: 54.6216\n",
      "[1470]\ttraining's rmse: 2.0305\tvalid_1's rmse: 54.614\n",
      "[1500]\ttraining's rmse: 1.93106\tvalid_1's rmse: 54.6094\n",
      "[1530]\ttraining's rmse: 1.83418\tvalid_1's rmse: 54.6042\n",
      "[1560]\ttraining's rmse: 1.74475\tvalid_1's rmse: 54.5999\n",
      "[1590]\ttraining's rmse: 1.66027\tvalid_1's rmse: 54.5964\n",
      "[1620]\ttraining's rmse: 1.5791\tvalid_1's rmse: 54.5927\n",
      "[1650]\ttraining's rmse: 1.50265\tvalid_1's rmse: 54.5879\n",
      "[1680]\ttraining's rmse: 1.43161\tvalid_1's rmse: 54.5865\n",
      "[1710]\ttraining's rmse: 1.36389\tvalid_1's rmse: 54.583\n",
      "[1740]\ttraining's rmse: 1.29902\tvalid_1's rmse: 54.5789\n",
      "[1770]\ttraining's rmse: 1.23599\tvalid_1's rmse: 54.5761\n",
      "[1800]\ttraining's rmse: 1.17624\tvalid_1's rmse: 54.5746\n",
      "[1830]\ttraining's rmse: 1.12097\tvalid_1's rmse: 54.5709\n",
      "[1860]\ttraining's rmse: 1.06606\tvalid_1's rmse: 54.5678\n",
      "[1890]\ttraining's rmse: 1.01449\tvalid_1's rmse: 54.5652\n",
      "[1920]\ttraining's rmse: 0.96694\tvalid_1's rmse: 54.5638\n",
      "[1950]\ttraining's rmse: 0.921625\tvalid_1's rmse: 54.5626\n",
      "[1980]\ttraining's rmse: 0.878798\tvalid_1's rmse: 54.5608\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's rmse: 0.851929\tvalid_1's rmse: 54.5614\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003406 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 20024\n",
      "[LightGBM] [Info] Number of data points in the train set: 9219, number of used features: 79\n",
      "[LightGBM] [Info] Start training from score 372.870075\n",
      "Training until validation scores don't improve for 125 rounds\n",
      "[30]\ttraining's rmse: 148.68\tvalid_1's rmse: 154.721\n",
      "[60]\ttraining's rmse: 94.8864\tvalid_1's rmse: 107.226\n",
      "[90]\ttraining's rmse: 65.6772\tvalid_1's rmse: 83.9473\n",
      "[120]\ttraining's rmse: 49.8171\tvalid_1's rmse: 72.8337\n",
      "[150]\ttraining's rmse: 40.5936\tvalid_1's rmse: 66.9234\n",
      "[180]\ttraining's rmse: 34.712\tvalid_1's rmse: 63.7115\n",
      "[210]\ttraining's rmse: 30.4675\tvalid_1's rmse: 61.7265\n",
      "[240]\ttraining's rmse: 27.2177\tvalid_1's rmse: 60.291\n",
      "[270]\ttraining's rmse: 24.6531\tvalid_1's rmse: 59.4017\n",
      "[300]\ttraining's rmse: 22.5054\tvalid_1's rmse: 58.8178\n",
      "[330]\ttraining's rmse: 20.6451\tvalid_1's rmse: 58.4162\n",
      "[360]\ttraining's rmse: 19.0456\tvalid_1's rmse: 58.0938\n",
      "[390]\ttraining's rmse: 17.649\tvalid_1's rmse: 57.8092\n",
      "[420]\ttraining's rmse: 16.3704\tvalid_1's rmse: 57.5756\n",
      "[450]\ttraining's rmse: 15.2327\tvalid_1's rmse: 57.3954\n",
      "[480]\ttraining's rmse: 14.1962\tvalid_1's rmse: 57.2311\n",
      "[510]\ttraining's rmse: 13.2445\tvalid_1's rmse: 57.1501\n",
      "[540]\ttraining's rmse: 12.3746\tvalid_1's rmse: 57.0355\n",
      "[570]\ttraining's rmse: 11.6001\tvalid_1's rmse: 56.9265\n",
      "[600]\ttraining's rmse: 10.8853\tvalid_1's rmse: 56.8291\n",
      "[630]\ttraining's rmse: 10.21\tvalid_1's rmse: 56.7447\n",
      "[660]\ttraining's rmse: 9.59733\tvalid_1's rmse: 56.6995\n",
      "[690]\ttraining's rmse: 9.04751\tvalid_1's rmse: 56.6647\n",
      "[720]\ttraining's rmse: 8.52263\tvalid_1's rmse: 56.6398\n",
      "[750]\ttraining's rmse: 8.03832\tvalid_1's rmse: 56.6031\n",
      "[780]\ttraining's rmse: 7.59725\tvalid_1's rmse: 56.5749\n",
      "[810]\ttraining's rmse: 7.17366\tvalid_1's rmse: 56.5465\n",
      "[840]\ttraining's rmse: 6.78148\tvalid_1's rmse: 56.5071\n",
      "[870]\ttraining's rmse: 6.41012\tvalid_1's rmse: 56.4699\n",
      "[900]\ttraining's rmse: 6.0673\tvalid_1's rmse: 56.4386\n",
      "[930]\ttraining's rmse: 5.74608\tvalid_1's rmse: 56.4243\n",
      "[960]\ttraining's rmse: 5.44729\tvalid_1's rmse: 56.4163\n",
      "[990]\ttraining's rmse: 5.15945\tvalid_1's rmse: 56.4078\n",
      "[1020]\ttraining's rmse: 4.88521\tvalid_1's rmse: 56.3902\n",
      "[1050]\ttraining's rmse: 4.63934\tvalid_1's rmse: 56.3654\n",
      "[1080]\ttraining's rmse: 4.40607\tvalid_1's rmse: 56.3619\n",
      "[1110]\ttraining's rmse: 4.18255\tvalid_1's rmse: 56.3452\n",
      "[1140]\ttraining's rmse: 3.97065\tvalid_1's rmse: 56.3335\n",
      "[1170]\ttraining's rmse: 3.76916\tvalid_1's rmse: 56.3108\n",
      "[1200]\ttraining's rmse: 3.58291\tvalid_1's rmse: 56.3031\n",
      "[1230]\ttraining's rmse: 3.40389\tvalid_1's rmse: 56.3022\n",
      "[1260]\ttraining's rmse: 3.23599\tvalid_1's rmse: 56.2888\n",
      "[1290]\ttraining's rmse: 3.08414\tvalid_1's rmse: 56.2796\n",
      "[1320]\ttraining's rmse: 2.92929\tvalid_1's rmse: 56.2652\n",
      "[1350]\ttraining's rmse: 2.78884\tvalid_1's rmse: 56.2616\n",
      "[1380]\ttraining's rmse: 2.64999\tvalid_1's rmse: 56.2583\n",
      "[1410]\ttraining's rmse: 2.52031\tvalid_1's rmse: 56.254\n",
      "[1440]\ttraining's rmse: 2.40149\tvalid_1's rmse: 56.2493\n",
      "[1470]\ttraining's rmse: 2.28778\tvalid_1's rmse: 56.2416\n",
      "[1500]\ttraining's rmse: 2.17959\tvalid_1's rmse: 56.2388\n",
      "[1530]\ttraining's rmse: 2.08204\tvalid_1's rmse: 56.2398\n",
      "[1560]\ttraining's rmse: 1.98441\tvalid_1's rmse: 56.2329\n",
      "[1590]\ttraining's rmse: 1.89399\tvalid_1's rmse: 56.2289\n",
      "[1620]\ttraining's rmse: 1.80146\tvalid_1's rmse: 56.22\n",
      "[1650]\ttraining's rmse: 1.72204\tvalid_1's rmse: 56.2176\n",
      "[1680]\ttraining's rmse: 1.64318\tvalid_1's rmse: 56.2135\n",
      "[1710]\ttraining's rmse: 1.56982\tvalid_1's rmse: 56.2092\n",
      "[1740]\ttraining's rmse: 1.49947\tvalid_1's rmse: 56.2079\n",
      "[1770]\ttraining's rmse: 1.42953\tvalid_1's rmse: 56.2053\n",
      "[1800]\ttraining's rmse: 1.3628\tvalid_1's rmse: 56.2046\n",
      "[1830]\ttraining's rmse: 1.30207\tvalid_1's rmse: 56.2046\n",
      "[1860]\ttraining's rmse: 1.24277\tvalid_1's rmse: 56.2053\n",
      "[1890]\ttraining's rmse: 1.19032\tvalid_1's rmse: 56.2038\n",
      "[1920]\ttraining's rmse: 1.14221\tvalid_1's rmse: 56.2018\n",
      "[1950]\ttraining's rmse: 1.09149\tvalid_1's rmse: 56.2019\n",
      "[1980]\ttraining's rmse: 1.04378\tvalid_1's rmse: 56.1992\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's rmse: 1.01495\tvalid_1's rmse: 56.1967\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002499 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 20024\n",
      "[LightGBM] [Info] Number of data points in the train set: 9219, number of used features: 79\n",
      "[LightGBM] [Info] Start training from score 371.327908\n",
      "Training until validation scores don't improve for 125 rounds\n",
      "[30]\ttraining's rmse: 148.656\tvalid_1's rmse: 151.956\n",
      "[60]\ttraining's rmse: 94.8613\tvalid_1's rmse: 104.475\n",
      "[90]\ttraining's rmse: 65.4676\tvalid_1's rmse: 81.0862\n",
      "[120]\ttraining's rmse: 49.3585\tvalid_1's rmse: 69.9236\n",
      "[150]\ttraining's rmse: 40.0473\tvalid_1's rmse: 64.3782\n",
      "[180]\ttraining's rmse: 34.1746\tvalid_1's rmse: 61.4576\n",
      "[210]\ttraining's rmse: 30.0325\tvalid_1's rmse: 59.6427\n",
      "[240]\ttraining's rmse: 26.8231\tvalid_1's rmse: 58.4685\n",
      "[270]\ttraining's rmse: 24.2408\tvalid_1's rmse: 57.7135\n",
      "[300]\ttraining's rmse: 22.1024\tvalid_1's rmse: 57.181\n",
      "[330]\ttraining's rmse: 20.288\tvalid_1's rmse: 56.7083\n",
      "[360]\ttraining's rmse: 18.6758\tvalid_1's rmse: 56.4312\n",
      "[390]\ttraining's rmse: 17.2878\tvalid_1's rmse: 56.1885\n",
      "[420]\ttraining's rmse: 16.0266\tvalid_1's rmse: 55.9588\n",
      "[450]\ttraining's rmse: 14.8955\tvalid_1's rmse: 55.7901\n",
      "[480]\ttraining's rmse: 13.8743\tvalid_1's rmse: 55.66\n",
      "[510]\ttraining's rmse: 12.9383\tvalid_1's rmse: 55.5342\n",
      "[540]\ttraining's rmse: 12.0861\tvalid_1's rmse: 55.4038\n",
      "[570]\ttraining's rmse: 11.3363\tvalid_1's rmse: 55.3249\n",
      "[600]\ttraining's rmse: 10.6349\tvalid_1's rmse: 55.2791\n",
      "[630]\ttraining's rmse: 9.97676\tvalid_1's rmse: 55.2303\n",
      "[660]\ttraining's rmse: 9.3594\tvalid_1's rmse: 55.172\n",
      "[690]\ttraining's rmse: 8.79966\tvalid_1's rmse: 55.125\n",
      "[720]\ttraining's rmse: 8.28456\tvalid_1's rmse: 55.0835\n",
      "[750]\ttraining's rmse: 7.82127\tvalid_1's rmse: 55.0552\n",
      "[780]\ttraining's rmse: 7.38198\tvalid_1's rmse: 55.0205\n",
      "[810]\ttraining's rmse: 6.95195\tvalid_1's rmse: 54.9864\n",
      "[840]\ttraining's rmse: 6.56114\tvalid_1's rmse: 54.9502\n",
      "[870]\ttraining's rmse: 6.19624\tvalid_1's rmse: 54.9215\n",
      "[900]\ttraining's rmse: 5.85724\tvalid_1's rmse: 54.899\n",
      "[930]\ttraining's rmse: 5.54085\tvalid_1's rmse: 54.876\n",
      "[960]\ttraining's rmse: 5.24535\tvalid_1's rmse: 54.8571\n",
      "[990]\ttraining's rmse: 4.96132\tvalid_1's rmse: 54.8376\n",
      "[1020]\ttraining's rmse: 4.69644\tvalid_1's rmse: 54.8298\n",
      "[1050]\ttraining's rmse: 4.4498\tvalid_1's rmse: 54.8099\n",
      "[1080]\ttraining's rmse: 4.21459\tvalid_1's rmse: 54.799\n",
      "[1110]\ttraining's rmse: 3.99842\tvalid_1's rmse: 54.7913\n",
      "[1140]\ttraining's rmse: 3.78554\tvalid_1's rmse: 54.7791\n",
      "[1170]\ttraining's rmse: 3.58854\tvalid_1's rmse: 54.7701\n",
      "[1200]\ttraining's rmse: 3.40678\tvalid_1's rmse: 54.7695\n",
      "[1230]\ttraining's rmse: 3.22986\tvalid_1's rmse: 54.7594\n",
      "[1260]\ttraining's rmse: 3.06379\tvalid_1's rmse: 54.7524\n",
      "[1290]\ttraining's rmse: 2.91136\tvalid_1's rmse: 54.7456\n",
      "[1320]\ttraining's rmse: 2.765\tvalid_1's rmse: 54.7378\n",
      "[1350]\ttraining's rmse: 2.62639\tvalid_1's rmse: 54.7343\n",
      "[1380]\ttraining's rmse: 2.49893\tvalid_1's rmse: 54.728\n",
      "[1410]\ttraining's rmse: 2.37326\tvalid_1's rmse: 54.7286\n",
      "[1440]\ttraining's rmse: 2.25702\tvalid_1's rmse: 54.7234\n",
      "[1470]\ttraining's rmse: 2.14726\tvalid_1's rmse: 54.7184\n",
      "[1500]\ttraining's rmse: 2.0422\tvalid_1's rmse: 54.7168\n",
      "[1530]\ttraining's rmse: 1.94595\tvalid_1's rmse: 54.7138\n",
      "[1560]\ttraining's rmse: 1.84961\tvalid_1's rmse: 54.7099\n",
      "[1590]\ttraining's rmse: 1.76048\tvalid_1's rmse: 54.7094\n",
      "[1620]\ttraining's rmse: 1.67637\tvalid_1's rmse: 54.7087\n",
      "[1650]\ttraining's rmse: 1.59799\tvalid_1's rmse: 54.7053\n",
      "[1680]\ttraining's rmse: 1.52004\tvalid_1's rmse: 54.7035\n",
      "[1710]\ttraining's rmse: 1.44735\tvalid_1's rmse: 54.7009\n",
      "[1740]\ttraining's rmse: 1.37945\tvalid_1's rmse: 54.7018\n",
      "[1770]\ttraining's rmse: 1.31492\tvalid_1's rmse: 54.6999\n",
      "[1800]\ttraining's rmse: 1.2522\tvalid_1's rmse: 54.6947\n",
      "[1830]\ttraining's rmse: 1.19451\tvalid_1's rmse: 54.6922\n",
      "[1860]\ttraining's rmse: 1.13812\tvalid_1's rmse: 54.6907\n",
      "[1890]\ttraining's rmse: 1.08631\tvalid_1's rmse: 54.6903\n",
      "[1920]\ttraining's rmse: 1.03775\tvalid_1's rmse: 54.6894\n",
      "[1950]\ttraining's rmse: 0.988969\tvalid_1's rmse: 54.6876\n",
      "[1980]\ttraining's rmse: 0.943545\tvalid_1's rmse: 54.6858\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's rmse: 0.914751\tvalid_1's rmse: 54.6855\n",
      "38\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002371 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 20024\n",
      "[LightGBM] [Info] Number of data points in the train set: 9219, number of used features: 79\n",
      "[LightGBM] [Info] Start training from score 364.805854\n",
      "Training until validation scores don't improve for 125 rounds\n",
      "[30]\ttraining's rmse: 141.438\tvalid_1's rmse: 144.953\n",
      "[60]\ttraining's rmse: 90.0012\tvalid_1's rmse: 96.9749\n",
      "[90]\ttraining's rmse: 62.0787\tvalid_1's rmse: 72.9744\n",
      "[120]\ttraining's rmse: 46.6536\tvalid_1's rmse: 61.3851\n",
      "[150]\ttraining's rmse: 37.874\tvalid_1's rmse: 56.0042\n",
      "[180]\ttraining's rmse: 32.4328\tvalid_1's rmse: 53.2003\n",
      "[210]\ttraining's rmse: 28.5391\tvalid_1's rmse: 51.4637\n",
      "[240]\ttraining's rmse: 25.5055\tvalid_1's rmse: 50.1977\n",
      "[270]\ttraining's rmse: 23.04\tvalid_1's rmse: 49.4332\n",
      "[300]\ttraining's rmse: 21.0271\tvalid_1's rmse: 48.7962\n",
      "[330]\ttraining's rmse: 19.3385\tvalid_1's rmse: 48.3577\n",
      "[360]\ttraining's rmse: 17.837\tvalid_1's rmse: 48.0566\n",
      "[390]\ttraining's rmse: 16.5134\tvalid_1's rmse: 47.8777\n",
      "[420]\ttraining's rmse: 15.3418\tvalid_1's rmse: 47.7096\n",
      "[450]\ttraining's rmse: 14.2698\tvalid_1's rmse: 47.5265\n",
      "[480]\ttraining's rmse: 13.3057\tvalid_1's rmse: 47.4061\n",
      "[510]\ttraining's rmse: 12.4198\tvalid_1's rmse: 47.3067\n",
      "[540]\ttraining's rmse: 11.6036\tvalid_1's rmse: 47.2348\n",
      "[570]\ttraining's rmse: 10.8601\tvalid_1's rmse: 47.1856\n",
      "[600]\ttraining's rmse: 10.1894\tvalid_1's rmse: 47.1051\n",
      "[630]\ttraining's rmse: 9.56878\tvalid_1's rmse: 47.0466\n",
      "[660]\ttraining's rmse: 8.98937\tvalid_1's rmse: 46.9915\n",
      "[690]\ttraining's rmse: 8.46302\tvalid_1's rmse: 46.9581\n",
      "[720]\ttraining's rmse: 7.97204\tvalid_1's rmse: 46.9373\n",
      "[750]\ttraining's rmse: 7.51153\tvalid_1's rmse: 46.9026\n",
      "[780]\ttraining's rmse: 7.07801\tvalid_1's rmse: 46.857\n",
      "[810]\ttraining's rmse: 6.66615\tvalid_1's rmse: 46.8381\n",
      "[840]\ttraining's rmse: 6.30134\tvalid_1's rmse: 46.8045\n",
      "[870]\ttraining's rmse: 5.95863\tvalid_1's rmse: 46.771\n",
      "[900]\ttraining's rmse: 5.61905\tvalid_1's rmse: 46.7475\n",
      "[930]\ttraining's rmse: 5.31977\tvalid_1's rmse: 46.7401\n",
      "[960]\ttraining's rmse: 5.04273\tvalid_1's rmse: 46.7217\n",
      "[990]\ttraining's rmse: 4.77608\tvalid_1's rmse: 46.717\n",
      "[1020]\ttraining's rmse: 4.52045\tvalid_1's rmse: 46.7137\n",
      "[1050]\ttraining's rmse: 4.27069\tvalid_1's rmse: 46.7008\n",
      "[1080]\ttraining's rmse: 4.05557\tvalid_1's rmse: 46.684\n",
      "[1110]\ttraining's rmse: 3.84259\tvalid_1's rmse: 46.669\n",
      "[1140]\ttraining's rmse: 3.64409\tvalid_1's rmse: 46.6613\n",
      "[1170]\ttraining's rmse: 3.45552\tvalid_1's rmse: 46.6567\n",
      "[1200]\ttraining's rmse: 3.28173\tvalid_1's rmse: 46.6449\n",
      "[1230]\ttraining's rmse: 3.11364\tvalid_1's rmse: 46.6381\n",
      "[1260]\ttraining's rmse: 2.95192\tvalid_1's rmse: 46.628\n",
      "[1290]\ttraining's rmse: 2.80213\tvalid_1's rmse: 46.6148\n",
      "[1320]\ttraining's rmse: 2.6629\tvalid_1's rmse: 46.6073\n",
      "[1350]\ttraining's rmse: 2.5328\tvalid_1's rmse: 46.6048\n",
      "[1380]\ttraining's rmse: 2.41083\tvalid_1's rmse: 46.6012\n",
      "[1410]\ttraining's rmse: 2.29117\tvalid_1's rmse: 46.6005\n",
      "[1440]\ttraining's rmse: 2.18059\tvalid_1's rmse: 46.5929\n",
      "[1470]\ttraining's rmse: 2.07679\tvalid_1's rmse: 46.5842\n",
      "[1500]\ttraining's rmse: 1.9763\tvalid_1's rmse: 46.5782\n",
      "[1530]\ttraining's rmse: 1.87881\tvalid_1's rmse: 46.5756\n",
      "[1560]\ttraining's rmse: 1.78779\tvalid_1's rmse: 46.5738\n",
      "[1590]\ttraining's rmse: 1.70523\tvalid_1's rmse: 46.5738\n",
      "[1620]\ttraining's rmse: 1.62474\tvalid_1's rmse: 46.5694\n",
      "[1650]\ttraining's rmse: 1.54788\tvalid_1's rmse: 46.5644\n",
      "[1680]\ttraining's rmse: 1.47604\tvalid_1's rmse: 46.5626\n",
      "[1710]\ttraining's rmse: 1.40924\tvalid_1's rmse: 46.5626\n",
      "[1740]\ttraining's rmse: 1.34456\tvalid_1's rmse: 46.5624\n",
      "[1770]\ttraining's rmse: 1.28232\tvalid_1's rmse: 46.5617\n",
      "[1800]\ttraining's rmse: 1.22361\tvalid_1's rmse: 46.559\n",
      "[1830]\ttraining's rmse: 1.16621\tvalid_1's rmse: 46.5591\n",
      "[1860]\ttraining's rmse: 1.11408\tvalid_1's rmse: 46.5584\n",
      "[1890]\ttraining's rmse: 1.06511\tvalid_1's rmse: 46.556\n",
      "[1920]\ttraining's rmse: 1.01673\tvalid_1's rmse: 46.5555\n",
      "[1950]\ttraining's rmse: 0.971301\tvalid_1's rmse: 46.5532\n",
      "[1980]\ttraining's rmse: 0.929242\tvalid_1's rmse: 46.5516\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's rmse: 0.902303\tvalid_1's rmse: 46.5509\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003295 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 20024\n",
      "[LightGBM] [Info] Number of data points in the train set: 9219, number of used features: 79\n",
      "[LightGBM] [Info] Start training from score 367.983441\n",
      "Training until validation scores don't improve for 125 rounds\n",
      "[30]\ttraining's rmse: 148.4\tvalid_1's rmse: 153.051\n",
      "[60]\ttraining's rmse: 95.4039\tvalid_1's rmse: 103.789\n",
      "[90]\ttraining's rmse: 66.3306\tvalid_1's rmse: 78.3431\n",
      "[120]\ttraining's rmse: 50.206\tvalid_1's rmse: 65.8937\n",
      "[150]\ttraining's rmse: 40.7768\tvalid_1's rmse: 59.6362\n",
      "[180]\ttraining's rmse: 34.8063\tvalid_1's rmse: 56.3348\n",
      "[210]\ttraining's rmse: 30.5867\tvalid_1's rmse: 54.3915\n",
      "[240]\ttraining's rmse: 27.4009\tvalid_1's rmse: 53.1668\n",
      "[270]\ttraining's rmse: 24.7988\tvalid_1's rmse: 52.2951\n",
      "[300]\ttraining's rmse: 22.6393\tvalid_1's rmse: 51.7273\n",
      "[330]\ttraining's rmse: 20.7942\tvalid_1's rmse: 51.2934\n",
      "[360]\ttraining's rmse: 19.1464\tvalid_1's rmse: 51.0211\n",
      "[390]\ttraining's rmse: 17.6969\tvalid_1's rmse: 50.807\n",
      "[420]\ttraining's rmse: 16.4279\tvalid_1's rmse: 50.6047\n",
      "[450]\ttraining's rmse: 15.266\tvalid_1's rmse: 50.4685\n",
      "[480]\ttraining's rmse: 14.2269\tvalid_1's rmse: 50.3688\n",
      "[510]\ttraining's rmse: 13.2586\tvalid_1's rmse: 50.2649\n",
      "[540]\ttraining's rmse: 12.4106\tvalid_1's rmse: 50.2131\n",
      "[570]\ttraining's rmse: 11.5978\tvalid_1's rmse: 50.1189\n",
      "[600]\ttraining's rmse: 10.8567\tvalid_1's rmse: 50.0434\n",
      "[630]\ttraining's rmse: 10.171\tvalid_1's rmse: 50.0009\n",
      "[660]\ttraining's rmse: 9.53817\tvalid_1's rmse: 49.9441\n",
      "[690]\ttraining's rmse: 8.96643\tvalid_1's rmse: 49.8904\n",
      "[720]\ttraining's rmse: 8.43385\tvalid_1's rmse: 49.8573\n",
      "[750]\ttraining's rmse: 7.94516\tvalid_1's rmse: 49.8256\n",
      "[780]\ttraining's rmse: 7.48801\tvalid_1's rmse: 49.794\n",
      "[810]\ttraining's rmse: 7.05244\tvalid_1's rmse: 49.7472\n",
      "[840]\ttraining's rmse: 6.65937\tvalid_1's rmse: 49.7324\n",
      "[870]\ttraining's rmse: 6.28142\tvalid_1's rmse: 49.7196\n",
      "[900]\ttraining's rmse: 5.93206\tvalid_1's rmse: 49.7004\n",
      "[930]\ttraining's rmse: 5.60599\tvalid_1's rmse: 49.6803\n",
      "[960]\ttraining's rmse: 5.29406\tvalid_1's rmse: 49.6644\n",
      "[990]\ttraining's rmse: 5.0055\tvalid_1's rmse: 49.6478\n",
      "[1020]\ttraining's rmse: 4.73025\tvalid_1's rmse: 49.6433\n",
      "[1050]\ttraining's rmse: 4.46927\tvalid_1's rmse: 49.635\n",
      "[1080]\ttraining's rmse: 4.23168\tvalid_1's rmse: 49.6206\n",
      "[1110]\ttraining's rmse: 4.00561\tvalid_1's rmse: 49.6089\n",
      "[1140]\ttraining's rmse: 3.79461\tvalid_1's rmse: 49.5978\n",
      "[1170]\ttraining's rmse: 3.59126\tvalid_1's rmse: 49.5852\n",
      "[1200]\ttraining's rmse: 3.40016\tvalid_1's rmse: 49.5761\n",
      "[1230]\ttraining's rmse: 3.2215\tvalid_1's rmse: 49.5695\n",
      "[1260]\ttraining's rmse: 3.05393\tvalid_1's rmse: 49.5646\n",
      "[1290]\ttraining's rmse: 2.89848\tvalid_1's rmse: 49.5583\n",
      "[1320]\ttraining's rmse: 2.75138\tvalid_1's rmse: 49.5492\n",
      "[1350]\ttraining's rmse: 2.60994\tvalid_1's rmse: 49.5402\n",
      "[1380]\ttraining's rmse: 2.47389\tvalid_1's rmse: 49.538\n",
      "[1410]\ttraining's rmse: 2.34776\tvalid_1's rmse: 49.5335\n",
      "[1440]\ttraining's rmse: 2.23036\tvalid_1's rmse: 49.5298\n",
      "[1470]\ttraining's rmse: 2.12029\tvalid_1's rmse: 49.5236\n",
      "[1500]\ttraining's rmse: 2.01642\tvalid_1's rmse: 49.5205\n",
      "[1530]\ttraining's rmse: 1.91728\tvalid_1's rmse: 49.5167\n",
      "[1560]\ttraining's rmse: 1.82319\tvalid_1's rmse: 49.5162\n",
      "[1590]\ttraining's rmse: 1.73358\tvalid_1's rmse: 49.5118\n",
      "[1620]\ttraining's rmse: 1.64968\tvalid_1's rmse: 49.5097\n",
      "[1650]\ttraining's rmse: 1.57206\tvalid_1's rmse: 49.51\n",
      "[1680]\ttraining's rmse: 1.49439\tvalid_1's rmse: 49.5096\n",
      "[1710]\ttraining's rmse: 1.42166\tvalid_1's rmse: 49.5096\n",
      "[1740]\ttraining's rmse: 1.35318\tvalid_1's rmse: 49.5073\n",
      "[1770]\ttraining's rmse: 1.28875\tvalid_1's rmse: 49.5053\n",
      "[1800]\ttraining's rmse: 1.2283\tvalid_1's rmse: 49.5035\n",
      "[1830]\ttraining's rmse: 1.16963\tvalid_1's rmse: 49.5034\n",
      "[1860]\ttraining's rmse: 1.11395\tvalid_1's rmse: 49.5011\n",
      "[1890]\ttraining's rmse: 1.06182\tvalid_1's rmse: 49.4985\n",
      "[1920]\ttraining's rmse: 1.01139\tvalid_1's rmse: 49.4961\n",
      "[1950]\ttraining's rmse: 0.964666\tvalid_1's rmse: 49.4938\n",
      "[1980]\ttraining's rmse: 0.919203\tvalid_1's rmse: 49.4922\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's rmse: 0.889059\tvalid_1's rmse: 49.4928\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002992 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 20024\n",
      "[LightGBM] [Info] Number of data points in the train set: 9219, number of used features: 79\n",
      "[LightGBM] [Info] Start training from score 369.610226\n",
      "Training until validation scores don't improve for 125 rounds\n",
      "[30]\ttraining's rmse: 149.145\tvalid_1's rmse: 155.777\n",
      "[60]\ttraining's rmse: 96.0031\tvalid_1's rmse: 109.157\n",
      "[90]\ttraining's rmse: 66.7086\tvalid_1's rmse: 85.6502\n",
      "[120]\ttraining's rmse: 50.3031\tvalid_1's rmse: 73.7595\n",
      "[150]\ttraining's rmse: 40.8811\tvalid_1's rmse: 67.7339\n",
      "[180]\ttraining's rmse: 34.8218\tvalid_1's rmse: 64.3947\n",
      "[210]\ttraining's rmse: 30.5435\tvalid_1's rmse: 62.3238\n",
      "[240]\ttraining's rmse: 27.3114\tvalid_1's rmse: 60.9501\n",
      "[270]\ttraining's rmse: 24.6813\tvalid_1's rmse: 59.9436\n",
      "[300]\ttraining's rmse: 22.5084\tvalid_1's rmse: 59.2797\n",
      "[330]\ttraining's rmse: 20.6848\tvalid_1's rmse: 58.7832\n",
      "[360]\ttraining's rmse: 19.0651\tvalid_1's rmse: 58.4114\n",
      "[390]\ttraining's rmse: 17.6168\tvalid_1's rmse: 58.1257\n",
      "[420]\ttraining's rmse: 16.3247\tvalid_1's rmse: 57.8541\n",
      "[450]\ttraining's rmse: 15.1525\tvalid_1's rmse: 57.6876\n",
      "[480]\ttraining's rmse: 14.104\tvalid_1's rmse: 57.5481\n",
      "[510]\ttraining's rmse: 13.1531\tvalid_1's rmse: 57.4303\n",
      "[540]\ttraining's rmse: 12.2617\tvalid_1's rmse: 57.328\n",
      "[570]\ttraining's rmse: 11.4718\tvalid_1's rmse: 57.2689\n",
      "[600]\ttraining's rmse: 10.7528\tvalid_1's rmse: 57.2102\n",
      "[630]\ttraining's rmse: 10.0822\tvalid_1's rmse: 57.1682\n",
      "[660]\ttraining's rmse: 9.45878\tvalid_1's rmse: 57.1117\n",
      "[690]\ttraining's rmse: 8.87488\tvalid_1's rmse: 57.0797\n",
      "[720]\ttraining's rmse: 8.34042\tvalid_1's rmse: 57.0211\n",
      "[750]\ttraining's rmse: 7.84015\tvalid_1's rmse: 57.0056\n",
      "[780]\ttraining's rmse: 7.38552\tvalid_1's rmse: 56.9598\n",
      "[810]\ttraining's rmse: 6.95025\tvalid_1's rmse: 56.9168\n",
      "[840]\ttraining's rmse: 6.55153\tvalid_1's rmse: 56.9125\n",
      "[870]\ttraining's rmse: 6.17712\tvalid_1's rmse: 56.8929\n",
      "[900]\ttraining's rmse: 5.83455\tvalid_1's rmse: 56.8562\n",
      "[930]\ttraining's rmse: 5.51106\tvalid_1's rmse: 56.8467\n",
      "[960]\ttraining's rmse: 5.20979\tvalid_1's rmse: 56.8256\n",
      "[990]\ttraining's rmse: 4.92601\tvalid_1's rmse: 56.805\n",
      "[1020]\ttraining's rmse: 4.65493\tvalid_1's rmse: 56.7828\n",
      "[1050]\ttraining's rmse: 4.40649\tvalid_1's rmse: 56.7756\n",
      "[1080]\ttraining's rmse: 4.17349\tvalid_1's rmse: 56.7533\n",
      "[1110]\ttraining's rmse: 3.95572\tvalid_1's rmse: 56.7557\n",
      "[1140]\ttraining's rmse: 3.74923\tvalid_1's rmse: 56.7518\n",
      "[1170]\ttraining's rmse: 3.54788\tvalid_1's rmse: 56.7536\n",
      "[1200]\ttraining's rmse: 3.36528\tvalid_1's rmse: 56.7487\n",
      "[1230]\ttraining's rmse: 3.19065\tvalid_1's rmse: 56.7485\n",
      "[1260]\ttraining's rmse: 3.02816\tvalid_1's rmse: 56.7378\n",
      "[1290]\ttraining's rmse: 2.87293\tvalid_1's rmse: 56.7348\n",
      "[1320]\ttraining's rmse: 2.72546\tvalid_1's rmse: 56.734\n",
      "[1350]\ttraining's rmse: 2.58861\tvalid_1's rmse: 56.7297\n",
      "[1380]\ttraining's rmse: 2.45748\tvalid_1's rmse: 56.7317\n",
      "[1410]\ttraining's rmse: 2.33295\tvalid_1's rmse: 56.7262\n",
      "[1440]\ttraining's rmse: 2.2183\tvalid_1's rmse: 56.7231\n",
      "[1470]\ttraining's rmse: 2.11165\tvalid_1's rmse: 56.7205\n",
      "[1500]\ttraining's rmse: 2.00902\tvalid_1's rmse: 56.7166\n",
      "[1530]\ttraining's rmse: 1.91086\tvalid_1's rmse: 56.712\n",
      "[1560]\ttraining's rmse: 1.81919\tvalid_1's rmse: 56.7097\n",
      "[1590]\ttraining's rmse: 1.72933\tvalid_1's rmse: 56.7089\n",
      "[1620]\ttraining's rmse: 1.64623\tvalid_1's rmse: 56.7069\n",
      "[1650]\ttraining's rmse: 1.56708\tvalid_1's rmse: 56.7073\n",
      "[1680]\ttraining's rmse: 1.49242\tvalid_1's rmse: 56.7027\n",
      "[1710]\ttraining's rmse: 1.42569\tvalid_1's rmse: 56.6963\n",
      "[1740]\ttraining's rmse: 1.35849\tvalid_1's rmse: 56.6975\n",
      "[1770]\ttraining's rmse: 1.29416\tvalid_1's rmse: 56.6959\n",
      "[1800]\ttraining's rmse: 1.23387\tvalid_1's rmse: 56.6957\n",
      "[1830]\ttraining's rmse: 1.17752\tvalid_1's rmse: 56.6976\n",
      "[1860]\ttraining's rmse: 1.12302\tvalid_1's rmse: 56.6991\n",
      "[1890]\ttraining's rmse: 1.07029\tvalid_1's rmse: 56.6975\n",
      "Early stopping, best iteration is:\n",
      "[1778]\ttraining's rmse: 1.27773\tvalid_1's rmse: 56.6949\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002316 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 20024\n",
      "[LightGBM] [Info] Number of data points in the train set: 9219, number of used features: 79\n",
      "[LightGBM] [Info] Start training from score 370.036594\n",
      "Training until validation scores don't improve for 125 rounds\n",
      "[30]\ttraining's rmse: 149.781\tvalid_1's rmse: 156.065\n",
      "[60]\ttraining's rmse: 96.5786\tvalid_1's rmse: 107.991\n",
      "[90]\ttraining's rmse: 67.488\tvalid_1's rmse: 84.5344\n",
      "[120]\ttraining's rmse: 51.1944\tvalid_1's rmse: 72.9907\n",
      "[150]\ttraining's rmse: 41.7225\tvalid_1's rmse: 67.4202\n",
      "[180]\ttraining's rmse: 35.5703\tvalid_1's rmse: 64.4083\n",
      "[210]\ttraining's rmse: 31.1164\tvalid_1's rmse: 62.4916\n",
      "[240]\ttraining's rmse: 27.6876\tvalid_1's rmse: 61.2339\n",
      "[270]\ttraining's rmse: 24.9803\tvalid_1's rmse: 60.4276\n",
      "[300]\ttraining's rmse: 22.7397\tvalid_1's rmse: 59.8027\n",
      "[330]\ttraining's rmse: 20.8691\tvalid_1's rmse: 59.4048\n",
      "[360]\ttraining's rmse: 19.2231\tvalid_1's rmse: 59.0691\n",
      "[390]\ttraining's rmse: 17.7891\tvalid_1's rmse: 58.7949\n",
      "[420]\ttraining's rmse: 16.4758\tvalid_1's rmse: 58.543\n",
      "[450]\ttraining's rmse: 15.3028\tvalid_1's rmse: 58.3754\n",
      "[480]\ttraining's rmse: 14.2552\tvalid_1's rmse: 58.2187\n",
      "[510]\ttraining's rmse: 13.2991\tvalid_1's rmse: 58.0786\n",
      "[540]\ttraining's rmse: 12.4198\tvalid_1's rmse: 58.0206\n",
      "[570]\ttraining's rmse: 11.6371\tvalid_1's rmse: 57.9577\n",
      "[600]\ttraining's rmse: 10.9125\tvalid_1's rmse: 57.8986\n",
      "[630]\ttraining's rmse: 10.2466\tvalid_1's rmse: 57.8314\n",
      "[660]\ttraining's rmse: 9.62126\tvalid_1's rmse: 57.7703\n",
      "[690]\ttraining's rmse: 9.04169\tvalid_1's rmse: 57.7203\n",
      "[720]\ttraining's rmse: 8.52318\tvalid_1's rmse: 57.6516\n",
      "[750]\ttraining's rmse: 8.02597\tvalid_1's rmse: 57.6154\n",
      "[780]\ttraining's rmse: 7.5801\tvalid_1's rmse: 57.5834\n",
      "[810]\ttraining's rmse: 7.15144\tvalid_1's rmse: 57.5639\n",
      "[840]\ttraining's rmse: 6.7593\tvalid_1's rmse: 57.5535\n",
      "[870]\ttraining's rmse: 6.38189\tvalid_1's rmse: 57.5361\n",
      "[900]\ttraining's rmse: 6.0472\tvalid_1's rmse: 57.5179\n",
      "[930]\ttraining's rmse: 5.7267\tvalid_1's rmse: 57.4917\n",
      "[960]\ttraining's rmse: 5.41773\tvalid_1's rmse: 57.4675\n",
      "[990]\ttraining's rmse: 5.13263\tvalid_1's rmse: 57.4555\n",
      "[1020]\ttraining's rmse: 4.86901\tvalid_1's rmse: 57.4466\n",
      "[1050]\ttraining's rmse: 4.61603\tvalid_1's rmse: 57.4365\n",
      "[1080]\ttraining's rmse: 4.38012\tvalid_1's rmse: 57.4312\n",
      "[1110]\ttraining's rmse: 4.16403\tvalid_1's rmse: 57.419\n",
      "[1140]\ttraining's rmse: 3.95179\tvalid_1's rmse: 57.4078\n",
      "[1170]\ttraining's rmse: 3.7557\tvalid_1's rmse: 57.3954\n",
      "[1200]\ttraining's rmse: 3.57153\tvalid_1's rmse: 57.3854\n",
      "[1230]\ttraining's rmse: 3.39374\tvalid_1's rmse: 57.3818\n",
      "[1260]\ttraining's rmse: 3.2265\tvalid_1's rmse: 57.3733\n",
      "[1290]\ttraining's rmse: 3.07695\tvalid_1's rmse: 57.3688\n",
      "[1320]\ttraining's rmse: 2.93323\tvalid_1's rmse: 57.3609\n",
      "[1350]\ttraining's rmse: 2.79066\tvalid_1's rmse: 57.3535\n",
      "[1380]\ttraining's rmse: 2.66249\tvalid_1's rmse: 57.3453\n",
      "[1410]\ttraining's rmse: 2.54137\tvalid_1's rmse: 57.3443\n",
      "[1440]\ttraining's rmse: 2.429\tvalid_1's rmse: 57.3405\n",
      "[1470]\ttraining's rmse: 2.31859\tvalid_1's rmse: 57.3318\n",
      "[1500]\ttraining's rmse: 2.21321\tvalid_1's rmse: 57.3282\n",
      "[1530]\ttraining's rmse: 2.11124\tvalid_1's rmse: 57.3245\n",
      "[1560]\ttraining's rmse: 2.0144\tvalid_1's rmse: 57.3204\n",
      "[1590]\ttraining's rmse: 1.92175\tvalid_1's rmse: 57.3175\n",
      "[1620]\ttraining's rmse: 1.83879\tvalid_1's rmse: 57.315\n",
      "[1650]\ttraining's rmse: 1.75677\tvalid_1's rmse: 57.3111\n",
      "[1680]\ttraining's rmse: 1.67759\tvalid_1's rmse: 57.3094\n",
      "[1710]\ttraining's rmse: 1.60531\tvalid_1's rmse: 57.3118\n",
      "[1740]\ttraining's rmse: 1.53853\tvalid_1's rmse: 57.3114\n",
      "[1770]\ttraining's rmse: 1.47453\tvalid_1's rmse: 57.3082\n",
      "[1800]\ttraining's rmse: 1.41105\tvalid_1's rmse: 57.3061\n",
      "[1830]\ttraining's rmse: 1.35334\tvalid_1's rmse: 57.3044\n",
      "[1860]\ttraining's rmse: 1.29787\tvalid_1's rmse: 57.3022\n",
      "[1890]\ttraining's rmse: 1.24512\tvalid_1's rmse: 57.3001\n",
      "[1920]\ttraining's rmse: 1.19502\tvalid_1's rmse: 57.3008\n",
      "[1950]\ttraining's rmse: 1.14417\tvalid_1's rmse: 57.2997\n",
      "[1980]\ttraining's rmse: 1.09684\tvalid_1's rmse: 57.3002\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's rmse: 1.06746\tvalid_1's rmse: 57.3011\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002457 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 20024\n",
      "[LightGBM] [Info] Number of data points in the train set: 9219, number of used features: 79\n",
      "[LightGBM] [Info] Start training from score 370.719177\n",
      "Training until validation scores don't improve for 125 rounds\n",
      "[30]\ttraining's rmse: 148.537\tvalid_1's rmse: 152.324\n",
      "[60]\ttraining's rmse: 95.5111\tvalid_1's rmse: 103.382\n",
      "[90]\ttraining's rmse: 66.3653\tvalid_1's rmse: 78.3016\n",
      "[120]\ttraining's rmse: 50.3027\tvalid_1's rmse: 65.9549\n",
      "[150]\ttraining's rmse: 40.9376\tvalid_1's rmse: 59.7101\n",
      "[180]\ttraining's rmse: 35.0717\tvalid_1's rmse: 56.3049\n",
      "[210]\ttraining's rmse: 30.8385\tvalid_1's rmse: 54.3086\n",
      "[240]\ttraining's rmse: 27.4897\tvalid_1's rmse: 52.9691\n",
      "[270]\ttraining's rmse: 24.8037\tvalid_1's rmse: 52.1458\n",
      "[300]\ttraining's rmse: 22.5726\tvalid_1's rmse: 51.5609\n",
      "[330]\ttraining's rmse: 20.6899\tvalid_1's rmse: 51.176\n",
      "[360]\ttraining's rmse: 19.1134\tvalid_1's rmse: 50.9007\n",
      "[390]\ttraining's rmse: 17.6506\tvalid_1's rmse: 50.6957\n",
      "[420]\ttraining's rmse: 16.3541\tvalid_1's rmse: 50.504\n",
      "[450]\ttraining's rmse: 15.1888\tvalid_1's rmse: 50.3341\n",
      "[480]\ttraining's rmse: 14.1722\tvalid_1's rmse: 50.2088\n",
      "[510]\ttraining's rmse: 13.2232\tvalid_1's rmse: 50.0821\n",
      "[540]\ttraining's rmse: 12.3242\tvalid_1's rmse: 49.9404\n",
      "[570]\ttraining's rmse: 11.5229\tvalid_1's rmse: 49.8489\n",
      "[600]\ttraining's rmse: 10.8009\tvalid_1's rmse: 49.7805\n",
      "[630]\ttraining's rmse: 10.1396\tvalid_1's rmse: 49.7231\n",
      "[660]\ttraining's rmse: 9.52521\tvalid_1's rmse: 49.6591\n",
      "[690]\ttraining's rmse: 8.96989\tvalid_1's rmse: 49.6163\n",
      "[720]\ttraining's rmse: 8.44001\tvalid_1's rmse: 49.584\n",
      "[750]\ttraining's rmse: 7.95223\tvalid_1's rmse: 49.5456\n",
      "[780]\ttraining's rmse: 7.50064\tvalid_1's rmse: 49.5184\n",
      "[810]\ttraining's rmse: 7.07205\tvalid_1's rmse: 49.4974\n",
      "[840]\ttraining's rmse: 6.6861\tvalid_1's rmse: 49.4601\n",
      "[870]\ttraining's rmse: 6.32935\tvalid_1's rmse: 49.4357\n",
      "[900]\ttraining's rmse: 5.99103\tvalid_1's rmse: 49.415\n",
      "[930]\ttraining's rmse: 5.66892\tvalid_1's rmse: 49.3911\n",
      "[960]\ttraining's rmse: 5.36527\tvalid_1's rmse: 49.3799\n",
      "[990]\ttraining's rmse: 5.09235\tvalid_1's rmse: 49.3572\n",
      "[1020]\ttraining's rmse: 4.83265\tvalid_1's rmse: 49.3421\n",
      "[1050]\ttraining's rmse: 4.58232\tvalid_1's rmse: 49.3281\n",
      "[1080]\ttraining's rmse: 4.35164\tvalid_1's rmse: 49.3124\n",
      "[1110]\ttraining's rmse: 4.13552\tvalid_1's rmse: 49.3009\n",
      "[1140]\ttraining's rmse: 3.92613\tvalid_1's rmse: 49.2977\n",
      "[1170]\ttraining's rmse: 3.73368\tvalid_1's rmse: 49.294\n",
      "[1200]\ttraining's rmse: 3.54803\tvalid_1's rmse: 49.282\n",
      "[1230]\ttraining's rmse: 3.37518\tvalid_1's rmse: 49.2747\n",
      "[1260]\ttraining's rmse: 3.20716\tvalid_1's rmse: 49.2651\n",
      "[1290]\ttraining's rmse: 3.05654\tvalid_1's rmse: 49.2536\n",
      "[1320]\ttraining's rmse: 2.9064\tvalid_1's rmse: 49.2553\n",
      "[1350]\ttraining's rmse: 2.76778\tvalid_1's rmse: 49.2491\n",
      "[1380]\ttraining's rmse: 2.64022\tvalid_1's rmse: 49.2457\n",
      "[1410]\ttraining's rmse: 2.5164\tvalid_1's rmse: 49.2369\n",
      "[1440]\ttraining's rmse: 2.3995\tvalid_1's rmse: 49.2321\n",
      "[1470]\ttraining's rmse: 2.28817\tvalid_1's rmse: 49.2316\n",
      "[1500]\ttraining's rmse: 2.18524\tvalid_1's rmse: 49.2293\n",
      "[1530]\ttraining's rmse: 2.08649\tvalid_1's rmse: 49.2264\n",
      "[1560]\ttraining's rmse: 1.99102\tvalid_1's rmse: 49.2249\n",
      "[1590]\ttraining's rmse: 1.9017\tvalid_1's rmse: 49.2235\n",
      "[1620]\ttraining's rmse: 1.81619\tvalid_1's rmse: 49.2223\n",
      "[1650]\ttraining's rmse: 1.7309\tvalid_1's rmse: 49.2203\n",
      "[1680]\ttraining's rmse: 1.65432\tvalid_1's rmse: 49.2183\n",
      "[1710]\ttraining's rmse: 1.58078\tvalid_1's rmse: 49.2169\n",
      "[1740]\ttraining's rmse: 1.51214\tvalid_1's rmse: 49.2177\n",
      "[1770]\ttraining's rmse: 1.44537\tvalid_1's rmse: 49.2144\n",
      "[1800]\ttraining's rmse: 1.38304\tvalid_1's rmse: 49.2136\n",
      "[1830]\ttraining's rmse: 1.32135\tvalid_1's rmse: 49.2147\n",
      "[1860]\ttraining's rmse: 1.26372\tvalid_1's rmse: 49.2135\n",
      "[1890]\ttraining's rmse: 1.21307\tvalid_1's rmse: 49.2133\n",
      "[1920]\ttraining's rmse: 1.16391\tvalid_1's rmse: 49.2124\n",
      "[1950]\ttraining's rmse: 1.11526\tvalid_1's rmse: 49.2127\n",
      "[1980]\ttraining's rmse: 1.06409\tvalid_1's rmse: 49.2133\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's rmse: 1.03518\tvalid_1's rmse: 49.2125\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002376 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 20024\n",
      "[LightGBM] [Info] Number of data points in the train set: 9219, number of used features: 79\n",
      "[LightGBM] [Info] Start training from score 368.005407\n",
      "Training until validation scores don't improve for 125 rounds\n",
      "[30]\ttraining's rmse: 149.187\tvalid_1's rmse: 152.947\n",
      "[60]\ttraining's rmse: 94.8541\tvalid_1's rmse: 105.1\n",
      "[90]\ttraining's rmse: 65.5442\tvalid_1's rmse: 81.512\n",
      "[120]\ttraining's rmse: 49.4631\tvalid_1's rmse: 70.0232\n",
      "[150]\ttraining's rmse: 40.1942\tvalid_1's rmse: 64.306\n",
      "[180]\ttraining's rmse: 34.2945\tvalid_1's rmse: 61.2819\n",
      "[210]\ttraining's rmse: 30.0738\tvalid_1's rmse: 59.4192\n",
      "[240]\ttraining's rmse: 26.8502\tvalid_1's rmse: 58.1696\n",
      "[270]\ttraining's rmse: 24.2347\tvalid_1's rmse: 57.3171\n",
      "[300]\ttraining's rmse: 22.0855\tvalid_1's rmse: 56.7118\n",
      "[330]\ttraining's rmse: 20.2638\tvalid_1's rmse: 56.2979\n",
      "[360]\ttraining's rmse: 18.6891\tvalid_1's rmse: 56.043\n",
      "[390]\ttraining's rmse: 17.3253\tvalid_1's rmse: 55.8632\n",
      "[420]\ttraining's rmse: 16.0777\tvalid_1's rmse: 55.6859\n",
      "[450]\ttraining's rmse: 14.9322\tvalid_1's rmse: 55.5213\n",
      "[480]\ttraining's rmse: 13.9395\tvalid_1's rmse: 55.4081\n",
      "[510]\ttraining's rmse: 13.0203\tvalid_1's rmse: 55.288\n",
      "[540]\ttraining's rmse: 12.1855\tvalid_1's rmse: 55.2025\n",
      "[570]\ttraining's rmse: 11.4016\tvalid_1's rmse: 55.1288\n",
      "[600]\ttraining's rmse: 10.6942\tvalid_1's rmse: 55.0746\n",
      "[630]\ttraining's rmse: 10.0381\tvalid_1's rmse: 55.0175\n",
      "[660]\ttraining's rmse: 9.43769\tvalid_1's rmse: 54.9527\n",
      "[690]\ttraining's rmse: 8.89403\tvalid_1's rmse: 54.8832\n",
      "[720]\ttraining's rmse: 8.37293\tvalid_1's rmse: 54.8394\n",
      "[750]\ttraining's rmse: 7.90225\tvalid_1's rmse: 54.8061\n",
      "[780]\ttraining's rmse: 7.45899\tvalid_1's rmse: 54.7784\n",
      "[810]\ttraining's rmse: 7.05363\tvalid_1's rmse: 54.7484\n",
      "[840]\ttraining's rmse: 6.66135\tvalid_1's rmse: 54.7085\n",
      "[870]\ttraining's rmse: 6.28763\tvalid_1's rmse: 54.6845\n",
      "[900]\ttraining's rmse: 5.94471\tvalid_1's rmse: 54.6552\n",
      "[930]\ttraining's rmse: 5.62046\tvalid_1's rmse: 54.6274\n",
      "[960]\ttraining's rmse: 5.31485\tvalid_1's rmse: 54.6212\n",
      "[990]\ttraining's rmse: 5.03569\tvalid_1's rmse: 54.5963\n",
      "[1020]\ttraining's rmse: 4.77821\tvalid_1's rmse: 54.5701\n",
      "[1050]\ttraining's rmse: 4.53021\tvalid_1's rmse: 54.5624\n",
      "[1080]\ttraining's rmse: 4.29237\tvalid_1's rmse: 54.5476\n",
      "[1110]\ttraining's rmse: 4.07018\tvalid_1's rmse: 54.5254\n",
      "[1140]\ttraining's rmse: 3.85359\tvalid_1's rmse: 54.5138\n",
      "[1170]\ttraining's rmse: 3.66242\tvalid_1's rmse: 54.5061\n",
      "[1200]\ttraining's rmse: 3.48156\tvalid_1's rmse: 54.5017\n",
      "[1230]\ttraining's rmse: 3.306\tvalid_1's rmse: 54.4908\n",
      "[1260]\ttraining's rmse: 3.13558\tvalid_1's rmse: 54.4855\n",
      "[1290]\ttraining's rmse: 2.98562\tvalid_1's rmse: 54.4705\n",
      "[1320]\ttraining's rmse: 2.84054\tvalid_1's rmse: 54.4681\n",
      "[1350]\ttraining's rmse: 2.70508\tvalid_1's rmse: 54.4634\n",
      "[1380]\ttraining's rmse: 2.57258\tvalid_1's rmse: 54.4604\n",
      "[1410]\ttraining's rmse: 2.44793\tvalid_1's rmse: 54.4519\n",
      "[1440]\ttraining's rmse: 2.3308\tvalid_1's rmse: 54.4454\n",
      "[1470]\ttraining's rmse: 2.2215\tvalid_1's rmse: 54.4434\n",
      "[1500]\ttraining's rmse: 2.11594\tvalid_1's rmse: 54.4365\n",
      "[1530]\ttraining's rmse: 2.01674\tvalid_1's rmse: 54.4338\n",
      "[1560]\ttraining's rmse: 1.92076\tvalid_1's rmse: 54.431\n",
      "[1590]\ttraining's rmse: 1.83216\tvalid_1's rmse: 54.4284\n",
      "[1620]\ttraining's rmse: 1.74875\tvalid_1's rmse: 54.4259\n",
      "[1650]\ttraining's rmse: 1.66624\tvalid_1's rmse: 54.4236\n",
      "[1680]\ttraining's rmse: 1.59321\tvalid_1's rmse: 54.4202\n",
      "[1710]\ttraining's rmse: 1.52016\tvalid_1's rmse: 54.4184\n",
      "[1740]\ttraining's rmse: 1.45376\tvalid_1's rmse: 54.4177\n",
      "[1770]\ttraining's rmse: 1.3872\tvalid_1's rmse: 54.414\n",
      "[1800]\ttraining's rmse: 1.32435\tvalid_1's rmse: 54.4127\n",
      "[1830]\ttraining's rmse: 1.26279\tvalid_1's rmse: 54.4077\n",
      "[1860]\ttraining's rmse: 1.20701\tvalid_1's rmse: 54.4066\n",
      "[1890]\ttraining's rmse: 1.15359\tvalid_1's rmse: 54.4061\n",
      "[1920]\ttraining's rmse: 1.10026\tvalid_1's rmse: 54.4059\n",
      "[1950]\ttraining's rmse: 1.05228\tvalid_1's rmse: 54.4053\n",
      "[1980]\ttraining's rmse: 1.00505\tvalid_1's rmse: 54.4029\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's rmse: 0.974186\tvalid_1's rmse: 54.4016\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002449 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 20024\n",
      "[LightGBM] [Info] Number of data points in the train set: 9219, number of used features: 79\n",
      "[LightGBM] [Info] Start training from score 369.984226\n",
      "Training until validation scores don't improve for 125 rounds\n",
      "[30]\ttraining's rmse: 149.792\tvalid_1's rmse: 151.216\n",
      "[60]\ttraining's rmse: 96.1461\tvalid_1's rmse: 104.779\n",
      "[90]\ttraining's rmse: 66.5187\tvalid_1's rmse: 81.4998\n",
      "[120]\ttraining's rmse: 50.265\tvalid_1's rmse: 70.532\n",
      "[150]\ttraining's rmse: 40.8808\tvalid_1's rmse: 64.9141\n",
      "[180]\ttraining's rmse: 34.9431\tvalid_1's rmse: 61.9079\n",
      "[210]\ttraining's rmse: 30.629\tvalid_1's rmse: 60.034\n",
      "[240]\ttraining's rmse: 27.3409\tvalid_1's rmse: 58.8902\n",
      "[270]\ttraining's rmse: 24.6544\tvalid_1's rmse: 58.1122\n",
      "[300]\ttraining's rmse: 22.4769\tvalid_1's rmse: 57.5373\n",
      "[330]\ttraining's rmse: 20.5988\tvalid_1's rmse: 57.199\n",
      "[360]\ttraining's rmse: 18.9599\tvalid_1's rmse: 56.9134\n",
      "[390]\ttraining's rmse: 17.5569\tvalid_1's rmse: 56.6559\n",
      "[420]\ttraining's rmse: 16.281\tvalid_1's rmse: 56.4608\n",
      "[450]\ttraining's rmse: 15.1244\tvalid_1's rmse: 56.3257\n",
      "[480]\ttraining's rmse: 14.085\tvalid_1's rmse: 56.2102\n",
      "[510]\ttraining's rmse: 13.139\tvalid_1's rmse: 56.1212\n",
      "[540]\ttraining's rmse: 12.2792\tvalid_1's rmse: 55.959\n",
      "[570]\ttraining's rmse: 11.487\tvalid_1's rmse: 55.8644\n",
      "[600]\ttraining's rmse: 10.7478\tvalid_1's rmse: 55.8063\n",
      "[630]\ttraining's rmse: 10.0756\tvalid_1's rmse: 55.7433\n",
      "[660]\ttraining's rmse: 9.46132\tvalid_1's rmse: 55.681\n",
      "[690]\ttraining's rmse: 8.89462\tvalid_1's rmse: 55.6487\n",
      "[720]\ttraining's rmse: 8.35951\tvalid_1's rmse: 55.5957\n",
      "[750]\ttraining's rmse: 7.8706\tvalid_1's rmse: 55.5204\n",
      "[780]\ttraining's rmse: 7.41812\tvalid_1's rmse: 55.4841\n",
      "[810]\ttraining's rmse: 6.99595\tvalid_1's rmse: 55.4277\n",
      "[840]\ttraining's rmse: 6.59387\tvalid_1's rmse: 55.3894\n",
      "[870]\ttraining's rmse: 6.22216\tvalid_1's rmse: 55.3492\n",
      "[900]\ttraining's rmse: 5.86685\tvalid_1's rmse: 55.3122\n",
      "[930]\ttraining's rmse: 5.54751\tvalid_1's rmse: 55.281\n",
      "[960]\ttraining's rmse: 5.23669\tvalid_1's rmse: 55.2654\n",
      "[990]\ttraining's rmse: 4.95079\tvalid_1's rmse: 55.2583\n",
      "[1020]\ttraining's rmse: 4.68562\tvalid_1's rmse: 55.2386\n",
      "[1050]\ttraining's rmse: 4.43523\tvalid_1's rmse: 55.222\n",
      "[1080]\ttraining's rmse: 4.19683\tvalid_1's rmse: 55.2146\n",
      "[1110]\ttraining's rmse: 3.97714\tvalid_1's rmse: 55.1979\n",
      "[1140]\ttraining's rmse: 3.76547\tvalid_1's rmse: 55.1813\n",
      "[1170]\ttraining's rmse: 3.56702\tvalid_1's rmse: 55.1637\n",
      "[1200]\ttraining's rmse: 3.38156\tvalid_1's rmse: 55.1505\n",
      "[1230]\ttraining's rmse: 3.20192\tvalid_1's rmse: 55.1414\n",
      "[1260]\ttraining's rmse: 3.03635\tvalid_1's rmse: 55.142\n",
      "[1290]\ttraining's rmse: 2.88292\tvalid_1's rmse: 55.1323\n",
      "[1320]\ttraining's rmse: 2.73721\tvalid_1's rmse: 55.1223\n",
      "[1350]\ttraining's rmse: 2.59948\tvalid_1's rmse: 55.1214\n",
      "[1380]\ttraining's rmse: 2.46474\tvalid_1's rmse: 55.1138\n",
      "[1410]\ttraining's rmse: 2.33993\tvalid_1's rmse: 55.1089\n",
      "[1440]\ttraining's rmse: 2.22408\tvalid_1's rmse: 55.1041\n",
      "[1470]\ttraining's rmse: 2.1154\tvalid_1's rmse: 55.0991\n",
      "[1500]\ttraining's rmse: 2.01259\tvalid_1's rmse: 55.0952\n",
      "[1530]\ttraining's rmse: 1.91334\tvalid_1's rmse: 55.0934\n",
      "[1560]\ttraining's rmse: 1.82267\tvalid_1's rmse: 55.0865\n",
      "[1590]\ttraining's rmse: 1.73438\tvalid_1's rmse: 55.0819\n",
      "[1620]\ttraining's rmse: 1.65049\tvalid_1's rmse: 55.0771\n",
      "[1650]\ttraining's rmse: 1.57024\tvalid_1's rmse: 55.071\n",
      "[1680]\ttraining's rmse: 1.49467\tvalid_1's rmse: 55.0679\n",
      "[1710]\ttraining's rmse: 1.42521\tvalid_1's rmse: 55.0666\n",
      "[1740]\ttraining's rmse: 1.35989\tvalid_1's rmse: 55.0622\n",
      "[1770]\ttraining's rmse: 1.29503\tvalid_1's rmse: 55.0594\n",
      "[1800]\ttraining's rmse: 1.23411\tvalid_1's rmse: 55.0583\n",
      "[1830]\ttraining's rmse: 1.17631\tvalid_1's rmse: 55.0563\n",
      "[1860]\ttraining's rmse: 1.12057\tvalid_1's rmse: 55.0551\n",
      "[1890]\ttraining's rmse: 1.06861\tvalid_1's rmse: 55.0537\n",
      "[1920]\ttraining's rmse: 1.01872\tvalid_1's rmse: 55.0505\n",
      "[1950]\ttraining's rmse: 0.971911\tvalid_1's rmse: 55.0477\n",
      "[1980]\ttraining's rmse: 0.92582\tvalid_1's rmse: 55.0462\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's rmse: 0.897705\tvalid_1's rmse: 55.0454\n"
     ]
    }
   ],
   "source": [
    "#lgb direct example\n",
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "for slot in range(len(df_slots)):\n",
    "    print(slot)\n",
    "    gdf = df_slots[slot].XZ_globalReg(L=7, rolling_step = 1, mode= 'Tree')\n",
    "\n",
    "    H = gdf['Y_tr'].shape[-1]\n",
    "    X_train, X_val, y_train, y_val, mask_train, mask_val,  =  train_test_split(np.concatenate([gdf['X_tr'],gdf['Z_tr']],-1) ,gdf['Y_tr'] ,gdf['mask_tr'], test_size = 0.2, random_state =0)\n",
    "\n",
    "    predicts = []\n",
    "    for h in range(H): \n",
    "        dtrain = lgb.Dataset(X_train , label= y_train[:,h] ,weight = mask_train[:,h] )\n",
    "        dval = lgb.Dataset(X_val , label= y_val[:,h] , weight = mask_val[:,h] )\n",
    "        params = {\n",
    "                'num_leaves': 128,\n",
    "                'objective': 'regression',\n",
    "                'min_data_in_leaf': 10,\n",
    "                'learning_rate': 0.02,\n",
    "                'feature_fraction': 0.8,\n",
    "                'bagging_fraction': 0.7,\n",
    "                'bagging_freq': 1,\n",
    "                'metric': 'rmse',\n",
    "                'num_threads': 8\n",
    "            }\n",
    "            \n",
    "            \n",
    "        MAX_ROUNDS = 2000\n",
    "        bst = lgb.train(\n",
    "                params, dtrain, num_boost_round=MAX_ROUNDS, \n",
    "                        valid_sets=[dtrain,dval], early_stopping_rounds=125, verbose_eval=30\n",
    "                    )\n",
    "\n",
    "        predicts.append( bst.predict(np.concatenate([gdf['X_ts'],gdf['Z_ts']],-1) , num_iteration=bst.best_iteration or MAX_ROUNDS)[:,np.newaxis])\n",
    "\n",
    "    predicts = np.concatenate(predicts,-1)\n",
    "    df_slots[slot].add_Base_forecasts(predicts,'lightgbm_direct')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.019453 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 29705\n",
      "[LightGBM] [Info] Number of data points in the train set: 59281, number of used features: 117\n",
      "[LightGBM] [Info] Start training from score 355.410227\n",
      "Training until validation scores don't improve for 125 rounds\n",
      "[30]\ttraining's rmse: 211.817\tvalid_1's rmse: 217.189\n",
      "[60]\ttraining's rmse: 172.707\tvalid_1's rmse: 180.912\n",
      "[90]\ttraining's rmse: 152.534\tvalid_1's rmse: 163.45\n",
      "[120]\ttraining's rmse: 140.769\tvalid_1's rmse: 154.22\n",
      "[150]\ttraining's rmse: 132.858\tvalid_1's rmse: 148.592\n",
      "[180]\ttraining's rmse: 127.068\tvalid_1's rmse: 144.944\n",
      "[210]\ttraining's rmse: 122.473\tvalid_1's rmse: 142.363\n",
      "[240]\ttraining's rmse: 118.633\tvalid_1's rmse: 140.231\n",
      "[270]\ttraining's rmse: 115.219\tvalid_1's rmse: 138.351\n",
      "[300]\ttraining's rmse: 112.471\tvalid_1's rmse: 136.992\n",
      "[330]\ttraining's rmse: 110.296\tvalid_1's rmse: 136.256\n",
      "[360]\ttraining's rmse: 108.17\tvalid_1's rmse: 135.481\n",
      "[390]\ttraining's rmse: 106.324\tvalid_1's rmse: 134.995\n",
      "[420]\ttraining's rmse: 104.511\tvalid_1's rmse: 134.491\n",
      "[450]\ttraining's rmse: 102.798\tvalid_1's rmse: 134.04\n",
      "[480]\ttraining's rmse: 101.231\tvalid_1's rmse: 133.656\n",
      "[510]\ttraining's rmse: 99.7204\tvalid_1's rmse: 133.31\n",
      "[540]\ttraining's rmse: 98.2822\tvalid_1's rmse: 133.006\n",
      "[570]\ttraining's rmse: 96.9573\tvalid_1's rmse: 132.694\n",
      "[600]\ttraining's rmse: 95.693\tvalid_1's rmse: 132.493\n",
      "[630]\ttraining's rmse: 94.5731\tvalid_1's rmse: 132.427\n",
      "[660]\ttraining's rmse: 93.4405\tvalid_1's rmse: 132.342\n",
      "[690]\ttraining's rmse: 92.3707\tvalid_1's rmse: 132.218\n",
      "[720]\ttraining's rmse: 91.3116\tvalid_1's rmse: 132.131\n",
      "[750]\ttraining's rmse: 90.1376\tvalid_1's rmse: 131.918\n",
      "[780]\ttraining's rmse: 89.0729\tvalid_1's rmse: 131.847\n",
      "[810]\ttraining's rmse: 88.1057\tvalid_1's rmse: 131.795\n",
      "[840]\ttraining's rmse: 87.238\tvalid_1's rmse: 131.777\n",
      "[870]\ttraining's rmse: 86.3347\tvalid_1's rmse: 131.705\n",
      "[900]\ttraining's rmse: 85.4269\tvalid_1's rmse: 131.666\n",
      "[930]\ttraining's rmse: 84.4767\tvalid_1's rmse: 131.54\n",
      "[960]\ttraining's rmse: 83.627\tvalid_1's rmse: 131.442\n",
      "[990]\ttraining's rmse: 82.7608\tvalid_1's rmse: 131.365\n",
      "[1020]\ttraining's rmse: 82.0024\tvalid_1's rmse: 131.346\n",
      "[1050]\ttraining's rmse: 81.1685\tvalid_1's rmse: 131.233\n",
      "[1080]\ttraining's rmse: 80.3564\tvalid_1's rmse: 131.126\n",
      "[1110]\ttraining's rmse: 79.6809\tvalid_1's rmse: 131.152\n",
      "[1140]\ttraining's rmse: 78.9324\tvalid_1's rmse: 131.097\n",
      "[1170]\ttraining's rmse: 78.2403\tvalid_1's rmse: 131.116\n",
      "[1200]\ttraining's rmse: 77.5435\tvalid_1's rmse: 131.073\n",
      "[1230]\ttraining's rmse: 76.7868\tvalid_1's rmse: 130.979\n",
      "[1260]\ttraining's rmse: 76.1393\tvalid_1's rmse: 130.974\n",
      "[1290]\ttraining's rmse: 75.4906\tvalid_1's rmse: 130.988\n",
      "[1320]\ttraining's rmse: 74.8006\tvalid_1's rmse: 130.887\n",
      "[1350]\ttraining's rmse: 74.1339\tvalid_1's rmse: 130.839\n",
      "[1380]\ttraining's rmse: 73.442\tvalid_1's rmse: 130.743\n",
      "[1410]\ttraining's rmse: 72.8562\tvalid_1's rmse: 130.733\n",
      "[1440]\ttraining's rmse: 72.2454\tvalid_1's rmse: 130.688\n",
      "[1470]\ttraining's rmse: 71.6412\tvalid_1's rmse: 130.663\n",
      "[1500]\ttraining's rmse: 71.0069\tvalid_1's rmse: 130.603\n",
      "[1530]\ttraining's rmse: 70.4417\tvalid_1's rmse: 130.585\n",
      "[1560]\ttraining's rmse: 69.8871\tvalid_1's rmse: 130.55\n",
      "[1590]\ttraining's rmse: 69.3098\tvalid_1's rmse: 130.508\n",
      "[1620]\ttraining's rmse: 68.8084\tvalid_1's rmse: 130.534\n",
      "[1650]\ttraining's rmse: 68.2868\tvalid_1's rmse: 130.53\n",
      "[1680]\ttraining's rmse: 67.7619\tvalid_1's rmse: 130.494\n",
      "[1710]\ttraining's rmse: 67.2657\tvalid_1's rmse: 130.469\n",
      "[1740]\ttraining's rmse: 66.7539\tvalid_1's rmse: 130.462\n",
      "[1770]\ttraining's rmse: 66.266\tvalid_1's rmse: 130.429\n",
      "[1800]\ttraining's rmse: 65.7922\tvalid_1's rmse: 130.418\n",
      "[1830]\ttraining's rmse: 65.3052\tvalid_1's rmse: 130.376\n",
      "[1860]\ttraining's rmse: 64.8093\tvalid_1's rmse: 130.344\n",
      "[1890]\ttraining's rmse: 64.375\tvalid_1's rmse: 130.342\n",
      "[1920]\ttraining's rmse: 63.9463\tvalid_1's rmse: 130.301\n",
      "[1950]\ttraining's rmse: 63.5052\tvalid_1's rmse: 130.293\n",
      "[1980]\ttraining's rmse: 63.0255\tvalid_1's rmse: 130.25\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's rmse: 62.7546\tvalid_1's rmse: 130.263\n",
      "1\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.020140 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 29703\n",
      "[LightGBM] [Info] Number of data points in the train set: 59281, number of used features: 117\n",
      "[LightGBM] [Info] Start training from score 364.147760\n",
      "Training until validation scores don't improve for 125 rounds\n",
      "[30]\ttraining's rmse: 217.124\tvalid_1's rmse: 219.445\n",
      "[60]\ttraining's rmse: 175.983\tvalid_1's rmse: 181.304\n",
      "[90]\ttraining's rmse: 154.856\tvalid_1's rmse: 162.868\n",
      "[120]\ttraining's rmse: 142.928\tvalid_1's rmse: 153.656\n",
      "[150]\ttraining's rmse: 134.766\tvalid_1's rmse: 147.998\n",
      "[180]\ttraining's rmse: 128.806\tvalid_1's rmse: 144.091\n",
      "[210]\ttraining's rmse: 124.017\tvalid_1's rmse: 141.36\n",
      "[240]\ttraining's rmse: 120.19\tvalid_1's rmse: 139.232\n",
      "[270]\ttraining's rmse: 116.829\tvalid_1's rmse: 137.415\n",
      "[300]\ttraining's rmse: 114.047\tvalid_1's rmse: 136.146\n",
      "[330]\ttraining's rmse: 111.78\tvalid_1's rmse: 135.386\n",
      "[360]\ttraining's rmse: 109.699\tvalid_1's rmse: 134.654\n",
      "[390]\ttraining's rmse: 107.884\tvalid_1's rmse: 134.161\n",
      "[420]\ttraining's rmse: 105.902\tvalid_1's rmse: 133.497\n",
      "[450]\ttraining's rmse: 104.254\tvalid_1's rmse: 133.119\n",
      "[480]\ttraining's rmse: 102.705\tvalid_1's rmse: 132.793\n",
      "[510]\ttraining's rmse: 101.177\tvalid_1's rmse: 132.391\n",
      "[540]\ttraining's rmse: 99.6599\tvalid_1's rmse: 132.044\n",
      "[570]\ttraining's rmse: 98.21\tvalid_1's rmse: 131.667\n",
      "[600]\ttraining's rmse: 96.9285\tvalid_1's rmse: 131.446\n",
      "[630]\ttraining's rmse: 95.7172\tvalid_1's rmse: 131.23\n",
      "[660]\ttraining's rmse: 94.5612\tvalid_1's rmse: 131.161\n",
      "[690]\ttraining's rmse: 93.4969\tvalid_1's rmse: 131.05\n",
      "[720]\ttraining's rmse: 92.4196\tvalid_1's rmse: 130.944\n",
      "[750]\ttraining's rmse: 91.2299\tvalid_1's rmse: 130.732\n",
      "[780]\ttraining's rmse: 90.1556\tvalid_1's rmse: 130.583\n",
      "[810]\ttraining's rmse: 89.1252\tvalid_1's rmse: 130.498\n",
      "[840]\ttraining's rmse: 88.2464\tvalid_1's rmse: 130.427\n",
      "[870]\ttraining's rmse: 87.3476\tvalid_1's rmse: 130.369\n",
      "[900]\ttraining's rmse: 86.373\tvalid_1's rmse: 130.263\n",
      "[930]\ttraining's rmse: 85.4676\tvalid_1's rmse: 130.166\n",
      "[960]\ttraining's rmse: 84.6185\tvalid_1's rmse: 130.101\n",
      "[990]\ttraining's rmse: 83.779\tvalid_1's rmse: 130.068\n",
      "[1020]\ttraining's rmse: 82.9407\tvalid_1's rmse: 130.064\n",
      "[1050]\ttraining's rmse: 82.1311\tvalid_1's rmse: 129.967\n",
      "[1080]\ttraining's rmse: 81.3617\tvalid_1's rmse: 129.896\n",
      "[1110]\ttraining's rmse: 80.6699\tvalid_1's rmse: 129.874\n",
      "[1140]\ttraining's rmse: 79.8704\tvalid_1's rmse: 129.831\n",
      "[1170]\ttraining's rmse: 79.0804\tvalid_1's rmse: 129.756\n",
      "[1200]\ttraining's rmse: 78.3505\tvalid_1's rmse: 129.682\n",
      "[1230]\ttraining's rmse: 77.6574\tvalid_1's rmse: 129.661\n",
      "[1260]\ttraining's rmse: 77.0049\tvalid_1's rmse: 129.628\n",
      "[1290]\ttraining's rmse: 76.3049\tvalid_1's rmse: 129.569\n",
      "[1320]\ttraining's rmse: 75.6071\tvalid_1's rmse: 129.519\n",
      "[1350]\ttraining's rmse: 74.9525\tvalid_1's rmse: 129.494\n",
      "[1380]\ttraining's rmse: 74.2883\tvalid_1's rmse: 129.401\n",
      "[1410]\ttraining's rmse: 73.7122\tvalid_1's rmse: 129.387\n",
      "[1440]\ttraining's rmse: 73.1101\tvalid_1's rmse: 129.337\n",
      "[1470]\ttraining's rmse: 72.5258\tvalid_1's rmse: 129.331\n",
      "[1500]\ttraining's rmse: 71.9222\tvalid_1's rmse: 129.299\n",
      "[1530]\ttraining's rmse: 71.2976\tvalid_1's rmse: 129.212\n",
      "[1560]\ttraining's rmse: 70.6976\tvalid_1's rmse: 129.168\n",
      "[1590]\ttraining's rmse: 70.1211\tvalid_1's rmse: 129.112\n",
      "[1620]\ttraining's rmse: 69.5927\tvalid_1's rmse: 129.108\n",
      "[1650]\ttraining's rmse: 69.0118\tvalid_1's rmse: 129.052\n",
      "[1680]\ttraining's rmse: 68.4717\tvalid_1's rmse: 129.04\n",
      "[1710]\ttraining's rmse: 67.9461\tvalid_1's rmse: 129.006\n",
      "[1740]\ttraining's rmse: 67.4605\tvalid_1's rmse: 129.003\n",
      "[1770]\ttraining's rmse: 66.9512\tvalid_1's rmse: 129.018\n",
      "[1800]\ttraining's rmse: 66.4673\tvalid_1's rmse: 128.991\n",
      "[1830]\ttraining's rmse: 66.0115\tvalid_1's rmse: 128.99\n",
      "[1860]\ttraining's rmse: 65.533\tvalid_1's rmse: 128.984\n",
      "[1890]\ttraining's rmse: 65.0929\tvalid_1's rmse: 128.954\n",
      "[1920]\ttraining's rmse: 64.5978\tvalid_1's rmse: 128.89\n",
      "[1950]\ttraining's rmse: 64.0941\tvalid_1's rmse: 128.848\n",
      "[1980]\ttraining's rmse: 63.6342\tvalid_1's rmse: 128.833\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's rmse: 63.3481\tvalid_1's rmse: 128.821\n",
      "2\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.022513 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 29701\n",
      "[LightGBM] [Info] Number of data points in the train set: 59281, number of used features: 117\n",
      "[LightGBM] [Info] Start training from score 371.427122\n",
      "Training until validation scores don't improve for 125 rounds\n",
      "[30]\ttraining's rmse: 221.164\tvalid_1's rmse: 221.118\n",
      "[60]\ttraining's rmse: 178.065\tvalid_1's rmse: 182.71\n",
      "[90]\ttraining's rmse: 155.824\tvalid_1's rmse: 164.581\n",
      "[120]\ttraining's rmse: 143.309\tvalid_1's rmse: 155.389\n",
      "[150]\ttraining's rmse: 134.957\tvalid_1's rmse: 149.817\n",
      "[180]\ttraining's rmse: 129.023\tvalid_1's rmse: 146.3\n",
      "[210]\ttraining's rmse: 124.159\tvalid_1's rmse: 143.435\n",
      "[240]\ttraining's rmse: 120.093\tvalid_1's rmse: 141.167\n",
      "[270]\ttraining's rmse: 116.849\tvalid_1's rmse: 139.535\n",
      "[300]\ttraining's rmse: 114.037\tvalid_1's rmse: 138.189\n",
      "[330]\ttraining's rmse: 111.849\tvalid_1's rmse: 137.491\n",
      "[360]\ttraining's rmse: 109.69\tvalid_1's rmse: 136.649\n",
      "[390]\ttraining's rmse: 107.668\tvalid_1's rmse: 136.029\n",
      "[420]\ttraining's rmse: 105.74\tvalid_1's rmse: 135.388\n",
      "[450]\ttraining's rmse: 104.074\tvalid_1's rmse: 134.977\n",
      "[480]\ttraining's rmse: 102.533\tvalid_1's rmse: 134.677\n",
      "[510]\ttraining's rmse: 100.97\tvalid_1's rmse: 134.283\n",
      "[540]\ttraining's rmse: 99.5191\tvalid_1's rmse: 133.967\n",
      "[570]\ttraining's rmse: 98.1612\tvalid_1's rmse: 133.722\n",
      "[600]\ttraining's rmse: 96.8942\tvalid_1's rmse: 133.505\n",
      "[630]\ttraining's rmse: 95.7117\tvalid_1's rmse: 133.341\n",
      "[660]\ttraining's rmse: 94.6268\tvalid_1's rmse: 133.289\n",
      "[690]\ttraining's rmse: 93.3911\tvalid_1's rmse: 133.005\n",
      "[720]\ttraining's rmse: 92.3079\tvalid_1's rmse: 132.859\n",
      "[750]\ttraining's rmse: 91.2488\tvalid_1's rmse: 132.743\n",
      "[780]\ttraining's rmse: 90.1747\tvalid_1's rmse: 132.577\n",
      "[810]\ttraining's rmse: 89.1909\tvalid_1's rmse: 132.469\n",
      "[840]\ttraining's rmse: 88.2448\tvalid_1's rmse: 132.403\n",
      "[870]\ttraining's rmse: 87.2963\tvalid_1's rmse: 132.292\n",
      "[900]\ttraining's rmse: 86.3266\tvalid_1's rmse: 132.19\n",
      "[930]\ttraining's rmse: 85.4646\tvalid_1's rmse: 132.065\n",
      "[960]\ttraining's rmse: 84.5609\tvalid_1's rmse: 131.916\n",
      "[990]\ttraining's rmse: 83.7078\tvalid_1's rmse: 131.824\n",
      "[1020]\ttraining's rmse: 82.8717\tvalid_1's rmse: 131.764\n",
      "[1050]\ttraining's rmse: 82.0775\tvalid_1's rmse: 131.679\n",
      "[1080]\ttraining's rmse: 81.2714\tvalid_1's rmse: 131.637\n",
      "[1110]\ttraining's rmse: 80.4985\tvalid_1's rmse: 131.611\n",
      "[1140]\ttraining's rmse: 79.6598\tvalid_1's rmse: 131.503\n",
      "[1170]\ttraining's rmse: 78.9196\tvalid_1's rmse: 131.425\n",
      "[1200]\ttraining's rmse: 78.2393\tvalid_1's rmse: 131.415\n",
      "[1230]\ttraining's rmse: 77.5606\tvalid_1's rmse: 131.339\n",
      "[1260]\ttraining's rmse: 76.9065\tvalid_1's rmse: 131.307\n",
      "[1290]\ttraining's rmse: 76.2718\tvalid_1's rmse: 131.317\n",
      "[1320]\ttraining's rmse: 75.6097\tvalid_1's rmse: 131.271\n",
      "[1350]\ttraining's rmse: 75.0117\tvalid_1's rmse: 131.263\n",
      "[1380]\ttraining's rmse: 74.3417\tvalid_1's rmse: 131.203\n",
      "[1410]\ttraining's rmse: 73.7056\tvalid_1's rmse: 131.164\n",
      "[1440]\ttraining's rmse: 73.0786\tvalid_1's rmse: 131.093\n",
      "[1470]\ttraining's rmse: 72.4988\tvalid_1's rmse: 131.061\n",
      "[1500]\ttraining's rmse: 71.8923\tvalid_1's rmse: 130.999\n",
      "[1530]\ttraining's rmse: 71.1563\tvalid_1's rmse: 130.885\n",
      "[1560]\ttraining's rmse: 70.5889\tvalid_1's rmse: 130.845\n",
      "[1590]\ttraining's rmse: 70.0433\tvalid_1's rmse: 130.781\n",
      "[1620]\ttraining's rmse: 69.563\tvalid_1's rmse: 130.795\n",
      "[1650]\ttraining's rmse: 69.0688\tvalid_1's rmse: 130.777\n",
      "[1680]\ttraining's rmse: 68.5173\tvalid_1's rmse: 130.735\n",
      "[1710]\ttraining's rmse: 68.0352\tvalid_1's rmse: 130.728\n",
      "[1740]\ttraining's rmse: 67.5116\tvalid_1's rmse: 130.694\n",
      "[1770]\ttraining's rmse: 67.0293\tvalid_1's rmse: 130.688\n",
      "[1800]\ttraining's rmse: 66.5964\tvalid_1's rmse: 130.691\n",
      "[1830]\ttraining's rmse: 66.0513\tvalid_1's rmse: 130.604\n",
      "[1860]\ttraining's rmse: 65.6023\tvalid_1's rmse: 130.599\n",
      "[1890]\ttraining's rmse: 65.1436\tvalid_1's rmse: 130.597\n",
      "[1920]\ttraining's rmse: 64.6335\tvalid_1's rmse: 130.532\n",
      "[1950]\ttraining's rmse: 64.177\tvalid_1's rmse: 130.508\n",
      "[1980]\ttraining's rmse: 63.6916\tvalid_1's rmse: 130.441\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's rmse: 63.3793\tvalid_1's rmse: 130.412\n",
      "3\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.022963 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 29701\n",
      "[LightGBM] [Info] Number of data points in the train set: 59281, number of used features: 117\n",
      "[LightGBM] [Info] Start training from score 375.593701\n",
      "Training until validation scores don't improve for 125 rounds\n",
      "[30]\ttraining's rmse: 221.184\tvalid_1's rmse: 223.266\n",
      "[60]\ttraining's rmse: 177.959\tvalid_1's rmse: 183.837\n",
      "[90]\ttraining's rmse: 155.903\tvalid_1's rmse: 165.351\n",
      "[120]\ttraining's rmse: 143.374\tvalid_1's rmse: 155.882\n",
      "[150]\ttraining's rmse: 135.151\tvalid_1's rmse: 150.212\n",
      "[180]\ttraining's rmse: 129.145\tvalid_1's rmse: 146.481\n",
      "[210]\ttraining's rmse: 124.185\tvalid_1's rmse: 143.372\n",
      "[240]\ttraining's rmse: 120.312\tvalid_1's rmse: 141.261\n",
      "[270]\ttraining's rmse: 117.008\tvalid_1's rmse: 139.461\n",
      "[300]\ttraining's rmse: 114.269\tvalid_1's rmse: 138.17\n",
      "[330]\ttraining's rmse: 111.973\tvalid_1's rmse: 137.363\n",
      "[360]\ttraining's rmse: 109.826\tvalid_1's rmse: 136.561\n",
      "[390]\ttraining's rmse: 107.888\tvalid_1's rmse: 135.907\n",
      "[420]\ttraining's rmse: 106.026\tvalid_1's rmse: 135.252\n",
      "[450]\ttraining's rmse: 104.326\tvalid_1's rmse: 134.831\n",
      "[480]\ttraining's rmse: 102.802\tvalid_1's rmse: 134.497\n",
      "[510]\ttraining's rmse: 101.256\tvalid_1's rmse: 134.109\n",
      "[540]\ttraining's rmse: 99.9734\tvalid_1's rmse: 133.927\n",
      "[570]\ttraining's rmse: 98.5517\tvalid_1's rmse: 133.638\n",
      "[600]\ttraining's rmse: 97.271\tvalid_1's rmse: 133.443\n",
      "[630]\ttraining's rmse: 95.9943\tvalid_1's rmse: 133.24\n",
      "[660]\ttraining's rmse: 94.8486\tvalid_1's rmse: 133.157\n",
      "[690]\ttraining's rmse: 93.6174\tvalid_1's rmse: 132.946\n",
      "[720]\ttraining's rmse: 92.5254\tvalid_1's rmse: 132.833\n",
      "[750]\ttraining's rmse: 91.4303\tvalid_1's rmse: 132.686\n",
      "[780]\ttraining's rmse: 90.3739\tvalid_1's rmse: 132.574\n",
      "[810]\ttraining's rmse: 89.2737\tvalid_1's rmse: 132.408\n",
      "[840]\ttraining's rmse: 88.2927\tvalid_1's rmse: 132.296\n",
      "[870]\ttraining's rmse: 87.4284\tvalid_1's rmse: 132.274\n",
      "[900]\ttraining's rmse: 86.5149\tvalid_1's rmse: 132.245\n",
      "[930]\ttraining's rmse: 85.6366\tvalid_1's rmse: 132.144\n",
      "[960]\ttraining's rmse: 84.7548\tvalid_1's rmse: 132.062\n",
      "[990]\ttraining's rmse: 83.9271\tvalid_1's rmse: 131.982\n",
      "[1020]\ttraining's rmse: 83.0454\tvalid_1's rmse: 131.885\n",
      "[1050]\ttraining's rmse: 82.2193\tvalid_1's rmse: 131.802\n",
      "[1080]\ttraining's rmse: 81.4032\tvalid_1's rmse: 131.721\n",
      "[1110]\ttraining's rmse: 80.6122\tvalid_1's rmse: 131.65\n",
      "[1140]\ttraining's rmse: 79.8904\tvalid_1's rmse: 131.658\n",
      "[1170]\ttraining's rmse: 79.109\tvalid_1's rmse: 131.577\n",
      "[1200]\ttraining's rmse: 78.3607\tvalid_1's rmse: 131.51\n",
      "[1230]\ttraining's rmse: 77.5902\tvalid_1's rmse: 131.403\n",
      "[1260]\ttraining's rmse: 76.9251\tvalid_1's rmse: 131.408\n",
      "[1290]\ttraining's rmse: 76.3387\tvalid_1's rmse: 131.395\n",
      "[1320]\ttraining's rmse: 75.6823\tvalid_1's rmse: 131.402\n",
      "[1350]\ttraining's rmse: 75.0123\tvalid_1's rmse: 131.368\n",
      "[1380]\ttraining's rmse: 74.3944\tvalid_1's rmse: 131.372\n",
      "[1410]\ttraining's rmse: 73.7516\tvalid_1's rmse: 131.292\n",
      "[1440]\ttraining's rmse: 73.1035\tvalid_1's rmse: 131.215\n",
      "[1470]\ttraining's rmse: 72.5016\tvalid_1's rmse: 131.182\n",
      "[1500]\ttraining's rmse: 71.9703\tvalid_1's rmse: 131.201\n",
      "[1530]\ttraining's rmse: 71.3988\tvalid_1's rmse: 131.159\n",
      "[1560]\ttraining's rmse: 70.877\tvalid_1's rmse: 131.185\n",
      "[1590]\ttraining's rmse: 70.3013\tvalid_1's rmse: 131.165\n",
      "[1620]\ttraining's rmse: 69.7523\tvalid_1's rmse: 131.129\n",
      "[1650]\ttraining's rmse: 69.2621\tvalid_1's rmse: 131.121\n",
      "[1680]\ttraining's rmse: 68.715\tvalid_1's rmse: 131.061\n",
      "[1710]\ttraining's rmse: 68.1673\tvalid_1's rmse: 131.054\n",
      "[1740]\ttraining's rmse: 67.6924\tvalid_1's rmse: 131.035\n",
      "[1770]\ttraining's rmse: 67.2311\tvalid_1's rmse: 131.037\n",
      "[1800]\ttraining's rmse: 66.7224\tvalid_1's rmse: 131\n",
      "[1830]\ttraining's rmse: 66.2733\tvalid_1's rmse: 130.994\n",
      "[1860]\ttraining's rmse: 65.7768\tvalid_1's rmse: 130.972\n",
      "[1890]\ttraining's rmse: 65.3348\tvalid_1's rmse: 130.977\n",
      "[1920]\ttraining's rmse: 64.9141\tvalid_1's rmse: 130.955\n",
      "[1950]\ttraining's rmse: 64.4489\tvalid_1's rmse: 130.924\n",
      "[1980]\ttraining's rmse: 63.9948\tvalid_1's rmse: 130.896\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's rmse: 63.6795\tvalid_1's rmse: 130.888\n",
      "4\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.021046 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 29703\n",
      "[LightGBM] [Info] Number of data points in the train set: 59281, number of used features: 117\n",
      "[LightGBM] [Info] Start training from score 380.990681\n",
      "Training until validation scores don't improve for 125 rounds\n",
      "[30]\ttraining's rmse: 221.552\tvalid_1's rmse: 223.639\n",
      "[60]\ttraining's rmse: 178.832\tvalid_1's rmse: 184.07\n",
      "[90]\ttraining's rmse: 156.857\tvalid_1's rmse: 164.71\n",
      "[120]\ttraining's rmse: 144.375\tvalid_1's rmse: 154.97\n",
      "[150]\ttraining's rmse: 135.899\tvalid_1's rmse: 148.939\n",
      "[180]\ttraining's rmse: 129.821\tvalid_1's rmse: 145.068\n",
      "[210]\ttraining's rmse: 125.014\tvalid_1's rmse: 142.146\n",
      "[240]\ttraining's rmse: 121.044\tvalid_1's rmse: 139.888\n",
      "[270]\ttraining's rmse: 117.768\tvalid_1's rmse: 138.173\n",
      "[300]\ttraining's rmse: 114.905\tvalid_1's rmse: 136.762\n",
      "[330]\ttraining's rmse: 112.622\tvalid_1's rmse: 135.952\n",
      "[360]\ttraining's rmse: 110.339\tvalid_1's rmse: 135.079\n",
      "[390]\ttraining's rmse: 108.372\tvalid_1's rmse: 134.428\n",
      "[420]\ttraining's rmse: 106.391\tvalid_1's rmse: 133.789\n",
      "[450]\ttraining's rmse: 104.587\tvalid_1's rmse: 133.309\n",
      "[480]\ttraining's rmse: 103.025\tvalid_1's rmse: 132.944\n",
      "[510]\ttraining's rmse: 101.542\tvalid_1's rmse: 132.632\n",
      "[540]\ttraining's rmse: 100.065\tvalid_1's rmse: 132.277\n",
      "[570]\ttraining's rmse: 98.6797\tvalid_1's rmse: 131.975\n",
      "[600]\ttraining's rmse: 97.3987\tvalid_1's rmse: 131.756\n",
      "[630]\ttraining's rmse: 96.0618\tvalid_1's rmse: 131.455\n",
      "[660]\ttraining's rmse: 94.8858\tvalid_1's rmse: 131.292\n",
      "[690]\ttraining's rmse: 93.5995\tvalid_1's rmse: 131.045\n",
      "[720]\ttraining's rmse: 92.4454\tvalid_1's rmse: 130.872\n",
      "[750]\ttraining's rmse: 91.3898\tvalid_1's rmse: 130.731\n",
      "[780]\ttraining's rmse: 90.4021\tvalid_1's rmse: 130.652\n",
      "[810]\ttraining's rmse: 89.348\tvalid_1's rmse: 130.477\n",
      "[840]\ttraining's rmse: 88.3701\tvalid_1's rmse: 130.355\n",
      "[870]\ttraining's rmse: 87.467\tvalid_1's rmse: 130.27\n",
      "[900]\ttraining's rmse: 86.4979\tvalid_1's rmse: 130.156\n",
      "[930]\ttraining's rmse: 85.6266\tvalid_1's rmse: 130.066\n",
      "[960]\ttraining's rmse: 84.7166\tvalid_1's rmse: 129.988\n",
      "[990]\ttraining's rmse: 83.7933\tvalid_1's rmse: 129.895\n",
      "[1020]\ttraining's rmse: 82.9857\tvalid_1's rmse: 129.828\n",
      "[1050]\ttraining's rmse: 82.1886\tvalid_1's rmse: 129.764\n",
      "[1080]\ttraining's rmse: 81.4188\tvalid_1's rmse: 129.716\n",
      "[1110]\ttraining's rmse: 80.594\tvalid_1's rmse: 129.631\n",
      "[1140]\ttraining's rmse: 79.771\tvalid_1's rmse: 129.535\n",
      "[1170]\ttraining's rmse: 79.0062\tvalid_1's rmse: 129.488\n",
      "[1200]\ttraining's rmse: 78.3395\tvalid_1's rmse: 129.508\n",
      "[1230]\ttraining's rmse: 77.6134\tvalid_1's rmse: 129.475\n",
      "[1260]\ttraining's rmse: 76.9509\tvalid_1's rmse: 129.46\n",
      "[1290]\ttraining's rmse: 76.319\tvalid_1's rmse: 129.413\n",
      "[1320]\ttraining's rmse: 75.6652\tvalid_1's rmse: 129.373\n",
      "[1350]\ttraining's rmse: 74.9632\tvalid_1's rmse: 129.279\n",
      "[1380]\ttraining's rmse: 74.3156\tvalid_1's rmse: 129.231\n",
      "[1410]\ttraining's rmse: 73.6692\tvalid_1's rmse: 129.19\n",
      "[1440]\ttraining's rmse: 72.9999\tvalid_1's rmse: 129.144\n",
      "[1470]\ttraining's rmse: 72.3319\tvalid_1's rmse: 129.055\n",
      "[1500]\ttraining's rmse: 71.7816\tvalid_1's rmse: 129.033\n",
      "[1530]\ttraining's rmse: 71.1729\tvalid_1's rmse: 129.04\n",
      "[1560]\ttraining's rmse: 70.6404\tvalid_1's rmse: 129.04\n",
      "[1590]\ttraining's rmse: 70.1054\tvalid_1's rmse: 129.042\n",
      "[1620]\ttraining's rmse: 69.6032\tvalid_1's rmse: 129.035\n",
      "[1650]\ttraining's rmse: 69.0791\tvalid_1's rmse: 129.004\n",
      "[1680]\ttraining's rmse: 68.5569\tvalid_1's rmse: 128.987\n",
      "[1710]\ttraining's rmse: 68.0226\tvalid_1's rmse: 128.956\n",
      "[1740]\ttraining's rmse: 67.4765\tvalid_1's rmse: 128.911\n",
      "[1770]\ttraining's rmse: 66.9548\tvalid_1's rmse: 128.871\n",
      "[1800]\ttraining's rmse: 66.4535\tvalid_1's rmse: 128.841\n",
      "[1830]\ttraining's rmse: 65.9661\tvalid_1's rmse: 128.805\n",
      "[1860]\ttraining's rmse: 65.5195\tvalid_1's rmse: 128.773\n",
      "[1890]\ttraining's rmse: 65.0578\tvalid_1's rmse: 128.751\n",
      "[1920]\ttraining's rmse: 64.6196\tvalid_1's rmse: 128.742\n",
      "[1950]\ttraining's rmse: 64.1493\tvalid_1's rmse: 128.714\n",
      "[1980]\ttraining's rmse: 63.7128\tvalid_1's rmse: 128.698\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's rmse: 63.4131\tvalid_1's rmse: 128.672\n",
      "5\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.018421 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 29704\n",
      "[LightGBM] [Info] Number of data points in the train set: 59281, number of used features: 117\n",
      "[LightGBM] [Info] Start training from score 385.401335\n",
      "Training until validation scores don't improve for 125 rounds\n",
      "[30]\ttraining's rmse: 220.907\tvalid_1's rmse: 225.008\n",
      "[60]\ttraining's rmse: 178.403\tvalid_1's rmse: 185.347\n",
      "[90]\ttraining's rmse: 156.786\tvalid_1's rmse: 166.313\n",
      "[120]\ttraining's rmse: 144.286\tvalid_1's rmse: 156.325\n",
      "[150]\ttraining's rmse: 135.998\tvalid_1's rmse: 150.391\n",
      "[180]\ttraining's rmse: 129.935\tvalid_1's rmse: 146.451\n",
      "[210]\ttraining's rmse: 125.022\tvalid_1's rmse: 143.42\n",
      "[240]\ttraining's rmse: 121.064\tvalid_1's rmse: 141.248\n",
      "[270]\ttraining's rmse: 117.614\tvalid_1's rmse: 139.279\n",
      "[300]\ttraining's rmse: 114.785\tvalid_1's rmse: 137.858\n",
      "[330]\ttraining's rmse: 112.468\tvalid_1's rmse: 136.93\n",
      "[360]\ttraining's rmse: 110.185\tvalid_1's rmse: 135.999\n",
      "[390]\ttraining's rmse: 108.312\tvalid_1's rmse: 135.407\n",
      "[420]\ttraining's rmse: 106.364\tvalid_1's rmse: 134.795\n",
      "[450]\ttraining's rmse: 104.668\tvalid_1's rmse: 134.367\n",
      "[480]\ttraining's rmse: 103.14\tvalid_1's rmse: 134.04\n",
      "[510]\ttraining's rmse: 101.641\tvalid_1's rmse: 133.652\n",
      "[540]\ttraining's rmse: 100.325\tvalid_1's rmse: 133.436\n",
      "[570]\ttraining's rmse: 98.8735\tvalid_1's rmse: 133.002\n",
      "[600]\ttraining's rmse: 97.5097\tvalid_1's rmse: 132.751\n",
      "[630]\ttraining's rmse: 96.3159\tvalid_1's rmse: 132.594\n",
      "[660]\ttraining's rmse: 95.179\tvalid_1's rmse: 132.486\n",
      "[690]\ttraining's rmse: 94.055\tvalid_1's rmse: 132.365\n",
      "[720]\ttraining's rmse: 92.9712\tvalid_1's rmse: 132.241\n",
      "[750]\ttraining's rmse: 91.8241\tvalid_1's rmse: 132.002\n",
      "[780]\ttraining's rmse: 90.7475\tvalid_1's rmse: 131.816\n",
      "[810]\ttraining's rmse: 89.6866\tvalid_1's rmse: 131.689\n",
      "[840]\ttraining's rmse: 88.7125\tvalid_1's rmse: 131.621\n",
      "[870]\ttraining's rmse: 87.7895\tvalid_1's rmse: 131.549\n",
      "[900]\ttraining's rmse: 86.8693\tvalid_1's rmse: 131.437\n",
      "[930]\ttraining's rmse: 85.9953\tvalid_1's rmse: 131.289\n",
      "[960]\ttraining's rmse: 85.0755\tvalid_1's rmse: 131.182\n",
      "[990]\ttraining's rmse: 84.146\tvalid_1's rmse: 131.06\n",
      "[1020]\ttraining's rmse: 83.3496\tvalid_1's rmse: 131.047\n",
      "[1050]\ttraining's rmse: 82.4423\tvalid_1's rmse: 130.917\n",
      "[1080]\ttraining's rmse: 81.6788\tvalid_1's rmse: 130.899\n",
      "[1110]\ttraining's rmse: 80.9261\tvalid_1's rmse: 130.879\n",
      "[1140]\ttraining's rmse: 80.0676\tvalid_1's rmse: 130.753\n",
      "[1170]\ttraining's rmse: 79.3587\tvalid_1's rmse: 130.695\n",
      "[1200]\ttraining's rmse: 78.654\tvalid_1's rmse: 130.672\n",
      "[1230]\ttraining's rmse: 77.8952\tvalid_1's rmse: 130.548\n",
      "[1260]\ttraining's rmse: 77.2143\tvalid_1's rmse: 130.459\n",
      "[1290]\ttraining's rmse: 76.5576\tvalid_1's rmse: 130.425\n",
      "[1320]\ttraining's rmse: 75.8751\tvalid_1's rmse: 130.385\n",
      "[1350]\ttraining's rmse: 75.2484\tvalid_1's rmse: 130.342\n",
      "[1380]\ttraining's rmse: 74.5558\tvalid_1's rmse: 130.245\n",
      "[1410]\ttraining's rmse: 73.9118\tvalid_1's rmse: 130.175\n",
      "[1440]\ttraining's rmse: 73.3211\tvalid_1's rmse: 130.119\n",
      "[1470]\ttraining's rmse: 72.6882\tvalid_1's rmse: 130.039\n",
      "[1500]\ttraining's rmse: 72.0769\tvalid_1's rmse: 130.004\n",
      "[1530]\ttraining's rmse: 71.4719\tvalid_1's rmse: 129.988\n",
      "[1560]\ttraining's rmse: 70.9013\tvalid_1's rmse: 129.963\n",
      "[1590]\ttraining's rmse: 70.3494\tvalid_1's rmse: 129.944\n",
      "[1620]\ttraining's rmse: 69.7955\tvalid_1's rmse: 129.912\n",
      "[1650]\ttraining's rmse: 69.2922\tvalid_1's rmse: 129.889\n",
      "[1680]\ttraining's rmse: 68.7481\tvalid_1's rmse: 129.869\n",
      "[1710]\ttraining's rmse: 68.2192\tvalid_1's rmse: 129.824\n",
      "[1740]\ttraining's rmse: 67.7423\tvalid_1's rmse: 129.809\n",
      "[1770]\ttraining's rmse: 67.2321\tvalid_1's rmse: 129.796\n",
      "[1800]\ttraining's rmse: 66.7516\tvalid_1's rmse: 129.764\n",
      "[1830]\ttraining's rmse: 66.2119\tvalid_1's rmse: 129.711\n",
      "[1860]\ttraining's rmse: 65.7205\tvalid_1's rmse: 129.678\n",
      "[1890]\ttraining's rmse: 65.2386\tvalid_1's rmse: 129.654\n",
      "[1920]\ttraining's rmse: 64.8034\tvalid_1's rmse: 129.645\n",
      "[1950]\ttraining's rmse: 64.3625\tvalid_1's rmse: 129.608\n",
      "[1980]\ttraining's rmse: 63.9284\tvalid_1's rmse: 129.615\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's rmse: 63.6067\tvalid_1's rmse: 129.594\n",
      "6\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.017839 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 29705\n",
      "[LightGBM] [Info] Number of data points in the train set: 59281, number of used features: 117\n",
      "[LightGBM] [Info] Start training from score 388.672848\n",
      "Training until validation scores don't improve for 125 rounds\n",
      "[30]\ttraining's rmse: 221.33\tvalid_1's rmse: 223.118\n",
      "[60]\ttraining's rmse: 179.574\tvalid_1's rmse: 184.007\n",
      "[90]\ttraining's rmse: 158.435\tvalid_1's rmse: 165.735\n",
      "[120]\ttraining's rmse: 146.091\tvalid_1's rmse: 156.057\n",
      "[150]\ttraining's rmse: 137.674\tvalid_1's rmse: 150.029\n",
      "[180]\ttraining's rmse: 131.746\tvalid_1's rmse: 146.23\n",
      "[210]\ttraining's rmse: 126.895\tvalid_1's rmse: 143.203\n",
      "[240]\ttraining's rmse: 122.94\tvalid_1's rmse: 141.042\n",
      "[270]\ttraining's rmse: 119.553\tvalid_1's rmse: 139.34\n",
      "[300]\ttraining's rmse: 116.656\tvalid_1's rmse: 137.986\n",
      "[330]\ttraining's rmse: 114.318\tvalid_1's rmse: 137.195\n",
      "[360]\ttraining's rmse: 112.116\tvalid_1's rmse: 136.411\n",
      "[390]\ttraining's rmse: 110.251\tvalid_1's rmse: 135.914\n",
      "[420]\ttraining's rmse: 108.272\tvalid_1's rmse: 135.249\n",
      "[450]\ttraining's rmse: 106.512\tvalid_1's rmse: 134.8\n",
      "[480]\ttraining's rmse: 104.911\tvalid_1's rmse: 134.361\n",
      "[510]\ttraining's rmse: 103.449\tvalid_1's rmse: 134.054\n",
      "[540]\ttraining's rmse: 102.076\tvalid_1's rmse: 133.82\n",
      "[570]\ttraining's rmse: 100.568\tvalid_1's rmse: 133.448\n",
      "[600]\ttraining's rmse: 99.2897\tvalid_1's rmse: 133.212\n",
      "[630]\ttraining's rmse: 97.9468\tvalid_1's rmse: 132.995\n",
      "[660]\ttraining's rmse: 96.6573\tvalid_1's rmse: 132.797\n",
      "[690]\ttraining's rmse: 95.4231\tvalid_1's rmse: 132.608\n",
      "[720]\ttraining's rmse: 94.2674\tvalid_1's rmse: 132.412\n",
      "[750]\ttraining's rmse: 93.2451\tvalid_1's rmse: 132.287\n",
      "[780]\ttraining's rmse: 92.2021\tvalid_1's rmse: 132.186\n",
      "[810]\ttraining's rmse: 91.1295\tvalid_1's rmse: 132.062\n",
      "[840]\ttraining's rmse: 90.2377\tvalid_1's rmse: 132.043\n",
      "[870]\ttraining's rmse: 89.3302\tvalid_1's rmse: 132.028\n",
      "[900]\ttraining's rmse: 88.3767\tvalid_1's rmse: 131.953\n",
      "[930]\ttraining's rmse: 87.4122\tvalid_1's rmse: 131.895\n",
      "[960]\ttraining's rmse: 86.5262\tvalid_1's rmse: 131.784\n",
      "[990]\ttraining's rmse: 85.6188\tvalid_1's rmse: 131.702\n",
      "[1020]\ttraining's rmse: 84.8407\tvalid_1's rmse: 131.683\n",
      "[1050]\ttraining's rmse: 84.0166\tvalid_1's rmse: 131.597\n",
      "[1080]\ttraining's rmse: 83.1825\tvalid_1's rmse: 131.523\n",
      "[1110]\ttraining's rmse: 82.3467\tvalid_1's rmse: 131.391\n",
      "[1140]\ttraining's rmse: 81.5341\tvalid_1's rmse: 131.312\n",
      "[1170]\ttraining's rmse: 80.8147\tvalid_1's rmse: 131.314\n",
      "[1200]\ttraining's rmse: 80.0873\tvalid_1's rmse: 131.327\n",
      "[1230]\ttraining's rmse: 79.3769\tvalid_1's rmse: 131.3\n",
      "[1260]\ttraining's rmse: 78.682\tvalid_1's rmse: 131.241\n",
      "[1290]\ttraining's rmse: 77.9952\tvalid_1's rmse: 131.234\n",
      "[1320]\ttraining's rmse: 77.3385\tvalid_1's rmse: 131.192\n",
      "[1350]\ttraining's rmse: 76.6581\tvalid_1's rmse: 131.156\n",
      "[1380]\ttraining's rmse: 75.9471\tvalid_1's rmse: 131.053\n",
      "[1410]\ttraining's rmse: 75.2728\tvalid_1's rmse: 131.054\n",
      "[1440]\ttraining's rmse: 74.6255\tvalid_1's rmse: 130.998\n",
      "[1470]\ttraining's rmse: 74.0422\tvalid_1's rmse: 130.983\n",
      "[1500]\ttraining's rmse: 73.4649\tvalid_1's rmse: 130.983\n",
      "[1530]\ttraining's rmse: 72.816\tvalid_1's rmse: 130.953\n",
      "[1560]\ttraining's rmse: 72.2258\tvalid_1's rmse: 130.926\n",
      "[1590]\ttraining's rmse: 71.7051\tvalid_1's rmse: 130.927\n",
      "[1620]\ttraining's rmse: 71.219\tvalid_1's rmse: 130.936\n",
      "[1650]\ttraining's rmse: 70.6545\tvalid_1's rmse: 130.891\n",
      "[1680]\ttraining's rmse: 70.1763\tvalid_1's rmse: 130.903\n",
      "[1710]\ttraining's rmse: 69.6603\tvalid_1's rmse: 130.879\n",
      "[1740]\ttraining's rmse: 69.095\tvalid_1's rmse: 130.841\n",
      "[1770]\ttraining's rmse: 68.568\tvalid_1's rmse: 130.848\n",
      "[1800]\ttraining's rmse: 68.0813\tvalid_1's rmse: 130.8\n",
      "[1830]\ttraining's rmse: 67.5529\tvalid_1's rmse: 130.772\n",
      "[1860]\ttraining's rmse: 67.1075\tvalid_1's rmse: 130.746\n",
      "[1890]\ttraining's rmse: 66.6536\tvalid_1's rmse: 130.765\n",
      "[1920]\ttraining's rmse: 66.1268\tvalid_1's rmse: 130.731\n",
      "[1950]\ttraining's rmse: 65.6734\tvalid_1's rmse: 130.703\n",
      "[1980]\ttraining's rmse: 65.2146\tvalid_1's rmse: 130.711\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's rmse: 64.8948\tvalid_1's rmse: 130.694\n",
      "7\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.018531 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 29706\n",
      "[LightGBM] [Info] Number of data points in the train set: 59281, number of used features: 117\n",
      "[LightGBM] [Info] Start training from score 392.051949\n",
      "Training until validation scores don't improve for 125 rounds\n",
      "[30]\ttraining's rmse: 222.711\tvalid_1's rmse: 221.608\n",
      "[60]\ttraining's rmse: 181.417\tvalid_1's rmse: 183.386\n",
      "[90]\ttraining's rmse: 160.401\tvalid_1's rmse: 165.512\n",
      "[120]\ttraining's rmse: 148.043\tvalid_1's rmse: 156.222\n",
      "[150]\ttraining's rmse: 139.688\tvalid_1's rmse: 150.604\n",
      "[180]\ttraining's rmse: 133.7\tvalid_1's rmse: 146.955\n",
      "[210]\ttraining's rmse: 128.72\tvalid_1's rmse: 144.135\n",
      "[240]\ttraining's rmse: 124.799\tvalid_1's rmse: 142.037\n",
      "[270]\ttraining's rmse: 121.302\tvalid_1's rmse: 140.252\n",
      "[300]\ttraining's rmse: 118.409\tvalid_1's rmse: 138.931\n",
      "[330]\ttraining's rmse: 116.187\tvalid_1's rmse: 138.166\n",
      "[360]\ttraining's rmse: 114.027\tvalid_1's rmse: 137.417\n",
      "[390]\ttraining's rmse: 112.096\tvalid_1's rmse: 136.907\n",
      "[420]\ttraining's rmse: 110.12\tvalid_1's rmse: 136.274\n",
      "[450]\ttraining's rmse: 108.372\tvalid_1's rmse: 135.866\n",
      "[480]\ttraining's rmse: 106.818\tvalid_1's rmse: 135.567\n",
      "[510]\ttraining's rmse: 105.213\tvalid_1's rmse: 135.175\n",
      "[540]\ttraining's rmse: 103.648\tvalid_1's rmse: 134.889\n",
      "[570]\ttraining's rmse: 102.245\tvalid_1's rmse: 134.529\n",
      "[600]\ttraining's rmse: 100.918\tvalid_1's rmse: 134.303\n",
      "[630]\ttraining's rmse: 99.7199\tvalid_1's rmse: 134.176\n",
      "[660]\ttraining's rmse: 98.5364\tvalid_1's rmse: 134.04\n",
      "[690]\ttraining's rmse: 97.3079\tvalid_1's rmse: 133.817\n",
      "[720]\ttraining's rmse: 96.2085\tvalid_1's rmse: 133.719\n",
      "[750]\ttraining's rmse: 95.2041\tvalid_1's rmse: 133.645\n",
      "[780]\ttraining's rmse: 94.0267\tvalid_1's rmse: 133.49\n",
      "[810]\ttraining's rmse: 92.9792\tvalid_1's rmse: 133.368\n",
      "[840]\ttraining's rmse: 91.9341\tvalid_1's rmse: 133.293\n",
      "[870]\ttraining's rmse: 91.0009\tvalid_1's rmse: 133.244\n",
      "[900]\ttraining's rmse: 90.0711\tvalid_1's rmse: 133.199\n",
      "[930]\ttraining's rmse: 89.0853\tvalid_1's rmse: 133.071\n",
      "[960]\ttraining's rmse: 88.1895\tvalid_1's rmse: 132.97\n",
      "[990]\ttraining's rmse: 87.2992\tvalid_1's rmse: 132.906\n",
      "[1020]\ttraining's rmse: 86.4159\tvalid_1's rmse: 132.778\n",
      "[1050]\ttraining's rmse: 85.5278\tvalid_1's rmse: 132.699\n",
      "[1080]\ttraining's rmse: 84.7382\tvalid_1's rmse: 132.644\n",
      "[1110]\ttraining's rmse: 83.9547\tvalid_1's rmse: 132.62\n",
      "[1140]\ttraining's rmse: 83.1414\tvalid_1's rmse: 132.557\n",
      "[1170]\ttraining's rmse: 82.3227\tvalid_1's rmse: 132.468\n",
      "[1200]\ttraining's rmse: 81.4998\tvalid_1's rmse: 132.345\n",
      "[1230]\ttraining's rmse: 80.7349\tvalid_1's rmse: 132.346\n",
      "[1260]\ttraining's rmse: 80.0312\tvalid_1's rmse: 132.301\n",
      "[1290]\ttraining's rmse: 79.2769\tvalid_1's rmse: 132.205\n",
      "[1320]\ttraining's rmse: 78.6152\tvalid_1's rmse: 132.164\n",
      "[1350]\ttraining's rmse: 77.8835\tvalid_1's rmse: 132.128\n",
      "[1380]\ttraining's rmse: 77.2366\tvalid_1's rmse: 132.083\n",
      "[1410]\ttraining's rmse: 76.6104\tvalid_1's rmse: 132.069\n",
      "[1440]\ttraining's rmse: 75.9729\tvalid_1's rmse: 131.993\n",
      "[1470]\ttraining's rmse: 75.241\tvalid_1's rmse: 131.839\n",
      "[1500]\ttraining's rmse: 74.5723\tvalid_1's rmse: 131.796\n",
      "[1530]\ttraining's rmse: 74.0074\tvalid_1's rmse: 131.778\n",
      "[1560]\ttraining's rmse: 73.4231\tvalid_1's rmse: 131.734\n",
      "[1590]\ttraining's rmse: 72.793\tvalid_1's rmse: 131.699\n",
      "[1620]\ttraining's rmse: 72.2315\tvalid_1's rmse: 131.693\n",
      "[1650]\ttraining's rmse: 71.6429\tvalid_1's rmse: 131.67\n",
      "[1680]\ttraining's rmse: 71.0306\tvalid_1's rmse: 131.629\n",
      "[1710]\ttraining's rmse: 70.4759\tvalid_1's rmse: 131.61\n",
      "[1740]\ttraining's rmse: 69.8883\tvalid_1's rmse: 131.577\n",
      "[1770]\ttraining's rmse: 69.3309\tvalid_1's rmse: 131.538\n",
      "[1800]\ttraining's rmse: 68.802\tvalid_1's rmse: 131.522\n",
      "[1830]\ttraining's rmse: 68.3099\tvalid_1's rmse: 131.512\n",
      "[1860]\ttraining's rmse: 67.7817\tvalid_1's rmse: 131.443\n",
      "[1890]\ttraining's rmse: 67.2678\tvalid_1's rmse: 131.414\n",
      "[1920]\ttraining's rmse: 66.7564\tvalid_1's rmse: 131.394\n",
      "[1950]\ttraining's rmse: 66.2274\tvalid_1's rmse: 131.338\n",
      "[1980]\ttraining's rmse: 65.7621\tvalid_1's rmse: 131.33\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's rmse: 65.4471\tvalid_1's rmse: 131.303\n",
      "8\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.023735 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 29707\n",
      "[LightGBM] [Info] Number of data points in the train set: 59281, number of used features: 117\n",
      "[LightGBM] [Info] Start training from score 388.210557\n",
      "Training until validation scores don't improve for 125 rounds\n",
      "[30]\ttraining's rmse: 221.335\tvalid_1's rmse: 223.57\n",
      "[60]\ttraining's rmse: 179.996\tvalid_1's rmse: 184.922\n",
      "[90]\ttraining's rmse: 158.932\tvalid_1's rmse: 166.853\n",
      "[120]\ttraining's rmse: 146.666\tvalid_1's rmse: 157.646\n",
      "[150]\ttraining's rmse: 138.42\tvalid_1's rmse: 152.092\n",
      "[180]\ttraining's rmse: 132.485\tvalid_1's rmse: 148.407\n",
      "[210]\ttraining's rmse: 127.712\tvalid_1's rmse: 145.622\n",
      "[240]\ttraining's rmse: 123.949\tvalid_1's rmse: 143.628\n",
      "[270]\ttraining's rmse: 120.588\tvalid_1's rmse: 141.76\n",
      "[300]\ttraining's rmse: 117.622\tvalid_1's rmse: 140.323\n",
      "[330]\ttraining's rmse: 115.372\tvalid_1's rmse: 139.567\n",
      "[360]\ttraining's rmse: 113.144\tvalid_1's rmse: 138.778\n",
      "[390]\ttraining's rmse: 111.286\tvalid_1's rmse: 138.23\n",
      "[420]\ttraining's rmse: 109.264\tvalid_1's rmse: 137.575\n",
      "[450]\ttraining's rmse: 107.552\tvalid_1's rmse: 137.133\n",
      "[480]\ttraining's rmse: 105.988\tvalid_1's rmse: 136.779\n",
      "[510]\ttraining's rmse: 104.373\tvalid_1's rmse: 136.433\n",
      "[540]\ttraining's rmse: 102.866\tvalid_1's rmse: 136.131\n",
      "[570]\ttraining's rmse: 101.385\tvalid_1's rmse: 135.802\n",
      "[600]\ttraining's rmse: 99.9192\tvalid_1's rmse: 135.469\n",
      "[630]\ttraining's rmse: 98.6435\tvalid_1's rmse: 135.274\n",
      "[660]\ttraining's rmse: 97.3453\tvalid_1's rmse: 135.111\n",
      "[690]\ttraining's rmse: 96.1498\tvalid_1's rmse: 134.901\n",
      "[720]\ttraining's rmse: 94.9397\tvalid_1's rmse: 134.742\n",
      "[750]\ttraining's rmse: 93.8292\tvalid_1's rmse: 134.584\n",
      "[780]\ttraining's rmse: 92.6923\tvalid_1's rmse: 134.379\n",
      "[810]\ttraining's rmse: 91.5861\tvalid_1's rmse: 134.172\n",
      "[840]\ttraining's rmse: 90.583\tvalid_1's rmse: 134.072\n",
      "[870]\ttraining's rmse: 89.6755\tvalid_1's rmse: 134.07\n",
      "[900]\ttraining's rmse: 88.7191\tvalid_1's rmse: 133.985\n",
      "[930]\ttraining's rmse: 87.7676\tvalid_1's rmse: 133.889\n",
      "[960]\ttraining's rmse: 86.841\tvalid_1's rmse: 133.783\n",
      "[990]\ttraining's rmse: 86.0482\tvalid_1's rmse: 133.761\n",
      "[1020]\ttraining's rmse: 85.2094\tvalid_1's rmse: 133.73\n",
      "[1050]\ttraining's rmse: 84.3353\tvalid_1's rmse: 133.677\n",
      "[1080]\ttraining's rmse: 83.5582\tvalid_1's rmse: 133.633\n",
      "[1110]\ttraining's rmse: 82.7403\tvalid_1's rmse: 133.522\n",
      "[1140]\ttraining's rmse: 81.9363\tvalid_1's rmse: 133.463\n",
      "[1170]\ttraining's rmse: 81.1836\tvalid_1's rmse: 133.414\n",
      "[1200]\ttraining's rmse: 80.4025\tvalid_1's rmse: 133.332\n",
      "[1230]\ttraining's rmse: 79.6294\tvalid_1's rmse: 133.295\n",
      "[1260]\ttraining's rmse: 78.9956\tvalid_1's rmse: 133.304\n",
      "[1290]\ttraining's rmse: 78.3261\tvalid_1's rmse: 133.26\n",
      "[1320]\ttraining's rmse: 77.5878\tvalid_1's rmse: 133.217\n",
      "[1350]\ttraining's rmse: 76.9157\tvalid_1's rmse: 133.197\n",
      "[1380]\ttraining's rmse: 76.2507\tvalid_1's rmse: 133.139\n",
      "[1410]\ttraining's rmse: 75.6346\tvalid_1's rmse: 133.125\n",
      "[1440]\ttraining's rmse: 74.9307\tvalid_1's rmse: 133.029\n",
      "[1470]\ttraining's rmse: 74.3289\tvalid_1's rmse: 132.984\n",
      "[1500]\ttraining's rmse: 73.7305\tvalid_1's rmse: 132.928\n",
      "[1530]\ttraining's rmse: 73.1689\tvalid_1's rmse: 132.926\n",
      "[1560]\ttraining's rmse: 72.6274\tvalid_1's rmse: 132.927\n",
      "[1590]\ttraining's rmse: 72.011\tvalid_1's rmse: 132.855\n",
      "[1620]\ttraining's rmse: 71.4834\tvalid_1's rmse: 132.869\n",
      "[1650]\ttraining's rmse: 70.9538\tvalid_1's rmse: 132.836\n",
      "[1680]\ttraining's rmse: 70.3813\tvalid_1's rmse: 132.778\n",
      "[1710]\ttraining's rmse: 69.8578\tvalid_1's rmse: 132.758\n",
      "[1740]\ttraining's rmse: 69.3265\tvalid_1's rmse: 132.685\n",
      "[1770]\ttraining's rmse: 68.7941\tvalid_1's rmse: 132.658\n",
      "[1800]\ttraining's rmse: 68.2907\tvalid_1's rmse: 132.635\n",
      "[1830]\ttraining's rmse: 67.7934\tvalid_1's rmse: 132.605\n",
      "[1860]\ttraining's rmse: 67.3024\tvalid_1's rmse: 132.593\n",
      "[1890]\ttraining's rmse: 66.8007\tvalid_1's rmse: 132.554\n",
      "[1920]\ttraining's rmse: 66.2817\tvalid_1's rmse: 132.51\n",
      "[1950]\ttraining's rmse: 65.8009\tvalid_1's rmse: 132.483\n",
      "[1980]\ttraining's rmse: 65.3493\tvalid_1's rmse: 132.488\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's rmse: 65.0088\tvalid_1's rmse: 132.443\n",
      "9\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.022879 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 29707\n",
      "[LightGBM] [Info] Number of data points in the train set: 59281, number of used features: 117\n",
      "[LightGBM] [Info] Start training from score 385.372676\n",
      "Training until validation scores don't improve for 125 rounds\n",
      "[30]\ttraining's rmse: 219.871\tvalid_1's rmse: 221.976\n",
      "[60]\ttraining's rmse: 178.078\tvalid_1's rmse: 182.779\n",
      "[90]\ttraining's rmse: 156.571\tvalid_1's rmse: 163.792\n",
      "[120]\ttraining's rmse: 144.196\tvalid_1's rmse: 154.03\n",
      "[150]\ttraining's rmse: 136.015\tvalid_1's rmse: 148.056\n",
      "[180]\ttraining's rmse: 130.099\tvalid_1's rmse: 144.25\n",
      "[210]\ttraining's rmse: 125.406\tvalid_1's rmse: 141.347\n",
      "[240]\ttraining's rmse: 121.605\tvalid_1's rmse: 139.251\n",
      "[270]\ttraining's rmse: 118.291\tvalid_1's rmse: 137.516\n",
      "[300]\ttraining's rmse: 115.569\tvalid_1's rmse: 136.278\n",
      "[330]\ttraining's rmse: 113.353\tvalid_1's rmse: 135.531\n",
      "[360]\ttraining's rmse: 111.325\tvalid_1's rmse: 134.86\n",
      "[390]\ttraining's rmse: 109.443\tvalid_1's rmse: 134.29\n",
      "[420]\ttraining's rmse: 107.652\tvalid_1's rmse: 133.725\n",
      "[450]\ttraining's rmse: 106.051\tvalid_1's rmse: 133.351\n",
      "[480]\ttraining's rmse: 104.499\tvalid_1's rmse: 132.998\n",
      "[510]\ttraining's rmse: 103.115\tvalid_1's rmse: 132.796\n",
      "[540]\ttraining's rmse: 101.743\tvalid_1's rmse: 132.467\n",
      "[570]\ttraining's rmse: 100.248\tvalid_1's rmse: 132.055\n",
      "[600]\ttraining's rmse: 98.8971\tvalid_1's rmse: 131.795\n",
      "[630]\ttraining's rmse: 97.6582\tvalid_1's rmse: 131.59\n",
      "[660]\ttraining's rmse: 96.4507\tvalid_1's rmse: 131.387\n",
      "[690]\ttraining's rmse: 95.255\tvalid_1's rmse: 131.152\n",
      "[720]\ttraining's rmse: 94.1501\tvalid_1's rmse: 131.003\n",
      "[750]\ttraining's rmse: 93.0083\tvalid_1's rmse: 130.808\n",
      "[780]\ttraining's rmse: 91.9019\tvalid_1's rmse: 130.629\n",
      "[810]\ttraining's rmse: 90.8038\tvalid_1's rmse: 130.416\n",
      "[840]\ttraining's rmse: 89.879\tvalid_1's rmse: 130.322\n",
      "[870]\ttraining's rmse: 88.9302\tvalid_1's rmse: 130.252\n",
      "[900]\ttraining's rmse: 87.9829\tvalid_1's rmse: 130.142\n",
      "[930]\ttraining's rmse: 87.0663\tvalid_1's rmse: 130.014\n",
      "[960]\ttraining's rmse: 86.2023\tvalid_1's rmse: 129.908\n",
      "[990]\ttraining's rmse: 85.3448\tvalid_1's rmse: 129.815\n",
      "[1020]\ttraining's rmse: 84.4848\tvalid_1's rmse: 129.724\n",
      "[1050]\ttraining's rmse: 83.6502\tvalid_1's rmse: 129.643\n",
      "[1080]\ttraining's rmse: 82.8274\tvalid_1's rmse: 129.575\n",
      "[1110]\ttraining's rmse: 82.0256\tvalid_1's rmse: 129.443\n",
      "[1140]\ttraining's rmse: 81.2058\tvalid_1's rmse: 129.324\n",
      "[1170]\ttraining's rmse: 80.4511\tvalid_1's rmse: 129.21\n",
      "[1200]\ttraining's rmse: 79.7123\tvalid_1's rmse: 129.12\n",
      "[1230]\ttraining's rmse: 78.9936\tvalid_1's rmse: 129.019\n",
      "[1260]\ttraining's rmse: 78.2469\tvalid_1's rmse: 128.945\n",
      "[1290]\ttraining's rmse: 77.553\tvalid_1's rmse: 128.892\n",
      "[1320]\ttraining's rmse: 76.8928\tvalid_1's rmse: 128.884\n",
      "[1350]\ttraining's rmse: 76.2071\tvalid_1's rmse: 128.809\n",
      "[1380]\ttraining's rmse: 75.4893\tvalid_1's rmse: 128.715\n",
      "[1410]\ttraining's rmse: 74.9062\tvalid_1's rmse: 128.706\n",
      "[1440]\ttraining's rmse: 74.3183\tvalid_1's rmse: 128.706\n",
      "[1470]\ttraining's rmse: 73.7296\tvalid_1's rmse: 128.68\n",
      "[1500]\ttraining's rmse: 73.1514\tvalid_1's rmse: 128.668\n",
      "[1530]\ttraining's rmse: 72.5356\tvalid_1's rmse: 128.631\n",
      "[1560]\ttraining's rmse: 71.9583\tvalid_1's rmse: 128.585\n",
      "[1590]\ttraining's rmse: 71.3606\tvalid_1's rmse: 128.534\n",
      "[1620]\ttraining's rmse: 70.8241\tvalid_1's rmse: 128.516\n",
      "[1650]\ttraining's rmse: 70.304\tvalid_1's rmse: 128.476\n",
      "[1680]\ttraining's rmse: 69.739\tvalid_1's rmse: 128.383\n",
      "[1710]\ttraining's rmse: 69.1971\tvalid_1's rmse: 128.345\n",
      "[1740]\ttraining's rmse: 68.6425\tvalid_1's rmse: 128.319\n",
      "[1770]\ttraining's rmse: 68.1105\tvalid_1's rmse: 128.279\n",
      "[1800]\ttraining's rmse: 67.6206\tvalid_1's rmse: 128.254\n",
      "[1830]\ttraining's rmse: 67.1274\tvalid_1's rmse: 128.219\n",
      "[1860]\ttraining's rmse: 66.643\tvalid_1's rmse: 128.213\n",
      "[1890]\ttraining's rmse: 66.162\tvalid_1's rmse: 128.165\n",
      "[1920]\ttraining's rmse: 65.7107\tvalid_1's rmse: 128.161\n",
      "[1950]\ttraining's rmse: 65.2346\tvalid_1's rmse: 128.141\n",
      "[1980]\ttraining's rmse: 64.7389\tvalid_1's rmse: 128.123\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's rmse: 64.4394\tvalid_1's rmse: 128.113\n",
      "10\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.022233 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 29706\n",
      "[LightGBM] [Info] Number of data points in the train set: 59281, number of used features: 117\n",
      "[LightGBM] [Info] Start training from score 386.230886\n",
      "Training until validation scores don't improve for 125 rounds\n",
      "[30]\ttraining's rmse: 218.107\tvalid_1's rmse: 217.175\n",
      "[60]\ttraining's rmse: 176.021\tvalid_1's rmse: 178.358\n",
      "[90]\ttraining's rmse: 154.127\tvalid_1's rmse: 159.432\n",
      "[120]\ttraining's rmse: 141.656\tvalid_1's rmse: 149.675\n",
      "[150]\ttraining's rmse: 133.428\tvalid_1's rmse: 143.76\n",
      "[180]\ttraining's rmse: 127.41\tvalid_1's rmse: 139.756\n",
      "[210]\ttraining's rmse: 122.782\tvalid_1's rmse: 136.96\n",
      "[240]\ttraining's rmse: 119.022\tvalid_1's rmse: 134.909\n",
      "[270]\ttraining's rmse: 115.889\tvalid_1's rmse: 133.25\n",
      "[300]\ttraining's rmse: 113.257\tvalid_1's rmse: 132.094\n",
      "[330]\ttraining's rmse: 111.062\tvalid_1's rmse: 131.285\n",
      "[360]\ttraining's rmse: 109.014\tvalid_1's rmse: 130.567\n",
      "[390]\ttraining's rmse: 107.162\tvalid_1's rmse: 130.049\n",
      "[420]\ttraining's rmse: 105.425\tvalid_1's rmse: 129.535\n",
      "[450]\ttraining's rmse: 103.78\tvalid_1's rmse: 129.054\n",
      "[480]\ttraining's rmse: 102.321\tvalid_1's rmse: 128.776\n",
      "[510]\ttraining's rmse: 100.735\tvalid_1's rmse: 128.283\n",
      "[540]\ttraining's rmse: 99.3\tvalid_1's rmse: 127.953\n",
      "[570]\ttraining's rmse: 97.9888\tvalid_1's rmse: 127.648\n",
      "[600]\ttraining's rmse: 96.6256\tvalid_1's rmse: 127.345\n",
      "[630]\ttraining's rmse: 95.362\tvalid_1's rmse: 127.044\n",
      "[660]\ttraining's rmse: 94.2781\tvalid_1's rmse: 126.991\n",
      "[690]\ttraining's rmse: 93.1066\tvalid_1's rmse: 126.743\n",
      "[720]\ttraining's rmse: 91.9942\tvalid_1's rmse: 126.58\n",
      "[750]\ttraining's rmse: 90.923\tvalid_1's rmse: 126.438\n",
      "[780]\ttraining's rmse: 89.853\tvalid_1's rmse: 126.241\n",
      "[810]\ttraining's rmse: 88.7665\tvalid_1's rmse: 126.111\n",
      "[840]\ttraining's rmse: 87.808\tvalid_1's rmse: 126.075\n",
      "[870]\ttraining's rmse: 86.8598\tvalid_1's rmse: 126.001\n",
      "[900]\ttraining's rmse: 85.9313\tvalid_1's rmse: 125.921\n",
      "[930]\ttraining's rmse: 85.0663\tvalid_1's rmse: 125.821\n",
      "[960]\ttraining's rmse: 84.1409\tvalid_1's rmse: 125.68\n",
      "[990]\ttraining's rmse: 83.2625\tvalid_1's rmse: 125.551\n",
      "[1020]\ttraining's rmse: 82.4403\tvalid_1's rmse: 125.47\n",
      "[1050]\ttraining's rmse: 81.5667\tvalid_1's rmse: 125.305\n",
      "[1080]\ttraining's rmse: 80.7518\tvalid_1's rmse: 125.204\n",
      "[1110]\ttraining's rmse: 79.9814\tvalid_1's rmse: 125.108\n",
      "[1140]\ttraining's rmse: 79.1485\tvalid_1's rmse: 124.95\n",
      "[1170]\ttraining's rmse: 78.3864\tvalid_1's rmse: 124.823\n",
      "[1200]\ttraining's rmse: 77.6759\tvalid_1's rmse: 124.811\n",
      "[1230]\ttraining's rmse: 76.9447\tvalid_1's rmse: 124.761\n",
      "[1260]\ttraining's rmse: 76.2129\tvalid_1's rmse: 124.711\n",
      "[1290]\ttraining's rmse: 75.5911\tvalid_1's rmse: 124.709\n",
      "[1320]\ttraining's rmse: 74.9414\tvalid_1's rmse: 124.687\n",
      "[1350]\ttraining's rmse: 74.3689\tvalid_1's rmse: 124.7\n",
      "[1380]\ttraining's rmse: 73.698\tvalid_1's rmse: 124.672\n",
      "[1410]\ttraining's rmse: 73.1094\tvalid_1's rmse: 124.682\n",
      "[1440]\ttraining's rmse: 72.4566\tvalid_1's rmse: 124.634\n",
      "[1470]\ttraining's rmse: 71.8335\tvalid_1's rmse: 124.587\n",
      "[1500]\ttraining's rmse: 71.264\tvalid_1's rmse: 124.551\n",
      "[1530]\ttraining's rmse: 70.6973\tvalid_1's rmse: 124.537\n",
      "[1560]\ttraining's rmse: 70.1704\tvalid_1's rmse: 124.552\n",
      "[1590]\ttraining's rmse: 69.6145\tvalid_1's rmse: 124.514\n",
      "[1620]\ttraining's rmse: 69.1016\tvalid_1's rmse: 124.491\n",
      "[1650]\ttraining's rmse: 68.565\tvalid_1's rmse: 124.464\n",
      "[1680]\ttraining's rmse: 68.0275\tvalid_1's rmse: 124.442\n",
      "[1710]\ttraining's rmse: 67.4973\tvalid_1's rmse: 124.403\n",
      "[1740]\ttraining's rmse: 66.9961\tvalid_1's rmse: 124.39\n",
      "[1770]\ttraining's rmse: 66.492\tvalid_1's rmse: 124.372\n",
      "[1800]\ttraining's rmse: 65.9822\tvalid_1's rmse: 124.34\n",
      "[1830]\ttraining's rmse: 65.4776\tvalid_1's rmse: 124.29\n",
      "[1860]\ttraining's rmse: 65.0194\tvalid_1's rmse: 124.28\n",
      "[1890]\ttraining's rmse: 64.5668\tvalid_1's rmse: 124.278\n",
      "[1920]\ttraining's rmse: 64.0965\tvalid_1's rmse: 124.258\n",
      "[1950]\ttraining's rmse: 63.6585\tvalid_1's rmse: 124.257\n",
      "[1980]\ttraining's rmse: 63.168\tvalid_1's rmse: 124.243\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's rmse: 62.8953\tvalid_1's rmse: 124.233\n",
      "11\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.023355 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 29704\n",
      "[LightGBM] [Info] Number of data points in the train set: 59281, number of used features: 117\n",
      "[LightGBM] [Info] Start training from score 383.935364\n",
      "Training until validation scores don't improve for 125 rounds\n",
      "[30]\ttraining's rmse: 214.184\tvalid_1's rmse: 213.101\n",
      "[60]\ttraining's rmse: 171.483\tvalid_1's rmse: 174.088\n",
      "[90]\ttraining's rmse: 149.222\tvalid_1's rmse: 155.23\n",
      "[120]\ttraining's rmse: 136.75\tvalid_1's rmse: 145.721\n",
      "[150]\ttraining's rmse: 128.511\tvalid_1's rmse: 140.065\n",
      "[180]\ttraining's rmse: 122.716\tvalid_1's rmse: 136.366\n",
      "[210]\ttraining's rmse: 118.355\tvalid_1's rmse: 133.851\n",
      "[240]\ttraining's rmse: 114.811\tvalid_1's rmse: 132.114\n",
      "[270]\ttraining's rmse: 111.72\tvalid_1's rmse: 130.57\n",
      "[300]\ttraining's rmse: 108.993\tvalid_1's rmse: 129.338\n",
      "[330]\ttraining's rmse: 106.957\tvalid_1's rmse: 128.711\n",
      "[360]\ttraining's rmse: 104.961\tvalid_1's rmse: 128.086\n",
      "[390]\ttraining's rmse: 103.197\tvalid_1's rmse: 127.613\n",
      "[420]\ttraining's rmse: 101.376\tvalid_1's rmse: 126.93\n",
      "[450]\ttraining's rmse: 99.7921\tvalid_1's rmse: 126.545\n",
      "[480]\ttraining's rmse: 98.3673\tvalid_1's rmse: 126.286\n",
      "[510]\ttraining's rmse: 96.8817\tvalid_1's rmse: 125.895\n",
      "[540]\ttraining's rmse: 95.4999\tvalid_1's rmse: 125.622\n",
      "[570]\ttraining's rmse: 94.0443\tvalid_1's rmse: 125.189\n",
      "[600]\ttraining's rmse: 92.752\tvalid_1's rmse: 124.944\n",
      "[630]\ttraining's rmse: 91.4908\tvalid_1's rmse: 124.717\n",
      "[660]\ttraining's rmse: 90.4298\tvalid_1's rmse: 124.649\n",
      "[690]\ttraining's rmse: 89.3306\tvalid_1's rmse: 124.444\n",
      "[720]\ttraining's rmse: 88.2943\tvalid_1's rmse: 124.296\n",
      "[750]\ttraining's rmse: 87.1993\tvalid_1's rmse: 124.12\n",
      "[780]\ttraining's rmse: 86.2158\tvalid_1's rmse: 123.975\n",
      "[810]\ttraining's rmse: 85.2236\tvalid_1's rmse: 123.801\n",
      "[840]\ttraining's rmse: 84.3181\tvalid_1's rmse: 123.71\n",
      "[870]\ttraining's rmse: 83.4367\tvalid_1's rmse: 123.622\n",
      "[900]\ttraining's rmse: 82.5965\tvalid_1's rmse: 123.55\n",
      "[930]\ttraining's rmse: 81.705\tvalid_1's rmse: 123.469\n",
      "[960]\ttraining's rmse: 80.8163\tvalid_1's rmse: 123.354\n",
      "[990]\ttraining's rmse: 80.0212\tvalid_1's rmse: 123.262\n",
      "[1020]\ttraining's rmse: 79.2354\tvalid_1's rmse: 123.195\n",
      "[1050]\ttraining's rmse: 78.4992\tvalid_1's rmse: 123.139\n",
      "[1080]\ttraining's rmse: 77.7182\tvalid_1's rmse: 123.076\n",
      "[1110]\ttraining's rmse: 76.9846\tvalid_1's rmse: 122.985\n",
      "[1140]\ttraining's rmse: 76.1955\tvalid_1's rmse: 122.883\n",
      "[1170]\ttraining's rmse: 75.473\tvalid_1's rmse: 122.805\n",
      "[1200]\ttraining's rmse: 74.7734\tvalid_1's rmse: 122.73\n",
      "[1230]\ttraining's rmse: 74.0313\tvalid_1's rmse: 122.63\n",
      "[1260]\ttraining's rmse: 73.4159\tvalid_1's rmse: 122.633\n",
      "[1290]\ttraining's rmse: 72.7565\tvalid_1's rmse: 122.574\n",
      "[1320]\ttraining's rmse: 72.0911\tvalid_1's rmse: 122.523\n",
      "[1350]\ttraining's rmse: 71.4377\tvalid_1's rmse: 122.494\n",
      "[1380]\ttraining's rmse: 70.7755\tvalid_1's rmse: 122.414\n",
      "[1410]\ttraining's rmse: 70.1965\tvalid_1's rmse: 122.361\n",
      "[1440]\ttraining's rmse: 69.5804\tvalid_1's rmse: 122.296\n",
      "[1470]\ttraining's rmse: 68.9912\tvalid_1's rmse: 122.229\n",
      "[1500]\ttraining's rmse: 68.4334\tvalid_1's rmse: 122.169\n",
      "[1530]\ttraining's rmse: 67.835\tvalid_1's rmse: 122.112\n",
      "[1560]\ttraining's rmse: 67.3147\tvalid_1's rmse: 122.105\n",
      "[1590]\ttraining's rmse: 66.7626\tvalid_1's rmse: 122.104\n",
      "[1620]\ttraining's rmse: 66.234\tvalid_1's rmse: 122.06\n",
      "[1650]\ttraining's rmse: 65.7541\tvalid_1's rmse: 122.07\n",
      "[1680]\ttraining's rmse: 65.226\tvalid_1's rmse: 122.025\n",
      "[1710]\ttraining's rmse: 64.6771\tvalid_1's rmse: 121.954\n",
      "[1740]\ttraining's rmse: 64.1588\tvalid_1's rmse: 121.875\n",
      "[1770]\ttraining's rmse: 63.6703\tvalid_1's rmse: 121.847\n",
      "[1800]\ttraining's rmse: 63.1993\tvalid_1's rmse: 121.825\n",
      "[1830]\ttraining's rmse: 62.7817\tvalid_1's rmse: 121.798\n",
      "[1860]\ttraining's rmse: 62.3452\tvalid_1's rmse: 121.782\n",
      "[1890]\ttraining's rmse: 61.9339\tvalid_1's rmse: 121.783\n",
      "[1920]\ttraining's rmse: 61.5294\tvalid_1's rmse: 121.75\n",
      "[1950]\ttraining's rmse: 61.095\tvalid_1's rmse: 121.734\n",
      "[1980]\ttraining's rmse: 60.6491\tvalid_1's rmse: 121.709\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's rmse: 60.3387\tvalid_1's rmse: 121.693\n",
      "12\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.018581 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 29703\n",
      "[LightGBM] [Info] Number of data points in the train set: 59281, number of used features: 117\n",
      "[LightGBM] [Info] Start training from score 378.838733\n",
      "Training until validation scores don't improve for 125 rounds\n",
      "[30]\ttraining's rmse: 208.111\tvalid_1's rmse: 212.911\n",
      "[60]\ttraining's rmse: 166.797\tvalid_1's rmse: 173.775\n",
      "[90]\ttraining's rmse: 145.529\tvalid_1's rmse: 154.58\n",
      "[120]\ttraining's rmse: 133.323\tvalid_1's rmse: 144.62\n",
      "[150]\ttraining's rmse: 125.569\tvalid_1's rmse: 138.763\n",
      "[180]\ttraining's rmse: 120.105\tvalid_1's rmse: 135.13\n",
      "[210]\ttraining's rmse: 115.712\tvalid_1's rmse: 132.468\n",
      "[240]\ttraining's rmse: 112.304\tvalid_1's rmse: 130.687\n",
      "[270]\ttraining's rmse: 109.371\tvalid_1's rmse: 129.234\n",
      "[300]\ttraining's rmse: 106.918\tvalid_1's rmse: 128.198\n",
      "[330]\ttraining's rmse: 104.893\tvalid_1's rmse: 127.619\n",
      "[360]\ttraining's rmse: 102.986\tvalid_1's rmse: 127.133\n",
      "[390]\ttraining's rmse: 101.394\tvalid_1's rmse: 126.846\n",
      "[420]\ttraining's rmse: 99.5486\tvalid_1's rmse: 126.222\n",
      "[450]\ttraining's rmse: 98.0472\tvalid_1's rmse: 125.927\n",
      "[480]\ttraining's rmse: 96.7197\tvalid_1's rmse: 125.721\n",
      "[510]\ttraining's rmse: 95.3503\tvalid_1's rmse: 125.443\n",
      "[540]\ttraining's rmse: 93.9526\tvalid_1's rmse: 125.083\n",
      "[570]\ttraining's rmse: 92.6168\tvalid_1's rmse: 124.755\n",
      "[600]\ttraining's rmse: 91.4062\tvalid_1's rmse: 124.531\n",
      "[630]\ttraining's rmse: 90.3206\tvalid_1's rmse: 124.43\n",
      "[660]\ttraining's rmse: 89.2474\tvalid_1's rmse: 124.361\n",
      "[690]\ttraining's rmse: 88.1441\tvalid_1's rmse: 124.222\n",
      "[720]\ttraining's rmse: 87.1105\tvalid_1's rmse: 124.065\n",
      "[750]\ttraining's rmse: 86.0695\tvalid_1's rmse: 123.915\n",
      "[780]\ttraining's rmse: 85.062\tvalid_1's rmse: 123.787\n",
      "[810]\ttraining's rmse: 84.1195\tvalid_1's rmse: 123.689\n",
      "[840]\ttraining's rmse: 83.3302\tvalid_1's rmse: 123.69\n",
      "[870]\ttraining's rmse: 82.4272\tvalid_1's rmse: 123.664\n",
      "[900]\ttraining's rmse: 81.5801\tvalid_1's rmse: 123.596\n",
      "[930]\ttraining's rmse: 80.7385\tvalid_1's rmse: 123.507\n",
      "[960]\ttraining's rmse: 79.9143\tvalid_1's rmse: 123.417\n",
      "[990]\ttraining's rmse: 79.0901\tvalid_1's rmse: 123.339\n",
      "[1020]\ttraining's rmse: 78.3069\tvalid_1's rmse: 123.294\n",
      "[1050]\ttraining's rmse: 77.5221\tvalid_1's rmse: 123.242\n",
      "[1080]\ttraining's rmse: 76.7231\tvalid_1's rmse: 123.113\n",
      "[1110]\ttraining's rmse: 75.9936\tvalid_1's rmse: 123.085\n",
      "[1140]\ttraining's rmse: 75.2966\tvalid_1's rmse: 123.051\n",
      "[1170]\ttraining's rmse: 74.5218\tvalid_1's rmse: 122.928\n",
      "[1200]\ttraining's rmse: 73.7972\tvalid_1's rmse: 122.867\n",
      "[1230]\ttraining's rmse: 73.1358\tvalid_1's rmse: 122.841\n",
      "[1260]\ttraining's rmse: 72.5089\tvalid_1's rmse: 122.856\n",
      "[1290]\ttraining's rmse: 71.88\tvalid_1's rmse: 122.816\n",
      "[1320]\ttraining's rmse: 71.1934\tvalid_1's rmse: 122.773\n",
      "[1350]\ttraining's rmse: 70.5663\tvalid_1's rmse: 122.752\n",
      "[1380]\ttraining's rmse: 69.9668\tvalid_1's rmse: 122.734\n",
      "[1410]\ttraining's rmse: 69.3817\tvalid_1's rmse: 122.696\n",
      "[1440]\ttraining's rmse: 68.752\tvalid_1's rmse: 122.614\n",
      "[1470]\ttraining's rmse: 68.1811\tvalid_1's rmse: 122.551\n",
      "[1500]\ttraining's rmse: 67.6015\tvalid_1's rmse: 122.523\n",
      "[1530]\ttraining's rmse: 67.0246\tvalid_1's rmse: 122.486\n",
      "[1560]\ttraining's rmse: 66.4942\tvalid_1's rmse: 122.484\n",
      "[1590]\ttraining's rmse: 65.9307\tvalid_1's rmse: 122.446\n",
      "[1620]\ttraining's rmse: 65.4121\tvalid_1's rmse: 122.442\n",
      "[1650]\ttraining's rmse: 64.9253\tvalid_1's rmse: 122.445\n",
      "[1680]\ttraining's rmse: 64.4202\tvalid_1's rmse: 122.447\n",
      "[1710]\ttraining's rmse: 63.8842\tvalid_1's rmse: 122.404\n",
      "[1740]\ttraining's rmse: 63.336\tvalid_1's rmse: 122.337\n",
      "[1770]\ttraining's rmse: 62.847\tvalid_1's rmse: 122.304\n",
      "[1800]\ttraining's rmse: 62.3797\tvalid_1's rmse: 122.265\n",
      "[1830]\ttraining's rmse: 61.9238\tvalid_1's rmse: 122.246\n",
      "[1860]\ttraining's rmse: 61.4789\tvalid_1's rmse: 122.233\n",
      "[1890]\ttraining's rmse: 61.0871\tvalid_1's rmse: 122.233\n",
      "[1920]\ttraining's rmse: 60.6004\tvalid_1's rmse: 122.192\n",
      "[1950]\ttraining's rmse: 60.1894\tvalid_1's rmse: 122.187\n",
      "[1980]\ttraining's rmse: 59.7294\tvalid_1's rmse: 122.144\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's rmse: 59.4118\tvalid_1's rmse: 122.123\n",
      "13\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.022113 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 29702\n",
      "[LightGBM] [Info] Number of data points in the train set: 59281, number of used features: 117\n",
      "[LightGBM] [Info] Start training from score 376.830472\n",
      "Training until validation scores don't improve for 125 rounds\n",
      "[30]\ttraining's rmse: 203.742\tvalid_1's rmse: 206.713\n",
      "[60]\ttraining's rmse: 163.508\tvalid_1's rmse: 169.099\n",
      "[90]\ttraining's rmse: 142.975\tvalid_1's rmse: 150.996\n",
      "[120]\ttraining's rmse: 131.34\tvalid_1's rmse: 141.616\n",
      "[150]\ttraining's rmse: 123.747\tvalid_1's rmse: 136.025\n",
      "[180]\ttraining's rmse: 118.495\tvalid_1's rmse: 132.482\n",
      "[210]\ttraining's rmse: 114.426\tvalid_1's rmse: 130.143\n",
      "[240]\ttraining's rmse: 111.07\tvalid_1's rmse: 128.357\n",
      "[270]\ttraining's rmse: 108.11\tvalid_1's rmse: 126.786\n",
      "[300]\ttraining's rmse: 105.698\tvalid_1's rmse: 125.687\n",
      "[330]\ttraining's rmse: 103.658\tvalid_1's rmse: 124.993\n",
      "[360]\ttraining's rmse: 101.853\tvalid_1's rmse: 124.405\n",
      "[390]\ttraining's rmse: 100.126\tvalid_1's rmse: 123.911\n",
      "[420]\ttraining's rmse: 98.5438\tvalid_1's rmse: 123.479\n",
      "[450]\ttraining's rmse: 97.0576\tvalid_1's rmse: 123.07\n",
      "[480]\ttraining's rmse: 95.6782\tvalid_1's rmse: 122.794\n",
      "[510]\ttraining's rmse: 94.3432\tvalid_1's rmse: 122.509\n",
      "[540]\ttraining's rmse: 92.9953\tvalid_1's rmse: 122.256\n",
      "[570]\ttraining's rmse: 91.6857\tvalid_1's rmse: 122.007\n",
      "[600]\ttraining's rmse: 90.5102\tvalid_1's rmse: 121.856\n",
      "[630]\ttraining's rmse: 89.4119\tvalid_1's rmse: 121.78\n",
      "[660]\ttraining's rmse: 88.3198\tvalid_1's rmse: 121.631\n",
      "[690]\ttraining's rmse: 87.2009\tvalid_1's rmse: 121.441\n",
      "[720]\ttraining's rmse: 86.1561\tvalid_1's rmse: 121.309\n",
      "[750]\ttraining's rmse: 85.1028\tvalid_1's rmse: 121.117\n",
      "[780]\ttraining's rmse: 84.1133\tvalid_1's rmse: 120.98\n",
      "[810]\ttraining's rmse: 83.1372\tvalid_1's rmse: 120.838\n",
      "[840]\ttraining's rmse: 82.3216\tvalid_1's rmse: 120.799\n",
      "[870]\ttraining's rmse: 81.4977\tvalid_1's rmse: 120.757\n",
      "[900]\ttraining's rmse: 80.6484\tvalid_1's rmse: 120.69\n",
      "[930]\ttraining's rmse: 79.7845\tvalid_1's rmse: 120.579\n",
      "[960]\ttraining's rmse: 78.9657\tvalid_1's rmse: 120.494\n",
      "[990]\ttraining's rmse: 78.1654\tvalid_1's rmse: 120.436\n",
      "[1020]\ttraining's rmse: 77.3483\tvalid_1's rmse: 120.322\n",
      "[1050]\ttraining's rmse: 76.6084\tvalid_1's rmse: 120.274\n",
      "[1080]\ttraining's rmse: 75.8805\tvalid_1's rmse: 120.248\n",
      "[1110]\ttraining's rmse: 75.1198\tvalid_1's rmse: 120.201\n",
      "[1140]\ttraining's rmse: 74.4135\tvalid_1's rmse: 120.142\n",
      "[1170]\ttraining's rmse: 73.6968\tvalid_1's rmse: 120.077\n",
      "[1200]\ttraining's rmse: 73.0701\tvalid_1's rmse: 120.058\n",
      "[1230]\ttraining's rmse: 72.4299\tvalid_1's rmse: 120.02\n",
      "[1260]\ttraining's rmse: 71.7829\tvalid_1's rmse: 119.992\n",
      "[1290]\ttraining's rmse: 71.1896\tvalid_1's rmse: 119.965\n",
      "[1320]\ttraining's rmse: 70.5333\tvalid_1's rmse: 119.894\n",
      "[1350]\ttraining's rmse: 69.9035\tvalid_1's rmse: 119.834\n",
      "[1380]\ttraining's rmse: 69.3237\tvalid_1's rmse: 119.806\n",
      "[1410]\ttraining's rmse: 68.7673\tvalid_1's rmse: 119.781\n",
      "[1440]\ttraining's rmse: 68.1431\tvalid_1's rmse: 119.683\n",
      "[1470]\ttraining's rmse: 67.5735\tvalid_1's rmse: 119.684\n",
      "[1500]\ttraining's rmse: 67.0075\tvalid_1's rmse: 119.657\n",
      "[1530]\ttraining's rmse: 66.4808\tvalid_1's rmse: 119.613\n",
      "[1560]\ttraining's rmse: 65.955\tvalid_1's rmse: 119.583\n",
      "[1590]\ttraining's rmse: 65.4286\tvalid_1's rmse: 119.586\n",
      "[1620]\ttraining's rmse: 64.9237\tvalid_1's rmse: 119.526\n",
      "[1650]\ttraining's rmse: 64.3958\tvalid_1's rmse: 119.514\n",
      "[1680]\ttraining's rmse: 63.9431\tvalid_1's rmse: 119.504\n",
      "[1710]\ttraining's rmse: 63.4215\tvalid_1's rmse: 119.444\n",
      "[1740]\ttraining's rmse: 62.9517\tvalid_1's rmse: 119.429\n",
      "[1770]\ttraining's rmse: 62.5165\tvalid_1's rmse: 119.438\n",
      "[1800]\ttraining's rmse: 62.0387\tvalid_1's rmse: 119.38\n",
      "[1830]\ttraining's rmse: 61.5958\tvalid_1's rmse: 119.326\n",
      "[1860]\ttraining's rmse: 61.1245\tvalid_1's rmse: 119.303\n",
      "[1890]\ttraining's rmse: 60.7562\tvalid_1's rmse: 119.339\n",
      "[1920]\ttraining's rmse: 60.2999\tvalid_1's rmse: 119.311\n",
      "[1950]\ttraining's rmse: 59.9092\tvalid_1's rmse: 119.312\n",
      "[1980]\ttraining's rmse: 59.4404\tvalid_1's rmse: 119.294\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's rmse: 59.126\tvalid_1's rmse: 119.26\n",
      "14\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.018099 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 29701\n",
      "[LightGBM] [Info] Number of data points in the train set: 59281, number of used features: 117\n",
      "[LightGBM] [Info] Start training from score 373.405102\n",
      "Training until validation scores don't improve for 125 rounds\n",
      "[30]\ttraining's rmse: 198.747\tvalid_1's rmse: 200.415\n",
      "[60]\ttraining's rmse: 159.475\tvalid_1's rmse: 164.014\n",
      "[90]\ttraining's rmse: 139.124\tvalid_1's rmse: 146.253\n",
      "[120]\ttraining's rmse: 127.619\tvalid_1's rmse: 136.979\n",
      "[150]\ttraining's rmse: 120.021\tvalid_1's rmse: 131.365\n",
      "[180]\ttraining's rmse: 114.694\tvalid_1's rmse: 127.832\n",
      "[210]\ttraining's rmse: 110.563\tvalid_1's rmse: 125.344\n",
      "[240]\ttraining's rmse: 107.301\tvalid_1's rmse: 123.662\n",
      "[270]\ttraining's rmse: 104.407\tvalid_1's rmse: 122.139\n",
      "[300]\ttraining's rmse: 102.033\tvalid_1's rmse: 121.155\n",
      "[330]\ttraining's rmse: 100.174\tvalid_1's rmse: 120.616\n",
      "[360]\ttraining's rmse: 98.3296\tvalid_1's rmse: 119.99\n",
      "[390]\ttraining's rmse: 96.6468\tvalid_1's rmse: 119.613\n",
      "[420]\ttraining's rmse: 95.0457\tvalid_1's rmse: 119.145\n",
      "[450]\ttraining's rmse: 93.6392\tvalid_1's rmse: 118.846\n",
      "[480]\ttraining's rmse: 92.2712\tvalid_1's rmse: 118.555\n",
      "[510]\ttraining's rmse: 90.9808\tvalid_1's rmse: 118.327\n",
      "[540]\ttraining's rmse: 89.7295\tvalid_1's rmse: 118.12\n",
      "[570]\ttraining's rmse: 88.4911\tvalid_1's rmse: 117.913\n",
      "[600]\ttraining's rmse: 87.3781\tvalid_1's rmse: 117.75\n",
      "[630]\ttraining's rmse: 86.2945\tvalid_1's rmse: 117.591\n",
      "[660]\ttraining's rmse: 85.2698\tvalid_1's rmse: 117.481\n",
      "[690]\ttraining's rmse: 84.251\tvalid_1's rmse: 117.334\n",
      "[720]\ttraining's rmse: 83.3246\tvalid_1's rmse: 117.256\n",
      "[750]\ttraining's rmse: 82.337\tvalid_1's rmse: 117.122\n",
      "[780]\ttraining's rmse: 81.3895\tvalid_1's rmse: 116.99\n",
      "[810]\ttraining's rmse: 80.4749\tvalid_1's rmse: 116.843\n",
      "[840]\ttraining's rmse: 79.6414\tvalid_1's rmse: 116.757\n",
      "[870]\ttraining's rmse: 78.8291\tvalid_1's rmse: 116.698\n",
      "[900]\ttraining's rmse: 77.9831\tvalid_1's rmse: 116.601\n",
      "[930]\ttraining's rmse: 77.1888\tvalid_1's rmse: 116.519\n",
      "[960]\ttraining's rmse: 76.38\tvalid_1's rmse: 116.396\n",
      "[990]\ttraining's rmse: 75.6768\tvalid_1's rmse: 116.336\n",
      "[1020]\ttraining's rmse: 75.0061\tvalid_1's rmse: 116.327\n",
      "[1050]\ttraining's rmse: 74.2398\tvalid_1's rmse: 116.246\n",
      "[1080]\ttraining's rmse: 73.5822\tvalid_1's rmse: 116.191\n",
      "[1110]\ttraining's rmse: 72.8963\tvalid_1's rmse: 116.156\n",
      "[1140]\ttraining's rmse: 72.2121\tvalid_1's rmse: 116.081\n",
      "[1170]\ttraining's rmse: 71.5631\tvalid_1's rmse: 115.997\n",
      "[1200]\ttraining's rmse: 70.8862\tvalid_1's rmse: 115.94\n",
      "[1230]\ttraining's rmse: 70.2834\tvalid_1's rmse: 115.918\n",
      "[1260]\ttraining's rmse: 69.685\tvalid_1's rmse: 115.889\n",
      "[1290]\ttraining's rmse: 69.1017\tvalid_1's rmse: 115.87\n",
      "[1320]\ttraining's rmse: 68.4938\tvalid_1's rmse: 115.828\n",
      "[1350]\ttraining's rmse: 67.9055\tvalid_1's rmse: 115.815\n",
      "[1380]\ttraining's rmse: 67.3318\tvalid_1's rmse: 115.766\n",
      "[1410]\ttraining's rmse: 66.7877\tvalid_1's rmse: 115.736\n",
      "[1440]\ttraining's rmse: 66.2089\tvalid_1's rmse: 115.696\n",
      "[1470]\ttraining's rmse: 65.6922\tvalid_1's rmse: 115.671\n",
      "[1500]\ttraining's rmse: 65.1458\tvalid_1's rmse: 115.654\n",
      "[1530]\ttraining's rmse: 64.6396\tvalid_1's rmse: 115.631\n",
      "[1560]\ttraining's rmse: 64.1949\tvalid_1's rmse: 115.653\n",
      "[1590]\ttraining's rmse: 63.6584\tvalid_1's rmse: 115.617\n",
      "[1620]\ttraining's rmse: 63.223\tvalid_1's rmse: 115.608\n",
      "[1650]\ttraining's rmse: 62.7193\tvalid_1's rmse: 115.585\n",
      "[1680]\ttraining's rmse: 62.2669\tvalid_1's rmse: 115.561\n",
      "[1710]\ttraining's rmse: 61.7491\tvalid_1's rmse: 115.509\n",
      "[1740]\ttraining's rmse: 61.2661\tvalid_1's rmse: 115.484\n",
      "[1770]\ttraining's rmse: 60.8506\tvalid_1's rmse: 115.486\n",
      "[1800]\ttraining's rmse: 60.4229\tvalid_1's rmse: 115.472\n",
      "[1830]\ttraining's rmse: 59.9931\tvalid_1's rmse: 115.446\n",
      "[1860]\ttraining's rmse: 59.5985\tvalid_1's rmse: 115.441\n",
      "[1890]\ttraining's rmse: 59.1937\tvalid_1's rmse: 115.421\n",
      "[1920]\ttraining's rmse: 58.76\tvalid_1's rmse: 115.376\n",
      "[1950]\ttraining's rmse: 58.3599\tvalid_1's rmse: 115.35\n",
      "[1980]\ttraining's rmse: 57.9976\tvalid_1's rmse: 115.371\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's rmse: 57.7162\tvalid_1's rmse: 115.352\n",
      "15\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.024687 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 29701\n",
      "[LightGBM] [Info] Number of data points in the train set: 59281, number of used features: 117\n",
      "[LightGBM] [Info] Start training from score 369.065035\n",
      "Training until validation scores don't improve for 125 rounds\n",
      "[30]\ttraining's rmse: 194.29\tvalid_1's rmse: 196.987\n",
      "[60]\ttraining's rmse: 156.167\tvalid_1's rmse: 161.391\n",
      "[90]\ttraining's rmse: 136.053\tvalid_1's rmse: 143.505\n",
      "[120]\ttraining's rmse: 124.687\tvalid_1's rmse: 134.115\n",
      "[150]\ttraining's rmse: 117.244\tvalid_1's rmse: 128.383\n",
      "[180]\ttraining's rmse: 112.019\tvalid_1's rmse: 124.603\n",
      "[210]\ttraining's rmse: 107.933\tvalid_1's rmse: 121.867\n",
      "[240]\ttraining's rmse: 104.844\tvalid_1's rmse: 120.044\n",
      "[270]\ttraining's rmse: 101.985\tvalid_1's rmse: 118.382\n",
      "[300]\ttraining's rmse: 99.6157\tvalid_1's rmse: 117.144\n",
      "[330]\ttraining's rmse: 97.659\tvalid_1's rmse: 116.373\n",
      "[360]\ttraining's rmse: 95.9041\tvalid_1's rmse: 115.712\n",
      "[390]\ttraining's rmse: 94.2925\tvalid_1's rmse: 115.173\n",
      "[420]\ttraining's rmse: 92.7076\tvalid_1's rmse: 114.622\n",
      "[450]\ttraining's rmse: 91.2114\tvalid_1's rmse: 114.189\n",
      "[480]\ttraining's rmse: 89.8729\tvalid_1's rmse: 113.826\n",
      "[510]\ttraining's rmse: 88.5742\tvalid_1's rmse: 113.463\n",
      "[540]\ttraining's rmse: 87.3368\tvalid_1's rmse: 113.183\n",
      "[570]\ttraining's rmse: 86.2003\tvalid_1's rmse: 112.914\n",
      "[600]\ttraining's rmse: 85.1134\tvalid_1's rmse: 112.672\n",
      "[630]\ttraining's rmse: 84.1122\tvalid_1's rmse: 112.521\n",
      "[660]\ttraining's rmse: 83.0965\tvalid_1's rmse: 112.382\n",
      "[690]\ttraining's rmse: 82.1187\tvalid_1's rmse: 112.171\n",
      "[720]\ttraining's rmse: 81.2039\tvalid_1's rmse: 112.032\n",
      "[750]\ttraining's rmse: 80.2747\tvalid_1's rmse: 111.886\n",
      "[780]\ttraining's rmse: 79.3386\tvalid_1's rmse: 111.693\n",
      "[810]\ttraining's rmse: 78.4553\tvalid_1's rmse: 111.545\n",
      "[840]\ttraining's rmse: 77.6948\tvalid_1's rmse: 111.51\n",
      "[870]\ttraining's rmse: 76.8703\tvalid_1's rmse: 111.395\n",
      "[900]\ttraining's rmse: 76.0605\tvalid_1's rmse: 111.313\n",
      "[930]\ttraining's rmse: 75.2456\tvalid_1's rmse: 111.162\n",
      "[960]\ttraining's rmse: 74.4673\tvalid_1's rmse: 111.051\n",
      "[990]\ttraining's rmse: 73.7211\tvalid_1's rmse: 110.953\n",
      "[1020]\ttraining's rmse: 72.9832\tvalid_1's rmse: 110.875\n",
      "[1050]\ttraining's rmse: 72.2779\tvalid_1's rmse: 110.808\n",
      "[1080]\ttraining's rmse: 71.5251\tvalid_1's rmse: 110.681\n",
      "[1110]\ttraining's rmse: 70.8204\tvalid_1's rmse: 110.577\n",
      "[1140]\ttraining's rmse: 70.0938\tvalid_1's rmse: 110.467\n",
      "[1170]\ttraining's rmse: 69.4443\tvalid_1's rmse: 110.392\n",
      "[1200]\ttraining's rmse: 68.8253\tvalid_1's rmse: 110.356\n",
      "[1230]\ttraining's rmse: 68.1879\tvalid_1's rmse: 110.277\n",
      "[1260]\ttraining's rmse: 67.6293\tvalid_1's rmse: 110.255\n",
      "[1290]\ttraining's rmse: 67.081\tvalid_1's rmse: 110.231\n",
      "[1320]\ttraining's rmse: 66.5036\tvalid_1's rmse: 110.201\n",
      "[1350]\ttraining's rmse: 65.9533\tvalid_1's rmse: 110.142\n",
      "[1380]\ttraining's rmse: 65.3505\tvalid_1's rmse: 110.056\n",
      "[1410]\ttraining's rmse: 64.8142\tvalid_1's rmse: 110.032\n",
      "[1440]\ttraining's rmse: 64.1487\tvalid_1's rmse: 109.877\n",
      "[1470]\ttraining's rmse: 63.6285\tvalid_1's rmse: 109.829\n",
      "[1500]\ttraining's rmse: 63.0951\tvalid_1's rmse: 109.761\n",
      "[1530]\ttraining's rmse: 62.5604\tvalid_1's rmse: 109.689\n",
      "[1560]\ttraining's rmse: 62.084\tvalid_1's rmse: 109.684\n",
      "[1590]\ttraining's rmse: 61.6238\tvalid_1's rmse: 109.655\n",
      "[1620]\ttraining's rmse: 61.1855\tvalid_1's rmse: 109.645\n",
      "[1650]\ttraining's rmse: 60.7141\tvalid_1's rmse: 109.619\n",
      "[1680]\ttraining's rmse: 60.2652\tvalid_1's rmse: 109.612\n",
      "[1710]\ttraining's rmse: 59.7969\tvalid_1's rmse: 109.555\n",
      "[1740]\ttraining's rmse: 59.3362\tvalid_1's rmse: 109.509\n",
      "[1770]\ttraining's rmse: 58.8874\tvalid_1's rmse: 109.508\n",
      "[1800]\ttraining's rmse: 58.465\tvalid_1's rmse: 109.494\n",
      "[1830]\ttraining's rmse: 58.0443\tvalid_1's rmse: 109.49\n",
      "[1860]\ttraining's rmse: 57.6272\tvalid_1's rmse: 109.462\n",
      "[1890]\ttraining's rmse: 57.1997\tvalid_1's rmse: 109.448\n",
      "[1920]\ttraining's rmse: 56.7352\tvalid_1's rmse: 109.409\n",
      "[1950]\ttraining's rmse: 56.3249\tvalid_1's rmse: 109.377\n",
      "[1980]\ttraining's rmse: 55.9442\tvalid_1's rmse: 109.356\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's rmse: 55.695\tvalid_1's rmse: 109.354\n",
      "16\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.020012 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 29703\n",
      "[LightGBM] [Info] Number of data points in the train set: 59281, number of used features: 117\n",
      "[LightGBM] [Info] Start training from score 363.329701\n",
      "Training until validation scores don't improve for 125 rounds\n",
      "[30]\ttraining's rmse: 188.865\tvalid_1's rmse: 190.406\n",
      "[60]\ttraining's rmse: 151.989\tvalid_1's rmse: 155.962\n",
      "[90]\ttraining's rmse: 132.697\tvalid_1's rmse: 139.112\n",
      "[120]\ttraining's rmse: 121.708\tvalid_1's rmse: 130.105\n",
      "[150]\ttraining's rmse: 114.694\tvalid_1's rmse: 124.846\n",
      "[180]\ttraining's rmse: 109.679\tvalid_1's rmse: 121.455\n",
      "[210]\ttraining's rmse: 105.746\tvalid_1's rmse: 119.007\n",
      "[240]\ttraining's rmse: 102.55\tvalid_1's rmse: 117.176\n",
      "[270]\ttraining's rmse: 99.7607\tvalid_1's rmse: 115.663\n",
      "[300]\ttraining's rmse: 97.4651\tvalid_1's rmse: 114.528\n",
      "[330]\ttraining's rmse: 95.5572\tvalid_1's rmse: 113.791\n",
      "[360]\ttraining's rmse: 93.803\tvalid_1's rmse: 113.216\n",
      "[390]\ttraining's rmse: 92.2605\tvalid_1's rmse: 112.78\n",
      "[420]\ttraining's rmse: 90.6262\tvalid_1's rmse: 112.159\n",
      "[450]\ttraining's rmse: 89.2622\tvalid_1's rmse: 111.789\n",
      "[480]\ttraining's rmse: 88.1012\tvalid_1's rmse: 111.616\n",
      "[510]\ttraining's rmse: 86.8372\tvalid_1's rmse: 111.287\n",
      "[540]\ttraining's rmse: 85.6531\tvalid_1's rmse: 110.983\n",
      "[570]\ttraining's rmse: 84.5257\tvalid_1's rmse: 110.763\n",
      "[600]\ttraining's rmse: 83.39\tvalid_1's rmse: 110.508\n",
      "[630]\ttraining's rmse: 82.4495\tvalid_1's rmse: 110.337\n",
      "[660]\ttraining's rmse: 81.4743\tvalid_1's rmse: 110.157\n",
      "[690]\ttraining's rmse: 80.5247\tvalid_1's rmse: 109.949\n",
      "[720]\ttraining's rmse: 79.6086\tvalid_1's rmse: 109.825\n",
      "[750]\ttraining's rmse: 78.6364\tvalid_1's rmse: 109.604\n",
      "[780]\ttraining's rmse: 77.6886\tvalid_1's rmse: 109.417\n",
      "[810]\ttraining's rmse: 76.8635\tvalid_1's rmse: 109.296\n",
      "[840]\ttraining's rmse: 76.0871\tvalid_1's rmse: 109.211\n",
      "[870]\ttraining's rmse: 75.329\tvalid_1's rmse: 109.162\n",
      "[900]\ttraining's rmse: 74.5744\tvalid_1's rmse: 109.06\n",
      "[930]\ttraining's rmse: 73.9012\tvalid_1's rmse: 109.042\n",
      "[960]\ttraining's rmse: 73.1756\tvalid_1's rmse: 108.945\n",
      "[990]\ttraining's rmse: 72.4022\tvalid_1's rmse: 108.836\n",
      "[1020]\ttraining's rmse: 71.7427\tvalid_1's rmse: 108.8\n",
      "[1050]\ttraining's rmse: 71.0895\tvalid_1's rmse: 108.735\n",
      "[1080]\ttraining's rmse: 70.4024\tvalid_1's rmse: 108.648\n",
      "[1110]\ttraining's rmse: 69.7258\tvalid_1's rmse: 108.544\n",
      "[1140]\ttraining's rmse: 69.0239\tvalid_1's rmse: 108.431\n",
      "[1170]\ttraining's rmse: 68.3876\tvalid_1's rmse: 108.382\n",
      "[1200]\ttraining's rmse: 67.7511\tvalid_1's rmse: 108.277\n",
      "[1230]\ttraining's rmse: 67.1722\tvalid_1's rmse: 108.259\n",
      "[1260]\ttraining's rmse: 66.6165\tvalid_1's rmse: 108.199\n",
      "[1290]\ttraining's rmse: 66.0027\tvalid_1's rmse: 108.098\n",
      "[1320]\ttraining's rmse: 65.4879\tvalid_1's rmse: 108.089\n",
      "[1350]\ttraining's rmse: 64.9078\tvalid_1's rmse: 108.044\n",
      "[1380]\ttraining's rmse: 64.3515\tvalid_1's rmse: 107.994\n",
      "[1410]\ttraining's rmse: 63.8296\tvalid_1's rmse: 107.953\n",
      "[1440]\ttraining's rmse: 63.3456\tvalid_1's rmse: 107.915\n",
      "[1470]\ttraining's rmse: 62.8045\tvalid_1's rmse: 107.861\n",
      "[1500]\ttraining's rmse: 62.2812\tvalid_1's rmse: 107.825\n",
      "[1530]\ttraining's rmse: 61.7839\tvalid_1's rmse: 107.765\n",
      "[1560]\ttraining's rmse: 61.3678\tvalid_1's rmse: 107.762\n",
      "[1590]\ttraining's rmse: 60.8658\tvalid_1's rmse: 107.722\n",
      "[1620]\ttraining's rmse: 60.4358\tvalid_1's rmse: 107.693\n",
      "[1650]\ttraining's rmse: 59.9856\tvalid_1's rmse: 107.676\n",
      "[1680]\ttraining's rmse: 59.4605\tvalid_1's rmse: 107.635\n",
      "[1710]\ttraining's rmse: 59.0013\tvalid_1's rmse: 107.616\n",
      "[1740]\ttraining's rmse: 58.5506\tvalid_1's rmse: 107.577\n",
      "[1770]\ttraining's rmse: 58.1096\tvalid_1's rmse: 107.559\n",
      "[1800]\ttraining's rmse: 57.6665\tvalid_1's rmse: 107.525\n",
      "[1830]\ttraining's rmse: 57.2316\tvalid_1's rmse: 107.488\n",
      "[1860]\ttraining's rmse: 56.8119\tvalid_1's rmse: 107.469\n",
      "[1890]\ttraining's rmse: 56.4574\tvalid_1's rmse: 107.467\n",
      "[1920]\ttraining's rmse: 56.0613\tvalid_1's rmse: 107.448\n",
      "[1950]\ttraining's rmse: 55.6642\tvalid_1's rmse: 107.433\n",
      "[1980]\ttraining's rmse: 55.2486\tvalid_1's rmse: 107.383\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's rmse: 55.0023\tvalid_1's rmse: 107.38\n",
      "17\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.021479 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 29705\n",
      "[LightGBM] [Info] Number of data points in the train set: 59281, number of used features: 117\n",
      "[LightGBM] [Info] Start training from score 358.917880\n",
      "Training until validation scores don't improve for 125 rounds\n",
      "[30]\ttraining's rmse: 185.348\tvalid_1's rmse: 185.309\n",
      "[60]\ttraining's rmse: 149.389\tvalid_1's rmse: 152.266\n",
      "[90]\ttraining's rmse: 130.943\tvalid_1's rmse: 136.082\n",
      "[120]\ttraining's rmse: 120.419\tvalid_1's rmse: 127.507\n",
      "[150]\ttraining's rmse: 113.534\tvalid_1's rmse: 122.355\n",
      "[180]\ttraining's rmse: 108.667\tvalid_1's rmse: 119.022\n",
      "[210]\ttraining's rmse: 104.887\tvalid_1's rmse: 116.684\n",
      "[240]\ttraining's rmse: 101.822\tvalid_1's rmse: 114.971\n",
      "[270]\ttraining's rmse: 99.1794\tvalid_1's rmse: 113.562\n",
      "[300]\ttraining's rmse: 96.9624\tvalid_1's rmse: 112.539\n",
      "[330]\ttraining's rmse: 95.1686\tvalid_1's rmse: 111.923\n",
      "[360]\ttraining's rmse: 93.5547\tvalid_1's rmse: 111.448\n",
      "[390]\ttraining's rmse: 92.0551\tvalid_1's rmse: 111.014\n",
      "[420]\ttraining's rmse: 90.5942\tvalid_1's rmse: 110.541\n",
      "[450]\ttraining's rmse: 89.2563\tvalid_1's rmse: 110.226\n",
      "[480]\ttraining's rmse: 88.0133\tvalid_1's rmse: 109.958\n",
      "[510]\ttraining's rmse: 86.7612\tvalid_1's rmse: 109.626\n",
      "[540]\ttraining's rmse: 85.6735\tvalid_1's rmse: 109.468\n",
      "[570]\ttraining's rmse: 84.6168\tvalid_1's rmse: 109.239\n",
      "[600]\ttraining's rmse: 83.5607\tvalid_1's rmse: 109.092\n",
      "[630]\ttraining's rmse: 82.5613\tvalid_1's rmse: 108.907\n",
      "[660]\ttraining's rmse: 81.534\tvalid_1's rmse: 108.71\n",
      "[690]\ttraining's rmse: 80.5813\tvalid_1's rmse: 108.572\n",
      "[720]\ttraining's rmse: 79.6243\tvalid_1's rmse: 108.417\n",
      "[750]\ttraining's rmse: 78.653\tvalid_1's rmse: 108.252\n",
      "[780]\ttraining's rmse: 77.7384\tvalid_1's rmse: 108.069\n",
      "[810]\ttraining's rmse: 76.8727\tvalid_1's rmse: 107.96\n",
      "[840]\ttraining's rmse: 76.0561\tvalid_1's rmse: 107.891\n",
      "[870]\ttraining's rmse: 75.3124\tvalid_1's rmse: 107.841\n",
      "[900]\ttraining's rmse: 74.5912\tvalid_1's rmse: 107.802\n",
      "[930]\ttraining's rmse: 73.8174\tvalid_1's rmse: 107.713\n",
      "[960]\ttraining's rmse: 73.0114\tvalid_1's rmse: 107.588\n",
      "[990]\ttraining's rmse: 72.3403\tvalid_1's rmse: 107.553\n",
      "[1020]\ttraining's rmse: 71.6823\tvalid_1's rmse: 107.519\n",
      "[1050]\ttraining's rmse: 70.9986\tvalid_1's rmse: 107.447\n",
      "[1080]\ttraining's rmse: 70.3313\tvalid_1's rmse: 107.391\n",
      "[1110]\ttraining's rmse: 69.6874\tvalid_1's rmse: 107.359\n",
      "[1140]\ttraining's rmse: 69.0145\tvalid_1's rmse: 107.298\n",
      "[1170]\ttraining's rmse: 68.427\tvalid_1's rmse: 107.273\n",
      "[1200]\ttraining's rmse: 67.8013\tvalid_1's rmse: 107.236\n",
      "[1230]\ttraining's rmse: 67.1911\tvalid_1's rmse: 107.151\n",
      "[1260]\ttraining's rmse: 66.6135\tvalid_1's rmse: 107.111\n",
      "[1290]\ttraining's rmse: 66.0705\tvalid_1's rmse: 107.091\n",
      "[1320]\ttraining's rmse: 65.5081\tvalid_1's rmse: 107.051\n",
      "[1350]\ttraining's rmse: 64.9531\tvalid_1's rmse: 107.018\n",
      "[1380]\ttraining's rmse: 64.4171\tvalid_1's rmse: 107.004\n",
      "[1410]\ttraining's rmse: 63.8461\tvalid_1's rmse: 106.963\n",
      "[1440]\ttraining's rmse: 63.2541\tvalid_1's rmse: 106.939\n",
      "[1470]\ttraining's rmse: 62.7203\tvalid_1's rmse: 106.909\n",
      "[1500]\ttraining's rmse: 62.1932\tvalid_1's rmse: 106.881\n",
      "[1530]\ttraining's rmse: 61.681\tvalid_1's rmse: 106.851\n",
      "[1560]\ttraining's rmse: 61.1856\tvalid_1's rmse: 106.848\n",
      "[1590]\ttraining's rmse: 60.6831\tvalid_1's rmse: 106.827\n",
      "[1620]\ttraining's rmse: 60.2459\tvalid_1's rmse: 106.802\n",
      "[1650]\ttraining's rmse: 59.7998\tvalid_1's rmse: 106.807\n",
      "[1680]\ttraining's rmse: 59.3294\tvalid_1's rmse: 106.791\n",
      "[1710]\ttraining's rmse: 58.8968\tvalid_1's rmse: 106.795\n",
      "[1740]\ttraining's rmse: 58.4594\tvalid_1's rmse: 106.769\n",
      "[1770]\ttraining's rmse: 58.0049\tvalid_1's rmse: 106.766\n",
      "[1800]\ttraining's rmse: 57.5759\tvalid_1's rmse: 106.749\n",
      "[1830]\ttraining's rmse: 57.1497\tvalid_1's rmse: 106.743\n",
      "[1860]\ttraining's rmse: 56.7308\tvalid_1's rmse: 106.724\n",
      "[1890]\ttraining's rmse: 56.3383\tvalid_1's rmse: 106.722\n",
      "[1920]\ttraining's rmse: 55.8987\tvalid_1's rmse: 106.691\n",
      "[1950]\ttraining's rmse: 55.5316\tvalid_1's rmse: 106.678\n",
      "[1980]\ttraining's rmse: 55.1142\tvalid_1's rmse: 106.667\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's rmse: 54.8771\tvalid_1's rmse: 106.659\n",
      "18\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.023929 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 29707\n",
      "[LightGBM] [Info] Number of data points in the train set: 59281, number of used features: 117\n",
      "[LightGBM] [Info] Start training from score 354.281361\n",
      "Training until validation scores don't improve for 125 rounds\n",
      "[30]\ttraining's rmse: 179.94\tvalid_1's rmse: 182.798\n",
      "[60]\ttraining's rmse: 143.888\tvalid_1's rmse: 148.361\n",
      "[90]\ttraining's rmse: 126.155\tvalid_1's rmse: 132.502\n",
      "[120]\ttraining's rmse: 116.22\tvalid_1's rmse: 124.395\n",
      "[150]\ttraining's rmse: 110.033\tvalid_1's rmse: 120.015\n",
      "[180]\ttraining's rmse: 105.575\tvalid_1's rmse: 117.104\n",
      "[210]\ttraining's rmse: 102.222\tvalid_1's rmse: 115.26\n",
      "[240]\ttraining's rmse: 99.3448\tvalid_1's rmse: 113.813\n",
      "[270]\ttraining's rmse: 96.9256\tvalid_1's rmse: 112.661\n",
      "[300]\ttraining's rmse: 94.8204\tvalid_1's rmse: 111.793\n",
      "[330]\ttraining's rmse: 93.1279\tvalid_1's rmse: 111.289\n",
      "[360]\ttraining's rmse: 91.5949\tvalid_1's rmse: 110.806\n",
      "[390]\ttraining's rmse: 90.1876\tvalid_1's rmse: 110.498\n",
      "[420]\ttraining's rmse: 88.6761\tvalid_1's rmse: 110.055\n",
      "[450]\ttraining's rmse: 87.3242\tvalid_1's rmse: 109.757\n",
      "[480]\ttraining's rmse: 86.1943\tvalid_1's rmse: 109.592\n",
      "[510]\ttraining's rmse: 85.0392\tvalid_1's rmse: 109.406\n",
      "[540]\ttraining's rmse: 83.9917\tvalid_1's rmse: 109.27\n",
      "[570]\ttraining's rmse: 82.9035\tvalid_1's rmse: 109.05\n",
      "[600]\ttraining's rmse: 81.8223\tvalid_1's rmse: 108.826\n",
      "[630]\ttraining's rmse: 80.8494\tvalid_1's rmse: 108.661\n",
      "[660]\ttraining's rmse: 79.9634\tvalid_1's rmse: 108.598\n",
      "[690]\ttraining's rmse: 79.0137\tvalid_1's rmse: 108.524\n",
      "[720]\ttraining's rmse: 78.1394\tvalid_1's rmse: 108.417\n",
      "[750]\ttraining's rmse: 77.2736\tvalid_1's rmse: 108.27\n",
      "[780]\ttraining's rmse: 76.4798\tvalid_1's rmse: 108.245\n",
      "[810]\ttraining's rmse: 75.6362\tvalid_1's rmse: 108.128\n",
      "[840]\ttraining's rmse: 74.939\tvalid_1's rmse: 108.129\n",
      "[870]\ttraining's rmse: 74.2313\tvalid_1's rmse: 108.094\n",
      "[900]\ttraining's rmse: 73.481\tvalid_1's rmse: 108.001\n",
      "[930]\ttraining's rmse: 72.7513\tvalid_1's rmse: 107.955\n",
      "[960]\ttraining's rmse: 72.0157\tvalid_1's rmse: 107.899\n",
      "[990]\ttraining's rmse: 71.3292\tvalid_1's rmse: 107.841\n",
      "[1020]\ttraining's rmse: 70.7002\tvalid_1's rmse: 107.818\n",
      "[1050]\ttraining's rmse: 70.0093\tvalid_1's rmse: 107.755\n",
      "[1080]\ttraining's rmse: 69.412\tvalid_1's rmse: 107.749\n",
      "[1110]\ttraining's rmse: 68.8043\tvalid_1's rmse: 107.7\n",
      "[1140]\ttraining's rmse: 68.1574\tvalid_1's rmse: 107.653\n",
      "[1170]\ttraining's rmse: 67.5572\tvalid_1's rmse: 107.621\n",
      "[1200]\ttraining's rmse: 66.9549\tvalid_1's rmse: 107.61\n",
      "[1230]\ttraining's rmse: 66.402\tvalid_1's rmse: 107.592\n",
      "[1260]\ttraining's rmse: 65.8201\tvalid_1's rmse: 107.554\n",
      "[1290]\ttraining's rmse: 65.2717\tvalid_1's rmse: 107.551\n",
      "[1320]\ttraining's rmse: 64.7481\tvalid_1's rmse: 107.563\n",
      "[1350]\ttraining's rmse: 64.2084\tvalid_1's rmse: 107.567\n",
      "[1380]\ttraining's rmse: 63.6452\tvalid_1's rmse: 107.486\n",
      "[1410]\ttraining's rmse: 63.0884\tvalid_1's rmse: 107.454\n",
      "[1440]\ttraining's rmse: 62.5646\tvalid_1's rmse: 107.427\n",
      "[1470]\ttraining's rmse: 62.0302\tvalid_1's rmse: 107.383\n",
      "[1500]\ttraining's rmse: 61.5363\tvalid_1's rmse: 107.334\n",
      "[1530]\ttraining's rmse: 61.0161\tvalid_1's rmse: 107.275\n",
      "[1560]\ttraining's rmse: 60.5136\tvalid_1's rmse: 107.226\n",
      "[1590]\ttraining's rmse: 60.022\tvalid_1's rmse: 107.199\n",
      "[1620]\ttraining's rmse: 59.5791\tvalid_1's rmse: 107.183\n",
      "[1650]\ttraining's rmse: 59.1129\tvalid_1's rmse: 107.171\n",
      "[1680]\ttraining's rmse: 58.6498\tvalid_1's rmse: 107.165\n",
      "[1710]\ttraining's rmse: 58.2225\tvalid_1's rmse: 107.161\n",
      "[1740]\ttraining's rmse: 57.7969\tvalid_1's rmse: 107.156\n",
      "[1770]\ttraining's rmse: 57.3865\tvalid_1's rmse: 107.151\n",
      "[1800]\ttraining's rmse: 56.9433\tvalid_1's rmse: 107.123\n",
      "[1830]\ttraining's rmse: 56.5187\tvalid_1's rmse: 107.087\n",
      "[1860]\ttraining's rmse: 56.1146\tvalid_1's rmse: 107.075\n",
      "[1890]\ttraining's rmse: 55.7114\tvalid_1's rmse: 107.062\n",
      "[1920]\ttraining's rmse: 55.3002\tvalid_1's rmse: 107.045\n",
      "[1950]\ttraining's rmse: 54.9443\tvalid_1's rmse: 107.045\n",
      "[1980]\ttraining's rmse: 54.5514\tvalid_1's rmse: 107.029\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's rmse: 54.3006\tvalid_1's rmse: 107.027\n",
      "19\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.024824 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 29709\n",
      "[LightGBM] [Info] Number of data points in the train set: 59281, number of used features: 117\n",
      "[LightGBM] [Info] Start training from score 357.965686\n",
      "Training until validation scores don't improve for 125 rounds\n",
      "[30]\ttraining's rmse: 180.44\tvalid_1's rmse: 184.15\n",
      "[60]\ttraining's rmse: 143.613\tvalid_1's rmse: 148.934\n",
      "[90]\ttraining's rmse: 125.664\tvalid_1's rmse: 132.695\n",
      "[120]\ttraining's rmse: 115.628\tvalid_1's rmse: 124.316\n",
      "[150]\ttraining's rmse: 109.546\tvalid_1's rmse: 119.88\n",
      "[180]\ttraining's rmse: 105.247\tvalid_1's rmse: 117.07\n",
      "[210]\ttraining's rmse: 101.868\tvalid_1's rmse: 115.025\n",
      "[240]\ttraining's rmse: 99.0574\tvalid_1's rmse: 113.599\n",
      "[270]\ttraining's rmse: 96.7216\tvalid_1's rmse: 112.506\n",
      "[300]\ttraining's rmse: 94.6219\tvalid_1's rmse: 111.56\n",
      "[330]\ttraining's rmse: 92.9573\tvalid_1's rmse: 111.07\n",
      "[360]\ttraining's rmse: 91.366\tvalid_1's rmse: 110.541\n",
      "[390]\ttraining's rmse: 89.9852\tvalid_1's rmse: 110.195\n",
      "[420]\ttraining's rmse: 88.5802\tvalid_1's rmse: 109.798\n",
      "[450]\ttraining's rmse: 87.3051\tvalid_1's rmse: 109.573\n",
      "[480]\ttraining's rmse: 86.1677\tvalid_1's rmse: 109.434\n",
      "[510]\ttraining's rmse: 85.0053\tvalid_1's rmse: 109.158\n",
      "[540]\ttraining's rmse: 84.0093\tvalid_1's rmse: 109.067\n",
      "[570]\ttraining's rmse: 82.9248\tvalid_1's rmse: 108.865\n",
      "[600]\ttraining's rmse: 81.8948\tvalid_1's rmse: 108.666\n",
      "[630]\ttraining's rmse: 80.9233\tvalid_1's rmse: 108.57\n",
      "[660]\ttraining's rmse: 80.073\tvalid_1's rmse: 108.514\n",
      "[690]\ttraining's rmse: 79.1361\tvalid_1's rmse: 108.367\n",
      "[720]\ttraining's rmse: 78.2373\tvalid_1's rmse: 108.252\n",
      "[750]\ttraining's rmse: 77.3733\tvalid_1's rmse: 108.136\n",
      "[780]\ttraining's rmse: 76.4784\tvalid_1's rmse: 108\n",
      "[810]\ttraining's rmse: 75.6069\tvalid_1's rmse: 107.867\n",
      "[840]\ttraining's rmse: 74.8277\tvalid_1's rmse: 107.84\n",
      "[870]\ttraining's rmse: 74.0836\tvalid_1's rmse: 107.763\n",
      "[900]\ttraining's rmse: 73.3507\tvalid_1's rmse: 107.705\n",
      "[930]\ttraining's rmse: 72.6\tvalid_1's rmse: 107.649\n",
      "[960]\ttraining's rmse: 71.9441\tvalid_1's rmse: 107.593\n",
      "[990]\ttraining's rmse: 71.257\tvalid_1's rmse: 107.51\n",
      "[1020]\ttraining's rmse: 70.5863\tvalid_1's rmse: 107.477\n",
      "[1050]\ttraining's rmse: 69.9332\tvalid_1's rmse: 107.396\n",
      "[1080]\ttraining's rmse: 69.3114\tvalid_1's rmse: 107.36\n",
      "[1110]\ttraining's rmse: 68.6241\tvalid_1's rmse: 107.253\n",
      "[1140]\ttraining's rmse: 67.9552\tvalid_1's rmse: 107.126\n",
      "[1170]\ttraining's rmse: 67.3634\tvalid_1's rmse: 107.082\n",
      "[1200]\ttraining's rmse: 66.7525\tvalid_1's rmse: 107.051\n",
      "[1230]\ttraining's rmse: 66.1862\tvalid_1's rmse: 107.01\n",
      "[1260]\ttraining's rmse: 65.6307\tvalid_1's rmse: 106.995\n",
      "[1290]\ttraining's rmse: 65.0792\tvalid_1's rmse: 106.975\n",
      "[1320]\ttraining's rmse: 64.5576\tvalid_1's rmse: 106.959\n",
      "[1350]\ttraining's rmse: 64.0212\tvalid_1's rmse: 106.912\n",
      "[1380]\ttraining's rmse: 63.4587\tvalid_1's rmse: 106.866\n",
      "[1410]\ttraining's rmse: 62.9912\tvalid_1's rmse: 106.876\n",
      "[1440]\ttraining's rmse: 62.4563\tvalid_1's rmse: 106.832\n",
      "[1470]\ttraining's rmse: 61.9774\tvalid_1's rmse: 106.822\n",
      "[1500]\ttraining's rmse: 61.4752\tvalid_1's rmse: 106.765\n",
      "[1530]\ttraining's rmse: 60.9825\tvalid_1's rmse: 106.745\n",
      "[1560]\ttraining's rmse: 60.531\tvalid_1's rmse: 106.718\n",
      "[1590]\ttraining's rmse: 60.0633\tvalid_1's rmse: 106.675\n",
      "[1620]\ttraining's rmse: 59.6202\tvalid_1's rmse: 106.688\n",
      "[1650]\ttraining's rmse: 59.189\tvalid_1's rmse: 106.67\n",
      "[1680]\ttraining's rmse: 58.7817\tvalid_1's rmse: 106.655\n",
      "[1710]\ttraining's rmse: 58.3548\tvalid_1's rmse: 106.665\n",
      "[1740]\ttraining's rmse: 57.9449\tvalid_1's rmse: 106.667\n",
      "[1770]\ttraining's rmse: 57.5367\tvalid_1's rmse: 106.64\n",
      "[1800]\ttraining's rmse: 57.1543\tvalid_1's rmse: 106.639\n",
      "[1830]\ttraining's rmse: 56.7481\tvalid_1's rmse: 106.607\n",
      "[1860]\ttraining's rmse: 56.3207\tvalid_1's rmse: 106.589\n",
      "[1890]\ttraining's rmse: 55.9904\tvalid_1's rmse: 106.62\n",
      "[1920]\ttraining's rmse: 55.6005\tvalid_1's rmse: 106.59\n",
      "[1950]\ttraining's rmse: 55.2488\tvalid_1's rmse: 106.576\n",
      "[1980]\ttraining's rmse: 54.8621\tvalid_1's rmse: 106.565\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's rmse: 54.5942\tvalid_1's rmse: 106.55\n",
      "20\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.020152 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 29711\n",
      "[LightGBM] [Info] Number of data points in the train set: 59281, number of used features: 117\n",
      "[LightGBM] [Info] Start training from score 363.484399\n",
      "Training until validation scores don't improve for 125 rounds\n",
      "[30]\ttraining's rmse: 182.841\tvalid_1's rmse: 185.66\n",
      "[60]\ttraining's rmse: 145.063\tvalid_1's rmse: 149.534\n",
      "[90]\ttraining's rmse: 126.703\tvalid_1's rmse: 132.948\n",
      "[120]\ttraining's rmse: 116.508\tvalid_1's rmse: 124.419\n",
      "[150]\ttraining's rmse: 110.149\tvalid_1's rmse: 119.736\n",
      "[180]\ttraining's rmse: 105.812\tvalid_1's rmse: 116.964\n",
      "[210]\ttraining's rmse: 102.441\tvalid_1's rmse: 115.032\n",
      "[240]\ttraining's rmse: 99.7512\tvalid_1's rmse: 113.639\n",
      "[270]\ttraining's rmse: 97.3671\tvalid_1's rmse: 112.486\n",
      "[300]\ttraining's rmse: 95.3137\tvalid_1's rmse: 111.563\n",
      "[330]\ttraining's rmse: 93.6346\tvalid_1's rmse: 111.083\n",
      "[360]\ttraining's rmse: 92.0261\tvalid_1's rmse: 110.602\n",
      "[390]\ttraining's rmse: 90.5661\tvalid_1's rmse: 110.295\n",
      "[420]\ttraining's rmse: 89.1998\tvalid_1's rmse: 109.989\n",
      "[450]\ttraining's rmse: 87.881\tvalid_1's rmse: 109.705\n",
      "[480]\ttraining's rmse: 86.6943\tvalid_1's rmse: 109.454\n",
      "[510]\ttraining's rmse: 85.5329\tvalid_1's rmse: 109.248\n",
      "[540]\ttraining's rmse: 84.4018\tvalid_1's rmse: 109.025\n",
      "[570]\ttraining's rmse: 83.3662\tvalid_1's rmse: 108.867\n",
      "[600]\ttraining's rmse: 82.327\tvalid_1's rmse: 108.737\n",
      "[630]\ttraining's rmse: 81.3867\tvalid_1's rmse: 108.638\n",
      "[660]\ttraining's rmse: 80.416\tvalid_1's rmse: 108.474\n",
      "[690]\ttraining's rmse: 79.5485\tvalid_1's rmse: 108.391\n",
      "[720]\ttraining's rmse: 78.6566\tvalid_1's rmse: 108.262\n",
      "[750]\ttraining's rmse: 77.8609\tvalid_1's rmse: 108.146\n",
      "[780]\ttraining's rmse: 76.9437\tvalid_1's rmse: 108.05\n",
      "[810]\ttraining's rmse: 76.1469\tvalid_1's rmse: 107.977\n",
      "[840]\ttraining's rmse: 75.3919\tvalid_1's rmse: 107.955\n",
      "[870]\ttraining's rmse: 74.6265\tvalid_1's rmse: 107.926\n",
      "[900]\ttraining's rmse: 73.8762\tvalid_1's rmse: 107.874\n",
      "[930]\ttraining's rmse: 73.1782\tvalid_1's rmse: 107.861\n",
      "[960]\ttraining's rmse: 72.4794\tvalid_1's rmse: 107.759\n",
      "[990]\ttraining's rmse: 71.8192\tvalid_1's rmse: 107.708\n",
      "[1020]\ttraining's rmse: 71.1629\tvalid_1's rmse: 107.653\n",
      "[1050]\ttraining's rmse: 70.5483\tvalid_1's rmse: 107.621\n",
      "[1080]\ttraining's rmse: 69.9326\tvalid_1's rmse: 107.568\n",
      "[1110]\ttraining's rmse: 69.3042\tvalid_1's rmse: 107.525\n",
      "[1140]\ttraining's rmse: 68.6692\tvalid_1's rmse: 107.457\n",
      "[1170]\ttraining's rmse: 68.0139\tvalid_1's rmse: 107.392\n",
      "[1200]\ttraining's rmse: 67.3941\tvalid_1's rmse: 107.358\n",
      "[1230]\ttraining's rmse: 66.7764\tvalid_1's rmse: 107.325\n",
      "[1260]\ttraining's rmse: 66.2336\tvalid_1's rmse: 107.315\n",
      "[1290]\ttraining's rmse: 65.7375\tvalid_1's rmse: 107.306\n",
      "[1320]\ttraining's rmse: 65.1741\tvalid_1's rmse: 107.271\n",
      "[1350]\ttraining's rmse: 64.6106\tvalid_1's rmse: 107.241\n",
      "[1380]\ttraining's rmse: 64.0781\tvalid_1's rmse: 107.215\n",
      "[1410]\ttraining's rmse: 63.5891\tvalid_1's rmse: 107.203\n",
      "[1440]\ttraining's rmse: 63.0622\tvalid_1's rmse: 107.149\n",
      "[1470]\ttraining's rmse: 62.5553\tvalid_1's rmse: 107.117\n",
      "[1500]\ttraining's rmse: 62.0382\tvalid_1's rmse: 107.096\n",
      "[1530]\ttraining's rmse: 61.521\tvalid_1's rmse: 107.074\n",
      "[1560]\ttraining's rmse: 61.0717\tvalid_1's rmse: 107.054\n",
      "[1590]\ttraining's rmse: 60.565\tvalid_1's rmse: 107.024\n",
      "[1620]\ttraining's rmse: 60.1318\tvalid_1's rmse: 107.024\n",
      "[1650]\ttraining's rmse: 59.6536\tvalid_1's rmse: 106.987\n",
      "[1680]\ttraining's rmse: 59.2025\tvalid_1's rmse: 106.99\n",
      "[1710]\ttraining's rmse: 58.7374\tvalid_1's rmse: 106.941\n",
      "[1740]\ttraining's rmse: 58.2853\tvalid_1's rmse: 106.917\n",
      "[1770]\ttraining's rmse: 57.8784\tvalid_1's rmse: 106.941\n",
      "[1800]\ttraining's rmse: 57.4554\tvalid_1's rmse: 106.894\n",
      "[1830]\ttraining's rmse: 57.0474\tvalid_1's rmse: 106.87\n",
      "[1860]\ttraining's rmse: 56.645\tvalid_1's rmse: 106.857\n",
      "[1890]\ttraining's rmse: 56.258\tvalid_1's rmse: 106.834\n",
      "[1920]\ttraining's rmse: 55.8196\tvalid_1's rmse: 106.79\n",
      "[1950]\ttraining's rmse: 55.4428\tvalid_1's rmse: 106.793\n",
      "[1980]\ttraining's rmse: 55.0499\tvalid_1's rmse: 106.765\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's rmse: 54.7861\tvalid_1's rmse: 106.756\n",
      "21\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.019819 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 29713\n",
      "[LightGBM] [Info] Number of data points in the train set: 59281, number of used features: 117\n",
      "[LightGBM] [Info] Start training from score 366.402225\n",
      "Training until validation scores don't improve for 125 rounds\n",
      "[30]\ttraining's rmse: 185.005\tvalid_1's rmse: 187.26\n",
      "[60]\ttraining's rmse: 146.708\tvalid_1's rmse: 152.059\n",
      "[90]\ttraining's rmse: 127.962\tvalid_1's rmse: 136.001\n",
      "[120]\ttraining's rmse: 117.667\tvalid_1's rmse: 128.029\n",
      "[150]\ttraining's rmse: 111.238\tvalid_1's rmse: 123.452\n",
      "[180]\ttraining's rmse: 106.833\tvalid_1's rmse: 120.75\n",
      "[210]\ttraining's rmse: 103.334\tvalid_1's rmse: 118.784\n",
      "[240]\ttraining's rmse: 100.483\tvalid_1's rmse: 117.366\n",
      "[270]\ttraining's rmse: 97.9903\tvalid_1's rmse: 116.136\n",
      "[300]\ttraining's rmse: 95.9067\tvalid_1's rmse: 115.26\n",
      "[330]\ttraining's rmse: 94.2164\tvalid_1's rmse: 114.791\n",
      "[360]\ttraining's rmse: 92.5876\tvalid_1's rmse: 114.35\n",
      "[390]\ttraining's rmse: 91.1489\tvalid_1's rmse: 114.058\n",
      "[420]\ttraining's rmse: 89.6638\tvalid_1's rmse: 113.567\n",
      "[450]\ttraining's rmse: 88.4057\tvalid_1's rmse: 113.441\n",
      "[480]\ttraining's rmse: 87.1981\tvalid_1's rmse: 113.207\n",
      "[510]\ttraining's rmse: 86.0524\tvalid_1's rmse: 113.018\n",
      "[540]\ttraining's rmse: 84.9157\tvalid_1's rmse: 112.851\n",
      "[570]\ttraining's rmse: 83.7771\tvalid_1's rmse: 112.641\n",
      "[600]\ttraining's rmse: 82.7636\tvalid_1's rmse: 112.505\n",
      "[630]\ttraining's rmse: 81.8572\tvalid_1's rmse: 112.466\n",
      "[660]\ttraining's rmse: 80.8738\tvalid_1's rmse: 112.317\n",
      "[690]\ttraining's rmse: 79.8753\tvalid_1's rmse: 112.169\n",
      "[720]\ttraining's rmse: 78.9586\tvalid_1's rmse: 112.081\n",
      "[750]\ttraining's rmse: 78.0733\tvalid_1's rmse: 111.985\n",
      "[780]\ttraining's rmse: 77.1837\tvalid_1's rmse: 111.901\n",
      "[810]\ttraining's rmse: 76.3676\tvalid_1's rmse: 111.835\n",
      "[840]\ttraining's rmse: 75.5841\tvalid_1's rmse: 111.769\n",
      "[870]\ttraining's rmse: 74.8553\tvalid_1's rmse: 111.777\n",
      "[900]\ttraining's rmse: 74.1362\tvalid_1's rmse: 111.773\n",
      "[930]\ttraining's rmse: 73.3698\tvalid_1's rmse: 111.701\n",
      "[960]\ttraining's rmse: 72.6354\tvalid_1's rmse: 111.664\n",
      "[990]\ttraining's rmse: 71.8783\tvalid_1's rmse: 111.555\n",
      "[1020]\ttraining's rmse: 71.1865\tvalid_1's rmse: 111.492\n",
      "[1050]\ttraining's rmse: 70.5627\tvalid_1's rmse: 111.472\n",
      "[1080]\ttraining's rmse: 69.9103\tvalid_1's rmse: 111.416\n",
      "[1110]\ttraining's rmse: 69.2177\tvalid_1's rmse: 111.357\n",
      "[1140]\ttraining's rmse: 68.5612\tvalid_1's rmse: 111.291\n",
      "[1170]\ttraining's rmse: 67.8927\tvalid_1's rmse: 111.214\n",
      "[1200]\ttraining's rmse: 67.308\tvalid_1's rmse: 111.169\n",
      "[1230]\ttraining's rmse: 66.7088\tvalid_1's rmse: 111.132\n",
      "[1260]\ttraining's rmse: 66.132\tvalid_1's rmse: 111.116\n",
      "[1290]\ttraining's rmse: 65.571\tvalid_1's rmse: 111.102\n",
      "[1320]\ttraining's rmse: 65.0349\tvalid_1's rmse: 111.1\n",
      "[1350]\ttraining's rmse: 64.4577\tvalid_1's rmse: 111.078\n",
      "[1380]\ttraining's rmse: 63.935\tvalid_1's rmse: 111.078\n",
      "[1410]\ttraining's rmse: 63.4049\tvalid_1's rmse: 111.063\n",
      "[1440]\ttraining's rmse: 62.8712\tvalid_1's rmse: 111.035\n",
      "[1470]\ttraining's rmse: 62.3533\tvalid_1's rmse: 111.02\n",
      "[1500]\ttraining's rmse: 61.8563\tvalid_1's rmse: 111.029\n",
      "[1530]\ttraining's rmse: 61.3385\tvalid_1's rmse: 111.008\n",
      "[1560]\ttraining's rmse: 60.864\tvalid_1's rmse: 111.006\n",
      "[1590]\ttraining's rmse: 60.3532\tvalid_1's rmse: 110.988\n",
      "[1620]\ttraining's rmse: 59.9244\tvalid_1's rmse: 110.993\n",
      "[1650]\ttraining's rmse: 59.4589\tvalid_1's rmse: 110.999\n",
      "[1680]\ttraining's rmse: 58.9958\tvalid_1's rmse: 110.987\n",
      "[1710]\ttraining's rmse: 58.5503\tvalid_1's rmse: 110.977\n",
      "[1740]\ttraining's rmse: 58.0926\tvalid_1's rmse: 110.951\n",
      "[1770]\ttraining's rmse: 57.6576\tvalid_1's rmse: 110.945\n",
      "[1800]\ttraining's rmse: 57.224\tvalid_1's rmse: 110.9\n",
      "[1830]\ttraining's rmse: 56.8193\tvalid_1's rmse: 110.932\n",
      "[1860]\ttraining's rmse: 56.4113\tvalid_1's rmse: 110.928\n",
      "[1890]\ttraining's rmse: 56.0361\tvalid_1's rmse: 110.937\n",
      "[1920]\ttraining's rmse: 55.6043\tvalid_1's rmse: 110.912\n",
      "Early stopping, best iteration is:\n",
      "[1795]\ttraining's rmse: 57.2816\tvalid_1's rmse: 110.897\n",
      "22\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.023651 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 29714\n",
      "[LightGBM] [Info] Number of data points in the train set: 59281, number of used features: 117\n",
      "[LightGBM] [Info] Start training from score 366.571794\n",
      "Training until validation scores don't improve for 125 rounds\n",
      "[30]\ttraining's rmse: 185.345\tvalid_1's rmse: 186.674\n",
      "[60]\ttraining's rmse: 147.524\tvalid_1's rmse: 150.328\n",
      "[90]\ttraining's rmse: 129.055\tvalid_1's rmse: 133.664\n",
      "[120]\ttraining's rmse: 118.861\tvalid_1's rmse: 125.311\n",
      "[150]\ttraining's rmse: 112.451\tvalid_1's rmse: 120.583\n",
      "[180]\ttraining's rmse: 108.072\tvalid_1's rmse: 117.849\n",
      "[210]\ttraining's rmse: 104.629\tvalid_1's rmse: 115.897\n",
      "[240]\ttraining's rmse: 101.878\tvalid_1's rmse: 114.634\n",
      "[270]\ttraining's rmse: 99.4352\tvalid_1's rmse: 113.483\n",
      "[300]\ttraining's rmse: 97.3402\tvalid_1's rmse: 112.693\n",
      "[330]\ttraining's rmse: 95.675\tvalid_1's rmse: 112.286\n",
      "[360]\ttraining's rmse: 94.1049\tvalid_1's rmse: 111.866\n",
      "[390]\ttraining's rmse: 92.6864\tvalid_1's rmse: 111.51\n",
      "[420]\ttraining's rmse: 91.2392\tvalid_1's rmse: 111.161\n",
      "[450]\ttraining's rmse: 89.9031\tvalid_1's rmse: 110.929\n",
      "[480]\ttraining's rmse: 88.6445\tvalid_1's rmse: 110.695\n",
      "[510]\ttraining's rmse: 87.4286\tvalid_1's rmse: 110.482\n",
      "[540]\ttraining's rmse: 86.3265\tvalid_1's rmse: 110.325\n",
      "[570]\ttraining's rmse: 85.2178\tvalid_1's rmse: 110.15\n",
      "[600]\ttraining's rmse: 84.1704\tvalid_1's rmse: 110.019\n",
      "[630]\ttraining's rmse: 83.1858\tvalid_1's rmse: 109.907\n",
      "[660]\ttraining's rmse: 82.2765\tvalid_1's rmse: 109.887\n",
      "[690]\ttraining's rmse: 81.3243\tvalid_1's rmse: 109.729\n",
      "[720]\ttraining's rmse: 80.4183\tvalid_1's rmse: 109.691\n",
      "[750]\ttraining's rmse: 79.4824\tvalid_1's rmse: 109.562\n",
      "[780]\ttraining's rmse: 78.6375\tvalid_1's rmse: 109.497\n",
      "[810]\ttraining's rmse: 77.816\tvalid_1's rmse: 109.411\n",
      "[840]\ttraining's rmse: 77.0456\tvalid_1's rmse: 109.397\n",
      "[870]\ttraining's rmse: 76.3488\tvalid_1's rmse: 109.415\n",
      "[900]\ttraining's rmse: 75.6406\tvalid_1's rmse: 109.42\n",
      "[930]\ttraining's rmse: 74.9174\tvalid_1's rmse: 109.394\n",
      "[960]\ttraining's rmse: 74.1972\tvalid_1's rmse: 109.363\n",
      "[990]\ttraining's rmse: 73.441\tvalid_1's rmse: 109.288\n",
      "[1020]\ttraining's rmse: 72.6788\tvalid_1's rmse: 109.223\n",
      "[1050]\ttraining's rmse: 72.0299\tvalid_1's rmse: 109.172\n",
      "[1080]\ttraining's rmse: 71.3341\tvalid_1's rmse: 109.128\n",
      "[1110]\ttraining's rmse: 70.6666\tvalid_1's rmse: 109.109\n",
      "[1140]\ttraining's rmse: 70.0176\tvalid_1's rmse: 109.06\n",
      "[1170]\ttraining's rmse: 69.4155\tvalid_1's rmse: 109.048\n",
      "[1200]\ttraining's rmse: 68.8149\tvalid_1's rmse: 109.031\n",
      "[1230]\ttraining's rmse: 68.2416\tvalid_1's rmse: 109.055\n",
      "[1260]\ttraining's rmse: 67.6828\tvalid_1's rmse: 109.048\n",
      "[1290]\ttraining's rmse: 67.1347\tvalid_1's rmse: 109.048\n",
      "[1320]\ttraining's rmse: 66.5947\tvalid_1's rmse: 109.032\n",
      "Early stopping, best iteration is:\n",
      "[1198]\ttraining's rmse: 68.8495\tvalid_1's rmse: 109.019\n",
      "23\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.023140 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 29714\n",
      "[LightGBM] [Info] Number of data points in the train set: 59281, number of used features: 117\n",
      "[LightGBM] [Info] Start training from score 365.875940\n",
      "Training until validation scores don't improve for 125 rounds\n",
      "[30]\ttraining's rmse: 185.33\tvalid_1's rmse: 189.476\n",
      "[60]\ttraining's rmse: 147.668\tvalid_1's rmse: 153.539\n",
      "[90]\ttraining's rmse: 129.22\tvalid_1's rmse: 136.88\n",
      "[120]\ttraining's rmse: 118.931\tvalid_1's rmse: 128.429\n",
      "[150]\ttraining's rmse: 112.606\tvalid_1's rmse: 123.819\n",
      "[180]\ttraining's rmse: 108.057\tvalid_1's rmse: 120.937\n",
      "[210]\ttraining's rmse: 104.525\tvalid_1's rmse: 118.985\n",
      "[240]\ttraining's rmse: 101.728\tvalid_1's rmse: 117.631\n",
      "[270]\ttraining's rmse: 99.449\tvalid_1's rmse: 116.653\n",
      "[300]\ttraining's rmse: 97.3892\tvalid_1's rmse: 115.888\n",
      "[330]\ttraining's rmse: 95.6194\tvalid_1's rmse: 115.381\n",
      "[360]\ttraining's rmse: 93.9582\tvalid_1's rmse: 114.884\n",
      "[390]\ttraining's rmse: 92.4874\tvalid_1's rmse: 114.522\n",
      "[420]\ttraining's rmse: 91.0737\tvalid_1's rmse: 114.123\n",
      "[450]\ttraining's rmse: 89.7554\tvalid_1's rmse: 113.88\n",
      "[480]\ttraining's rmse: 88.6275\tvalid_1's rmse: 113.764\n",
      "[510]\ttraining's rmse: 87.4894\tvalid_1's rmse: 113.653\n",
      "[540]\ttraining's rmse: 86.4333\tvalid_1's rmse: 113.636\n",
      "[570]\ttraining's rmse: 85.3338\tvalid_1's rmse: 113.48\n",
      "[600]\ttraining's rmse: 84.2734\tvalid_1's rmse: 113.351\n",
      "[630]\ttraining's rmse: 83.3049\tvalid_1's rmse: 113.274\n",
      "[660]\ttraining's rmse: 82.3198\tvalid_1's rmse: 113.223\n",
      "[690]\ttraining's rmse: 81.3564\tvalid_1's rmse: 113.094\n",
      "[720]\ttraining's rmse: 80.4125\tvalid_1's rmse: 113.004\n",
      "[750]\ttraining's rmse: 79.4682\tvalid_1's rmse: 112.906\n",
      "[780]\ttraining's rmse: 78.6238\tvalid_1's rmse: 112.843\n",
      "[810]\ttraining's rmse: 77.8086\tvalid_1's rmse: 112.769\n",
      "[840]\ttraining's rmse: 77.073\tvalid_1's rmse: 112.717\n",
      "[870]\ttraining's rmse: 76.3204\tvalid_1's rmse: 112.694\n",
      "[900]\ttraining's rmse: 75.5868\tvalid_1's rmse: 112.647\n",
      "[930]\ttraining's rmse: 74.8532\tvalid_1's rmse: 112.622\n",
      "[960]\ttraining's rmse: 74.1031\tvalid_1's rmse: 112.568\n",
      "[990]\ttraining's rmse: 73.389\tvalid_1's rmse: 112.508\n",
      "[1020]\ttraining's rmse: 72.7284\tvalid_1's rmse: 112.493\n",
      "[1050]\ttraining's rmse: 72.0616\tvalid_1's rmse: 112.45\n",
      "[1080]\ttraining's rmse: 71.4003\tvalid_1's rmse: 112.434\n",
      "[1110]\ttraining's rmse: 70.7358\tvalid_1's rmse: 112.4\n",
      "[1140]\ttraining's rmse: 70.1686\tvalid_1's rmse: 112.404\n",
      "[1170]\ttraining's rmse: 69.5495\tvalid_1's rmse: 112.362\n",
      "[1200]\ttraining's rmse: 68.9338\tvalid_1's rmse: 112.337\n",
      "[1230]\ttraining's rmse: 68.3233\tvalid_1's rmse: 112.337\n",
      "[1260]\ttraining's rmse: 67.7851\tvalid_1's rmse: 112.352\n",
      "[1290]\ttraining's rmse: 67.2394\tvalid_1's rmse: 112.379\n",
      "[1320]\ttraining's rmse: 66.6815\tvalid_1's rmse: 112.386\n",
      "Early stopping, best iteration is:\n",
      "[1224]\ttraining's rmse: 68.4322\tvalid_1's rmse: 112.313\n",
      "24\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.023322 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 29714\n",
      "[LightGBM] [Info] Number of data points in the train set: 59281, number of used features: 117\n",
      "[LightGBM] [Info] Start training from score 364.423187\n",
      "Training until validation scores don't improve for 125 rounds\n",
      "[30]\ttraining's rmse: 185.549\tvalid_1's rmse: 188.975\n",
      "[60]\ttraining's rmse: 147.849\tvalid_1's rmse: 153.489\n",
      "[90]\ttraining's rmse: 129.24\tvalid_1's rmse: 136.724\n",
      "[120]\ttraining's rmse: 119.024\tvalid_1's rmse: 128.345\n",
      "[150]\ttraining's rmse: 112.57\tvalid_1's rmse: 123.585\n",
      "[180]\ttraining's rmse: 108.017\tvalid_1's rmse: 120.574\n",
      "[210]\ttraining's rmse: 104.45\tvalid_1's rmse: 118.479\n",
      "[240]\ttraining's rmse: 101.642\tvalid_1's rmse: 117.012\n",
      "[270]\ttraining's rmse: 99.2124\tvalid_1's rmse: 115.847\n",
      "[300]\ttraining's rmse: 97.168\tvalid_1's rmse: 115.007\n",
      "[330]\ttraining's rmse: 95.4755\tvalid_1's rmse: 114.475\n",
      "[360]\ttraining's rmse: 93.8584\tvalid_1's rmse: 113.929\n",
      "[390]\ttraining's rmse: 92.3709\tvalid_1's rmse: 113.504\n",
      "[420]\ttraining's rmse: 90.8379\tvalid_1's rmse: 112.993\n",
      "[450]\ttraining's rmse: 89.5458\tvalid_1's rmse: 112.719\n",
      "[480]\ttraining's rmse: 88.318\tvalid_1's rmse: 112.505\n",
      "[510]\ttraining's rmse: 87.1482\tvalid_1's rmse: 112.333\n",
      "[540]\ttraining's rmse: 85.9018\tvalid_1's rmse: 112.017\n",
      "[570]\ttraining's rmse: 84.7722\tvalid_1's rmse: 111.813\n",
      "[600]\ttraining's rmse: 83.6908\tvalid_1's rmse: 111.674\n",
      "[630]\ttraining's rmse: 82.7016\tvalid_1's rmse: 111.51\n",
      "[660]\ttraining's rmse: 81.8232\tvalid_1's rmse: 111.422\n",
      "[690]\ttraining's rmse: 80.7872\tvalid_1's rmse: 111.201\n",
      "[720]\ttraining's rmse: 79.8461\tvalid_1's rmse: 111.083\n",
      "[750]\ttraining's rmse: 78.971\tvalid_1's rmse: 110.957\n",
      "[780]\ttraining's rmse: 78.0804\tvalid_1's rmse: 110.779\n",
      "[810]\ttraining's rmse: 77.2805\tvalid_1's rmse: 110.703\n",
      "[840]\ttraining's rmse: 76.541\tvalid_1's rmse: 110.66\n",
      "[870]\ttraining's rmse: 75.7928\tvalid_1's rmse: 110.609\n",
      "[900]\ttraining's rmse: 75.0533\tvalid_1's rmse: 110.561\n",
      "[930]\ttraining's rmse: 74.3121\tvalid_1's rmse: 110.489\n",
      "[960]\ttraining's rmse: 73.5282\tvalid_1's rmse: 110.396\n",
      "[990]\ttraining's rmse: 72.8293\tvalid_1's rmse: 110.345\n",
      "[1020]\ttraining's rmse: 72.1294\tvalid_1's rmse: 110.29\n",
      "[1050]\ttraining's rmse: 71.5286\tvalid_1's rmse: 110.281\n",
      "[1080]\ttraining's rmse: 70.8357\tvalid_1's rmse: 110.232\n",
      "[1110]\ttraining's rmse: 70.185\tvalid_1's rmse: 110.209\n",
      "[1140]\ttraining's rmse: 69.4839\tvalid_1's rmse: 110.106\n",
      "[1170]\ttraining's rmse: 68.8873\tvalid_1's rmse: 110.065\n",
      "[1200]\ttraining's rmse: 68.2623\tvalid_1's rmse: 110.022\n",
      "[1230]\ttraining's rmse: 67.7065\tvalid_1's rmse: 109.99\n",
      "[1260]\ttraining's rmse: 67.15\tvalid_1's rmse: 109.98\n",
      "[1290]\ttraining's rmse: 66.5845\tvalid_1's rmse: 109.96\n",
      "[1320]\ttraining's rmse: 66.0364\tvalid_1's rmse: 109.923\n",
      "[1350]\ttraining's rmse: 65.4706\tvalid_1's rmse: 109.928\n",
      "[1380]\ttraining's rmse: 64.9638\tvalid_1's rmse: 109.912\n",
      "[1410]\ttraining's rmse: 64.421\tvalid_1's rmse: 109.879\n",
      "[1440]\ttraining's rmse: 63.859\tvalid_1's rmse: 109.832\n",
      "[1470]\ttraining's rmse: 63.3306\tvalid_1's rmse: 109.799\n",
      "[1500]\ttraining's rmse: 62.8481\tvalid_1's rmse: 109.794\n",
      "[1530]\ttraining's rmse: 62.35\tvalid_1's rmse: 109.765\n",
      "[1560]\ttraining's rmse: 61.8487\tvalid_1's rmse: 109.737\n",
      "[1590]\ttraining's rmse: 61.3593\tvalid_1's rmse: 109.707\n",
      "[1620]\ttraining's rmse: 60.9121\tvalid_1's rmse: 109.691\n",
      "[1650]\ttraining's rmse: 60.4614\tvalid_1's rmse: 109.673\n",
      "[1680]\ttraining's rmse: 59.976\tvalid_1's rmse: 109.64\n",
      "[1710]\ttraining's rmse: 59.5398\tvalid_1's rmse: 109.642\n",
      "[1740]\ttraining's rmse: 59.0942\tvalid_1's rmse: 109.617\n",
      "[1770]\ttraining's rmse: 58.639\tvalid_1's rmse: 109.578\n",
      "[1800]\ttraining's rmse: 58.1725\tvalid_1's rmse: 109.52\n",
      "[1830]\ttraining's rmse: 57.7313\tvalid_1's rmse: 109.483\n",
      "[1860]\ttraining's rmse: 57.3056\tvalid_1's rmse: 109.438\n",
      "[1890]\ttraining's rmse: 56.9536\tvalid_1's rmse: 109.44\n",
      "[1920]\ttraining's rmse: 56.5621\tvalid_1's rmse: 109.439\n",
      "[1950]\ttraining's rmse: 56.1481\tvalid_1's rmse: 109.421\n",
      "[1980]\ttraining's rmse: 55.751\tvalid_1's rmse: 109.404\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's rmse: 55.4881\tvalid_1's rmse: 109.372\n",
      "25\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.023403 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 29712\n",
      "[LightGBM] [Info] Number of data points in the train set: 59281, number of used features: 117\n",
      "[LightGBM] [Info] Start training from score 366.485971\n",
      "Training until validation scores don't improve for 125 rounds\n",
      "[30]\ttraining's rmse: 186.088\tvalid_1's rmse: 187.048\n",
      "[60]\ttraining's rmse: 147.894\tvalid_1's rmse: 152.022\n",
      "[90]\ttraining's rmse: 129.038\tvalid_1's rmse: 135.764\n",
      "[120]\ttraining's rmse: 118.593\tvalid_1's rmse: 127.492\n",
      "[150]\ttraining's rmse: 112.115\tvalid_1's rmse: 122.94\n",
      "[180]\ttraining's rmse: 107.484\tvalid_1's rmse: 119.968\n",
      "[210]\ttraining's rmse: 103.869\tvalid_1's rmse: 117.782\n",
      "[240]\ttraining's rmse: 100.968\tvalid_1's rmse: 116.276\n",
      "[270]\ttraining's rmse: 98.5139\tvalid_1's rmse: 115.086\n",
      "[300]\ttraining's rmse: 96.4437\tvalid_1's rmse: 114.092\n",
      "[330]\ttraining's rmse: 94.7\tvalid_1's rmse: 113.497\n",
      "[360]\ttraining's rmse: 93.0852\tvalid_1's rmse: 112.966\n",
      "[390]\ttraining's rmse: 91.4899\tvalid_1's rmse: 112.476\n",
      "[420]\ttraining's rmse: 90.0428\tvalid_1's rmse: 112.09\n",
      "[450]\ttraining's rmse: 88.6742\tvalid_1's rmse: 111.71\n",
      "[480]\ttraining's rmse: 87.4988\tvalid_1's rmse: 111.473\n",
      "[510]\ttraining's rmse: 86.2218\tvalid_1's rmse: 111.116\n",
      "[540]\ttraining's rmse: 85.0234\tvalid_1's rmse: 110.837\n",
      "[570]\ttraining's rmse: 83.9158\tvalid_1's rmse: 110.56\n",
      "[600]\ttraining's rmse: 82.8743\tvalid_1's rmse: 110.386\n",
      "[630]\ttraining's rmse: 81.8817\tvalid_1's rmse: 110.266\n",
      "[660]\ttraining's rmse: 80.9349\tvalid_1's rmse: 110.113\n",
      "[690]\ttraining's rmse: 79.9963\tvalid_1's rmse: 109.983\n",
      "[720]\ttraining's rmse: 79.0108\tvalid_1's rmse: 109.787\n",
      "[750]\ttraining's rmse: 78.14\tvalid_1's rmse: 109.658\n",
      "[780]\ttraining's rmse: 77.2472\tvalid_1's rmse: 109.54\n",
      "[810]\ttraining's rmse: 76.3914\tvalid_1's rmse: 109.42\n",
      "[840]\ttraining's rmse: 75.6526\tvalid_1's rmse: 109.375\n",
      "[870]\ttraining's rmse: 74.8692\tvalid_1's rmse: 109.27\n",
      "[900]\ttraining's rmse: 74.1176\tvalid_1's rmse: 109.2\n",
      "[930]\ttraining's rmse: 73.3768\tvalid_1's rmse: 109.112\n",
      "[960]\ttraining's rmse: 72.5855\tvalid_1's rmse: 108.976\n",
      "[990]\ttraining's rmse: 71.8845\tvalid_1's rmse: 108.914\n",
      "[1020]\ttraining's rmse: 71.1791\tvalid_1's rmse: 108.843\n",
      "[1050]\ttraining's rmse: 70.5103\tvalid_1's rmse: 108.786\n",
      "[1080]\ttraining's rmse: 69.8242\tvalid_1's rmse: 108.703\n",
      "[1110]\ttraining's rmse: 69.1677\tvalid_1's rmse: 108.627\n",
      "[1140]\ttraining's rmse: 68.4608\tvalid_1's rmse: 108.498\n",
      "[1170]\ttraining's rmse: 67.7999\tvalid_1's rmse: 108.427\n",
      "[1200]\ttraining's rmse: 67.2285\tvalid_1's rmse: 108.376\n",
      "[1230]\ttraining's rmse: 66.5989\tvalid_1's rmse: 108.294\n",
      "[1260]\ttraining's rmse: 65.9928\tvalid_1's rmse: 108.255\n",
      "[1290]\ttraining's rmse: 65.4222\tvalid_1's rmse: 108.24\n",
      "[1320]\ttraining's rmse: 64.9301\tvalid_1's rmse: 108.24\n",
      "[1350]\ttraining's rmse: 64.3804\tvalid_1's rmse: 108.182\n",
      "[1380]\ttraining's rmse: 63.8214\tvalid_1's rmse: 108.144\n",
      "[1410]\ttraining's rmse: 63.3192\tvalid_1's rmse: 108.151\n",
      "[1440]\ttraining's rmse: 62.7737\tvalid_1's rmse: 108.105\n",
      "[1470]\ttraining's rmse: 62.3007\tvalid_1's rmse: 108.124\n",
      "[1500]\ttraining's rmse: 61.8154\tvalid_1's rmse: 108.123\n",
      "[1530]\ttraining's rmse: 61.2924\tvalid_1's rmse: 108.095\n",
      "[1560]\ttraining's rmse: 60.8202\tvalid_1's rmse: 108.071\n",
      "[1590]\ttraining's rmse: 60.3397\tvalid_1's rmse: 108.032\n",
      "[1620]\ttraining's rmse: 59.9123\tvalid_1's rmse: 108.05\n",
      "[1650]\ttraining's rmse: 59.4216\tvalid_1's rmse: 108.013\n",
      "[1680]\ttraining's rmse: 58.9681\tvalid_1's rmse: 108.014\n",
      "[1710]\ttraining's rmse: 58.5053\tvalid_1's rmse: 107.951\n",
      "[1740]\ttraining's rmse: 58.083\tvalid_1's rmse: 107.944\n",
      "[1770]\ttraining's rmse: 57.6896\tvalid_1's rmse: 107.923\n",
      "[1800]\ttraining's rmse: 57.2538\tvalid_1's rmse: 107.889\n",
      "[1830]\ttraining's rmse: 56.8677\tvalid_1's rmse: 107.883\n",
      "[1860]\ttraining's rmse: 56.4661\tvalid_1's rmse: 107.91\n",
      "[1890]\ttraining's rmse: 56.1306\tvalid_1's rmse: 107.929\n",
      "[1920]\ttraining's rmse: 55.7395\tvalid_1's rmse: 107.916\n",
      "[1950]\ttraining's rmse: 55.371\tvalid_1's rmse: 107.913\n",
      "Early stopping, best iteration is:\n",
      "[1841]\ttraining's rmse: 56.7098\tvalid_1's rmse: 107.868\n",
      "26\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.020923 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 29710\n",
      "[LightGBM] [Info] Number of data points in the train set: 59281, number of used features: 117\n",
      "[LightGBM] [Info] Start training from score 370.385036\n",
      "Training until validation scores don't improve for 125 rounds\n",
      "[30]\ttraining's rmse: 186.456\tvalid_1's rmse: 186.803\n",
      "[60]\ttraining's rmse: 148.136\tvalid_1's rmse: 151.863\n",
      "[90]\ttraining's rmse: 129.553\tvalid_1's rmse: 136.058\n",
      "[120]\ttraining's rmse: 119.238\tvalid_1's rmse: 128.056\n",
      "[150]\ttraining's rmse: 112.704\tvalid_1's rmse: 123.412\n",
      "[180]\ttraining's rmse: 108.084\tvalid_1's rmse: 120.508\n",
      "[210]\ttraining's rmse: 104.404\tvalid_1's rmse: 118.357\n",
      "[240]\ttraining's rmse: 101.533\tvalid_1's rmse: 116.899\n",
      "[270]\ttraining's rmse: 98.9765\tvalid_1's rmse: 115.663\n",
      "[300]\ttraining's rmse: 96.7877\tvalid_1's rmse: 114.701\n",
      "[330]\ttraining's rmse: 94.9508\tvalid_1's rmse: 114.018\n",
      "[360]\ttraining's rmse: 93.2537\tvalid_1's rmse: 113.485\n",
      "[390]\ttraining's rmse: 91.7627\tvalid_1's rmse: 113.032\n",
      "[420]\ttraining's rmse: 90.3587\tvalid_1's rmse: 112.66\n",
      "[450]\ttraining's rmse: 89.0366\tvalid_1's rmse: 112.392\n",
      "[480]\ttraining's rmse: 87.6951\tvalid_1's rmse: 112.023\n",
      "[510]\ttraining's rmse: 86.4236\tvalid_1's rmse: 111.7\n",
      "[540]\ttraining's rmse: 85.2658\tvalid_1's rmse: 111.465\n",
      "[570]\ttraining's rmse: 84.1153\tvalid_1's rmse: 111.294\n",
      "[600]\ttraining's rmse: 83.0296\tvalid_1's rmse: 111.115\n",
      "[630]\ttraining's rmse: 82.0017\tvalid_1's rmse: 110.966\n",
      "[660]\ttraining's rmse: 81.0327\tvalid_1's rmse: 110.886\n",
      "[690]\ttraining's rmse: 79.9898\tvalid_1's rmse: 110.697\n",
      "[720]\ttraining's rmse: 79.1289\tvalid_1's rmse: 110.631\n",
      "[750]\ttraining's rmse: 78.2847\tvalid_1's rmse: 110.583\n",
      "[780]\ttraining's rmse: 77.4175\tvalid_1's rmse: 110.506\n",
      "[810]\ttraining's rmse: 76.5734\tvalid_1's rmse: 110.425\n",
      "[840]\ttraining's rmse: 75.8087\tvalid_1's rmse: 110.393\n",
      "[870]\ttraining's rmse: 75.0684\tvalid_1's rmse: 110.363\n",
      "[900]\ttraining's rmse: 74.3674\tvalid_1's rmse: 110.307\n",
      "[930]\ttraining's rmse: 73.6173\tvalid_1's rmse: 110.224\n",
      "[960]\ttraining's rmse: 72.825\tvalid_1's rmse: 110.145\n",
      "[990]\ttraining's rmse: 72.1261\tvalid_1's rmse: 110.105\n",
      "[1020]\ttraining's rmse: 71.47\tvalid_1's rmse: 110.103\n",
      "[1050]\ttraining's rmse: 70.8182\tvalid_1's rmse: 110.062\n",
      "[1080]\ttraining's rmse: 70.1246\tvalid_1's rmse: 109.989\n",
      "[1110]\ttraining's rmse: 69.4643\tvalid_1's rmse: 109.934\n",
      "[1140]\ttraining's rmse: 68.7908\tvalid_1's rmse: 109.861\n",
      "[1170]\ttraining's rmse: 68.1494\tvalid_1's rmse: 109.796\n",
      "[1200]\ttraining's rmse: 67.5121\tvalid_1's rmse: 109.766\n",
      "[1230]\ttraining's rmse: 66.9177\tvalid_1's rmse: 109.739\n",
      "[1260]\ttraining's rmse: 66.3557\tvalid_1's rmse: 109.721\n",
      "[1290]\ttraining's rmse: 65.7881\tvalid_1's rmse: 109.738\n",
      "[1320]\ttraining's rmse: 65.2587\tvalid_1's rmse: 109.725\n",
      "[1350]\ttraining's rmse: 64.6789\tvalid_1's rmse: 109.709\n",
      "[1380]\ttraining's rmse: 64.1212\tvalid_1's rmse: 109.663\n",
      "[1410]\ttraining's rmse: 63.5965\tvalid_1's rmse: 109.624\n",
      "[1440]\ttraining's rmse: 63.0799\tvalid_1's rmse: 109.627\n",
      "[1470]\ttraining's rmse: 62.5599\tvalid_1's rmse: 109.575\n",
      "[1500]\ttraining's rmse: 62.0236\tvalid_1's rmse: 109.518\n",
      "[1530]\ttraining's rmse: 61.4748\tvalid_1's rmse: 109.452\n",
      "[1560]\ttraining's rmse: 60.9777\tvalid_1's rmse: 109.431\n",
      "[1590]\ttraining's rmse: 60.5106\tvalid_1's rmse: 109.425\n",
      "[1620]\ttraining's rmse: 60.061\tvalid_1's rmse: 109.403\n",
      "[1650]\ttraining's rmse: 59.5679\tvalid_1's rmse: 109.361\n",
      "[1680]\ttraining's rmse: 59.0711\tvalid_1's rmse: 109.315\n",
      "[1710]\ttraining's rmse: 58.6233\tvalid_1's rmse: 109.269\n",
      "[1740]\ttraining's rmse: 58.1499\tvalid_1's rmse: 109.252\n",
      "[1770]\ttraining's rmse: 57.7414\tvalid_1's rmse: 109.266\n",
      "[1800]\ttraining's rmse: 57.3001\tvalid_1's rmse: 109.243\n",
      "[1830]\ttraining's rmse: 56.8754\tvalid_1's rmse: 109.225\n",
      "[1860]\ttraining's rmse: 56.4686\tvalid_1's rmse: 109.236\n",
      "[1890]\ttraining's rmse: 56.074\tvalid_1's rmse: 109.229\n",
      "[1920]\ttraining's rmse: 55.6579\tvalid_1's rmse: 109.202\n",
      "[1950]\ttraining's rmse: 55.2572\tvalid_1's rmse: 109.191\n",
      "[1980]\ttraining's rmse: 54.8342\tvalid_1's rmse: 109.153\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's rmse: 54.581\tvalid_1's rmse: 109.144\n",
      "27\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.022031 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 29708\n",
      "[LightGBM] [Info] Number of data points in the train set: 59281, number of used features: 117\n",
      "[LightGBM] [Info] Start training from score 369.489713\n",
      "Training until validation scores don't improve for 125 rounds\n",
      "[30]\ttraining's rmse: 184.947\tvalid_1's rmse: 187.165\n",
      "[60]\ttraining's rmse: 146.449\tvalid_1's rmse: 151.802\n",
      "[90]\ttraining's rmse: 127.468\tvalid_1's rmse: 135.317\n",
      "[120]\ttraining's rmse: 116.773\tvalid_1's rmse: 126.622\n",
      "[150]\ttraining's rmse: 110.283\tvalid_1's rmse: 121.87\n",
      "[180]\ttraining's rmse: 105.672\tvalid_1's rmse: 118.905\n",
      "[210]\ttraining's rmse: 102.02\tvalid_1's rmse: 116.722\n",
      "[240]\ttraining's rmse: 99.1095\tvalid_1's rmse: 115.194\n",
      "[270]\ttraining's rmse: 96.6805\tvalid_1's rmse: 114.006\n",
      "[300]\ttraining's rmse: 94.4903\tvalid_1's rmse: 113.008\n",
      "[330]\ttraining's rmse: 92.6934\tvalid_1's rmse: 112.369\n",
      "[360]\ttraining's rmse: 91.1085\tvalid_1's rmse: 111.923\n",
      "[390]\ttraining's rmse: 89.6324\tvalid_1's rmse: 111.46\n",
      "[420]\ttraining's rmse: 88.1571\tvalid_1's rmse: 111.041\n",
      "[450]\ttraining's rmse: 86.8596\tvalid_1's rmse: 110.727\n",
      "[480]\ttraining's rmse: 85.6885\tvalid_1's rmse: 110.442\n",
      "[510]\ttraining's rmse: 84.4502\tvalid_1's rmse: 110.175\n",
      "[540]\ttraining's rmse: 83.2961\tvalid_1's rmse: 109.961\n",
      "[570]\ttraining's rmse: 82.1464\tvalid_1's rmse: 109.658\n",
      "[600]\ttraining's rmse: 81.1221\tvalid_1's rmse: 109.493\n",
      "[630]\ttraining's rmse: 80.1697\tvalid_1's rmse: 109.369\n",
      "[660]\ttraining's rmse: 79.1967\tvalid_1's rmse: 109.27\n",
      "[690]\ttraining's rmse: 78.172\tvalid_1's rmse: 109.033\n",
      "[720]\ttraining's rmse: 77.2665\tvalid_1's rmse: 108.942\n",
      "[750]\ttraining's rmse: 76.3631\tvalid_1's rmse: 108.868\n",
      "[780]\ttraining's rmse: 75.4998\tvalid_1's rmse: 108.744\n",
      "[810]\ttraining's rmse: 74.6131\tvalid_1's rmse: 108.645\n",
      "[840]\ttraining's rmse: 73.9137\tvalid_1's rmse: 108.613\n",
      "[870]\ttraining's rmse: 73.1631\tvalid_1's rmse: 108.545\n",
      "[900]\ttraining's rmse: 72.4508\tvalid_1's rmse: 108.49\n",
      "[930]\ttraining's rmse: 71.714\tvalid_1's rmse: 108.421\n",
      "[960]\ttraining's rmse: 70.9266\tvalid_1's rmse: 108.287\n",
      "[990]\ttraining's rmse: 70.1955\tvalid_1's rmse: 108.19\n",
      "[1020]\ttraining's rmse: 69.5002\tvalid_1's rmse: 108.098\n",
      "[1050]\ttraining's rmse: 68.8843\tvalid_1's rmse: 108.082\n",
      "[1080]\ttraining's rmse: 68.2537\tvalid_1's rmse: 108.032\n",
      "[1110]\ttraining's rmse: 67.6105\tvalid_1's rmse: 107.983\n",
      "[1140]\ttraining's rmse: 66.9338\tvalid_1's rmse: 107.932\n",
      "[1170]\ttraining's rmse: 66.3043\tvalid_1's rmse: 107.867\n",
      "[1200]\ttraining's rmse: 65.7038\tvalid_1's rmse: 107.86\n",
      "[1230]\ttraining's rmse: 65.1132\tvalid_1's rmse: 107.776\n",
      "[1260]\ttraining's rmse: 64.5835\tvalid_1's rmse: 107.777\n",
      "[1290]\ttraining's rmse: 64.047\tvalid_1's rmse: 107.754\n",
      "[1320]\ttraining's rmse: 63.4772\tvalid_1's rmse: 107.732\n",
      "[1350]\ttraining's rmse: 62.9473\tvalid_1's rmse: 107.693\n",
      "[1380]\ttraining's rmse: 62.3852\tvalid_1's rmse: 107.656\n",
      "[1410]\ttraining's rmse: 61.8929\tvalid_1's rmse: 107.655\n",
      "[1440]\ttraining's rmse: 61.3594\tvalid_1's rmse: 107.581\n",
      "[1470]\ttraining's rmse: 60.8409\tvalid_1's rmse: 107.543\n",
      "[1500]\ttraining's rmse: 60.3475\tvalid_1's rmse: 107.505\n",
      "[1530]\ttraining's rmse: 59.8371\tvalid_1's rmse: 107.456\n",
      "[1560]\ttraining's rmse: 59.3393\tvalid_1's rmse: 107.432\n",
      "[1590]\ttraining's rmse: 58.8866\tvalid_1's rmse: 107.392\n",
      "[1620]\ttraining's rmse: 58.4252\tvalid_1's rmse: 107.376\n",
      "[1650]\ttraining's rmse: 57.9865\tvalid_1's rmse: 107.35\n",
      "[1680]\ttraining's rmse: 57.5361\tvalid_1's rmse: 107.317\n",
      "[1710]\ttraining's rmse: 57.1108\tvalid_1's rmse: 107.296\n",
      "[1740]\ttraining's rmse: 56.6957\tvalid_1's rmse: 107.268\n",
      "[1770]\ttraining's rmse: 56.2609\tvalid_1's rmse: 107.211\n",
      "[1800]\ttraining's rmse: 55.8146\tvalid_1's rmse: 107.18\n",
      "[1830]\ttraining's rmse: 55.3829\tvalid_1's rmse: 107.145\n",
      "[1860]\ttraining's rmse: 54.9876\tvalid_1's rmse: 107.13\n",
      "[1890]\ttraining's rmse: 54.619\tvalid_1's rmse: 107.109\n",
      "[1920]\ttraining's rmse: 54.2328\tvalid_1's rmse: 107.117\n",
      "[1950]\ttraining's rmse: 53.8431\tvalid_1's rmse: 107.089\n",
      "[1980]\ttraining's rmse: 53.4326\tvalid_1's rmse: 107.04\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's rmse: 53.196\tvalid_1's rmse: 107.039\n",
      "28\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.018770 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 29706\n",
      "[LightGBM] [Info] Number of data points in the train set: 59281, number of used features: 117\n",
      "[LightGBM] [Info] Start training from score 370.509210\n",
      "Training until validation scores don't improve for 125 rounds\n",
      "[30]\ttraining's rmse: 183.719\tvalid_1's rmse: 186.037\n",
      "[60]\ttraining's rmse: 145.037\tvalid_1's rmse: 149.37\n",
      "[90]\ttraining's rmse: 126.181\tvalid_1's rmse: 132.641\n",
      "[120]\ttraining's rmse: 115.426\tvalid_1's rmse: 123.638\n",
      "[150]\ttraining's rmse: 108.674\tvalid_1's rmse: 118.51\n",
      "[180]\ttraining's rmse: 104.054\tvalid_1's rmse: 115.438\n",
      "[210]\ttraining's rmse: 100.428\tvalid_1's rmse: 113.217\n",
      "[240]\ttraining's rmse: 97.5248\tvalid_1's rmse: 111.635\n",
      "[270]\ttraining's rmse: 95.1023\tvalid_1's rmse: 110.375\n",
      "[300]\ttraining's rmse: 92.9744\tvalid_1's rmse: 109.356\n",
      "[330]\ttraining's rmse: 91.2734\tvalid_1's rmse: 108.733\n",
      "[360]\ttraining's rmse: 89.6752\tvalid_1's rmse: 108.22\n",
      "[390]\ttraining's rmse: 88.2754\tvalid_1's rmse: 107.79\n",
      "[420]\ttraining's rmse: 86.8048\tvalid_1's rmse: 107.285\n",
      "[450]\ttraining's rmse: 85.5038\tvalid_1's rmse: 106.974\n",
      "[480]\ttraining's rmse: 84.2801\tvalid_1's rmse: 106.643\n",
      "[510]\ttraining's rmse: 83.1004\tvalid_1's rmse: 106.31\n",
      "[540]\ttraining's rmse: 82.0087\tvalid_1's rmse: 106.028\n",
      "[570]\ttraining's rmse: 80.9594\tvalid_1's rmse: 105.801\n",
      "[600]\ttraining's rmse: 79.9476\tvalid_1's rmse: 105.595\n",
      "[630]\ttraining's rmse: 78.9661\tvalid_1's rmse: 105.414\n",
      "[660]\ttraining's rmse: 78.0483\tvalid_1's rmse: 105.295\n",
      "[690]\ttraining's rmse: 77.0968\tvalid_1's rmse: 105.137\n",
      "[720]\ttraining's rmse: 76.2007\tvalid_1's rmse: 105.007\n",
      "[750]\ttraining's rmse: 75.3201\tvalid_1's rmse: 104.835\n",
      "[780]\ttraining's rmse: 74.4696\tvalid_1's rmse: 104.666\n",
      "[810]\ttraining's rmse: 73.6808\tvalid_1's rmse: 104.574\n",
      "[840]\ttraining's rmse: 72.9249\tvalid_1's rmse: 104.514\n",
      "[870]\ttraining's rmse: 72.2485\tvalid_1's rmse: 104.502\n",
      "[900]\ttraining's rmse: 71.475\tvalid_1's rmse: 104.444\n",
      "[930]\ttraining's rmse: 70.7282\tvalid_1's rmse: 104.314\n",
      "[960]\ttraining's rmse: 70.0115\tvalid_1's rmse: 104.245\n",
      "[990]\ttraining's rmse: 69.3477\tvalid_1's rmse: 104.181\n",
      "[1020]\ttraining's rmse: 68.6527\tvalid_1's rmse: 104.118\n",
      "[1050]\ttraining's rmse: 68.0278\tvalid_1's rmse: 104.037\n",
      "[1080]\ttraining's rmse: 67.3661\tvalid_1's rmse: 103.945\n",
      "[1110]\ttraining's rmse: 66.7534\tvalid_1's rmse: 103.894\n",
      "[1140]\ttraining's rmse: 66.1167\tvalid_1's rmse: 103.81\n",
      "[1170]\ttraining's rmse: 65.5284\tvalid_1's rmse: 103.787\n",
      "[1200]\ttraining's rmse: 64.9272\tvalid_1's rmse: 103.756\n",
      "[1230]\ttraining's rmse: 64.3406\tvalid_1's rmse: 103.707\n",
      "[1260]\ttraining's rmse: 63.8173\tvalid_1's rmse: 103.681\n",
      "[1290]\ttraining's rmse: 63.2823\tvalid_1's rmse: 103.65\n",
      "[1320]\ttraining's rmse: 62.7524\tvalid_1's rmse: 103.584\n",
      "[1350]\ttraining's rmse: 62.1962\tvalid_1's rmse: 103.514\n",
      "[1380]\ttraining's rmse: 61.6495\tvalid_1's rmse: 103.462\n",
      "[1410]\ttraining's rmse: 61.1131\tvalid_1's rmse: 103.402\n",
      "[1440]\ttraining's rmse: 60.5891\tvalid_1's rmse: 103.351\n",
      "[1470]\ttraining's rmse: 60.0956\tvalid_1's rmse: 103.292\n",
      "[1500]\ttraining's rmse: 59.5965\tvalid_1's rmse: 103.25\n",
      "[1530]\ttraining's rmse: 59.1141\tvalid_1's rmse: 103.236\n",
      "[1560]\ttraining's rmse: 58.631\tvalid_1's rmse: 103.191\n",
      "[1590]\ttraining's rmse: 58.1857\tvalid_1's rmse: 103.164\n",
      "[1620]\ttraining's rmse: 57.7324\tvalid_1's rmse: 103.119\n",
      "[1650]\ttraining's rmse: 57.2772\tvalid_1's rmse: 103.08\n",
      "[1680]\ttraining's rmse: 56.8691\tvalid_1's rmse: 103.078\n",
      "[1710]\ttraining's rmse: 56.4566\tvalid_1's rmse: 103.052\n",
      "[1740]\ttraining's rmse: 56.0301\tvalid_1's rmse: 103.025\n",
      "[1770]\ttraining's rmse: 55.6326\tvalid_1's rmse: 103.01\n",
      "[1800]\ttraining's rmse: 55.2398\tvalid_1's rmse: 103.01\n",
      "[1830]\ttraining's rmse: 54.8409\tvalid_1's rmse: 102.992\n",
      "[1860]\ttraining's rmse: 54.414\tvalid_1's rmse: 102.936\n",
      "[1890]\ttraining's rmse: 54.0256\tvalid_1's rmse: 102.917\n",
      "[1920]\ttraining's rmse: 53.6107\tvalid_1's rmse: 102.905\n",
      "[1950]\ttraining's rmse: 53.2146\tvalid_1's rmse: 102.9\n",
      "[1980]\ttraining's rmse: 52.8173\tvalid_1's rmse: 102.87\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's rmse: 52.5883\tvalid_1's rmse: 102.866\n",
      "29\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.023839 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 29704\n",
      "[LightGBM] [Info] Number of data points in the train set: 59281, number of used features: 117\n",
      "[LightGBM] [Info] Start training from score 370.462944\n",
      "Training until validation scores don't improve for 125 rounds\n",
      "[30]\ttraining's rmse: 182.013\tvalid_1's rmse: 182.944\n",
      "[60]\ttraining's rmse: 143.511\tvalid_1's rmse: 147.714\n",
      "[90]\ttraining's rmse: 124.542\tvalid_1's rmse: 131.283\n",
      "[120]\ttraining's rmse: 113.992\tvalid_1's rmse: 122.767\n",
      "[150]\ttraining's rmse: 107.465\tvalid_1's rmse: 117.925\n",
      "[180]\ttraining's rmse: 102.779\tvalid_1's rmse: 114.706\n",
      "[210]\ttraining's rmse: 99.2318\tvalid_1's rmse: 112.495\n",
      "[240]\ttraining's rmse: 96.3763\tvalid_1's rmse: 110.869\n",
      "[270]\ttraining's rmse: 93.9235\tvalid_1's rmse: 109.497\n",
      "[300]\ttraining's rmse: 91.8524\tvalid_1's rmse: 108.455\n",
      "[330]\ttraining's rmse: 90.0787\tvalid_1's rmse: 107.775\n",
      "[360]\ttraining's rmse: 88.4796\tvalid_1's rmse: 107.165\n",
      "[390]\ttraining's rmse: 87.0615\tvalid_1's rmse: 106.708\n",
      "[420]\ttraining's rmse: 85.6477\tvalid_1's rmse: 106.262\n",
      "[450]\ttraining's rmse: 84.342\tvalid_1's rmse: 105.876\n",
      "[480]\ttraining's rmse: 83.102\tvalid_1's rmse: 105.533\n",
      "[510]\ttraining's rmse: 81.9194\tvalid_1's rmse: 105.21\n",
      "[540]\ttraining's rmse: 80.8056\tvalid_1's rmse: 104.967\n",
      "[570]\ttraining's rmse: 79.726\tvalid_1's rmse: 104.705\n",
      "[600]\ttraining's rmse: 78.6747\tvalid_1's rmse: 104.471\n",
      "[630]\ttraining's rmse: 77.7794\tvalid_1's rmse: 104.41\n",
      "[660]\ttraining's rmse: 76.8239\tvalid_1's rmse: 104.232\n",
      "[690]\ttraining's rmse: 75.9173\tvalid_1's rmse: 104.041\n",
      "[720]\ttraining's rmse: 75.0664\tvalid_1's rmse: 103.924\n",
      "[750]\ttraining's rmse: 74.2838\tvalid_1's rmse: 103.784\n",
      "[780]\ttraining's rmse: 73.4267\tvalid_1's rmse: 103.613\n",
      "[810]\ttraining's rmse: 72.6764\tvalid_1's rmse: 103.517\n",
      "[840]\ttraining's rmse: 71.9504\tvalid_1's rmse: 103.448\n",
      "[870]\ttraining's rmse: 71.1959\tvalid_1's rmse: 103.374\n",
      "[900]\ttraining's rmse: 70.506\tvalid_1's rmse: 103.317\n",
      "[930]\ttraining's rmse: 69.8279\tvalid_1's rmse: 103.266\n",
      "[960]\ttraining's rmse: 69.1332\tvalid_1's rmse: 103.2\n",
      "[990]\ttraining's rmse: 68.3987\tvalid_1's rmse: 103.091\n",
      "[1020]\ttraining's rmse: 67.7427\tvalid_1's rmse: 103.026\n",
      "[1050]\ttraining's rmse: 67.0938\tvalid_1's rmse: 102.967\n",
      "[1080]\ttraining's rmse: 66.4639\tvalid_1's rmse: 102.857\n",
      "[1110]\ttraining's rmse: 65.9012\tvalid_1's rmse: 102.818\n",
      "[1140]\ttraining's rmse: 65.299\tvalid_1's rmse: 102.726\n",
      "[1170]\ttraining's rmse: 64.6931\tvalid_1's rmse: 102.687\n",
      "[1200]\ttraining's rmse: 64.1498\tvalid_1's rmse: 102.629\n",
      "[1230]\ttraining's rmse: 63.6384\tvalid_1's rmse: 102.617\n",
      "[1260]\ttraining's rmse: 63.1181\tvalid_1's rmse: 102.605\n",
      "[1290]\ttraining's rmse: 62.5845\tvalid_1's rmse: 102.565\n",
      "[1320]\ttraining's rmse: 62.0999\tvalid_1's rmse: 102.56\n",
      "[1350]\ttraining's rmse: 61.5974\tvalid_1's rmse: 102.537\n",
      "[1380]\ttraining's rmse: 61.1028\tvalid_1's rmse: 102.518\n",
      "[1410]\ttraining's rmse: 60.6646\tvalid_1's rmse: 102.5\n",
      "[1440]\ttraining's rmse: 60.1424\tvalid_1's rmse: 102.477\n",
      "[1470]\ttraining's rmse: 59.663\tvalid_1's rmse: 102.445\n",
      "[1500]\ttraining's rmse: 59.1519\tvalid_1's rmse: 102.415\n",
      "[1530]\ttraining's rmse: 58.6818\tvalid_1's rmse: 102.392\n",
      "[1560]\ttraining's rmse: 58.2358\tvalid_1's rmse: 102.365\n",
      "[1590]\ttraining's rmse: 57.7476\tvalid_1's rmse: 102.309\n",
      "[1620]\ttraining's rmse: 57.295\tvalid_1's rmse: 102.297\n",
      "[1650]\ttraining's rmse: 56.8574\tvalid_1's rmse: 102.285\n",
      "[1680]\ttraining's rmse: 56.4232\tvalid_1's rmse: 102.248\n",
      "[1710]\ttraining's rmse: 55.9878\tvalid_1's rmse: 102.197\n",
      "[1740]\ttraining's rmse: 55.6018\tvalid_1's rmse: 102.181\n",
      "[1770]\ttraining's rmse: 55.1955\tvalid_1's rmse: 102.145\n",
      "[1800]\ttraining's rmse: 54.7797\tvalid_1's rmse: 102.119\n",
      "[1830]\ttraining's rmse: 54.3547\tvalid_1's rmse: 102.061\n",
      "[1860]\ttraining's rmse: 53.9568\tvalid_1's rmse: 102.036\n",
      "[1890]\ttraining's rmse: 53.6125\tvalid_1's rmse: 102.051\n",
      "[1920]\ttraining's rmse: 53.2076\tvalid_1's rmse: 102.001\n",
      "[1950]\ttraining's rmse: 52.8544\tvalid_1's rmse: 101.998\n",
      "[1980]\ttraining's rmse: 52.4723\tvalid_1's rmse: 101.975\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's rmse: 52.2403\tvalid_1's rmse: 101.974\n",
      "30\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.018870 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 29702\n",
      "[LightGBM] [Info] Number of data points in the train set: 59281, number of used features: 117\n",
      "[LightGBM] [Info] Start training from score 370.084795\n",
      "Training until validation scores don't improve for 125 rounds\n",
      "[30]\ttraining's rmse: 180.946\tvalid_1's rmse: 180.838\n",
      "[60]\ttraining's rmse: 142.595\tvalid_1's rmse: 145.264\n",
      "[90]\ttraining's rmse: 123.961\tvalid_1's rmse: 128.931\n",
      "[120]\ttraining's rmse: 113.373\tvalid_1's rmse: 120.353\n",
      "[150]\ttraining's rmse: 106.784\tvalid_1's rmse: 115.376\n",
      "[180]\ttraining's rmse: 102.344\tvalid_1's rmse: 112.513\n",
      "[210]\ttraining's rmse: 98.7445\tvalid_1's rmse: 110.348\n",
      "[240]\ttraining's rmse: 95.9273\tvalid_1's rmse: 108.877\n",
      "[270]\ttraining's rmse: 93.5613\tvalid_1's rmse: 107.71\n",
      "[300]\ttraining's rmse: 91.5115\tvalid_1's rmse: 106.798\n",
      "[330]\ttraining's rmse: 89.8017\tvalid_1's rmse: 106.192\n",
      "[360]\ttraining's rmse: 88.1459\tvalid_1's rmse: 105.622\n",
      "[390]\ttraining's rmse: 86.653\tvalid_1's rmse: 105.12\n",
      "[420]\ttraining's rmse: 85.2908\tvalid_1's rmse: 104.701\n",
      "[450]\ttraining's rmse: 84.0898\tvalid_1's rmse: 104.423\n",
      "[480]\ttraining's rmse: 82.9209\tvalid_1's rmse: 104.152\n",
      "[510]\ttraining's rmse: 81.7402\tvalid_1's rmse: 103.858\n",
      "[540]\ttraining's rmse: 80.6681\tvalid_1's rmse: 103.65\n",
      "[570]\ttraining's rmse: 79.5842\tvalid_1's rmse: 103.423\n",
      "[600]\ttraining's rmse: 78.5946\tvalid_1's rmse: 103.248\n",
      "[630]\ttraining's rmse: 77.6158\tvalid_1's rmse: 103.094\n",
      "[660]\ttraining's rmse: 76.7252\tvalid_1's rmse: 102.984\n",
      "[690]\ttraining's rmse: 75.8139\tvalid_1's rmse: 102.812\n",
      "[720]\ttraining's rmse: 74.9307\tvalid_1's rmse: 102.678\n",
      "[750]\ttraining's rmse: 74.064\tvalid_1's rmse: 102.51\n",
      "[780]\ttraining's rmse: 73.243\tvalid_1's rmse: 102.425\n",
      "[810]\ttraining's rmse: 72.4553\tvalid_1's rmse: 102.333\n",
      "[840]\ttraining's rmse: 71.7528\tvalid_1's rmse: 102.303\n",
      "[870]\ttraining's rmse: 71.0369\tvalid_1's rmse: 102.236\n",
      "[900]\ttraining's rmse: 70.3821\tvalid_1's rmse: 102.186\n",
      "[930]\ttraining's rmse: 69.7065\tvalid_1's rmse: 102.112\n",
      "[960]\ttraining's rmse: 69.02\tvalid_1's rmse: 102.067\n",
      "[990]\ttraining's rmse: 68.3739\tvalid_1's rmse: 102.03\n",
      "[1020]\ttraining's rmse: 67.7235\tvalid_1's rmse: 102.019\n",
      "[1050]\ttraining's rmse: 67.1024\tvalid_1's rmse: 101.987\n",
      "[1080]\ttraining's rmse: 66.4731\tvalid_1's rmse: 101.937\n",
      "[1110]\ttraining's rmse: 65.8285\tvalid_1's rmse: 101.836\n",
      "[1140]\ttraining's rmse: 65.2067\tvalid_1's rmse: 101.78\n",
      "[1170]\ttraining's rmse: 64.6316\tvalid_1's rmse: 101.739\n",
      "[1200]\ttraining's rmse: 64.0794\tvalid_1's rmse: 101.703\n",
      "[1230]\ttraining's rmse: 63.5255\tvalid_1's rmse: 101.668\n",
      "[1260]\ttraining's rmse: 62.9955\tvalid_1's rmse: 101.645\n",
      "[1290]\ttraining's rmse: 62.4881\tvalid_1's rmse: 101.607\n",
      "[1320]\ttraining's rmse: 61.9674\tvalid_1's rmse: 101.605\n",
      "[1350]\ttraining's rmse: 61.4242\tvalid_1's rmse: 101.576\n",
      "[1380]\ttraining's rmse: 60.9279\tvalid_1's rmse: 101.574\n",
      "[1410]\ttraining's rmse: 60.4565\tvalid_1's rmse: 101.571\n",
      "[1440]\ttraining's rmse: 59.9542\tvalid_1's rmse: 101.528\n",
      "[1470]\ttraining's rmse: 59.4333\tvalid_1's rmse: 101.467\n",
      "[1500]\ttraining's rmse: 58.9779\tvalid_1's rmse: 101.459\n",
      "[1530]\ttraining's rmse: 58.5245\tvalid_1's rmse: 101.454\n",
      "[1560]\ttraining's rmse: 58.0651\tvalid_1's rmse: 101.428\n",
      "[1590]\ttraining's rmse: 57.6221\tvalid_1's rmse: 101.398\n",
      "[1620]\ttraining's rmse: 57.207\tvalid_1's rmse: 101.393\n",
      "[1650]\ttraining's rmse: 56.7614\tvalid_1's rmse: 101.376\n",
      "[1680]\ttraining's rmse: 56.316\tvalid_1's rmse: 101.367\n",
      "[1710]\ttraining's rmse: 55.918\tvalid_1's rmse: 101.355\n",
      "[1740]\ttraining's rmse: 55.5314\tvalid_1's rmse: 101.352\n",
      "[1770]\ttraining's rmse: 55.1056\tvalid_1's rmse: 101.319\n",
      "[1800]\ttraining's rmse: 54.7156\tvalid_1's rmse: 101.291\n",
      "[1830]\ttraining's rmse: 54.3286\tvalid_1's rmse: 101.266\n",
      "[1860]\ttraining's rmse: 53.9331\tvalid_1's rmse: 101.258\n",
      "[1890]\ttraining's rmse: 53.5903\tvalid_1's rmse: 101.277\n",
      "[1920]\ttraining's rmse: 53.2386\tvalid_1's rmse: 101.266\n",
      "[1950]\ttraining's rmse: 52.8817\tvalid_1's rmse: 101.265\n",
      "[1980]\ttraining's rmse: 52.5225\tvalid_1's rmse: 101.255\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's rmse: 52.2699\tvalid_1's rmse: 101.242\n",
      "31\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.024004 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 29700\n",
      "[LightGBM] [Info] Number of data points in the train set: 59281, number of used features: 117\n",
      "[LightGBM] [Info] Start training from score 367.737610\n",
      "Training until validation scores don't improve for 125 rounds\n",
      "[30]\ttraining's rmse: 178.995\tvalid_1's rmse: 179.877\n",
      "[60]\ttraining's rmse: 141.514\tvalid_1's rmse: 145.925\n",
      "[90]\ttraining's rmse: 123.127\tvalid_1's rmse: 130.209\n",
      "[120]\ttraining's rmse: 112.644\tvalid_1's rmse: 121.944\n",
      "[150]\ttraining's rmse: 106.052\tvalid_1's rmse: 117.133\n",
      "[180]\ttraining's rmse: 101.587\tvalid_1's rmse: 114.218\n",
      "[210]\ttraining's rmse: 98.1715\tvalid_1's rmse: 112.211\n",
      "[240]\ttraining's rmse: 95.4893\tvalid_1's rmse: 110.837\n",
      "[270]\ttraining's rmse: 93.1062\tvalid_1's rmse: 109.695\n",
      "[300]\ttraining's rmse: 91.0212\tvalid_1's rmse: 108.706\n",
      "[330]\ttraining's rmse: 89.3314\tvalid_1's rmse: 108.053\n",
      "[360]\ttraining's rmse: 87.7321\tvalid_1's rmse: 107.479\n",
      "[390]\ttraining's rmse: 86.2878\tvalid_1's rmse: 107.043\n",
      "[420]\ttraining's rmse: 84.9445\tvalid_1's rmse: 106.645\n",
      "[450]\ttraining's rmse: 83.7089\tvalid_1's rmse: 106.323\n",
      "[480]\ttraining's rmse: 82.4992\tvalid_1's rmse: 105.983\n",
      "[510]\ttraining's rmse: 81.3746\tvalid_1's rmse: 105.681\n",
      "[540]\ttraining's rmse: 80.3764\tvalid_1's rmse: 105.556\n",
      "[570]\ttraining's rmse: 79.2836\tvalid_1's rmse: 105.248\n",
      "[600]\ttraining's rmse: 78.2674\tvalid_1's rmse: 105.046\n",
      "[630]\ttraining's rmse: 77.3557\tvalid_1's rmse: 104.925\n",
      "[660]\ttraining's rmse: 76.4703\tvalid_1's rmse: 104.819\n",
      "[690]\ttraining's rmse: 75.5439\tvalid_1's rmse: 104.633\n",
      "[720]\ttraining's rmse: 74.692\tvalid_1's rmse: 104.505\n",
      "[750]\ttraining's rmse: 73.8383\tvalid_1's rmse: 104.365\n",
      "[780]\ttraining's rmse: 72.9952\tvalid_1's rmse: 104.21\n",
      "[810]\ttraining's rmse: 72.197\tvalid_1's rmse: 104.087\n",
      "[840]\ttraining's rmse: 71.4677\tvalid_1's rmse: 104.026\n",
      "[870]\ttraining's rmse: 70.7556\tvalid_1's rmse: 103.96\n",
      "[900]\ttraining's rmse: 70.0179\tvalid_1's rmse: 103.848\n",
      "[930]\ttraining's rmse: 69.3589\tvalid_1's rmse: 103.837\n",
      "[960]\ttraining's rmse: 68.6505\tvalid_1's rmse: 103.742\n",
      "[990]\ttraining's rmse: 67.9755\tvalid_1's rmse: 103.675\n",
      "[1020]\ttraining's rmse: 67.3628\tvalid_1's rmse: 103.626\n",
      "[1050]\ttraining's rmse: 66.7469\tvalid_1's rmse: 103.595\n",
      "[1080]\ttraining's rmse: 66.1117\tvalid_1's rmse: 103.497\n",
      "[1110]\ttraining's rmse: 65.5231\tvalid_1's rmse: 103.453\n",
      "[1140]\ttraining's rmse: 64.8662\tvalid_1's rmse: 103.371\n",
      "[1170]\ttraining's rmse: 64.3111\tvalid_1's rmse: 103.352\n",
      "[1200]\ttraining's rmse: 63.8015\tvalid_1's rmse: 103.349\n",
      "[1230]\ttraining's rmse: 63.2044\tvalid_1's rmse: 103.299\n",
      "[1260]\ttraining's rmse: 62.662\tvalid_1's rmse: 103.243\n",
      "[1290]\ttraining's rmse: 62.176\tvalid_1's rmse: 103.23\n",
      "[1320]\ttraining's rmse: 61.6274\tvalid_1's rmse: 103.162\n",
      "[1350]\ttraining's rmse: 61.1502\tvalid_1's rmse: 103.143\n",
      "[1380]\ttraining's rmse: 60.6488\tvalid_1's rmse: 103.112\n",
      "[1410]\ttraining's rmse: 60.1802\tvalid_1's rmse: 103.107\n",
      "[1440]\ttraining's rmse: 59.7042\tvalid_1's rmse: 103.068\n",
      "[1470]\ttraining's rmse: 59.2438\tvalid_1's rmse: 103.061\n",
      "[1500]\ttraining's rmse: 58.7851\tvalid_1's rmse: 103.047\n",
      "[1530]\ttraining's rmse: 58.3307\tvalid_1's rmse: 103.03\n",
      "[1560]\ttraining's rmse: 57.889\tvalid_1's rmse: 103.007\n",
      "[1590]\ttraining's rmse: 57.4487\tvalid_1's rmse: 102.988\n",
      "[1620]\ttraining's rmse: 57.0575\tvalid_1's rmse: 102.995\n",
      "[1650]\ttraining's rmse: 56.6175\tvalid_1's rmse: 102.968\n",
      "[1680]\ttraining's rmse: 56.2135\tvalid_1's rmse: 102.956\n",
      "[1710]\ttraining's rmse: 55.7842\tvalid_1's rmse: 102.932\n",
      "[1740]\ttraining's rmse: 55.3698\tvalid_1's rmse: 102.91\n",
      "[1770]\ttraining's rmse: 54.9364\tvalid_1's rmse: 102.874\n",
      "[1800]\ttraining's rmse: 54.5245\tvalid_1's rmse: 102.842\n",
      "[1830]\ttraining's rmse: 54.131\tvalid_1's rmse: 102.826\n",
      "[1860]\ttraining's rmse: 53.7238\tvalid_1's rmse: 102.805\n",
      "[1890]\ttraining's rmse: 53.3851\tvalid_1's rmse: 102.828\n",
      "[1920]\ttraining's rmse: 52.9793\tvalid_1's rmse: 102.822\n",
      "[1950]\ttraining's rmse: 52.6295\tvalid_1's rmse: 102.828\n",
      "[1980]\ttraining's rmse: 52.2766\tvalid_1's rmse: 102.816\n",
      "Early stopping, best iteration is:\n",
      "[1872]\ttraining's rmse: 53.5874\tvalid_1's rmse: 102.803\n",
      "32\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.022869 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 29702\n",
      "[LightGBM] [Info] Number of data points in the train set: 59281, number of used features: 117\n",
      "[LightGBM] [Info] Start training from score 363.492117\n",
      "Training until validation scores don't improve for 125 rounds\n",
      "[30]\ttraining's rmse: 177.406\tvalid_1's rmse: 177.987\n",
      "[60]\ttraining's rmse: 140.725\tvalid_1's rmse: 143.155\n",
      "[90]\ttraining's rmse: 122.676\tvalid_1's rmse: 127.066\n",
      "[120]\ttraining's rmse: 112.403\tvalid_1's rmse: 118.56\n",
      "[150]\ttraining's rmse: 105.975\tvalid_1's rmse: 113.723\n",
      "[180]\ttraining's rmse: 101.582\tvalid_1's rmse: 110.782\n",
      "[210]\ttraining's rmse: 98.0889\tvalid_1's rmse: 108.644\n",
      "[240]\ttraining's rmse: 95.3728\tvalid_1's rmse: 107.201\n",
      "[270]\ttraining's rmse: 93.0011\tvalid_1's rmse: 106.024\n",
      "[300]\ttraining's rmse: 91.0016\tvalid_1's rmse: 105.155\n",
      "[330]\ttraining's rmse: 89.3201\tvalid_1's rmse: 104.592\n",
      "[360]\ttraining's rmse: 87.7665\tvalid_1's rmse: 104.123\n",
      "[390]\ttraining's rmse: 86.4097\tvalid_1's rmse: 103.753\n",
      "[420]\ttraining's rmse: 85.0501\tvalid_1's rmse: 103.347\n",
      "[450]\ttraining's rmse: 83.8227\tvalid_1's rmse: 103.057\n",
      "[480]\ttraining's rmse: 82.6288\tvalid_1's rmse: 102.759\n",
      "[510]\ttraining's rmse: 81.385\tvalid_1's rmse: 102.4\n",
      "[540]\ttraining's rmse: 80.3488\tvalid_1's rmse: 102.221\n",
      "[570]\ttraining's rmse: 79.3294\tvalid_1's rmse: 102.031\n",
      "[600]\ttraining's rmse: 78.2757\tvalid_1's rmse: 101.848\n",
      "[630]\ttraining's rmse: 77.3535\tvalid_1's rmse: 101.718\n",
      "[660]\ttraining's rmse: 76.4371\tvalid_1's rmse: 101.609\n",
      "[690]\ttraining's rmse: 75.5269\tvalid_1's rmse: 101.462\n",
      "[720]\ttraining's rmse: 74.7073\tvalid_1's rmse: 101.401\n",
      "[750]\ttraining's rmse: 73.819\tvalid_1's rmse: 101.253\n",
      "[780]\ttraining's rmse: 72.9796\tvalid_1's rmse: 101.15\n",
      "[810]\ttraining's rmse: 72.2351\tvalid_1's rmse: 101.115\n",
      "[840]\ttraining's rmse: 71.4474\tvalid_1's rmse: 101.006\n",
      "[870]\ttraining's rmse: 70.7154\tvalid_1's rmse: 100.929\n",
      "[900]\ttraining's rmse: 70.0071\tvalid_1's rmse: 100.854\n",
      "[930]\ttraining's rmse: 69.3504\tvalid_1's rmse: 100.818\n",
      "[960]\ttraining's rmse: 68.6923\tvalid_1's rmse: 100.785\n",
      "[990]\ttraining's rmse: 68.0416\tvalid_1's rmse: 100.731\n",
      "[1020]\ttraining's rmse: 67.4075\tvalid_1's rmse: 100.701\n",
      "[1050]\ttraining's rmse: 66.7871\tvalid_1's rmse: 100.67\n",
      "[1080]\ttraining's rmse: 66.1606\tvalid_1's rmse: 100.615\n",
      "[1110]\ttraining's rmse: 65.5493\tvalid_1's rmse: 100.591\n",
      "[1140]\ttraining's rmse: 64.9487\tvalid_1's rmse: 100.579\n",
      "[1170]\ttraining's rmse: 64.3723\tvalid_1's rmse: 100.522\n",
      "[1200]\ttraining's rmse: 63.7801\tvalid_1's rmse: 100.502\n",
      "[1230]\ttraining's rmse: 63.2382\tvalid_1's rmse: 100.473\n",
      "[1260]\ttraining's rmse: 62.7389\tvalid_1's rmse: 100.493\n",
      "[1290]\ttraining's rmse: 62.2192\tvalid_1's rmse: 100.471\n",
      "[1320]\ttraining's rmse: 61.6786\tvalid_1's rmse: 100.439\n",
      "[1350]\ttraining's rmse: 61.1743\tvalid_1's rmse: 100.403\n",
      "[1380]\ttraining's rmse: 60.6475\tvalid_1's rmse: 100.371\n",
      "[1410]\ttraining's rmse: 60.136\tvalid_1's rmse: 100.341\n",
      "[1440]\ttraining's rmse: 59.6509\tvalid_1's rmse: 100.321\n",
      "[1470]\ttraining's rmse: 59.1362\tvalid_1's rmse: 100.27\n",
      "[1500]\ttraining's rmse: 58.6897\tvalid_1's rmse: 100.283\n",
      "[1530]\ttraining's rmse: 58.2219\tvalid_1's rmse: 100.265\n",
      "[1560]\ttraining's rmse: 57.7912\tvalid_1's rmse: 100.263\n",
      "[1590]\ttraining's rmse: 57.3509\tvalid_1's rmse: 100.235\n",
      "[1620]\ttraining's rmse: 56.9248\tvalid_1's rmse: 100.25\n",
      "[1650]\ttraining's rmse: 56.4911\tvalid_1's rmse: 100.244\n",
      "[1680]\ttraining's rmse: 56.0897\tvalid_1's rmse: 100.22\n",
      "[1710]\ttraining's rmse: 55.6773\tvalid_1's rmse: 100.23\n",
      "[1740]\ttraining's rmse: 55.2487\tvalid_1's rmse: 100.188\n",
      "[1770]\ttraining's rmse: 54.8793\tvalid_1's rmse: 100.201\n",
      "[1800]\ttraining's rmse: 54.4544\tvalid_1's rmse: 100.188\n",
      "[1830]\ttraining's rmse: 54.1092\tvalid_1's rmse: 100.196\n",
      "[1860]\ttraining's rmse: 53.7008\tvalid_1's rmse: 100.168\n",
      "[1890]\ttraining's rmse: 53.3605\tvalid_1's rmse: 100.183\n",
      "[1920]\ttraining's rmse: 52.9761\tvalid_1's rmse: 100.186\n",
      "[1950]\ttraining's rmse: 52.6103\tvalid_1's rmse: 100.182\n",
      "[1980]\ttraining's rmse: 52.2461\tvalid_1's rmse: 100.175\n",
      "Early stopping, best iteration is:\n",
      "[1856]\ttraining's rmse: 53.7463\tvalid_1's rmse: 100.166\n",
      "33\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.019894 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 29704\n",
      "[LightGBM] [Info] Number of data points in the train set: 59281, number of used features: 117\n",
      "[LightGBM] [Info] Start training from score 361.577609\n",
      "Training until validation scores don't improve for 125 rounds\n",
      "[30]\ttraining's rmse: 176.355\tvalid_1's rmse: 178.688\n",
      "[60]\ttraining's rmse: 140.108\tvalid_1's rmse: 144.803\n",
      "[90]\ttraining's rmse: 122.168\tvalid_1's rmse: 128.861\n",
      "[120]\ttraining's rmse: 112.058\tvalid_1's rmse: 120.545\n",
      "[150]\ttraining's rmse: 105.722\tvalid_1's rmse: 115.846\n",
      "[180]\ttraining's rmse: 101.284\tvalid_1's rmse: 112.869\n",
      "[210]\ttraining's rmse: 97.8835\tvalid_1's rmse: 110.782\n",
      "[240]\ttraining's rmse: 95.1312\tvalid_1's rmse: 109.238\n",
      "[270]\ttraining's rmse: 92.8899\tvalid_1's rmse: 108.175\n",
      "[300]\ttraining's rmse: 90.9797\tvalid_1's rmse: 107.284\n",
      "[330]\ttraining's rmse: 89.394\tvalid_1's rmse: 106.794\n",
      "[360]\ttraining's rmse: 87.8813\tvalid_1's rmse: 106.326\n",
      "[390]\ttraining's rmse: 86.5515\tvalid_1's rmse: 106.013\n",
      "[420]\ttraining's rmse: 85.2185\tvalid_1's rmse: 105.648\n",
      "[450]\ttraining's rmse: 83.9518\tvalid_1's rmse: 105.312\n",
      "[480]\ttraining's rmse: 82.7974\tvalid_1's rmse: 105.059\n",
      "[510]\ttraining's rmse: 81.6491\tvalid_1's rmse: 104.784\n",
      "[540]\ttraining's rmse: 80.5468\tvalid_1's rmse: 104.558\n",
      "[570]\ttraining's rmse: 79.5569\tvalid_1's rmse: 104.346\n",
      "[600]\ttraining's rmse: 78.5619\tvalid_1's rmse: 104.181\n",
      "[630]\ttraining's rmse: 77.6823\tvalid_1's rmse: 104.09\n",
      "[660]\ttraining's rmse: 76.8172\tvalid_1's rmse: 103.967\n",
      "[690]\ttraining's rmse: 75.9557\tvalid_1's rmse: 103.862\n",
      "[720]\ttraining's rmse: 75.1067\tvalid_1's rmse: 103.747\n",
      "[750]\ttraining's rmse: 74.3022\tvalid_1's rmse: 103.666\n",
      "[780]\ttraining's rmse: 73.4806\tvalid_1's rmse: 103.567\n",
      "[810]\ttraining's rmse: 72.7203\tvalid_1's rmse: 103.498\n",
      "[840]\ttraining's rmse: 72.0268\tvalid_1's rmse: 103.478\n",
      "[870]\ttraining's rmse: 71.3054\tvalid_1's rmse: 103.429\n",
      "[900]\ttraining's rmse: 70.5597\tvalid_1's rmse: 103.322\n",
      "[930]\ttraining's rmse: 69.8682\tvalid_1's rmse: 103.257\n",
      "[960]\ttraining's rmse: 69.1833\tvalid_1's rmse: 103.184\n",
      "[990]\ttraining's rmse: 68.5031\tvalid_1's rmse: 103.126\n",
      "[1020]\ttraining's rmse: 67.8567\tvalid_1's rmse: 103.072\n",
      "[1050]\ttraining's rmse: 67.2346\tvalid_1's rmse: 103.054\n",
      "[1080]\ttraining's rmse: 66.6157\tvalid_1's rmse: 102.983\n",
      "[1110]\ttraining's rmse: 65.9835\tvalid_1's rmse: 102.902\n",
      "[1140]\ttraining's rmse: 65.3954\tvalid_1's rmse: 102.878\n",
      "[1170]\ttraining's rmse: 64.8292\tvalid_1's rmse: 102.868\n",
      "[1200]\ttraining's rmse: 64.2261\tvalid_1's rmse: 102.834\n",
      "[1230]\ttraining's rmse: 63.6803\tvalid_1's rmse: 102.8\n",
      "[1260]\ttraining's rmse: 63.1657\tvalid_1's rmse: 102.784\n",
      "[1290]\ttraining's rmse: 62.6494\tvalid_1's rmse: 102.759\n",
      "[1320]\ttraining's rmse: 62.1041\tvalid_1's rmse: 102.706\n",
      "[1350]\ttraining's rmse: 61.5859\tvalid_1's rmse: 102.667\n",
      "[1380]\ttraining's rmse: 61.0944\tvalid_1's rmse: 102.649\n",
      "[1410]\ttraining's rmse: 60.6348\tvalid_1's rmse: 102.645\n",
      "[1440]\ttraining's rmse: 60.1172\tvalid_1's rmse: 102.611\n",
      "[1470]\ttraining's rmse: 59.6483\tvalid_1's rmse: 102.583\n",
      "[1500]\ttraining's rmse: 59.1711\tvalid_1's rmse: 102.572\n",
      "[1530]\ttraining's rmse: 58.6991\tvalid_1's rmse: 102.591\n",
      "[1560]\ttraining's rmse: 58.2783\tvalid_1's rmse: 102.581\n",
      "[1590]\ttraining's rmse: 57.8351\tvalid_1's rmse: 102.557\n",
      "[1620]\ttraining's rmse: 57.4023\tvalid_1's rmse: 102.531\n",
      "[1650]\ttraining's rmse: 56.9764\tvalid_1's rmse: 102.505\n",
      "[1680]\ttraining's rmse: 56.5514\tvalid_1's rmse: 102.509\n",
      "[1710]\ttraining's rmse: 56.1653\tvalid_1's rmse: 102.501\n",
      "[1740]\ttraining's rmse: 55.7089\tvalid_1's rmse: 102.494\n",
      "[1770]\ttraining's rmse: 55.3328\tvalid_1's rmse: 102.493\n",
      "[1800]\ttraining's rmse: 54.8647\tvalid_1's rmse: 102.463\n",
      "[1830]\ttraining's rmse: 54.4835\tvalid_1's rmse: 102.426\n",
      "[1860]\ttraining's rmse: 54.1195\tvalid_1's rmse: 102.426\n",
      "[1890]\ttraining's rmse: 53.7675\tvalid_1's rmse: 102.422\n",
      "[1920]\ttraining's rmse: 53.3895\tvalid_1's rmse: 102.405\n",
      "[1950]\ttraining's rmse: 53.0267\tvalid_1's rmse: 102.421\n",
      "[1980]\ttraining's rmse: 52.7022\tvalid_1's rmse: 102.43\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's rmse: 52.4265\tvalid_1's rmse: 102.395\n",
      "34\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.022842 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 29706\n",
      "[LightGBM] [Info] Number of data points in the train set: 59281, number of used features: 117\n",
      "[LightGBM] [Info] Start training from score 366.153827\n",
      "Training until validation scores don't improve for 125 rounds\n",
      "[30]\ttraining's rmse: 177.24\tvalid_1's rmse: 176.334\n",
      "[60]\ttraining's rmse: 140.724\tvalid_1's rmse: 143.197\n",
      "[90]\ttraining's rmse: 122.758\tvalid_1's rmse: 127.951\n",
      "[120]\ttraining's rmse: 112.66\tvalid_1's rmse: 119.953\n",
      "[150]\ttraining's rmse: 106.184\tvalid_1's rmse: 115.211\n",
      "[180]\ttraining's rmse: 101.733\tvalid_1's rmse: 112.285\n",
      "[210]\ttraining's rmse: 98.3334\tvalid_1's rmse: 110.264\n",
      "[240]\ttraining's rmse: 95.6588\tvalid_1's rmse: 108.828\n",
      "[270]\ttraining's rmse: 93.4636\tvalid_1's rmse: 107.738\n",
      "[300]\ttraining's rmse: 91.5644\tvalid_1's rmse: 107.012\n",
      "[330]\ttraining's rmse: 89.9843\tvalid_1's rmse: 106.555\n",
      "[360]\ttraining's rmse: 88.4412\tvalid_1's rmse: 106.035\n",
      "[390]\ttraining's rmse: 87.1034\tvalid_1's rmse: 105.654\n",
      "[420]\ttraining's rmse: 85.7091\tvalid_1's rmse: 105.237\n",
      "[450]\ttraining's rmse: 84.4536\tvalid_1's rmse: 104.894\n",
      "[480]\ttraining's rmse: 83.2725\tvalid_1's rmse: 104.593\n",
      "[510]\ttraining's rmse: 82.2318\tvalid_1's rmse: 104.405\n",
      "[540]\ttraining's rmse: 81.1085\tvalid_1's rmse: 104.132\n",
      "[570]\ttraining's rmse: 80.0605\tvalid_1's rmse: 103.878\n",
      "[600]\ttraining's rmse: 79.1318\tvalid_1's rmse: 103.714\n",
      "[630]\ttraining's rmse: 78.125\tvalid_1's rmse: 103.49\n",
      "[660]\ttraining's rmse: 77.2188\tvalid_1's rmse: 103.378\n",
      "[690]\ttraining's rmse: 76.3693\tvalid_1's rmse: 103.253\n",
      "[720]\ttraining's rmse: 75.5591\tvalid_1's rmse: 103.145\n",
      "[750]\ttraining's rmse: 74.6672\tvalid_1's rmse: 102.983\n",
      "[780]\ttraining's rmse: 73.8379\tvalid_1's rmse: 102.837\n",
      "[810]\ttraining's rmse: 73.0781\tvalid_1's rmse: 102.749\n",
      "[840]\ttraining's rmse: 72.3358\tvalid_1's rmse: 102.678\n",
      "[870]\ttraining's rmse: 71.5971\tvalid_1's rmse: 102.617\n",
      "[900]\ttraining's rmse: 70.9273\tvalid_1's rmse: 102.568\n",
      "[930]\ttraining's rmse: 70.2379\tvalid_1's rmse: 102.497\n",
      "[960]\ttraining's rmse: 69.5636\tvalid_1's rmse: 102.447\n",
      "[990]\ttraining's rmse: 68.8591\tvalid_1's rmse: 102.36\n",
      "[1020]\ttraining's rmse: 68.2288\tvalid_1's rmse: 102.321\n",
      "[1050]\ttraining's rmse: 67.5999\tvalid_1's rmse: 102.29\n",
      "[1080]\ttraining's rmse: 66.9699\tvalid_1's rmse: 102.228\n",
      "[1110]\ttraining's rmse: 66.3326\tvalid_1's rmse: 102.164\n",
      "[1140]\ttraining's rmse: 65.6897\tvalid_1's rmse: 102.056\n",
      "[1170]\ttraining's rmse: 65.1147\tvalid_1's rmse: 102.017\n",
      "[1200]\ttraining's rmse: 64.5456\tvalid_1's rmse: 101.991\n",
      "[1230]\ttraining's rmse: 64.0183\tvalid_1's rmse: 102.001\n",
      "[1260]\ttraining's rmse: 63.5222\tvalid_1's rmse: 101.981\n",
      "[1290]\ttraining's rmse: 62.9914\tvalid_1's rmse: 101.95\n",
      "[1320]\ttraining's rmse: 62.4836\tvalid_1's rmse: 101.954\n",
      "[1350]\ttraining's rmse: 61.9767\tvalid_1's rmse: 101.903\n",
      "[1380]\ttraining's rmse: 61.4881\tvalid_1's rmse: 101.907\n",
      "[1410]\ttraining's rmse: 61.0601\tvalid_1's rmse: 101.911\n",
      "[1440]\ttraining's rmse: 60.5037\tvalid_1's rmse: 101.821\n",
      "[1470]\ttraining's rmse: 60.0467\tvalid_1's rmse: 101.802\n",
      "[1500]\ttraining's rmse: 59.565\tvalid_1's rmse: 101.762\n",
      "[1530]\ttraining's rmse: 59.0962\tvalid_1's rmse: 101.737\n",
      "[1560]\ttraining's rmse: 58.6336\tvalid_1's rmse: 101.72\n",
      "[1590]\ttraining's rmse: 58.1588\tvalid_1's rmse: 101.687\n",
      "[1620]\ttraining's rmse: 57.7419\tvalid_1's rmse: 101.71\n",
      "[1650]\ttraining's rmse: 57.2975\tvalid_1's rmse: 101.708\n",
      "[1680]\ttraining's rmse: 56.8304\tvalid_1's rmse: 101.686\n",
      "[1710]\ttraining's rmse: 56.3811\tvalid_1's rmse: 101.656\n",
      "[1740]\ttraining's rmse: 55.9565\tvalid_1's rmse: 101.634\n",
      "[1770]\ttraining's rmse: 55.5408\tvalid_1's rmse: 101.612\n",
      "[1800]\ttraining's rmse: 55.1547\tvalid_1's rmse: 101.567\n",
      "[1830]\ttraining's rmse: 54.7051\tvalid_1's rmse: 101.508\n",
      "[1860]\ttraining's rmse: 54.3134\tvalid_1's rmse: 101.504\n",
      "[1890]\ttraining's rmse: 53.9471\tvalid_1's rmse: 101.48\n",
      "[1920]\ttraining's rmse: 53.5761\tvalid_1's rmse: 101.471\n",
      "[1950]\ttraining's rmse: 53.2139\tvalid_1's rmse: 101.485\n",
      "[1980]\ttraining's rmse: 52.8886\tvalid_1's rmse: 101.493\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's rmse: 52.6541\tvalid_1's rmse: 101.481\n",
      "35\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.021106 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 29708\n",
      "[LightGBM] [Info] Number of data points in the train set: 59281, number of used features: 117\n",
      "[LightGBM] [Info] Start training from score 372.843039\n",
      "Training until validation scores don't improve for 125 rounds\n",
      "[30]\ttraining's rmse: 177.939\tvalid_1's rmse: 179.931\n",
      "[60]\ttraining's rmse: 142.587\tvalid_1's rmse: 146.105\n",
      "[90]\ttraining's rmse: 125.089\tvalid_1's rmse: 130.09\n",
      "[120]\ttraining's rmse: 114.963\tvalid_1's rmse: 121.522\n",
      "[150]\ttraining's rmse: 108.476\tvalid_1's rmse: 116.574\n",
      "[180]\ttraining's rmse: 103.945\tvalid_1's rmse: 113.392\n",
      "[210]\ttraining's rmse: 100.399\tvalid_1's rmse: 111.151\n",
      "[240]\ttraining's rmse: 97.6863\tvalid_1's rmse: 109.652\n",
      "[270]\ttraining's rmse: 95.381\tvalid_1's rmse: 108.517\n",
      "[300]\ttraining's rmse: 93.3809\tvalid_1's rmse: 107.586\n",
      "[330]\ttraining's rmse: 91.7742\tvalid_1's rmse: 107.079\n",
      "[360]\ttraining's rmse: 90.1992\tvalid_1's rmse: 106.508\n",
      "[390]\ttraining's rmse: 88.7941\tvalid_1's rmse: 106.108\n",
      "[420]\ttraining's rmse: 87.3876\tvalid_1's rmse: 105.69\n",
      "[450]\ttraining's rmse: 86.1448\tvalid_1's rmse: 105.389\n",
      "[480]\ttraining's rmse: 85.0455\tvalid_1's rmse: 105.199\n",
      "[510]\ttraining's rmse: 83.889\tvalid_1's rmse: 104.908\n",
      "[540]\ttraining's rmse: 82.8417\tvalid_1's rmse: 104.707\n",
      "[570]\ttraining's rmse: 81.7702\tvalid_1's rmse: 104.445\n",
      "[600]\ttraining's rmse: 80.7319\tvalid_1's rmse: 104.236\n",
      "[630]\ttraining's rmse: 79.7893\tvalid_1's rmse: 104.086\n",
      "[660]\ttraining's rmse: 78.9678\tvalid_1's rmse: 104.027\n",
      "[690]\ttraining's rmse: 78.0525\tvalid_1's rmse: 103.892\n",
      "[720]\ttraining's rmse: 77.2049\tvalid_1's rmse: 103.783\n",
      "[750]\ttraining's rmse: 76.4091\tvalid_1's rmse: 103.657\n",
      "[780]\ttraining's rmse: 75.5615\tvalid_1's rmse: 103.504\n",
      "[810]\ttraining's rmse: 74.7787\tvalid_1's rmse: 103.395\n",
      "[840]\ttraining's rmse: 74.0748\tvalid_1's rmse: 103.354\n",
      "[870]\ttraining's rmse: 73.3232\tvalid_1's rmse: 103.237\n",
      "[900]\ttraining's rmse: 72.6227\tvalid_1's rmse: 103.17\n",
      "[930]\ttraining's rmse: 71.9544\tvalid_1's rmse: 103.123\n",
      "[960]\ttraining's rmse: 71.226\tvalid_1's rmse: 103.008\n",
      "[990]\ttraining's rmse: 70.5281\tvalid_1's rmse: 102.904\n",
      "[1020]\ttraining's rmse: 69.872\tvalid_1's rmse: 102.856\n",
      "[1050]\ttraining's rmse: 69.2253\tvalid_1's rmse: 102.788\n",
      "[1080]\ttraining's rmse: 68.6062\tvalid_1's rmse: 102.741\n",
      "[1110]\ttraining's rmse: 68.0434\tvalid_1's rmse: 102.72\n",
      "[1140]\ttraining's rmse: 67.4153\tvalid_1's rmse: 102.653\n",
      "[1170]\ttraining's rmse: 66.7851\tvalid_1's rmse: 102.595\n",
      "[1200]\ttraining's rmse: 66.1746\tvalid_1's rmse: 102.532\n",
      "[1230]\ttraining's rmse: 65.6383\tvalid_1's rmse: 102.504\n",
      "[1260]\ttraining's rmse: 65.1193\tvalid_1's rmse: 102.497\n",
      "[1290]\ttraining's rmse: 64.6466\tvalid_1's rmse: 102.523\n",
      "[1320]\ttraining's rmse: 64.1307\tvalid_1's rmse: 102.492\n",
      "[1350]\ttraining's rmse: 63.642\tvalid_1's rmse: 102.48\n",
      "[1380]\ttraining's rmse: 63.1284\tvalid_1's rmse: 102.45\n",
      "[1410]\ttraining's rmse: 62.6296\tvalid_1's rmse: 102.407\n",
      "[1440]\ttraining's rmse: 62.0932\tvalid_1's rmse: 102.354\n",
      "[1470]\ttraining's rmse: 61.5509\tvalid_1's rmse: 102.27\n",
      "[1500]\ttraining's rmse: 61.0373\tvalid_1's rmse: 102.208\n",
      "[1530]\ttraining's rmse: 60.5541\tvalid_1's rmse: 102.17\n",
      "[1560]\ttraining's rmse: 60.0918\tvalid_1's rmse: 102.153\n",
      "[1590]\ttraining's rmse: 59.6574\tvalid_1's rmse: 102.124\n",
      "[1620]\ttraining's rmse: 59.2609\tvalid_1's rmse: 102.148\n",
      "[1650]\ttraining's rmse: 58.8164\tvalid_1's rmse: 102.113\n",
      "[1680]\ttraining's rmse: 58.4083\tvalid_1's rmse: 102.106\n",
      "[1710]\ttraining's rmse: 57.9451\tvalid_1's rmse: 102.069\n",
      "[1740]\ttraining's rmse: 57.5246\tvalid_1's rmse: 102.044\n",
      "[1770]\ttraining's rmse: 57.1193\tvalid_1's rmse: 102.014\n",
      "[1800]\ttraining's rmse: 56.6911\tvalid_1's rmse: 101.962\n",
      "[1830]\ttraining's rmse: 56.2701\tvalid_1's rmse: 101.939\n",
      "[1860]\ttraining's rmse: 55.8876\tvalid_1's rmse: 101.925\n",
      "[1890]\ttraining's rmse: 55.5238\tvalid_1's rmse: 101.933\n",
      "[1920]\ttraining's rmse: 55.143\tvalid_1's rmse: 101.912\n",
      "[1950]\ttraining's rmse: 54.7436\tvalid_1's rmse: 101.88\n",
      "[1980]\ttraining's rmse: 54.3671\tvalid_1's rmse: 101.842\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's rmse: 54.1147\tvalid_1's rmse: 101.818\n",
      "36\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.020224 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 29710\n",
      "[LightGBM] [Info] Number of data points in the train set: 59281, number of used features: 117\n",
      "[LightGBM] [Info] Start training from score 376.484045\n",
      "Training until validation scores don't improve for 125 rounds\n",
      "[30]\ttraining's rmse: 177.956\tvalid_1's rmse: 181.135\n",
      "[60]\ttraining's rmse: 142.695\tvalid_1's rmse: 148.664\n",
      "[90]\ttraining's rmse: 125.05\tvalid_1's rmse: 133.074\n",
      "[120]\ttraining's rmse: 115.056\tvalid_1's rmse: 124.888\n",
      "[150]\ttraining's rmse: 108.589\tvalid_1's rmse: 119.987\n",
      "[180]\ttraining's rmse: 104.133\tvalid_1's rmse: 116.886\n",
      "[210]\ttraining's rmse: 100.519\tvalid_1's rmse: 114.452\n",
      "[240]\ttraining's rmse: 97.7249\tvalid_1's rmse: 112.896\n",
      "[270]\ttraining's rmse: 95.5285\tvalid_1's rmse: 111.903\n",
      "[300]\ttraining's rmse: 93.5443\tvalid_1's rmse: 111.022\n",
      "[330]\ttraining's rmse: 91.9078\tvalid_1's rmse: 110.509\n",
      "[360]\ttraining's rmse: 90.3597\tvalid_1's rmse: 110.005\n",
      "[390]\ttraining's rmse: 88.9213\tvalid_1's rmse: 109.599\n",
      "[420]\ttraining's rmse: 87.5993\tvalid_1's rmse: 109.237\n",
      "[450]\ttraining's rmse: 86.304\tvalid_1's rmse: 108.887\n",
      "[480]\ttraining's rmse: 85.19\tvalid_1's rmse: 108.717\n",
      "[510]\ttraining's rmse: 84.0512\tvalid_1's rmse: 108.508\n",
      "[540]\ttraining's rmse: 82.9596\tvalid_1's rmse: 108.229\n",
      "[570]\ttraining's rmse: 81.8188\tvalid_1's rmse: 107.972\n",
      "[600]\ttraining's rmse: 80.8156\tvalid_1's rmse: 107.756\n",
      "[630]\ttraining's rmse: 79.9399\tvalid_1's rmse: 107.662\n",
      "[660]\ttraining's rmse: 79.074\tvalid_1's rmse: 107.58\n",
      "[690]\ttraining's rmse: 78.139\tvalid_1's rmse: 107.433\n",
      "[720]\ttraining's rmse: 77.3021\tvalid_1's rmse: 107.326\n",
      "[750]\ttraining's rmse: 76.4254\tvalid_1's rmse: 107.15\n",
      "[780]\ttraining's rmse: 75.6052\tvalid_1's rmse: 107.045\n",
      "[810]\ttraining's rmse: 74.7818\tvalid_1's rmse: 106.942\n",
      "[840]\ttraining's rmse: 74.0412\tvalid_1's rmse: 106.836\n",
      "[870]\ttraining's rmse: 73.3058\tvalid_1's rmse: 106.753\n",
      "[900]\ttraining's rmse: 72.6188\tvalid_1's rmse: 106.684\n",
      "[930]\ttraining's rmse: 71.9289\tvalid_1's rmse: 106.638\n",
      "[960]\ttraining's rmse: 71.2098\tvalid_1's rmse: 106.533\n",
      "[990]\ttraining's rmse: 70.5739\tvalid_1's rmse: 106.485\n",
      "[1020]\ttraining's rmse: 69.9304\tvalid_1's rmse: 106.421\n",
      "[1050]\ttraining's rmse: 69.308\tvalid_1's rmse: 106.357\n",
      "[1080]\ttraining's rmse: 68.6395\tvalid_1's rmse: 106.292\n",
      "[1110]\ttraining's rmse: 68.0765\tvalid_1's rmse: 106.266\n",
      "[1140]\ttraining's rmse: 67.4514\tvalid_1's rmse: 106.161\n",
      "[1170]\ttraining's rmse: 66.8611\tvalid_1's rmse: 106.081\n",
      "[1200]\ttraining's rmse: 66.3289\tvalid_1's rmse: 106.067\n",
      "[1230]\ttraining's rmse: 65.7397\tvalid_1's rmse: 106.001\n",
      "[1260]\ttraining's rmse: 65.1676\tvalid_1's rmse: 105.948\n",
      "[1290]\ttraining's rmse: 64.6515\tvalid_1's rmse: 105.936\n",
      "[1320]\ttraining's rmse: 64.1438\tvalid_1's rmse: 105.878\n",
      "[1350]\ttraining's rmse: 63.6468\tvalid_1's rmse: 105.861\n",
      "[1380]\ttraining's rmse: 63.1158\tvalid_1's rmse: 105.827\n",
      "[1410]\ttraining's rmse: 62.6065\tvalid_1's rmse: 105.787\n",
      "[1440]\ttraining's rmse: 62.0944\tvalid_1's rmse: 105.744\n",
      "[1470]\ttraining's rmse: 61.6376\tvalid_1's rmse: 105.736\n",
      "[1500]\ttraining's rmse: 61.155\tvalid_1's rmse: 105.701\n",
      "[1530]\ttraining's rmse: 60.7017\tvalid_1's rmse: 105.698\n",
      "[1560]\ttraining's rmse: 60.2353\tvalid_1's rmse: 105.683\n",
      "[1590]\ttraining's rmse: 59.7968\tvalid_1's rmse: 105.677\n",
      "[1620]\ttraining's rmse: 59.3596\tvalid_1's rmse: 105.658\n",
      "[1650]\ttraining's rmse: 58.931\tvalid_1's rmse: 105.679\n",
      "[1680]\ttraining's rmse: 58.5136\tvalid_1's rmse: 105.675\n",
      "[1710]\ttraining's rmse: 58.071\tvalid_1's rmse: 105.639\n",
      "[1740]\ttraining's rmse: 57.6059\tvalid_1's rmse: 105.6\n",
      "[1770]\ttraining's rmse: 57.215\tvalid_1's rmse: 105.628\n",
      "[1800]\ttraining's rmse: 56.795\tvalid_1's rmse: 105.59\n",
      "[1830]\ttraining's rmse: 56.3622\tvalid_1's rmse: 105.533\n",
      "[1860]\ttraining's rmse: 55.9522\tvalid_1's rmse: 105.486\n",
      "[1890]\ttraining's rmse: 55.5603\tvalid_1's rmse: 105.456\n",
      "[1920]\ttraining's rmse: 55.1463\tvalid_1's rmse: 105.434\n",
      "[1950]\ttraining's rmse: 54.7826\tvalid_1's rmse: 105.407\n",
      "[1980]\ttraining's rmse: 54.4238\tvalid_1's rmse: 105.404\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's rmse: 54.1915\tvalid_1's rmse: 105.394\n",
      "37\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.021219 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 29712\n",
      "[LightGBM] [Info] Number of data points in the train set: 59281, number of used features: 117\n",
      "[LightGBM] [Info] Start training from score 379.331795\n",
      "Training until validation scores don't improve for 125 rounds\n",
      "[30]\ttraining's rmse: 177.615\tvalid_1's rmse: 177.997\n",
      "[60]\ttraining's rmse: 142.353\tvalid_1's rmse: 145.925\n",
      "[90]\ttraining's rmse: 124.713\tvalid_1's rmse: 130.68\n",
      "[120]\ttraining's rmse: 114.571\tvalid_1's rmse: 122.553\n",
      "[150]\ttraining's rmse: 107.984\tvalid_1's rmse: 117.58\n",
      "[180]\ttraining's rmse: 103.465\tvalid_1's rmse: 114.546\n",
      "[210]\ttraining's rmse: 99.8288\tvalid_1's rmse: 112.271\n",
      "[240]\ttraining's rmse: 97.135\tvalid_1's rmse: 110.823\n",
      "[270]\ttraining's rmse: 94.8586\tvalid_1's rmse: 109.656\n",
      "[300]\ttraining's rmse: 92.903\tvalid_1's rmse: 108.778\n",
      "[330]\ttraining's rmse: 91.3327\tvalid_1's rmse: 108.293\n",
      "[360]\ttraining's rmse: 89.7535\tvalid_1's rmse: 107.738\n",
      "[390]\ttraining's rmse: 88.3642\tvalid_1's rmse: 107.383\n",
      "[420]\ttraining's rmse: 87.0195\tvalid_1's rmse: 106.956\n",
      "[450]\ttraining's rmse: 85.7374\tvalid_1's rmse: 106.627\n",
      "[480]\ttraining's rmse: 84.6478\tvalid_1's rmse: 106.45\n",
      "[510]\ttraining's rmse: 83.5529\tvalid_1's rmse: 106.25\n",
      "[540]\ttraining's rmse: 82.4905\tvalid_1's rmse: 106.027\n",
      "[570]\ttraining's rmse: 81.3806\tvalid_1's rmse: 105.723\n",
      "[600]\ttraining's rmse: 80.3811\tvalid_1's rmse: 105.514\n",
      "[630]\ttraining's rmse: 79.4214\tvalid_1's rmse: 105.336\n",
      "[660]\ttraining's rmse: 78.5185\tvalid_1's rmse: 105.217\n",
      "[690]\ttraining's rmse: 77.5606\tvalid_1's rmse: 105.011\n",
      "[720]\ttraining's rmse: 76.7086\tvalid_1's rmse: 104.878\n",
      "[750]\ttraining's rmse: 75.8857\tvalid_1's rmse: 104.755\n",
      "[780]\ttraining's rmse: 75.0929\tvalid_1's rmse: 104.695\n",
      "[810]\ttraining's rmse: 74.266\tvalid_1's rmse: 104.548\n",
      "[840]\ttraining's rmse: 73.5427\tvalid_1's rmse: 104.505\n",
      "[870]\ttraining's rmse: 72.8849\tvalid_1's rmse: 104.517\n",
      "[900]\ttraining's rmse: 72.1673\tvalid_1's rmse: 104.459\n",
      "[930]\ttraining's rmse: 71.4351\tvalid_1's rmse: 104.37\n",
      "[960]\ttraining's rmse: 70.6961\tvalid_1's rmse: 104.275\n",
      "[990]\ttraining's rmse: 69.9534\tvalid_1's rmse: 104.188\n",
      "[1020]\ttraining's rmse: 69.281\tvalid_1's rmse: 104.114\n",
      "[1050]\ttraining's rmse: 68.5936\tvalid_1's rmse: 104.005\n",
      "[1080]\ttraining's rmse: 67.9786\tvalid_1's rmse: 103.948\n",
      "[1110]\ttraining's rmse: 67.375\tvalid_1's rmse: 103.888\n",
      "[1140]\ttraining's rmse: 66.7885\tvalid_1's rmse: 103.844\n",
      "[1170]\ttraining's rmse: 66.2061\tvalid_1's rmse: 103.81\n",
      "[1200]\ttraining's rmse: 65.6456\tvalid_1's rmse: 103.758\n",
      "[1230]\ttraining's rmse: 65.0529\tvalid_1's rmse: 103.698\n",
      "[1260]\ttraining's rmse: 64.5775\tvalid_1's rmse: 103.7\n",
      "[1290]\ttraining's rmse: 64.0638\tvalid_1's rmse: 103.675\n",
      "[1320]\ttraining's rmse: 63.5848\tvalid_1's rmse: 103.681\n",
      "[1350]\ttraining's rmse: 63.0713\tvalid_1's rmse: 103.667\n",
      "[1380]\ttraining's rmse: 62.5511\tvalid_1's rmse: 103.656\n",
      "[1410]\ttraining's rmse: 62.1088\tvalid_1's rmse: 103.653\n",
      "[1440]\ttraining's rmse: 61.6177\tvalid_1's rmse: 103.612\n",
      "[1470]\ttraining's rmse: 61.1207\tvalid_1's rmse: 103.561\n",
      "[1500]\ttraining's rmse: 60.6302\tvalid_1's rmse: 103.535\n",
      "[1530]\ttraining's rmse: 60.2101\tvalid_1's rmse: 103.541\n",
      "[1560]\ttraining's rmse: 59.7246\tvalid_1's rmse: 103.513\n",
      "[1590]\ttraining's rmse: 59.2648\tvalid_1's rmse: 103.479\n",
      "[1620]\ttraining's rmse: 58.8089\tvalid_1's rmse: 103.48\n",
      "[1650]\ttraining's rmse: 58.3841\tvalid_1's rmse: 103.476\n",
      "[1680]\ttraining's rmse: 57.943\tvalid_1's rmse: 103.463\n",
      "[1710]\ttraining's rmse: 57.5352\tvalid_1's rmse: 103.459\n",
      "[1740]\ttraining's rmse: 57.1307\tvalid_1's rmse: 103.442\n",
      "[1770]\ttraining's rmse: 56.727\tvalid_1's rmse: 103.424\n",
      "[1800]\ttraining's rmse: 56.3256\tvalid_1's rmse: 103.392\n",
      "[1830]\ttraining's rmse: 55.9499\tvalid_1's rmse: 103.387\n",
      "[1860]\ttraining's rmse: 55.5219\tvalid_1's rmse: 103.345\n",
      "[1890]\ttraining's rmse: 55.1732\tvalid_1's rmse: 103.35\n",
      "[1920]\ttraining's rmse: 54.7951\tvalid_1's rmse: 103.345\n",
      "[1950]\ttraining's rmse: 54.4368\tvalid_1's rmse: 103.336\n",
      "[1980]\ttraining's rmse: 54.0491\tvalid_1's rmse: 103.295\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's rmse: 53.8126\tvalid_1's rmse: 103.289\n",
      "38\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.021833 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 29714\n",
      "[LightGBM] [Info] Number of data points in the train set: 59281, number of used features: 117\n",
      "[LightGBM] [Info] Start training from score 376.345109\n",
      "Training until validation scores don't improve for 125 rounds\n",
      "[30]\ttraining's rmse: 176.638\tvalid_1's rmse: 177.491\n",
      "[60]\ttraining's rmse: 141.714\tvalid_1's rmse: 145.513\n",
      "[90]\ttraining's rmse: 124.181\tvalid_1's rmse: 130.407\n",
      "[120]\ttraining's rmse: 113.969\tvalid_1's rmse: 122.306\n",
      "[150]\ttraining's rmse: 107.305\tvalid_1's rmse: 117.404\n",
      "[180]\ttraining's rmse: 102.679\tvalid_1's rmse: 114.354\n",
      "[210]\ttraining's rmse: 99.0463\tvalid_1's rmse: 112.17\n",
      "[240]\ttraining's rmse: 96.2658\tvalid_1's rmse: 110.75\n",
      "[270]\ttraining's rmse: 93.9257\tvalid_1's rmse: 109.569\n",
      "[300]\ttraining's rmse: 91.9076\tvalid_1's rmse: 108.669\n",
      "[330]\ttraining's rmse: 90.3661\tvalid_1's rmse: 108.196\n",
      "[360]\ttraining's rmse: 88.8323\tvalid_1's rmse: 107.702\n",
      "[390]\ttraining's rmse: 87.4238\tvalid_1's rmse: 107.299\n",
      "[420]\ttraining's rmse: 86.0608\tvalid_1's rmse: 106.931\n",
      "[450]\ttraining's rmse: 84.789\tvalid_1's rmse: 106.609\n",
      "[480]\ttraining's rmse: 83.7059\tvalid_1's rmse: 106.42\n",
      "[510]\ttraining's rmse: 82.5721\tvalid_1's rmse: 106.142\n",
      "[540]\ttraining's rmse: 81.5519\tvalid_1's rmse: 105.991\n",
      "[570]\ttraining's rmse: 80.4643\tvalid_1's rmse: 105.798\n",
      "[600]\ttraining's rmse: 79.4346\tvalid_1's rmse: 105.572\n",
      "[630]\ttraining's rmse: 78.5061\tvalid_1's rmse: 105.458\n",
      "[660]\ttraining's rmse: 77.6149\tvalid_1's rmse: 105.34\n",
      "[690]\ttraining's rmse: 76.7261\tvalid_1's rmse: 105.22\n",
      "[720]\ttraining's rmse: 75.8711\tvalid_1's rmse: 105.123\n",
      "[750]\ttraining's rmse: 75.0427\tvalid_1's rmse: 104.981\n",
      "[780]\ttraining's rmse: 74.2183\tvalid_1's rmse: 104.851\n",
      "[810]\ttraining's rmse: 73.4082\tvalid_1's rmse: 104.783\n",
      "[840]\ttraining's rmse: 72.6501\tvalid_1's rmse: 104.691\n",
      "[870]\ttraining's rmse: 71.9361\tvalid_1's rmse: 104.616\n",
      "[900]\ttraining's rmse: 71.2843\tvalid_1's rmse: 104.583\n",
      "[930]\ttraining's rmse: 70.5958\tvalid_1's rmse: 104.521\n",
      "[960]\ttraining's rmse: 69.9399\tvalid_1's rmse: 104.467\n",
      "[990]\ttraining's rmse: 69.2527\tvalid_1's rmse: 104.39\n",
      "[1020]\ttraining's rmse: 68.6248\tvalid_1's rmse: 104.361\n",
      "[1050]\ttraining's rmse: 67.9965\tvalid_1's rmse: 104.286\n",
      "[1080]\ttraining's rmse: 67.3774\tvalid_1's rmse: 104.219\n",
      "[1110]\ttraining's rmse: 66.7687\tvalid_1's rmse: 104.19\n",
      "[1140]\ttraining's rmse: 66.1406\tvalid_1's rmse: 104.109\n",
      "[1170]\ttraining's rmse: 65.5877\tvalid_1's rmse: 104.075\n",
      "[1200]\ttraining's rmse: 64.9925\tvalid_1's rmse: 104.004\n",
      "[1230]\ttraining's rmse: 64.4302\tvalid_1's rmse: 103.961\n",
      "[1260]\ttraining's rmse: 63.9448\tvalid_1's rmse: 103.956\n",
      "[1290]\ttraining's rmse: 63.4219\tvalid_1's rmse: 103.925\n",
      "[1320]\ttraining's rmse: 62.9534\tvalid_1's rmse: 103.918\n",
      "[1350]\ttraining's rmse: 62.4533\tvalid_1's rmse: 103.91\n",
      "[1380]\ttraining's rmse: 61.9134\tvalid_1's rmse: 103.868\n",
      "[1410]\ttraining's rmse: 61.4516\tvalid_1's rmse: 103.861\n",
      "[1440]\ttraining's rmse: 60.9316\tvalid_1's rmse: 103.848\n",
      "[1470]\ttraining's rmse: 60.4468\tvalid_1's rmse: 103.812\n",
      "[1500]\ttraining's rmse: 59.954\tvalid_1's rmse: 103.76\n",
      "[1530]\ttraining's rmse: 59.5295\tvalid_1's rmse: 103.76\n",
      "[1560]\ttraining's rmse: 59.1321\tvalid_1's rmse: 103.762\n",
      "[1590]\ttraining's rmse: 58.651\tvalid_1's rmse: 103.732\n",
      "[1620]\ttraining's rmse: 58.236\tvalid_1's rmse: 103.735\n",
      "[1650]\ttraining's rmse: 57.8249\tvalid_1's rmse: 103.718\n",
      "[1680]\ttraining's rmse: 57.4189\tvalid_1's rmse: 103.717\n",
      "[1710]\ttraining's rmse: 57.024\tvalid_1's rmse: 103.712\n",
      "[1740]\ttraining's rmse: 56.6205\tvalid_1's rmse: 103.696\n",
      "[1770]\ttraining's rmse: 56.2589\tvalid_1's rmse: 103.703\n",
      "[1800]\ttraining's rmse: 55.8312\tvalid_1's rmse: 103.684\n",
      "[1830]\ttraining's rmse: 55.4304\tvalid_1's rmse: 103.645\n",
      "[1860]\ttraining's rmse: 54.9977\tvalid_1's rmse: 103.624\n",
      "[1890]\ttraining's rmse: 54.6296\tvalid_1's rmse: 103.612\n",
      "[1920]\ttraining's rmse: 54.2327\tvalid_1's rmse: 103.596\n",
      "[1950]\ttraining's rmse: 53.8888\tvalid_1's rmse: 103.592\n",
      "[1980]\ttraining's rmse: 53.5108\tvalid_1's rmse: 103.571\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\ttraining's rmse: 53.2668\tvalid_1's rmse: 103.568\n"
     ]
    }
   ],
   "source": [
    "#lgb mimo example\n",
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "for slot in range(len(df_slots)):\n",
    "    print(slot)\n",
    "    gdf = df_slots[slot].XZ_globalReg(L=14, rolling_step = 1, mode= 'Tree')\n",
    "    \n",
    "    X = gdf['X_tr'].repeat(H,0)\n",
    "    Y =  gdf['Y_tr'].reshape(-1)\n",
    "    Z = np.stack([gdf['Z_tr'][:,(i*H):(i+1)*H].reshape(-1) for i in range(gdf['Z_tr'].shape[1]//H)],1)\n",
    "    mask = gdf['mask_tr'].reshape(-1)\n",
    "\n",
    "    H = gdf['Y_tr'].shape[-1]\n",
    "    X_train, X_val, y_train, y_val, mask_train, mask_val,  =  train_test_split(np.concatenate([X,Z],-1) ,Y ,mask, test_size = 0.2, random_state =0)\n",
    "\n",
    " \n",
    "    X_test = gdf['X_ts'].repeat(H,0)\n",
    "    Z_test = np.stack([gdf['Z_ts'][:,(i*H):(i+1)*H].reshape(-1) for i in range(gdf['Z_ts'].shape[1]//H)],1)\n",
    "    mask_val = mask_val.reshape(-1)\n",
    "    \n",
    "    dtrain = lgb.Dataset(X_train , label= y_train ,weight = mask_train )\n",
    "    dval = lgb.Dataset(X_val , label= y_val, weight = mask_val )\n",
    "    params = {\n",
    "            'num_leaves': 128,\n",
    "            'objective': 'regression',\n",
    "            'min_data_in_leaf': 15,\n",
    "            'learning_rate': 0.02,\n",
    "            'feature_fraction': 0.8,\n",
    "            'bagging_fraction': 0.7,\n",
    "            'bagging_freq': 1,\n",
    "            'metric': 'rmse',\n",
    "            'num_threads': 8\n",
    "        }\n",
    "        \n",
    "        \n",
    "    MAX_ROUNDS = 2000\n",
    "    bst = lgb.train(\n",
    "            params, dtrain, num_boost_round=MAX_ROUNDS, \n",
    "                    valid_sets=[dtrain,dval], early_stopping_rounds=125, verbose_eval=30\n",
    "                )\n",
    "\n",
    "    predicts = bst.predict( np.concatenate([X_test,Z_test],-1), num_iteration=bst.best_iteration or MAX_ROUNDS)\n",
    "\n",
    "    predicts = predicts.reshape(len(gdf['X_ts']),H )\n",
    "    df_slots[slot].add_Base_forecasts(predicts,'lightgbm_mimo')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n"
     ]
    }
   ],
   "source": [
    "# random forest example\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "for slot in range(len(df_slots)):\n",
    "    print(slot)\n",
    "    gdf = df_slots[slot].XZ_globalReg(L=7, rolling_step = 1, mode= 'Tree')\n",
    "\n",
    "    H = gdf['Y_tr'].shape[-1]\n",
    "        \n",
    "    regr = RandomForestRegressor(n_estimators=200 ,max_depth=10, random_state=0, n_jobs = 4 )\n",
    "    regr.fit(X = np.nan_to_num(np.concatenate([gdf['X_tr'],gdf['Z_tr']],-1),nan = -1),\n",
    "             y = np.nan_to_num(gdf['Y_tr'] ,nan = -1),\n",
    "             sample_weight = gdf['mask_tr'][:,0])    \n",
    "    predicts = regr.predict(X = np.nan_to_num(np.concatenate([gdf['X_ts'],gdf['Z_ts']],-1),nan = -1))   \n",
    "    df_slots[slot].add_Base_forecasts(predicts,'rf_mimo')\n",
    "pickle.dump(df_slots, open(dir_ +'kdd2022_metadata_slots_v2' +'.pkl', 'wb'), protocol= 4)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'E:/Datasets/KDD2022/'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(df_slots, open(dir_ +'kdd2022_metadata_slots_exp_h7_s2' +'.pkl', 'wb'), protocol= 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_slots = pickle.load( open(dir_ +'kdd2022_metadata_slots_exp_h7_s2' +'.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "### meta learning\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 1e-5\n",
    "batch_size = 256\n",
    "\n",
    "meta_train = Md_utils.md_concat([df_slots[i] for i in range(8,39)],fidx = [0,1,2,3,4])\n",
    "\n",
    "meta_test = Md_utils.md_concat([df_slots[i] for i in range(5)],fidx = [0,1,2,3,4])\n",
    "\n",
    "train_dataloader = meta_train.to_dataloader(train=True, batch_size=batch_size, num_workers=0)\n",
    "test_dataloader = meta_test.to_dataloader(train=False, batch_size=batch_size, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "66761.04541015625\n",
      "42185.833333333336\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "66193.08129882812\n",
      "41444.671875\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "65606.30029296875\n",
      "40696.908854166664\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "65151.26513671875\n",
      "39952.2421875\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "64470.614013671875\n",
      "39148.011067708336\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "63942.088623046875\n",
      "38271.747395833336\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "63314.432373046875\n",
      "37435.427734375\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "62752.94775390625\n",
      "36526.688151041664\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "62266.019287109375\n",
      "35755.177734375\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "61470.832763671875\n",
      "34859.613932291664\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "60958.57958984375\n",
      "34013.835286458336\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "60460.94873046875\n",
      "33192.184244791664\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "59777.9638671875\n",
      "32414.892578125\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "59223.9619140625\n",
      "31800.424479166668\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "58968.5703125\n",
      "31174.654947916668\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "58433.78076171875\n",
      "30634.694661458332\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "57982.621826171875\n",
      "30037.007161458332\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "57774.82177734375\n",
      "29661.958984375\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "57533.929443359375\n",
      "29208.615234375\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "57044.5537109375\n",
      "28990.745768229168\n",
      "Epoch 21\n",
      "-------------------------------\n",
      "56885.9423828125\n",
      "28627.572916666668\n",
      "Epoch 22\n",
      "-------------------------------\n",
      "56704.804931640625\n",
      "28403.664713541668\n",
      "Epoch 23\n",
      "-------------------------------\n",
      "56446.63232421875\n",
      "28045.2421875\n",
      "Epoch 24\n",
      "-------------------------------\n",
      "56347.0166015625\n",
      "27998.118489583332\n",
      "Epoch 25\n",
      "-------------------------------\n",
      "56299.794677734375\n",
      "27920.304361979168\n",
      "Epoch 26\n",
      "-------------------------------\n",
      "56180.493896484375\n",
      "27724.910481770832\n",
      "Epoch 27\n",
      "-------------------------------\n",
      "56001.784423828125\n",
      "27681.648763020832\n",
      "Epoch 28\n",
      "-------------------------------\n",
      "55973.352294921875\n",
      "27494.736653645832\n",
      "Epoch 29\n",
      "-------------------------------\n",
      "55842.312255859375\n",
      "27477.6875\n",
      "Epoch 30\n",
      "-------------------------------\n",
      "55814.57861328125\n",
      "27278.1884765625\n",
      "Epoch 31\n",
      "-------------------------------\n",
      "55861.62255859375\n",
      "27394.839192708332\n",
      "Epoch 32\n",
      "-------------------------------\n",
      "55634.51171875\n",
      "27249.0693359375\n",
      "Epoch 33\n",
      "-------------------------------\n",
      "55563.360107421875\n",
      "27178.145182291668\n",
      "Epoch 34\n",
      "-------------------------------\n",
      "55579.545166015625\n",
      "27397.038411458332\n",
      "Epoch 35\n",
      "-------------------------------\n",
      "55574.596923828125\n",
      "27037.930989583332\n",
      "Epoch 36\n",
      "-------------------------------\n",
      "55407.951171875\n",
      "27151.765950520832\n",
      "Epoch 37\n",
      "-------------------------------\n",
      "55503.94677734375\n",
      "27193.185546875\n",
      "Epoch 38\n",
      "-------------------------------\n",
      "55469.78662109375\n",
      "26947.3740234375\n",
      "Epoch 39\n",
      "-------------------------------\n",
      "55487.885986328125\n",
      "27057.381184895832\n",
      "Epoch 40\n",
      "-------------------------------\n",
      "55343.55908203125\n",
      "26955.795247395832\n",
      "Epoch 41\n",
      "-------------------------------\n",
      "55414.39111328125\n",
      "26929.7705078125\n",
      "Epoch 42\n",
      "-------------------------------\n",
      "55270.776611328125\n",
      "26969.622395833332\n",
      "Epoch 43\n",
      "-------------------------------\n",
      "55284.38232421875\n",
      "26934.680013020832\n",
      "Epoch 44\n",
      "-------------------------------\n",
      "55486.85107421875\n",
      "26973.6962890625\n",
      "Epoch 45\n",
      "-------------------------------\n",
      "55460.0771484375\n",
      "26932.790364583332\n",
      "Epoch 46\n",
      "-------------------------------\n",
      "55224.187255859375\n",
      "26889.965169270832\n",
      "Epoch 47\n",
      "-------------------------------\n",
      "55230.830078125\n",
      "26822.753580729168\n",
      "Epoch 48\n",
      "-------------------------------\n",
      "55308.805419921875\n",
      "26751.2021484375\n",
      "Epoch 49\n",
      "-------------------------------\n",
      "55241.50048828125\n",
      "26775.394856770832\n",
      "Epoch 50\n",
      "-------------------------------\n",
      "55333.86767578125\n",
      "26664.798177083332\n",
      "Done!\n",
      "26864.4638671875\n"
     ]
    }
   ],
   "source": [
    "## metacomb example\n",
    "preds = []\n",
    "n_features = meta_train.Z.shape[1]\n",
    "_, n_forecasters, horizon  = meta_train.B.shape\n",
    "window_x = meta_train.X.shape[2]\n",
    "\n",
    "n_known_features = len(meta_train.known_features)\n",
    "Use_z = True\n",
    "\n",
    "model = MetaNN.MetaComb(n_features= n_features, n_forecasters=n_forecasters,window_x=window_x,Use_z= Use_z,n_known_features= n_known_features, horizon=horizon).to(device)\n",
    "loss_fn = torch.nn.MSELoss()\n",
    "#optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "optimizer = torch.optim.Adam(model.parameters(),  lr=learning_rate)\n",
    "epochs = 50\n",
    "meta_learning = meta_learning_run(model,loss_fn, optimizer, train_dataloader,test_dataloader, device, epochs)\n",
    "loss, pred = meta_learning.forecast(test_dataloader)\n",
    "preds.append(np.expand_dims(pred.cpu().numpy(),1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "1.6137756630778313\n",
      "1.6130115985870361\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "1.6109770312905312\n",
      "1.6098813613255818\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "1.6078073307871819\n",
      "1.605297843615214\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "1.6047900393605232\n",
      "1.6010055144627888\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "1.6019626408815384\n",
      "1.5962287187576294\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "1.5984884798526764\n",
      "1.5923510789871216\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "1.5948734506964684\n",
      "1.587559660275777\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "1.5907770618796349\n",
      "1.580918550491333\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "1.5863177627325058\n",
      "1.5746070941289265\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "1.5818346589803696\n",
      "1.5685499906539917\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "1.5765976756811142\n",
      "1.5610446532567341\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "1.5715369209647179\n",
      "1.5534095764160156\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "1.565579205751419\n",
      "1.5445533593495686\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "1.5618483126163483\n",
      "1.5384893417358398\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "1.5562094077467918\n",
      "1.5323622226715088\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "1.5515350997447968\n",
      "1.5254964033762615\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "1.5472541376948357\n",
      "1.5168148676554363\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "1.5427341535687447\n",
      "1.5138463179270427\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "1.5379827618598938\n",
      "1.5099724928538005\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "1.536026917397976\n",
      "1.5068633556365967\n",
      "Epoch 21\n",
      "-------------------------------\n",
      "1.532316006720066\n",
      "1.4975907405217488\n",
      "Epoch 22\n",
      "-------------------------------\n",
      "1.5328744649887085\n",
      "1.5014577706654866\n",
      "Epoch 23\n",
      "-------------------------------\n",
      "1.5298220738768578\n",
      "1.4956855773925781\n",
      "Epoch 24\n",
      "-------------------------------\n",
      "1.5289172977209091\n",
      "1.4933674335479736\n",
      "Epoch 25\n",
      "-------------------------------\n",
      "1.528379887342453\n",
      "1.4947103261947632\n",
      "Epoch 26\n",
      "-------------------------------\n",
      "1.5260971188545227\n",
      "1.492754062016805\n",
      "Epoch 27\n",
      "-------------------------------\n",
      "1.5255178287625313\n",
      "1.4866021474202473\n",
      "Epoch 28\n",
      "-------------------------------\n",
      "1.524721771478653\n",
      "1.4881588220596313\n",
      "Epoch 29\n",
      "-------------------------------\n",
      "1.5242623016238213\n",
      "1.485935926437378\n",
      "Epoch 30\n",
      "-------------------------------\n",
      "1.5236234813928604\n",
      "1.4873640934626262\n",
      "Epoch 31\n",
      "-------------------------------\n",
      "1.5251269787549973\n",
      "1.4856490294138591\n",
      "Epoch 32\n",
      "-------------------------------\n",
      "1.5227946862578392\n",
      "1.4892613490422566\n",
      "Epoch 33\n",
      "-------------------------------\n",
      "1.5238739773631096\n",
      "1.487329085667928\n",
      "Epoch 34\n",
      "-------------------------------\n",
      "1.523165374994278\n",
      "1.487301190694173\n",
      "Epoch 35\n",
      "-------------------------------\n",
      "1.52138140052557\n",
      "1.487549106280009\n",
      "Epoch 36\n",
      "-------------------------------\n",
      "1.5211940631270409\n",
      "1.489182670911153\n",
      "Epoch 37\n",
      "-------------------------------\n",
      "1.5221358463168144\n",
      "1.4885963201522827\n",
      "Epoch 38\n",
      "-------------------------------\n",
      "1.523238942027092\n",
      "1.4879355827967327\n",
      "Epoch 39\n",
      "-------------------------------\n",
      "1.5198149681091309\n",
      "1.4832332531611125\n",
      "Epoch 40\n",
      "-------------------------------\n",
      "1.5202662870287895\n",
      "1.483527660369873\n",
      "Epoch 41\n",
      "-------------------------------\n",
      "1.5218696594238281\n",
      "1.4802089134852092\n",
      "Epoch 42\n",
      "-------------------------------\n",
      "1.5196630358695984\n",
      "1.4805810848871868\n",
      "Epoch 43\n",
      "-------------------------------\n",
      "1.5187030360102654\n",
      "1.4826475381851196\n",
      "Epoch 44\n",
      "-------------------------------\n",
      "1.518724001944065\n",
      "1.480159838994344\n",
      "Epoch 45\n",
      "-------------------------------\n",
      "1.5202836394309998\n",
      "1.4814730485280354\n",
      "Epoch 46\n",
      "-------------------------------\n",
      "1.5180959850549698\n",
      "1.4849557081858318\n",
      "Epoch 47\n",
      "-------------------------------\n",
      "1.5183368176221848\n",
      "1.4800628423690796\n",
      "Epoch 48\n",
      "-------------------------------\n",
      "1.5185129791498184\n",
      "1.481791337331136\n",
      "Epoch 49\n",
      "-------------------------------\n",
      "1.5193657279014587\n",
      "1.4799086650212605\n",
      "Epoch 50\n",
      "-------------------------------\n",
      "1.5178039446473122\n",
      "1.4757947127024333\n",
      "Done!\n",
      "28873.762044270832\n"
     ]
    }
   ],
   "source": [
    "## metaselection example\n",
    "n_features = meta_train.Z.shape[1]\n",
    "_, n_forecasters, horizon  = meta_train.B.shape\n",
    "window_x = meta_train.X.shape[2]\n",
    "\n",
    "model = MetaNN.MetaSelection(n_features= n_features, n_forecasters=n_forecasters,window_x=window_x, Use_z= Use_z,n_known_features=n_known_features,horizon=horizon).to(device)\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "#optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "optimizer = torch.optim.Adam(model.parameters(),  lr=learning_rate)\n",
    "epochs = 50\n",
    "meta_learning = meta_learning_run(model,loss_fn, optimizer, train_dataloader,test_dataloader, device, epochs)\n",
    "loss, pred = meta_learning.forecast(test_dataloader)\n",
    "preds.append(np.expand_dims(pred.cpu().numpy(),1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "13918974464.0\n",
      "7799354880.0\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "13917690560.0\n",
      "7799352661.333333\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "13848876928.0\n",
      "7799349760.0\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "13861092224.0\n",
      "7799347029.333333\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "13880778816.0\n",
      "7799344810.666667\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "13945496256.0\n",
      "7799341568.0\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "13892759488.0\n",
      "7799337984.0\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "13875955904.0\n",
      "7799333546.666667\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "13866547968.0\n",
      "7799328426.666667\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "13857211200.0\n",
      "7799321941.333333\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "13803114304.0\n",
      "7799312725.333333\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "13891948736.0\n",
      "7799301802.666667\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "13870959296.0\n",
      "7799289344.0\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "13847398336.0\n",
      "7799277738.666667\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "13841006400.0\n",
      "7799263061.333333\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "13865722496.0\n",
      "7799246848.0\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "13808687808.0\n",
      "7799229952.0\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "13833910720.0\n",
      "7799211008.0\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "13856968704.0\n",
      "7799192234.666667\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "13857938560.0\n",
      "7799169536.0\n",
      "Epoch 21\n",
      "-------------------------------\n",
      "13843732544.0\n",
      "7799146154.666667\n",
      "Epoch 22\n",
      "-------------------------------\n",
      "13812503744.0\n",
      "7799119701.333333\n",
      "Epoch 23\n",
      "-------------------------------\n",
      "13883061120.0\n",
      "7799096490.666667\n",
      "Epoch 24\n",
      "-------------------------------\n",
      "13858643968.0\n",
      "7799067818.666667\n",
      "Epoch 25\n",
      "-------------------------------\n",
      "13887769792.0\n",
      "7799036074.666667\n",
      "Epoch 26\n",
      "-------------------------------\n",
      "13873843328.0\n",
      "7799006378.666667\n",
      "Epoch 27\n",
      "-------------------------------\n",
      "13804447936.0\n",
      "7798964906.666667\n",
      "Epoch 28\n",
      "-------------------------------\n",
      "13817363328.0\n",
      "7798936064.0\n",
      "Epoch 29\n",
      "-------------------------------\n",
      "13839445248.0\n",
      "7798894762.666667\n",
      "Epoch 30\n",
      "-------------------------------\n",
      "13873006976.0\n",
      "7798857898.666667\n",
      "Epoch 31\n",
      "-------------------------------\n",
      "13910039424.0\n",
      "7798817280.0\n",
      "Epoch 32\n",
      "-------------------------------\n",
      "13834604416.0\n",
      "7798764885.333333\n",
      "Epoch 33\n",
      "-------------------------------\n",
      "13831530880.0\n",
      "7798717098.666667\n",
      "Epoch 34\n",
      "-------------------------------\n",
      "13856837824.0\n",
      "7798665728.0\n",
      "Epoch 35\n",
      "-------------------------------\n",
      "13881079680.0\n",
      "7798612138.666667\n",
      "Epoch 36\n",
      "-------------------------------\n",
      "13752117952.0\n",
      "7798574592.0\n",
      "Epoch 37\n",
      "-------------------------------\n",
      "13831988544.0\n",
      "7798496085.333333\n",
      "Epoch 38\n",
      "-------------------------------\n",
      "13813236544.0\n",
      "7798445909.333333\n",
      "Epoch 39\n",
      "-------------------------------\n",
      "13827372736.0\n",
      "7798380544.0\n",
      "Epoch 40\n",
      "-------------------------------\n",
      "13855794944.0\n",
      "7798313472.0\n",
      "Epoch 41\n",
      "-------------------------------\n",
      "13857926464.0\n",
      "7798245034.666667\n",
      "Epoch 42\n",
      "-------------------------------\n",
      "13855372480.0\n",
      "7798172842.666667\n",
      "Epoch 43\n",
      "-------------------------------\n",
      "13877501696.0\n",
      "7798104576.0\n",
      "Epoch 44\n",
      "-------------------------------\n",
      "13884245056.0\n",
      "7798019413.333333\n",
      "Epoch 45\n",
      "-------------------------------\n",
      "13908081280.0\n",
      "7797947221.333333\n",
      "Epoch 46\n",
      "-------------------------------\n",
      "13882423296.0\n",
      "7797840896.0\n",
      "Epoch 47\n",
      "-------------------------------\n",
      "13890225856.0\n",
      "7797732352.0\n",
      "Epoch 48\n",
      "-------------------------------\n",
      "13952055104.0\n",
      "7797673642.666667\n",
      "Epoch 49\n",
      "-------------------------------\n",
      "13845684672.0\n",
      "7797576362.666667\n",
      "Epoch 50\n",
      "-------------------------------\n",
      "13882660928.0\n",
      "7797483008.0\n",
      "Done!\n",
      "44147.97265625\n"
     ]
    }
   ],
   "source": [
    "## metalossn example\n",
    "n_features = meta_train.Z.shape[1]\n",
    "_, n_forecasters, horizon  = meta_train.B.shape\n",
    "window_x = meta_train.X.shape[2]\n",
    "\n",
    "model = MetaNN.MetaLoss(n_features= n_features, n_forecasters=n_forecasters,window_x=window_x, Use_z= Use_z,n_known_features= n_known_features,horizon=horizon).to(device)\n",
    "loss_fn = torch.nn.MSELoss()\n",
    "#optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "optimizer = torch.optim.Adam(model.parameters(),  lr=learning_rate)\n",
    "epochs = 50\n",
    "meta_learning = meta_learning_run(model,loss_fn, optimizer, train_dataloader,test_dataloader, device, epochs)\n",
    "loss, pred = meta_learning.forecast(test_dataloader)\n",
    "preds.append(np.expand_dims(pred.cpu().numpy(),1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MAE</th>\n",
       "      <th>MSE</th>\n",
       "      <th>sMAPE1</th>\n",
       "      <th>sMAPE2</th>\n",
       "      <th>RMSSE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>SimpleExpSmoothing</th>\n",
       "      <td>279.805108</td>\n",
       "      <td>113379.111133</td>\n",
       "      <td>0.401223</td>\n",
       "      <td>0.384955</td>\n",
       "      <td>1.149770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ExponentialSmoothing</th>\n",
       "      <td>283.127890</td>\n",
       "      <td>115406.332574</td>\n",
       "      <td>0.410289</td>\n",
       "      <td>0.393319</td>\n",
       "      <td>1.159131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lightgbm_direct</th>\n",
       "      <td>129.561539</td>\n",
       "      <td>28544.295530</td>\n",
       "      <td>0.179451</td>\n",
       "      <td>0.193225</td>\n",
       "      <td>0.567932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lightgbm_mimo</th>\n",
       "      <td>127.199703</td>\n",
       "      <td>27033.851736</td>\n",
       "      <td>0.181451</td>\n",
       "      <td>0.193018</td>\n",
       "      <td>0.559178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rf_mimo</th>\n",
       "      <td>137.996915</td>\n",
       "      <td>33158.710936</td>\n",
       "      <td>0.178129</td>\n",
       "      <td>0.196899</td>\n",
       "      <td>0.631642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>meta_comb</th>\n",
       "      <td>123.118840</td>\n",
       "      <td>25262.495127</td>\n",
       "      <td>0.170102</td>\n",
       "      <td>0.185577</td>\n",
       "      <td>0.538353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>meta_select</th>\n",
       "      <td>127.199703</td>\n",
       "      <td>27033.851649</td>\n",
       "      <td>0.181451</td>\n",
       "      <td>0.193018</td>\n",
       "      <td>0.559178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>meta_loss</th>\n",
       "      <td>165.998662</td>\n",
       "      <td>43014.574643</td>\n",
       "      <td>0.228979</td>\n",
       "      <td>0.238942</td>\n",
       "      <td>0.717454</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             MAE            MSE    sMAPE1    sMAPE2     RMSSE\n",
       "SimpleExpSmoothing    279.805108  113379.111133  0.401223  0.384955  1.149770\n",
       "ExponentialSmoothing  283.127890  115406.332574  0.410289  0.393319  1.159131\n",
       "lightgbm_direct       129.561539   28544.295530  0.179451  0.193225  0.567932\n",
       "lightgbm_mimo         127.199703   27033.851736  0.181451  0.193018  0.559178\n",
       "rf_mimo               137.996915   33158.710936  0.178129  0.196899  0.631642\n",
       "meta_comb             123.118840   25262.495127  0.170102  0.185577  0.538353\n",
       "meta_select           127.199703   27033.851649  0.181451  0.193018  0.559178\n",
       "meta_loss             165.998662   43014.574643  0.228979  0.238942  0.717454"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(meta_test.evaluate(np.concatenate(preds,1),utils.metrics),index= meta_test.forecasters + ['meta_comb','meta_select','meta_loss'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.11 ('pytorch')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ff6d4ce17eceee6fd1b58d61a6b43b34ae60da1a017957f957ae9fdd770bd0de"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
